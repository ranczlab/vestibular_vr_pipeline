{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import mode\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.signal import correlate\n",
    "import json\n",
    "%config Completer.use_jedi = False  # Fixes autocomplete issues\n",
    "%config InlineBackend.figure_format = 'retina'  # Improves plot resolution\n",
    "\n",
    "import gc # garbage collector for removing large variables from memory instantly \n",
    "import importlib #for force updating changed packages \n",
    "\n",
    "#import harp\n",
    "import harp_resources.process\n",
    "import harp_resources.utils\n",
    "from harp_resources import process, utils # Reassign to maintain direct references for force updating \n",
    "#from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_resampled_rate = 1000 #in Hz\n",
    "event_name = \"Apply halt: 2s\" #event to align data to, can make into list in the future?\n",
    "\n",
    "#PATH TO Cohort 1 visual mismatch THIS\n",
    "rawdata_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day3/B6J2717-2024-12-10T12-17-03')\n",
    "data_path = rawdata_path.parent / f\"{rawdata_path.name}_processedData/downsampled_data\"\n",
    "save_path = rawdata_path.parent / f\"{rawdata_path.name}_processedData\"\n",
    "session_name = \"_\".join(data_path.parts[-2:])\n",
    "\n",
    "\n",
    "photometry_tracking_encoder_data = pd.read_parquet(data_path / \"photometry_tracking_encoder_data.parquet\", engine=\"pyarrow\")\n",
    "camera_photodiode_data = pd.read_parquet(data_path / \"camera_photodiode_data.parquet\", engine=\"pyarrow\")\n",
    "experiment_events = pd.read_parquet(data_path / \"experiment_events.parquet\", engine=\"pyarrow\")\n",
    "photometry_info = pd.read_parquet(data_path / \"photometry_info.parquet\", engine=\"pyarrow\")\n",
    "session_settings = pd.read_parquet(data_path / \"session_settings.parquet\", engine=\"pyarrow\")\n",
    "session_settings[\"metadata\"] = session_settings[\"metadata\"].apply(process.safe_from_json)\n",
    "\n",
    "print(f\"âœ… Finished loading all parquet files\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------\n",
    "# PLOT FIGURE to ascertain everything is well loaded\n",
    "#---------------------------------------------------\n",
    "\n",
    "df_to_analyze = photometry_tracking_encoder_data[\"Photodiode_int\"] #using downsampled values in common time grid \n",
    "#df_to_analyze = camera_photodiode_data[\"Photodiode\"] #use async raw values if needed for troubleshooting, but the nearest indices needs to be found , see couple of lines below\n",
    "photodiode_halts, photodiode_delay_min, photodiode_delay_avg, photodiode_delay_max = process.analyze_photodiode(df_to_analyze, experiment_events, event_name, plot = True)\n",
    "# nearest_indices = photometry_tracking_encoder_data.index.get_indexer(photodiode_halts, method='nearest')\n",
    "# photodiode_halts = photometry_tracking_encoder_data.index[nearest_indices]\n",
    "process.plot_figure_1(photometry_tracking_encoder_data, session_name, save_path, common_resampled_rate, photodiode_halts, save_figure = False, show_figure = True, downsample_factor=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reload the modules\n",
    "importlib.reload(harp_resources.process)\n",
    "importlib.reload(harp_resources.utils)\n",
    "# Reassign after reloading to ensure updated references\n",
    "process = harp_resources.process\n",
    "utils = harp_resources.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------\n",
    "# Get Block times and durations\n",
    "#-----------------------------------------\n",
    "\n",
    "block_events = experiment_events[\n",
    "    experiment_events[\"Event\"].str.contains(\"block started|Block timer elapsed\", case=False, na=False)\n",
    "].copy()  # Use .copy() to avoid SettingWithCopyWarning\n",
    "block_events[\"Time Difference\"] = block_events.index.to_series().diff().dt.total_seconds()\n",
    "block_events = block_events.drop(columns=['Seconds'])\n",
    "\n",
    "# Print results\n",
    "print(block_events)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT - get event triggered averages of all relevant data and reproduce figure below \n",
    "**THIS IS NOT WORKING, SUGGEST 1. downsample photodiode signal and well and save togerther with dataset.**\n",
    "\n",
    "NEXT - think about / run some correlation analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Don't calculate velocity, but use Motor_Velocity column \n",
    "### add baselining to all data before new plot \n",
    "### quantify peak fluorescnce \n",
    "### quantify motor velocity vs animal velocity correlation - is there a lag?\n",
    "### LOOK INTO THE superbig filtering in the velocity and ACC calculations (looks like it's 1 Hz???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define time window variables\n",
    "time_window_start = -2  # Modify this to change the start time\n",
    "time_window_end = 6  # Modify this to change the end time\n",
    "\n",
    "# Create an empty DataFrame to store aligned data\n",
    "aligned_data = []\n",
    "\n",
    "# Loop through each halt event time\n",
    "for halt_time in photodiode_halts:\n",
    "    # Extract data within the selected time window\n",
    "    window_data = photometry_tracking_encoder_data.loc[\n",
    "        (photometry_tracking_encoder_data.index >= halt_time + pd.Timedelta(seconds=time_window_start)) &\n",
    "        (photometry_tracking_encoder_data.index <= halt_time + pd.Timedelta(seconds=time_window_end))\n",
    "    ].copy()\n",
    "\n",
    "    # Compute time relative to halt\n",
    "    window_data[\"Time (s)\"] = (window_data.index - halt_time).total_seconds()\n",
    "    \n",
    "    # Add event identifier\n",
    "    window_data[\"Halt Time\"] = halt_time\n",
    "\n",
    "    # Store aligned data\n",
    "    aligned_data.append(window_data)\n",
    "\n",
    "# Concatenate all windows\n",
    "aligned_df = pd.concat(aligned_data, ignore_index=True)\n",
    "\n",
    "# Unwrap the Encoder signal to remove discontinuities\n",
    "aligned_df[\"Unwrapped_Encoder\"] = np.unwrap(np.deg2rad(aligned_df[\"Encoder\"]))  \n",
    "aligned_df[\"Unwrapped_Encoder\"] = np.rad2deg(aligned_df[\"Unwrapped_Encoder\"])  \n",
    "\n",
    "# Compute motor velocity (derivative of unwrapped encoder)\n",
    "aligned_df[\"Motor_Velocity\"] = aligned_df[\"Unwrapped_Encoder\"].diff() / aligned_df[\"Time (s)\"].diff()\n",
    "\n",
    "# Apply a 100 Hz low-pass Butterworth filter to smooth motor velocity\n",
    "fs = 1000  \n",
    "cutoff = 100  \n",
    "b, a = signal.butter(2, cutoff / (fs / 2), btype='low', analog=False)\n",
    "aligned_df[\"Motor_Velocity_Smoothed\"] = signal.filtfilt(b, a, aligned_df[\"Motor_Velocity\"].fillna(0))\n",
    "\n",
    "# Compute velocity from Position_0X and Position_0Y, and scale Velocity_0X\n",
    "aligned_df[\"Velocity_0X\"] = aligned_df[\"Position_0X\"].diff() / aligned_df[\"Time (s)\"].diff() / 1000  \n",
    "aligned_df[\"Velocity_0Y\"] = aligned_df[\"Position_0Y\"].diff() / aligned_df[\"Time (s)\"].diff()\n",
    "\n",
    "# Compute mean and standard error of the mean (SEM)\n",
    "mean_df = aligned_df.groupby(\"Time (s)\").mean()\n",
    "sem_df = aligned_df.groupby(\"Time (s)\").sem()  \n",
    "\n",
    "# Create figure for the two plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True)\n",
    "\n",
    "### PLOT 1: Individual Traces - Photodiode, z_470, z_560 ###\n",
    "ax1 = axes[0]\n",
    "\n",
    "for halt_time in photodiode_halts:\n",
    "    subset = aligned_df[aligned_df[\"Halt Time\"] == halt_time]\n",
    "    ax1.plot(subset[\"Time (s)\"], subset[\"Photodiode_int\"], color='grey', alpha=0.5)\n",
    "\n",
    "ax1.set_xlabel('Time (s) relative to halt')\n",
    "ax1.set_ylabel('Photodiode_int')\n",
    "ax1.set_title('Photodiode, z_470, and z_560')\n",
    "\n",
    "ax1_2 = ax1.twinx()\n",
    "for halt_time in photodiode_halts:\n",
    "    subset = aligned_df[aligned_df[\"Halt Time\"] == halt_time]\n",
    "    ax1_2.plot(subset[\"Time (s)\"], subset[\"z_470\"], color='green', linestyle='-', alpha=0.5)\n",
    "    ax1_2.plot(subset[\"Time (s)\"], subset[\"z_560\"], color='red', linestyle='-', alpha=0.5)\n",
    "\n",
    "ax1_2.set_ylabel('Fluorescence (z_470: Green, z_560: Red)')\n",
    "\n",
    "### PLOT 2: Mean & SEM of All Signals ###\n",
    "ax2 = axes[1]\n",
    "\n",
    "ax2.plot(mean_df.index, mean_df[\"Photodiode_int\"], color='grey', alpha=0.8)\n",
    "ax2.fill_between(mean_df.index, mean_df[\"Photodiode_int\"] - sem_df[\"Photodiode_int\"], \n",
    "                 mean_df[\"Photodiode_int\"] + sem_df[\"Photodiode_int\"], color='grey', alpha=0.2)\n",
    "\n",
    "ax2.set_xlabel('Time (s) relative to halt')\n",
    "ax2.set_ylabel('Photodiode_int')\n",
    "ax2.set_title('Mean & SEM of All Signals')\n",
    "\n",
    "ax2_2 = ax2.twinx()\n",
    "ax2_2.plot(mean_df.index, mean_df[\"z_470\"], color='green', linestyle='-', alpha=0.8)\n",
    "ax2_2.fill_between(mean_df.index, mean_df[\"z_470\"] - sem_df[\"z_470\"], \n",
    "                    mean_df[\"z_470\"] + sem_df[\"z_470\"], color='green', alpha=0.2)\n",
    "\n",
    "ax2_2.plot(mean_df.index, mean_df[\"z_560\"], color='red', linestyle='-', alpha=0.8)\n",
    "ax2_2.fill_between(mean_df.index, mean_df[\"z_560\"] - sem_df[\"z_560\"], \n",
    "                    mean_df[\"z_560\"] + sem_df[\"z_560\"], color='red', alpha=0.2)\n",
    "\n",
    "ax2_3 = ax2.twinx()\n",
    "ax2_3.spines['right'].set_position(('outward', 50))  \n",
    "ax2_3.plot(mean_df.index, mean_df[\"Motor_Velocity_Smoothed\"], color='#00008B', linestyle='-', alpha=0.8)\n",
    "ax2_3.fill_between(mean_df.index, mean_df[\"Motor_Velocity_Smoothed\"] - sem_df[\"Motor_Velocity_Smoothed\"], \n",
    "                    mean_df[\"Motor_Velocity_Smoothed\"] + sem_df[\"Motor_Velocity_Smoothed\"], color='#00008B', alpha=0.2)\n",
    "\n",
    "ax2_3.set_ylabel('Motor Velocity (Dark Blue)')\n",
    "\n",
    "ax2_4 = ax2.twinx()\n",
    "ax2_4.spines['right'].set_position(('outward', 100))  \n",
    "ax2_4.plot(mean_df.index, mean_df[\"Velocity_0X\"], color='orange', linestyle='-', alpha=0.8)\n",
    "ax2_4.fill_between(mean_df.index, mean_df[\"Velocity_0X\"] - sem_df[\"Velocity_0X\"], \n",
    "                    mean_df[\"Velocity_0X\"] + sem_df[\"Velocity_0X\"], color='orange', alpha=0.2)\n",
    "\n",
    "ax2_4.set_ylabel('Velocity_0X (Orange) (scaled x1000)')\n",
    "\n",
    "ax2_5 = ax2.twinx()\n",
    "ax2_5.spines['right'].set_position(('outward', 150))  \n",
    "ax2_5.plot(mean_df.index, mean_df[\"Velocity_0Y\"], color='#ADD8E6', linestyle='-', alpha=0.8)\n",
    "ax2_5.fill_between(mean_df.index, mean_df[\"Velocity_0Y\"] - sem_df[\"Velocity_0Y\"], \n",
    "                    mean_df[\"Velocity_0Y\"] + sem_df[\"Velocity_0Y\"], color='#ADD8E6', alpha=0.2)\n",
    "\n",
    "ax2_5.set_ylabel('Velocity_0Y (Light Blue)')\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pympler_memory_df = utils.get_pympler_memory_usage(top_n=10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
