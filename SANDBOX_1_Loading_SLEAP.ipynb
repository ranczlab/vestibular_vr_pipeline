{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import gc\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import LogNorm\n",
    "from fastkde.fastKDE import fastKDE\n",
    "from scipy.stats import linregress\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp\n",
    "import aeon.io.api as api\n",
    "\n",
    "\n",
    "# symbols to use ✅ ℹ️ ⚠️ ❗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# set up variables and load data \n",
    "############################################################################################################\n",
    "\n",
    "plot_timeseries = False\n",
    "score_cutoff = 0.2 # for checking prediction accuracy\n",
    "outlier_sd_threshold = 10 # for removing outliers from the data\n",
    "\n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day3/B6J2717-2024-12-10T12-17-03')\n",
    "save_path = data_path.parent / f\"{data_path.name}_processedData\"\n",
    "\n",
    "print (\"\\n❗ ❗ ❗ if SleapData.csv was already saved in the VideoData folder, this will break. Delete the file if you want to rerun processing\\n\")\n",
    "VideoData1, VideoData2, VideoData1_Has_Sleap, VideoData2_Has_Sleap = lp.load_videography_data(data_path)\n",
    "VideoData1 = VideoData1.drop(columns=['track']) # drop the track column as it is empty\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "coordinates_dict=lp.get_coordinates_dict(VideoData1, columns_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "VideoData1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# plot timeseries of coordinates in borwser \n",
    "############################################################################################################\n",
    "if plot_timeseries:\n",
    "    print(f'⚠️ Check for long discontinouties and outsiders in the data, we will try to deal with them later')\n",
    "    print(f'ℹ️ Figure opens in browser window, takes a bit of time.')\n",
    "    fig = make_subplots(\n",
    "        rows=4, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.05,\n",
    "        subplot_titles=(\n",
    "            \"X coordinates for pupil centre add left-right eye corner\",\n",
    "            \"Y coordinates for pupil centre add left-right eye corner\",\n",
    "            \"X coordinates for iris points\",\n",
    "            \"Y coordinates for iris points\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Row 1: Plot left.x, center.x, right.x\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['left.x'], mode='lines', name='left.x'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['center.x'], mode='lines', name='center.x'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['right.x'], mode='lines', name='right.x'), row=1, col=1)\n",
    "\n",
    "    # Row 2: Plot left.y, center.y, right.y\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['left.y'], mode='lines', name='left.y'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['center.y'], mode='lines', name='center.y'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['right.y'], mode='lines', name='right.y'), row=2, col=1)\n",
    "\n",
    "    # Row 3: Plot p.x coordinates for p1 to p8\n",
    "    for col in ['p1.x', 'p2.x', 'p3.x', 'p4.x', 'p5.x', 'p6.x', 'p7.x', 'p8.x']:\n",
    "        fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=3, col=1)\n",
    "\n",
    "    # Row 4: Plot p.y coordinates for p1 to p8\n",
    "    for col in ['p1.y', 'p2.y', 'p3.y', 'p4.y', 'p5.y', 'p6.y', 'p7.y', 'p8.y']:\n",
    "        fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=4, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=1200,\n",
    "        title_text=\"Time series subplots for coordinates\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "    fig.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "\n",
    "# Filter out NaN values and calculate the min and max values for X and Y coordinates\n",
    "x_min = min([coordinates_dict[f'{col}.x'][~np.isnan(coordinates_dict[f'{col}.x'])].min() for col in columns_of_interest])\n",
    "x_max = max([coordinates_dict[f'{col}.x'][~np.isnan(coordinates_dict[f'{col}.x'])].max() for col in columns_of_interest])\n",
    "y_min = min([coordinates_dict[f'{col}.y'][~np.isnan(coordinates_dict[f'{col}.y'])].min() for col in columns_of_interest])\n",
    "y_max = max([coordinates_dict[f'{col}.y'][~np.isnan(coordinates_dict[f'{col}.y'])].max() for col in columns_of_interest])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "\n",
    "# Plot left, right, and center in the first plot\n",
    "ax[0].set_title('left, right, center')\n",
    "ax[0].scatter(coordinates_dict['left.x'], coordinates_dict['left.y'], color='black', label='left', s=10)\n",
    "ax[0].scatter(coordinates_dict['right.x'], coordinates_dict['right.y'], color='grey', label='right', s=10)\n",
    "ax[0].scatter(coordinates_dict['center.x'], coordinates_dict['center.y'], color='red', label='center', s=10)\n",
    "ax[0].set_xlim([x_min, x_max])\n",
    "ax[0].set_ylim([y_min, y_max])\n",
    "ax[0].set_xlabel('x coordinates (pixels)')\n",
    "ax[0].set_ylabel('y coordinates (pixels)')\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "# Plot p1 to p8 in the second plot with different colors and smaller markers\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'orange']\n",
    "for idx, col in enumerate(columns_of_interest[3:]):\n",
    "    ax[1].scatter(coordinates_dict[f'{col}.x'], coordinates_dict[f'{col}.y'], color=colors[idx], label=col, s=5)\n",
    "\n",
    "ax[1].set_xlim([x_min, x_max])\n",
    "ax[1].set_ylim([y_min, y_max])\n",
    "ax[1].set_title('p1 to p8')\n",
    "ax[1].set_xlabel('x coordinates (pixels)')\n",
    "ax[1].set_ylabel('y coordinates (pixels)')\n",
    "ax[1].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# deal with frames where all points are NaN\n",
    "############################################################################################################\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "\n",
    "all_nan_df = VideoData1[VideoData1[columns_of_interest].isnull().all(1)]\n",
    "all_nan_index_array = all_nan_df.index.values\n",
    "\n",
    "# print the groups of sequential NaNs\n",
    "group_counts = {'1-5': 0, '6-10': 0, '>10': 0}\n",
    "i = 1\n",
    "for group in lp.find_sequential_groups(all_nan_index_array):\n",
    "    #print(f'NaN frame group {i} with {len(group)} elements')\n",
    "    if 1 <= len(group) <= 5:\n",
    "        group_counts['1-5'] += 1\n",
    "    elif 6 <= len(group) <= 10:\n",
    "        group_counts['6-10'] += 1\n",
    "    else:\n",
    "        group_counts['>10'] += 1\n",
    "        print(f'⚠️ Framegroup {i} has {len(group)} consecutive all NaN frames  with indices {group}. If this is a long group, consider checking the data.')\n",
    "    i += 1\n",
    "\n",
    "print(f\"Framegroups with 1-5 consecutive all NaN frames: {group_counts['1-5']}\")\n",
    "print(f\"Framegroups with 6-10 consecutive all NaN frames: {group_counts['6-10']}\")\n",
    "print(f\"Framegroups with >10 consecutive all NaN frames: {group_counts['>10']}\")\n",
    "\n",
    "############################################################################################################\n",
    "# check if we can use some filtering on scores to remove bad frames\n",
    "############################################################################################################\n",
    "\n",
    "score_cutoff = 0.2\n",
    "columns_of_interest = ['left.score','center.score','right.score','p1.score','p2.score','p3.score','p4.score','p5.score','p6.score','p7.score','p8.score']\n",
    "total_points = len(VideoData1)\n",
    "print(f'\\nℹ️ Number of frames and consequitve sequences below {score_cutoff} confidence score.')\n",
    "\n",
    "for col in columns_of_interest:\n",
    "    count_below_threshold = (VideoData1[col] < score_cutoff).sum()\n",
    "    percentage_below_threshold = (count_below_threshold / total_points) * 100\n",
    "    \n",
    "    # Find the longest consecutive series below threshold\n",
    "    below_threshold = VideoData1[col] < score_cutoff\n",
    "    longest_series = 0\n",
    "    current_series = 0\n",
    "    \n",
    "    for value in below_threshold:\n",
    "        if value:\n",
    "            current_series += 1\n",
    "            if current_series > longest_series:\n",
    "                longest_series = current_series\n",
    "        else:\n",
    "            current_series = 0\n",
    "    \n",
    "    print(f\"Column: {col} | Values below {score_cutoff}: {count_below_threshold} ({percentage_below_threshold:.2f}%) | Longest consecutive frame series: {longest_series}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### SLEAP processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# center coordinates on median pupil centre \n",
    "############################################################################################################\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "\n",
    "# Calculate the mean of the center x and y points\n",
    "mean_center_x = VideoData1['center.x'].median()\n",
    "mean_center_y = VideoData1['center.y'].median()\n",
    "\n",
    "print(f\"Mean center.x: {mean_center_x}, Mean center.y: {mean_center_y}\")\n",
    "\n",
    "# Translate the coordinates\n",
    "for col in columns_of_interest:\n",
    "    if '.x' in col:\n",
    "        VideoData1[col] = VideoData1[col] - mean_center_x\n",
    "    elif '.y' in col:\n",
    "        VideoData1[col] = VideoData1[col] - mean_center_y\n",
    "\n",
    "############################################################################################################\n",
    "# remove outliers (x times SD) and interpolate between the previous and subsequent non-NaN value\n",
    "############################################################################################################\n",
    "\n",
    "# Calculate the standard deviation for each column of interest\n",
    "std_devs = {col: VideoData1[col].std() for col in columns_of_interest}\n",
    "\n",
    "# Calculate the number of outliers for each column\n",
    "outliers = {col: ((VideoData1[col] - VideoData1[col].mean()).abs() > 10 * std_devs[col]).sum() for col in columns_of_interest}\n",
    "\n",
    "# Find the channel with the maximum number of outliers\n",
    "max_outliers_channel = max(outliers, key=outliers.get)\n",
    "max_outliers_count = outliers[max_outliers_channel]\n",
    "\n",
    "# Print the channel with the maximum number of outliers and the number\n",
    "print(f\"Channel with the maximum number of outliers: {max_outliers_channel}, Number of outliers: {max_outliers_count}\")\n",
    "\n",
    "# Print the total number of outliers\n",
    "total_outliers = sum(outliers.values())\n",
    "print(f\"A total number of {total_outliers} outliers will be replaced by interpolation\")\n",
    "\n",
    "# Replace outliers by interpolating between the previous and subsequent non-NaN value\n",
    "for col in columns_of_interest:\n",
    "    outlier_indices = VideoData1[((VideoData1[col] - VideoData1[col].mean()).abs() > outlier_sd_threshold * std_devs[col])].index\n",
    "    VideoData1.loc[outlier_indices, col] = np.nan\n",
    "\n",
    "#VideoData1.interpolate(inplace=True)\n",
    "VideoData1 = VideoData1.interpolate(method='linear', limit_direction='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# plot timeseries of coordinates in borwser \n",
    "############################################################################################################\n",
    "\n",
    "if plot_timeseries:\n",
    "    print(f'⚠️ Check for long discontinouties and outsiders in the data, we will try to deal with them later')\n",
    "    print(f'ℹ️ Figure opens in browser window, takes a bit of time.')\n",
    "    fig = make_subplots(\n",
    "        rows=4, cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.05,\n",
    "        subplot_titles=(\n",
    "            \"X coordinates for pupil centre add left-right eye corner\",\n",
    "            \"Y coordinates for pupil centre add left-right eye corner\",\n",
    "            \"X coordinates for iris points\",\n",
    "            \"Y coordinates for iris points\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Row 1: Plot left.x, center.x, right.x\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['left.x'], mode='lines', name='left.x'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['center.x'], mode='lines', name='center.x'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['right.x'], mode='lines', name='right.x'), row=1, col=1)\n",
    "\n",
    "    # Row 2: Plot left.y, center.y, right.y\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['left.y'], mode='lines', name='left.y'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['center.y'], mode='lines', name='center.y'), row=2, col=1)\n",
    "    fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['right.y'], mode='lines', name='right.y'), row=2, col=1)\n",
    "\n",
    "    # Row 3: Plot p.x coordinates for p1 to p8\n",
    "    for col in ['p1.x', 'p2.x', 'p3.x', 'p4.x', 'p5.x', 'p6.x', 'p7.x', 'p8.x']:\n",
    "        fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=3, col=1)\n",
    "\n",
    "    # Row 4: Plot p.y coordinates for p1 to p8\n",
    "    for col in ['p1.y', 'p2.y', 'p3.y', 'p4.y', 'p5.y', 'p6.y', 'p7.y', 'p8.y']:\n",
    "        fig.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=4, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=1200,\n",
    "        title_text=\"Time series subplots for coordinates\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    fig.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "    fig.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "    fig.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "coordinates_dict=lp.get_coordinates_dict(VideoData1, columns_of_interest)\n",
    "\n",
    "columns_of_interest = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "\n",
    "# Filter out NaN values and calculate the min and max values for X and Y coordinates\n",
    "x_min = min([coordinates_dict[f'{col}.x'][~np.isnan(coordinates_dict[f'{col}.x'])].min() for col in columns_of_interest])\n",
    "x_max = max([coordinates_dict[f'{col}.x'][~np.isnan(coordinates_dict[f'{col}.x'])].max() for col in columns_of_interest])\n",
    "y_min = min([coordinates_dict[f'{col}.y'][~np.isnan(coordinates_dict[f'{col}.y'])].min() for col in columns_of_interest])\n",
    "y_max = max([coordinates_dict[f'{col}.y'][~np.isnan(coordinates_dict[f'{col}.y'])].max() for col in columns_of_interest])\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "\n",
    "# Plot left, right, and center in the first plot\n",
    "ax[0].set_title('left, right, center')\n",
    "ax[0].scatter(coordinates_dict['left.x'], coordinates_dict['left.y'], color='black', label='left', s=10)\n",
    "ax[0].scatter(coordinates_dict['right.x'], coordinates_dict['right.y'], color='grey', label='right', s=10)\n",
    "ax[0].scatter(coordinates_dict['center.x'], coordinates_dict['center.y'], color='red', label='center', s=10)\n",
    "ax[0].set_xlim([x_min, x_max])\n",
    "ax[0].set_ylim([y_min, y_max])\n",
    "ax[0].set_xlabel('x coordinates (pixels)')\n",
    "ax[0].set_ylabel('y coordinates (pixels)')\n",
    "ax[0].legend(loc='upper right')\n",
    "\n",
    "# Plot p1 to p8 in the second plot with different colors and smaller markers\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'orange']\n",
    "for idx, col in enumerate(columns_of_interest[3:]):\n",
    "    ax[1].scatter(coordinates_dict[f'{col}.x'], coordinates_dict[f'{col}.y'], color=colors[idx], label=col, s=5)\n",
    "\n",
    "ax[1].set_xlim([x_min, x_max])\n",
    "ax[1].set_ylim([y_min, y_max])\n",
    "ax[1].set_title('p1 to p8')\n",
    "ax[1].set_xlabel('x coordinates (pixels)')\n",
    "ax[1].set_ylabel('y coordinates (pixels)')\n",
    "ax[1].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# fit elypses on the 8 points to determine pupil centre and diameter\n",
    "############################################################################################################\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "coordinates_dict=lp.get_coordinates_dict(VideoData1, columns_of_interest)\n",
    "\n",
    "theta = lp.find_horizontal_axis_angle(VideoData1, 'left', 'center')\n",
    "center_point = lp.get_left_right_center_point(coordinates_dict)\n",
    "\n",
    "columns_of_interest = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "remformatted_coordinates_dict = lp.get_reformatted_coordinates_dict(coordinates_dict, columns_of_interest)\n",
    "centered_coordinates_dict = lp.get_centered_coordinates_dict(remformatted_coordinates_dict, center_point)\n",
    "rotated_coordinates_dict = lp.get_rotated_coordinates_dict(centered_coordinates_dict, theta)\n",
    "\n",
    "columns_of_interest = ['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "ellipse_parameters_data, ellipse_center_points_data = lp.get_fitted_ellipse_parameters(rotated_coordinates_dict, columns_of_interest)\n",
    "\n",
    "average_diameter = np.mean([ellipse_parameters_data[:,0], ellipse_parameters_data[:,1]], axis=0)\n",
    "\n",
    "SleapVideoData1 = process.convert_arrays_to_dataframe(['Seconds', 'Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'], [VideoData1['Seconds'].values, average_diameter, ellipse_parameters_data[:,2], ellipse_center_points_data[:,0], ellipse_center_points_data[:,1]])\n",
    "\n",
    "print(\"✅ Done calculating pupil diameter and angle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=[\"Pupil Diameter\", \"Pupil Ellipse Long Axis Angle\"],\n",
    "    column_widths=[0.67, 0.33]  # left plot is twice as wide as right plot\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=SleapVideoData1['Seconds'],\n",
    "        y=SleapVideoData1['Ellipse.Diameter'],\n",
    "        mode='lines',\n",
    "        name=\"Pupil Diameter\"\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=SleapVideoData1['Seconds'],\n",
    "        y=np.degrees(SleapVideoData1['Ellipse.Angle']),\n",
    "        mode='markers',\n",
    "        name=\"Ellipse Angle\",\n",
    "        marker=dict(size=1)\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Seconds\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Diameter\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"Seconds\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Angle (degrees)\", row=1, col=2)\n",
    "\n",
    "fig.update_layout(\n",
    "    height=500,\n",
    "    width=1200,\n",
    "    title_text=\"SLEAP VideoData1: Pupil Metrics\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# check if Second values match 1:1 between VideoData and SleapVideoData then merge them into VideoData\n",
    "############################################################################################################\n",
    "\n",
    "if VideoData1_Has_Sleap is True:\n",
    "    if VideoData1['Seconds'].equals(SleapVideoData1['Seconds']) is False:\n",
    "        print(\"❗ Video1: The 'Seconds' columns DO NOT correspond 1:1 between the two DataFrames. This should not happen\")\n",
    "    else:\n",
    "        VideoData1 = VideoData1.merge(SleapVideoData1, on='Seconds', how='outer')\n",
    "        del SleapVideoData1\n",
    "\n",
    "if VideoData2_Has_Sleap is True:\n",
    "    if VideoData2['Seconds'].equals(SleapVideoData2['Seconds']) is False:\n",
    "        print(\"❗ Video2: The 'Seconds' columns DO NOT correspond 1:1 between the two DataFrames. This should not happen\")\n",
    "    else:\n",
    "        VideoData2 = VideoData2.merge(SleapVideoData2, on='Seconds', how='outer')\n",
    "        del SleapVideoData2\n",
    "gc.collect()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# Compare center.x and .y with ellipse.centre.x and .y distributions\n",
    "############################################################################################################\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Compute correlations\n",
    "# ------------------------------------------------------------------\n",
    "slope_x, intercept_x, r_value_x, p_value_x, std_err_x = linregress(\n",
    "    VideoData1[\"Ellipse.Center.X\"], \n",
    "    VideoData1[\"center.x\"]\n",
    ")\n",
    "r_squared_x = r_value_x**2\n",
    "print(f\"R^2 between center point and ellipse center X data: {r_squared_x:.4f}\")\n",
    "\n",
    "slope_y, intercept_y, r_value_y, p_value_y, std_err_y = linregress(\n",
    "    VideoData1[\"Ellipse.Center.Y\"], \n",
    "    VideoData1[\"center.y\"]\n",
    ")\n",
    "r_squared_y = r_value_y**2\n",
    "print(f\"R^2 between center point and ellipse center Y data: {r_squared_y:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Create subplots\n",
    "# ------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(30, 6))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) Scatter plots + linear fits\n",
    "# ------------------------------------------------------------------\n",
    "# (a) For X data\n",
    "ax[0].scatter(\n",
    "    VideoData1[\"Ellipse.Center.X\"], \n",
    "    VideoData1[\"center.x\"], \n",
    "    alpha=0.5, \n",
    "    label=\"Data points\"\n",
    ")\n",
    "ax[0].plot(\n",
    "    VideoData1[\"Ellipse.Center.X\"],\n",
    "    intercept_x + slope_x * VideoData1[\"Ellipse.Center.X\"],\n",
    "    \"r\",\n",
    "    label=f\"Fitted line (R^2={r_squared_x:.2f})\"\n",
    ")\n",
    "ax[0].set_xlabel(\"Ellipse.Center.X\")\n",
    "ax[0].set_ylabel(\"center.x\")\n",
    "ax[0].set_title(\"Ellipse.Center.X vs center.x (with linear fit)\")\n",
    "ax[0].legend()\n",
    "\n",
    "# (b) For Y data\n",
    "ax[1].scatter(\n",
    "    VideoData1[\"Ellipse.Center.Y\"], \n",
    "    VideoData1[\"center.y\"], \n",
    "    alpha=0.5, \n",
    "    label=\"Data points\"\n",
    ")\n",
    "ax[1].plot(\n",
    "    VideoData1[\"Ellipse.Center.Y\"],\n",
    "    intercept_y + slope_y * VideoData1[\"Ellipse.Center.Y\"],\n",
    "    \"r\",\n",
    "    label=f\"Fitted line (R^2={r_squared_y:.2f})\"\n",
    ")\n",
    "ax[1].set_xlabel(\"Ellipse.Center.Y\")\n",
    "ax[1].set_ylabel(\"center.y\")\n",
    "ax[1].set_title(\"Ellipse.Center.Y vs center.y (with linear fit)\")\n",
    "ax[1].legend()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) 2D KDE for Ellipse.Center (blue)\n",
    "# ------------------------------------------------------------------\n",
    "x_ellipse = VideoData1[\"Ellipse.Center.X\"].to_numpy()\n",
    "y_ellipse = VideoData1[\"Ellipse.Center.Y\"].to_numpy()\n",
    "data_ellipse = np.vstack([x_ellipse, y_ellipse])\n",
    "\n",
    "fkde_ellipse = fastKDE(data_ellipse)\n",
    "pdf_ellipse = fkde_ellipse.pdf\n",
    "x_axis_ellipse, y_axis_ellipse = fkde_ellipse.axes\n",
    "\n",
    "im_ellipse = ax[2].imshow(\n",
    "    pdf_ellipse,\n",
    "    extent=[x_axis_ellipse.min(), x_axis_ellipse.max(), \n",
    "            y_axis_ellipse.min(), y_axis_ellipse.max()],\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"Blues\",\n",
    "    alpha=0.4,       # Lower alpha so red can be seen clearly\n",
    "    norm=LogNorm(),\n",
    "    zorder=1\n",
    ")\n",
    "\n",
    "cbar_ellipse = plt.colorbar(im_ellipse, ax=ax[2], orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "cbar_ellipse.set_label(\"Ellipse.Center Density (log scale)\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5) 2D KDE for center (red)\n",
    "# ------------------------------------------------------------------\n",
    "x_center = VideoData1[\"center.x\"].to_numpy()\n",
    "y_center = VideoData1[\"center.y\"].to_numpy()\n",
    "data_center = np.vstack([x_center, y_center])\n",
    "\n",
    "fkde_center = fastKDE(data_center)\n",
    "pdf_center = fkde_center.pdf\n",
    "x_axis_center, y_axis_center = fkde_center.axes\n",
    "\n",
    "im_center = ax[2].imshow(\n",
    "    pdf_center,\n",
    "    extent=[x_axis_center.min(), x_axis_center.max(), \n",
    "            y_axis_center.min(), y_axis_center.max()],\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    "    cmap=\"Reds\",\n",
    "    alpha=0.8,        # Higher alpha to make red more visible\n",
    "    norm=LogNorm(),\n",
    "    zorder=2          # Above the blue distribution\n",
    ")\n",
    "\n",
    "cbar_center = plt.colorbar(im_center, ax=ax[2], orientation=\"vertical\", fraction=0.046, pad=0.04)\n",
    "cbar_center.set_label(\"Center Density (log scale)\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6) Final formatting\n",
    "# ------------------------------------------------------------------\n",
    "ax[2].set_xlabel(\"X coordinates\")\n",
    "ax[2].set_ylabel(\"Y coordinates\")\n",
    "ax[2].set_title(\"Probability distribution of X-Y pairs\")\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color=\"blue\", lw=4, label=\"Ellipse.Center\"),\n",
    "    Line2D([0], [0], color=\"red\",  lw=4, label=\"center.xy\")\n",
    "]\n",
    "ax[2].legend(handles=legend_elements, loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# save as df to csv to be loaded in the photometry/harp/etc. analysis notebook \n",
    "############################################################################################################\n",
    "# reindex to aeon datetime to be done in the other notebook\n",
    " \n",
    "if VideoData1_Has_Sleap:\n",
    "    # Save  DataFrame as CSV to proper path and filename\n",
    "    save_path1 = save_path / \"Video_Sleap_Data1\" / \"Video_Sleap_Data1_1904-01-01T00-00-00.csv\"\n",
    "    save_path1.parent.mkdir(parents=True, exist_ok=True)\n",
    "    #save_path1.parent.mkdir(parents=True, exist_ok=True)\n",
    "    VideoData1.to_csv(save_path1)\n",
    "\n",
    "if VideoData2_Has_Sleap:\n",
    "    # Save  DataFrame as CSV to proper path and filename\n",
    "    save_path2 = save_path / \"Video_Sleap_Data2\" / \"Video_Sleap_Data2_1904-01-01T00-00-00.csv\"\n",
    "    save_path2.parent.mkdir(parents=True, exist_ok=True)\n",
    "    #save_path2.parent.mkdir(parents=True, exist_ok=True)\n",
    "    VideoData2.to_csv(save_path2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################################\n",
    "# INVESTIGATE issue of long stretches of consecutive very low inference predicition scores \n",
    "############################################################################################################\n",
    "\n",
    "\n",
    "score_cutoff = 0.0000001\n",
    "columns_of_interest = ['left.score','center.score','right.score','p1.score','p2.score','p3.score','p4.score','p5.score','p6.score','p7.score','p8.score']\n",
    "total_points = len(VideoData1)\n",
    "\n",
    "\n",
    "for col in columns_of_interest:\n",
    "    count_below_threshold = (VideoData1[col] < score_cutoff).sum()\n",
    "    percentage_below_threshold = (count_below_threshold / total_points) * 100\n",
    "    \n",
    "    # Find the longest consecutive series below threshold\n",
    "    below_threshold = VideoData1[col] < score_cutoff\n",
    "    longest_series = 0\n",
    "    current_series = 0\n",
    "    \n",
    "    for value in below_threshold:\n",
    "        if value:\n",
    "            current_series += 1\n",
    "            if current_series > longest_series:\n",
    "                longest_series = current_series\n",
    "        else:\n",
    "            current_series = 0\n",
    "    \n",
    "    print(f\"Column: {col} | Values below {score_cutoff}: {count_below_threshold} ({percentage_below_threshold:.2f}%) | Longest consecutive frame series: {longest_series}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pympler_memory_df = utils.get_pympler_memory_usage(top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
