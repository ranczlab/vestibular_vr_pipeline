{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a329aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import math\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import mode\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.signal import correlate\n",
    "import json\n",
    "%config Completer.use_jedi = False  # Fixes autocomplete issues\n",
    "%config InlineBackend.figure_format = 'retina'  # Improves plot resolution\n",
    "\n",
    "import gc # garbage collector for removing large variables from memory instantly \n",
    "import importlib #for force updating changed packages \n",
    "\n",
    "#import harp\n",
    "import harp_resources.process\n",
    "import harp_resources.utils\n",
    "from harp_resources import process, utils # Reassign to maintain direct references for force updating \n",
    "#from sleap import load_and_process as lp\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# injected variables from papermill \n",
    "#--------------------------------------------------------------------------------\n",
    "data_dir = Path(Data_dir) # injects at runtime by papermill or define explicetily below\n",
    "time_window_start = Time_window_start #-6  # s, FOR PLOTTING PURPOSES\n",
    "time_window_end = Time_window_end #10  # s, FOR PLOTTING PURPOSES\n",
    "baseline_window = Baseline_window  #(-1, 0) # s, FOR baselining averages \n",
    "plot_width= Plot_width #14\n",
    "\n",
    "event_name = Event_name #\"Apply halt: 2s\" #Apply halt: 2s, No halt\n",
    "vestibular_mismatch = Vestibular_mismatch #False\n",
    "common_resampled_rate = Common_resampled_rate #1000 #in Hz\n",
    "plot_fig1 = Plot_fig1 #False\n",
    "has_sleap = Has_sleap\n",
    "\n",
    "\n",
    "#-------------------------------\n",
    "# load downsampled data for each data path\n",
    "#-------------------------------\n",
    "loaded_data = {}  # Dictionary to store loaded data for each path\n",
    "\n",
    "for idx, data_path in enumerate(data_paths, start=1):\n",
    "    print(f\"\\nProcessing data path {idx}/{len(data_paths)}: {data_path}\")\n",
    "    try:\n",
    "        # Load all parquet files for this data path\n",
    "        photometry_tracking_encoder_data = pd.read_parquet(data_path / \"photometry_tracking_encoder_data.parquet\", engine=\"pyarrow\")\n",
    "        camera_photodiode_data = pd.read_parquet(data_path / \"camera_photodiode_data.parquet\", engine=\"pyarrow\")\n",
    "        experiment_events = pd.read_parquet(data_path / \"experiment_events.parquet\", engine=\"pyarrow\")\n",
    "        photometry_info = pd.read_parquet(data_path / \"photometry_info.parquet\", engine=\"pyarrow\")\n",
    "        session_settings = pd.read_parquet(data_path / \"session_settings.parquet\", engine=\"pyarrow\")\n",
    "        session_settings[\"metadata\"] = session_settings[\"metadata\"].apply(process.safe_from_json)\n",
    "        \n",
    "        print(f\"✅ Successfully loaded all parquet files for {data_path.name}\")\n",
    "        \n",
    "        # Calculate time differences between event_name events\n",
    "        event_times = experiment_events[experiment_events[\"Event\"] == event_name].index\n",
    "        if len(event_times) > 1:\n",
    "            time_diffs = event_times.to_series().diff().dropna().dt.total_seconds()\n",
    "            # Print the 5 shortest time differences\n",
    "            # print(\"5 shortest time differences between events:\")\n",
    "            # print(time_diffs.nsmallest(5))\n",
    "            if (time_diffs < 10).any():\n",
    "                print(f\"⚠️ Warning: Some '{event_name}' events are less than 10 seconds apart. Consider applying a filter to events.\")\n",
    "        else:\n",
    "            print(f\"ℹ️ INFO: Found {len(event_times)} events with name '{event_name}' - not enough to calculate differences\")\n",
    "        \n",
    "        # Check experiment events and get mouse name\n",
    "        mouse_name = process.check_exp_events(experiment_events, photometry_info, verbose=True)\n",
    "        \n",
    "        # Store all loaded data in the dictionary\n",
    "        loaded_data[data_path] = {\n",
    "            \"photometry_tracking_encoder_data\": photometry_tracking_encoder_data,\n",
    "            \"camera_photodiode_data\": camera_photodiode_data,\n",
    "            \"experiment_events\": experiment_events,\n",
    "            \"photometry_info\": photometry_info,\n",
    "            \"session_settings\": session_settings,\n",
    "            \"mouse_name\": mouse_name\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ERROR processing data path {data_path}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n✅ Finished loading data for all {len(loaded_data)} successfully processed data paths\")\n",
    "\n",
    "#---------------------------------------------------\n",
    "# create DFs and plot figure for each data path\n",
    "#---------------------------------------------------\n",
    "\n",
    "# Dictionary to store analysis results for each data path\n",
    "data_path_variables = {}\n",
    "\n",
    "for idx, data_path in enumerate(data_paths, start=1):\n",
    "    print(f\"\\n--------- Processing analysis for data path {idx}/{len(data_paths)}: {data_path} ---------\")\n",
    "    \n",
    "    # Skip if data wasn't successfully loaded for this path\n",
    "    if data_path not in loaded_data:\n",
    "        print(f\"⚠️ Skipping analysis for {data_path} - data not loaded successfully\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Extract data from loaded_data dictionary\n",
    "        photometry_tracking_encoder_data = loaded_data[data_path][\"photometry_tracking_encoder_data\"]\n",
    "        camera_photodiode_data = loaded_data[data_path][\"camera_photodiode_data\"]\n",
    "        experiment_events = loaded_data[data_path][\"experiment_events\"]\n",
    "        mouse_name = loaded_data[data_path][\"mouse_name\"]\n",
    "        session_name = f\"{mouse_name}_{data_path.name}\"  # Assuming session_name is constructed this way\n",
    "        \n",
    "        # Create dataframe to analyze\n",
    "        df_to_analyze = photometry_tracking_encoder_data[\"Photodiode_int\"]  # Using downsampled values in common time grid\n",
    "        # df_to_analyze = camera_photodiode_data[\"Photodiode\"]  # Use async raw values if needed for troubleshooting\n",
    "        \n",
    "        # Determine halt times based on different conditions\n",
    "        if vestibular_mismatch or event_name == \"No halt\":  # Determine halt times based on experiment events\n",
    "            events_matching_name = experiment_events[experiment_events[\"Event\"] == event_name]\n",
    "            if events_matching_name.empty:\n",
    "                print(f\"⚠️ WARNING: No events found with name '{event_name}', skipping this data path\")\n",
    "                continue\n",
    "                \n",
    "            photodiode_halts = events_matching_name.index.tolist()\n",
    "            nearest_indices = photometry_tracking_encoder_data.index.get_indexer(photodiode_halts, method='nearest')\n",
    "            photodiode_halts = photometry_tracking_encoder_data.index[nearest_indices]  # Align to downsampled data time grid\n",
    "            print(f\"ℹ️ INFO: vestibular MM or 'No halt', no signal in the photodiode, using experiment events for MM times\")\n",
    "            photodiode_delay_min = photodiode_delay_avg = photodiode_delay_max = None\n",
    "        else:  # Determine exact halt times based on photodiode signal\n",
    "            try:\n",
    "                photodiode_halts, photodiode_delay_min, photodiode_delay_avg, photodiode_delay_max = process.analyze_photodiode(\n",
    "                    df_to_analyze, experiment_events, event_name, plot=True\n",
    "                )\n",
    "                print(f\"✅ Successfully analyzed photodiode signal for {data_path.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ ERROR analyzing photodiode signal: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        # Store analysis results\n",
    "        data_path_variables[data_path] = {\n",
    "            \"photodiode_halts\": photodiode_halts,\n",
    "            \"photodiode_delay_min\": photodiode_delay_min,\n",
    "            \"photodiode_delay_avg\": photodiode_delay_avg,\n",
    "            \"photodiode_delay_max\": photodiode_delay_max,\n",
    "            \"session_name\": session_name\n",
    "        }\n",
    "        \n",
    "        # Plot figure if requested\n",
    "        if plot_fig1:\n",
    "            try:\n",
    "                process.plot_figure_1(\n",
    "                    photometry_tracking_encoder_data, \n",
    "                    session_name, \n",
    "                    save_path, \n",
    "                    common_resampled_rate, \n",
    "                    photodiode_halts, \n",
    "                    save_figure=True, \n",
    "                    show_figure=True, \n",
    "                    downsample_factor=50\n",
    "                )\n",
    "                print(f\"✅ Successfully created figure 1 for {data_path.name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ ERROR creating figure 1: {str(e)}\")\n",
    "        else:\n",
    "            print(f\"ℹ️ INFO: skipping figure 1 for {data_path.name}\")\n",
    "        \n",
    "        # Clean up to free memory\n",
    "        del df_to_analyze\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"✅ Completed analysis for data path: {data_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ ERROR during analysis of {data_path}: {str(e)}\")\n",
    "\n",
    "print(f\"\\n✅ Finished analyzing all {len(data_path_variables)} successfully processed data paths\")\n",
    "\n",
    "#---------------------------------------------------\n",
    "# Create aligned data and plot comprehensive figures for each data path\n",
    "#---------------------------------------------------\n",
    "\n",
    "print(f\"Using time window: {time_window_start}s to {time_window_end}s relative to halt\")\n",
    "\n",
    "# Iterate through each data path\n",
    "for idx, data_path in enumerate(data_paths, start=1):\n",
    "    print(f\"\\n--------- Processing {idx}/{len(data_paths)}: {data_path} ---------\")\n",
    "    \n",
    "    if data_path not in data_path_variables:\n",
    "        print(f\"⚠️ Skipping {data_path} - no analysis data found\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Extract data\n",
    "        data = loaded_data[data_path]\n",
    "        vars_ = data_path_variables[data_path]\n",
    "        \n",
    "        df = data[\"photometry_tracking_encoder_data\"]\n",
    "        halts = vars_[\"photodiode_halts\"]\n",
    "        \n",
    "        session_name = vars_.get(\"session_name\")\n",
    "        if not session_name:\n",
    "            mouse_name = data.get(\"mouse_name\", \"unknown_mouse\")\n",
    "            session_name = f\"{mouse_name}_{data_path.stem}\"\n",
    "            print(f\"⚠️ No session_name found, using: {session_name}\")\n",
    "\n",
    "        event_name = event_name\n",
    "        print(f\"Aligning {len(halts)} events for session '{session_name}'\")\n",
    "\n",
    "        # Align data to each halt event\n",
    "        aligned_data = []\n",
    "        for i, halt_time in enumerate(halts):\n",
    "            window = df.loc[\n",
    "                (df.index >= halt_time + pd.Timedelta(seconds=time_window_start)) &\n",
    "                (df.index <= halt_time + pd.Timedelta(seconds=time_window_end))\n",
    "            ].copy()\n",
    "\n",
    "            if window.empty:\n",
    "                print(f\"⚠️ No data in window around halt {halt_time}\")\n",
    "                continue\n",
    "\n",
    "            window[\"Time (s)\"] = (window.index - halt_time).total_seconds()\n",
    "            window[\"Halt Time\"] = halt_time\n",
    "            aligned_data.append(window)\n",
    "\n",
    "        if not aligned_data:\n",
    "            print(f\"⚠️ No aligned data generated for {session_name}, skipping\")\n",
    "            continue\n",
    "\n",
    "        aligned_df = pd.concat(aligned_data, ignore_index=True)\n",
    "\n",
    "        # Save CSV in same folder as data\n",
    "        aligned_dir = data_path.parent / \"aligned_data\"\n",
    "        aligned_dir.mkdir(exist_ok=True)\n",
    "\n",
    "        aligned_file = aligned_dir / f\"{session_name}_{event_name}_aligned.csv\"\n",
    "        aligned_df.to_csv(aligned_file, index=False)\n",
    "        print(f\"✅ Saved aligned data to {aligned_file}\")\n",
    "\n",
    "        # Fill in missing columns with dummy data (except required)\n",
    "        required_columns = [\"Time (s)\", \"Photodiode_int\", \"z_470\", \"z_560\", \"Motor_Velocity\", \"Velocity_0X\", \"Velocity_0Y\"]\n",
    "        for col in required_columns:\n",
    "            if col not in aligned_df.columns:\n",
    "                print(f\"⚠️ Missing column: {col}, adding zeros\")\n",
    "                aligned_df[col] = 0\n",
    "\n",
    "        # Compute group mean and SEM\n",
    "        mean_df = aligned_df.groupby(\"Time (s)\").mean()\n",
    "        sem_df = aligned_df.groupby(\"Time (s)\").sem()\n",
    "\n",
    "        # Create figure\n",
    "        print(f\"📈 Creating plot for {session_name}\")\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True)\n",
    "\n",
    "        ## Plot 1: Individual Traces\n",
    "        ax1 = axes[0]\n",
    "        for halt in aligned_df[\"Halt Time\"].unique():\n",
    "            subset = aligned_df[aligned_df[\"Halt Time\"] == halt]\n",
    "            ax1.plot(subset[\"Time (s)\"], subset[\"Photodiode_int\"], color='grey', alpha=0.5)\n",
    "\n",
    "        ax1.set_title('Photodiode, z_470, and z_560')\n",
    "        ax1.set_xlabel(\"Time (s)\")\n",
    "        ax1.set_ylabel(\"Photodiode\")\n",
    "\n",
    "        ax1_2 = ax1.twinx()\n",
    "        for halt in aligned_df[\"Halt Time\"].unique():\n",
    "            subset = aligned_df[aligned_df[\"Halt Time\"] == halt]\n",
    "            ax1_2.plot(subset[\"Time (s)\"], subset[\"z_470\"], color='green', alpha=0.5)\n",
    "            ax1_2.plot(subset[\"Time (s)\"], subset[\"z_560\"], color='red', alpha=0.5)\n",
    "\n",
    "        ax1_2.set_ylabel(\"Fluorescence (z-score)\", color='green')\n",
    "\n",
    "        ## Plot 2: Mean + SEM\n",
    "        ax2 = axes[1]\n",
    "        ax2.plot(mean_df.index, mean_df[\"Photodiode_int\"], color='grey')\n",
    "        ax2.fill_between(mean_df.index, mean_df[\"Photodiode_int\"] - sem_df[\"Photodiode_int\"],\n",
    "                         mean_df[\"Photodiode_int\"] + sem_df[\"Photodiode_int\"], color='grey', alpha=0.2)\n",
    "        ax2.set_xlabel(\"Time (s)\")\n",
    "        ax2.set_ylabel(\"Photodiode\")\n",
    "        ax2.set_title(\"Mean & SEM\")\n",
    "\n",
    "        ax2_2 = ax2.twinx()\n",
    "        ax2_2.plot(mean_df.index, mean_df[\"z_470\"], color='green')\n",
    "        ax2_2.fill_between(mean_df.index, mean_df[\"z_470\"] - sem_df[\"z_470\"], \n",
    "                           mean_df[\"z_470\"] + sem_df[\"z_470\"], color='green', alpha=0.2)\n",
    "\n",
    "        ax2_2.plot(mean_df.index, mean_df[\"z_560\"], color='red')\n",
    "        ax2_2.fill_between(mean_df.index, mean_df[\"z_560\"] - sem_df[\"z_560\"], \n",
    "                           mean_df[\"z_560\"] + sem_df[\"z_560\"], color='red', alpha=0.2)\n",
    "\n",
    "        ax2_2.set_ylabel(\"Fluorescence (z-score)\", color='green')\n",
    "\n",
    "        # Save figure in same folder as data\n",
    "        fig.suptitle(f\"{session_name} - {event_name}\")\n",
    "        fig.tight_layout()\n",
    "        figure_file = data_path.parent / f\"{session_name}_{event_name}.pdf\"\n",
    "        fig.savefig(figure_file, dpi=300)\n",
    "        plt.close(fig)\n",
    "        print(f\"✅ Saved figure to {figure_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"❌ ERROR processing {data_path}: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "print(\"\\n✅ Finished all data paths.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9c5d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-------------------------------\n",
    "# # data paths setup\n",
    "# #-------------------------------\n",
    "# data_dirs = [       #add your data directories here\n",
    "#     Path('/Volumes/RanczLab2/20250409_Cohort3_rotation/Visual_mismatch_day3').expanduser(),\n",
    "#     Path('/Volumes/RanczLab2/20250409_Cohort3_rotation/Visual_mismatch_day4').expanduser()\n",
    "# ]\n",
    "# # Collect raw data paths (excluding '_processedData' dirs)\n",
    "# rawdata_paths = []\n",
    "# for data_dir in data_dirs:\n",
    "#     subdirs = [p for p in data_dir.iterdir() if p.is_dir() and not p.name.endswith('_processedData')]\n",
    "#     rawdata_paths.append(subdirs[0])  # select mouse\n",
    "\n",
    "# # Build processed data paths\n",
    "# data_paths = [raw.parent / f\"{raw.name}_processedData/downsampled_data\" for raw in rawdata_paths]\n",
    "# #-------------------------------\n",
    "# # initial variables setup\n",
    "# #-------------------------------\n",
    "# time_window_start = -6  # s, FOR PLOTTING PURPOSES\n",
    "# time_window_end = 10  # s, FOR PLOTTING PURPOSES\n",
    "# baseline_window = (-1, 0) # s, FOR baselining averages \n",
    "# plot_width= 14\n",
    "\n",
    "# event_name = \"Apply halt: 2s\" #Apply halt: 2s, No halt\n",
    "# vestibular_mismatch = False\n",
    "# common_resampled_rate = 1000 #in Hz\n",
    "# plot_fig1 = False\n",
    "\n",
    "# # for saccades\n",
    "# framerate = 59.77  # Hz (in the future, should come from saved data)\n",
    "# threshold = 65  # px/s FIXME make this adaptive\n",
    "# refractory_period = pd.Timedelta(milliseconds=100)  # msec, using pd.Timedelta for datetime index\n",
    "# plot_saccade_detection_QC = False\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #-------------------------------\n",
    "# # load downsampled data for each data path\n",
    "# #-------------------------------\n",
    "# loaded_data = {}  # Dictionary to store loaded data for each path\n",
    "\n",
    "# for idx, data_path in enumerate(data_paths, start=1):\n",
    "#     print(f\"\\nProcessing data path {idx}/{len(data_paths)}: {data_path}\")\n",
    "#     try:\n",
    "#         # Load all parquet files for this data path\n",
    "#         photometry_tracking_encoder_data = pd.read_parquet(data_path / \"photometry_tracking_encoder_data.parquet\", engine=\"pyarrow\")\n",
    "#         camera_photodiode_data = pd.read_parquet(data_path / \"camera_photodiode_data.parquet\", engine=\"pyarrow\")\n",
    "#         experiment_events = pd.read_parquet(data_path / \"experiment_events.parquet\", engine=\"pyarrow\")\n",
    "#         photometry_info = pd.read_parquet(data_path / \"photometry_info.parquet\", engine=\"pyarrow\")\n",
    "#         session_settings = pd.read_parquet(data_path / \"session_settings.parquet\", engine=\"pyarrow\")\n",
    "#         session_settings[\"metadata\"] = session_settings[\"metadata\"].apply(process.safe_from_json)\n",
    "        \n",
    "#         print(f\"✅ Successfully loaded all parquet files for {data_path.name}\")\n",
    "        \n",
    "#         # Calculate time differences between event_name events\n",
    "#         event_times = experiment_events[experiment_events[\"Event\"] == event_name].index\n",
    "#         if len(event_times) > 1:\n",
    "#             time_diffs = event_times.to_series().diff().dropna().dt.total_seconds()\n",
    "#             # Print the 5 shortest time differences\n",
    "#             # print(\"5 shortest time differences between events:\")\n",
    "#             # print(time_diffs.nsmallest(5))\n",
    "#             if (time_diffs < 10).any():\n",
    "#                 print(f\"⚠️ Warning: Some '{event_name}' events are less than 10 seconds apart. Consider applying a filter to events.\")\n",
    "#         else:\n",
    "#             print(f\"ℹ️ INFO: Found {len(event_times)} events with name '{event_name}' - not enough to calculate differences\")\n",
    "        \n",
    "#         # Check experiment events and get mouse name\n",
    "#         mouse_name = process.check_exp_events(experiment_events, photometry_info, verbose=True)\n",
    "        \n",
    "#         # Store all loaded data in the dictionary\n",
    "#         loaded_data[data_path] = {\n",
    "#             \"photometry_tracking_encoder_data\": photometry_tracking_encoder_data,\n",
    "#             \"camera_photodiode_data\": camera_photodiode_data,\n",
    "#             \"experiment_events\": experiment_events,\n",
    "#             \"photometry_info\": photometry_info,\n",
    "#             \"session_settings\": session_settings,\n",
    "#             \"mouse_name\": mouse_name\n",
    "#         }\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠️ ERROR processing data path {data_path}: {str(e)}\")\n",
    "#         continue\n",
    "\n",
    "# print(f\"\\n✅ Finished loading data for all {len(loaded_data)} successfully processed data paths\")\n",
    "\n",
    "# # Now you can use loaded_data[data_path] to access the data for each path in your subsequent processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #---------------------------------------------------\n",
    "# # create DFs and plot figure for each data path\n",
    "# #---------------------------------------------------\n",
    "\n",
    "# # Dictionary to store analysis results for each data path\n",
    "# data_path_variables = {}\n",
    "\n",
    "# for idx, data_path in enumerate(data_paths, start=1):\n",
    "#     print(f\"\\n--------- Processing analysis for data path {idx}/{len(data_paths)}: {data_path} ---------\")\n",
    "    \n",
    "#     # Skip if data wasn't successfully loaded for this path\n",
    "#     if data_path not in loaded_data:\n",
    "#         print(f\"⚠️ Skipping analysis for {data_path} - data not loaded successfully\")\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         # Extract data from loaded_data dictionary\n",
    "#         photometry_tracking_encoder_data = loaded_data[data_path][\"photometry_tracking_encoder_data\"]\n",
    "#         camera_photodiode_data = loaded_data[data_path][\"camera_photodiode_data\"]\n",
    "#         experiment_events = loaded_data[data_path][\"experiment_events\"]\n",
    "#         mouse_name = loaded_data[data_path][\"mouse_name\"]\n",
    "#         session_name = f\"{mouse_name}_{data_path.name}\"  # Assuming session_name is constructed this way\n",
    "        \n",
    "#         # Create dataframe to analyze\n",
    "#         df_to_analyze = photometry_tracking_encoder_data[\"Photodiode_int\"]  # Using downsampled values in common time grid\n",
    "#         # df_to_analyze = camera_photodiode_data[\"Photodiode\"]  # Use async raw values if needed for troubleshooting\n",
    "        \n",
    "#         # Determine halt times based on different conditions\n",
    "#         if vestibular_mismatch or event_name == \"No halt\":  # Determine halt times based on experiment events\n",
    "#             events_matching_name = experiment_events[experiment_events[\"Event\"] == event_name]\n",
    "#             if events_matching_name.empty:\n",
    "#                 print(f\"⚠️ WARNING: No events found with name '{event_name}', skipping this data path\")\n",
    "#                 continue\n",
    "                \n",
    "#             photodiode_halts = events_matching_name.index.tolist()\n",
    "#             nearest_indices = photometry_tracking_encoder_data.index.get_indexer(photodiode_halts, method='nearest')\n",
    "#             photodiode_halts = photometry_tracking_encoder_data.index[nearest_indices]  # Align to downsampled data time grid\n",
    "#             print(f\"ℹ️ INFO: vestibular MM or 'No halt', no signal in the photodiode, using experiment events for MM times\")\n",
    "#             photodiode_delay_min = photodiode_delay_avg = photodiode_delay_max = None\n",
    "#         else:  # Determine exact halt times based on photodiode signal\n",
    "#             try:\n",
    "#                 photodiode_halts, photodiode_delay_min, photodiode_delay_avg, photodiode_delay_max = process.analyze_photodiode(\n",
    "#                     df_to_analyze, experiment_events, event_name, plot=True\n",
    "#                 )\n",
    "#                 print(f\"✅ Successfully analyzed photodiode signal for {data_path.name}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"⚠️ ERROR analyzing photodiode signal: {str(e)}\")\n",
    "#                 continue\n",
    "        \n",
    "#         # Store analysis results\n",
    "#         data_path_variables[data_path] = {\n",
    "#             \"photodiode_halts\": photodiode_halts,\n",
    "#             \"photodiode_delay_min\": photodiode_delay_min,\n",
    "#             \"photodiode_delay_avg\": photodiode_delay_avg,\n",
    "#             \"photodiode_delay_max\": photodiode_delay_max,\n",
    "#             \"session_name\": session_name\n",
    "#         }\n",
    "        \n",
    "#         # Plot figure if requested\n",
    "#         if plot_fig1:\n",
    "#             try:\n",
    "#                 process.plot_figure_1(\n",
    "#                     photometry_tracking_encoder_data, \n",
    "#                     session_name, \n",
    "#                     save_path, \n",
    "#                     common_resampled_rate, \n",
    "#                     photodiode_halts, \n",
    "#                     save_figure=True, \n",
    "#                     show_figure=True, \n",
    "#                     downsample_factor=50\n",
    "#                 )\n",
    "#                 print(f\"✅ Successfully created figure 1 for {data_path.name}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"⚠️ ERROR creating figure 1: {str(e)}\")\n",
    "#         else:\n",
    "#             print(f\"ℹ️ INFO: skipping figure 1 for {data_path.name}\")\n",
    "        \n",
    "#         # Clean up to free memory\n",
    "#         del df_to_analyze\n",
    "#         gc.collect()\n",
    "        \n",
    "#         print(f\"✅ Completed analysis for data path: {data_path}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠️ ERROR during analysis of {data_path}: {str(e)}\")\n",
    "\n",
    "# print(f\"\\n✅ Finished analyzing all {len(data_path_variables)} successfully processed data paths\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb2573e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #---------------------------------------------------\n",
    "# # Create aligned data and plot fluorescence traces for each data path (with improved error handling)\n",
    "# #---------------------------------------------------\n",
    "\n",
    "# # Check if required variables exist\n",
    "# required_vars = ['time_window_start', 'time_window_end']\n",
    "# for var in required_vars:\n",
    "#     if var not in globals():\n",
    "#         print(f\"⚠️ ERROR: Required variable '{var}' is not defined\")\n",
    "#         # Set default values\n",
    "#         if var == 'time_window_start':\n",
    "#             time_window_start = -5  # Default: 5 seconds before halt\n",
    "#             print(f\"  Setting default value: {var} = {time_window_start}\")\n",
    "#         elif var == 'time_window_end':\n",
    "#             time_window_end = 10  # Default: 10 seconds after halt\n",
    "#             print(f\"  Setting default value: {var} = {time_window_end}\")\n",
    "\n",
    "# # Define save_plots if not already defined\n",
    "# if 'save_plots' not in globals():\n",
    "#     save_plots = False\n",
    "#     print(f\"Setting default value: save_plots = {save_plots}\")\n",
    "\n",
    "# for idx, data_path in enumerate(data_paths, start=1):\n",
    "#     print(f\"\\n--------- Creating fluorescence plots for data path {idx}/{len(data_paths)}: {data_path} ---------\")\n",
    "    \n",
    "#     # Skip if data wasn't successfully analyzed for this path\n",
    "#     if data_path not in data_path_variables:\n",
    "#         print(f\"⚠️ Skipping fluorescence plots for {data_path} - analysis not completed successfully\")\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         # Verify data exists before attempting to extract it\n",
    "#         if data_path not in loaded_data:\n",
    "#             print(f\"⚠️ ERROR: data_path {data_path} not found in loaded_data\")\n",
    "#             continue\n",
    "            \n",
    "#         if \"photometry_tracking_encoder_data\" not in loaded_data[data_path]:\n",
    "#             print(f\"⚠️ ERROR: 'photometry_tracking_encoder_data' not found in loaded_data[{data_path}]\")\n",
    "#             continue\n",
    "            \n",
    "#         if \"photodiode_halts\" not in data_path_variables[data_path]:\n",
    "#             print(f\"⚠️ ERROR: 'photodiode_halts' not found in data_path_variables[{data_path}]\")\n",
    "#             continue\n",
    "            \n",
    "#         # Extract data from loaded_data and data_path_variables dictionaries\n",
    "#         photometry_tracking_encoder_data = loaded_data[data_path][\"photometry_tracking_encoder_data\"]\n",
    "#         photodiode_halts = data_path_variables[data_path][\"photodiode_halts\"]\n",
    "        \n",
    "#         # Check if session_name exists in data_path_variables\n",
    "#         if \"session_name\" in data_path_variables[data_path]:\n",
    "#             session_name = data_path_variables[data_path][\"session_name\"]\n",
    "#         else:\n",
    "#             # Try to generate session_name\n",
    "#             if \"mouse_name\" in loaded_data[data_path]:\n",
    "#                 mouse_name = loaded_data[data_path][\"mouse_name\"]\n",
    "#                 session_name = f\"{mouse_name}_{data_path.name}\"\n",
    "#             else:\n",
    "#                 session_name = f\"session_{data_path.name}\"\n",
    "#                 print(f\"⚠️ WARNING: Using generic session name: {session_name}\")\n",
    "        \n",
    "#         print(f\"Creating aligned data for {len(photodiode_halts)} events in {data_path.name}\")\n",
    "        \n",
    "#         # Check if required columns exist in photometry data\n",
    "#         required_columns = [\"z_470\", \"z_560\"]\n",
    "#         missing_columns = [col for col in required_columns if col not in photometry_tracking_encoder_data.columns]\n",
    "#         if missing_columns:\n",
    "#             print(f\"⚠️ ERROR: Missing columns in photometry_tracking_encoder_data: {missing_columns}\")\n",
    "#             print(f\"Available columns: {photometry_tracking_encoder_data.columns.tolist()}\")\n",
    "#             continue\n",
    "        \n",
    "#         # --- Data Alignment ---\n",
    "#         aligned_data = []\n",
    "#         for halt_time in photodiode_halts:\n",
    "#             try:\n",
    "#                 window_data = photometry_tracking_encoder_data.loc[\n",
    "#                     (photometry_tracking_encoder_data.index >= halt_time + pd.Timedelta(seconds=time_window_start)) &\n",
    "#                     (photometry_tracking_encoder_data.index <= halt_time + pd.Timedelta(seconds=time_window_end))\n",
    "#                 ].copy()\n",
    "                \n",
    "#                 if window_data.empty:\n",
    "#                     print(f\"⚠️ WARNING: No data found for window around halt time {halt_time}\")\n",
    "#                     continue\n",
    "                    \n",
    "#                 window_data[\"Time (s)\"] = (window_data.index - halt_time).total_seconds()\n",
    "#                 window_data[\"Halt Time\"] = halt_time\n",
    "#                 aligned_data.append(window_data)\n",
    "#             except Exception as e:\n",
    "#                 print(f\"⚠️ ERROR processing halt time {halt_time}: {str(e)}\")\n",
    "#                 continue\n",
    "        \n",
    "#         if not aligned_data:\n",
    "#             print(f\"⚠️ WARNING: No aligned data created for {data_path.name}, skipping plotting\")\n",
    "#             continue\n",
    "            \n",
    "#         aligned_df = pd.concat(aligned_data, ignore_index=True)\n",
    "        \n",
    "#         # --- Subplot Grid Setup ---\n",
    "#         n_events = len(photodiode_halts)\n",
    "#         n_cols = 4\n",
    "#         n_rows = math.ceil(n_events / n_cols)\n",
    "        \n",
    "#         print(f\"Creating subplot grid with {n_rows} rows and {n_cols} columns for {n_events} events\")\n",
    "        \n",
    "#         # Create subplots with a single (default) y-axis in each cell\n",
    "#         specs = [[{} for _ in range(n_cols)] for _ in range(n_rows)]\n",
    "#         subplot_titles = [f'Event: {halt_time}' for halt_time in photodiode_halts]\n",
    "#         fig = sp.make_subplots(rows=n_rows, cols=n_cols, subplot_titles=subplot_titles, specs=specs)\n",
    "        \n",
    "#         # Base extra is used to create unique axis IDs starting after the auto-assigned primary axes\n",
    "#         base_extra = n_events + 1\n",
    "        \n",
    "#         for i, halt_time in enumerate(photodiode_halts):\n",
    "#             try:\n",
    "#                 row = (i // n_cols) + 1\n",
    "#                 col = (i % n_cols) + 1\n",
    "                \n",
    "#                 subset = aligned_df[aligned_df[\"Halt Time\"] == halt_time]\n",
    "#                 if subset.empty:\n",
    "#                     print(f\"⚠️ WARNING: No data found for halt time {halt_time}\")\n",
    "#                     continue\n",
    "                \n",
    "#                 # Verify data exists in subset\n",
    "#                 for col_name in [\"Time (s)\", \"z_470\", \"z_560\"]:\n",
    "#                     if col_name not in subset.columns:\n",
    "#                         print(f\"⚠️ ERROR: Column '{col_name}' not found in aligned data subset\")\n",
    "#                         print(f\"Available columns: {subset.columns.tolist()}\")\n",
    "#                         raise KeyError(f\"Missing column: {col_name}\")\n",
    "                    \n",
    "#                 # -- Fluorescence Traces on Primary y-axis --\n",
    "#                 fig.add_trace(\n",
    "#                     go.Scatter(\n",
    "#                         x=subset[\"Time (s)\"],\n",
    "#                         y=subset[\"z_470\"],\n",
    "#                         mode='lines',\n",
    "#                         name='z_470',\n",
    "#                         line=dict(color='green')\n",
    "#                     ),\n",
    "#                     row=row, col=col\n",
    "#                 )\n",
    "                \n",
    "#                 fig.add_trace(\n",
    "#                     go.Scatter(\n",
    "#                         x=subset[\"Time (s)\"],\n",
    "#                         y=subset[\"z_560\"],\n",
    "#                         mode='lines',\n",
    "#                         name='z_560',\n",
    "#                         line=dict(color='red')\n",
    "#                     ),\n",
    "#                     row=row, col=col\n",
    "#                 )\n",
    "                \n",
    "#                 # Determine the subplot's x-axis anchor\n",
    "#                 xaxis_number = (row - 1) * n_cols + col\n",
    "#                 x_anchor = \"x\" if xaxis_number == 1 else f\"x{xaxis_number}\"\n",
    "                \n",
    "#                 # The primary y-axis for this subplot\n",
    "#                 primary_y = \"y\" if xaxis_number == 1 else f\"y{xaxis_number}\"\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"⚠️ ERROR processing subplot for halt time {halt_time}: {str(e)}\")\n",
    "#                 continue\n",
    "        \n",
    "#         # --- Update Common Axis Labels ---\n",
    "#         fig.update_xaxes(title_text=\"Time (s)\")\n",
    "#         fig.update_yaxes(title_text=\"Fluorescence (z-score)\")\n",
    "        \n",
    "#         # Create a descriptive title that includes session name\n",
    "#         title = f\"Fluorescence for each event - {session_name}\"\n",
    "        \n",
    "#         fig.update_layout(\n",
    "#             height=400 * n_rows,\n",
    "#             width=350 * n_cols,\n",
    "#             title_text=title,\n",
    "#             template='plotly_white'\n",
    "#         )\n",
    "        \n",
    "#         # Save the figure if needed\n",
    "#         if save_plots:\n",
    "#             try:\n",
    "#                 # Ensure save_path exists\n",
    "#                 if 'save_path' not in globals() or save_path is None:\n",
    "#                     from pathlib import Path\n",
    "#                     save_path = Path('./output')\n",
    "#                     save_path.mkdir(exist_ok=True)\n",
    "#                     print(f\"Creating default save_path: {save_path}\")\n",
    "                    \n",
    "#                 output_file = save_path / f\"{session_name}_fluorescence_events.html\"\n",
    "#                 fig.write_html(str(output_file))\n",
    "#                 print(f\"✅ Saved fluorescence plot to {output_file}\")\n",
    "#             except Exception as e:\n",
    "#                 print(f\"⚠️ ERROR saving fluorescence plot: {str(e)}\")\n",
    "        \n",
    "#         # Display the figure\n",
    "#         fig.show()\n",
    "        \n",
    "#         # Clean up to free memory\n",
    "#         del aligned_data\n",
    "#         gc.collect()\n",
    "        \n",
    "#         print(f\"✅ Completed fluorescence plots for data path: {data_path}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         import traceback\n",
    "#         print(f\"⚠️ ERROR creating fluorescence plots for {data_path}: {str(e)}\")\n",
    "#         print(\"Detailed error traceback:\")\n",
    "#         traceback.print_exc()  # This will print the full stack trace\n",
    "\n",
    "# print(f\"\\n✅ Finished creating fluorescence plots for all successfully processed data paths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ee9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #---------------------------------------------------\n",
    "# # Create aligned data and plot comprehensive figures for each data path\n",
    "# #---------------------------------------------------\n",
    "\n",
    "# print(f\"Using time window: {time_window_start}s to {time_window_end}s relative to halt\")\n",
    "\n",
    "# # Iterate through each data path\n",
    "# for idx, data_path in enumerate(data_paths, start=1):\n",
    "#     print(f\"\\n--------- Processing {idx}/{len(data_paths)}: {data_path} ---------\")\n",
    "    \n",
    "#     if data_path not in data_path_variables:\n",
    "#         print(f\"⚠️ Skipping {data_path} - no analysis data found\")\n",
    "#         continue\n",
    "    \n",
    "#     try:\n",
    "#         # Extract data\n",
    "#         data = loaded_data[data_path]\n",
    "#         vars_ = data_path_variables[data_path]\n",
    "        \n",
    "#         df = data[\"photometry_tracking_encoder_data\"]\n",
    "#         halts = vars_[\"photodiode_halts\"]\n",
    "        \n",
    "#         session_name = vars_.get(\"session_name\")\n",
    "#         if not session_name:\n",
    "#             mouse_name = data.get(\"mouse_name\", \"unknown_mouse\")\n",
    "#             session_name = f\"{mouse_name}_{data_path.stem}\"\n",
    "#             print(f\"⚠️ No session_name found, using: {session_name}\")\n",
    "\n",
    "#         event_name = event_name\n",
    "#         print(f\"Aligning {len(halts)} events for session '{session_name}'\")\n",
    "\n",
    "#         # Align data to each halt event\n",
    "#         aligned_data = []\n",
    "#         for i, halt_time in enumerate(halts):\n",
    "#             window = df.loc[\n",
    "#                 (df.index >= halt_time + pd.Timedelta(seconds=time_window_start)) &\n",
    "#                 (df.index <= halt_time + pd.Timedelta(seconds=time_window_end))\n",
    "#             ].copy()\n",
    "\n",
    "#             if window.empty:\n",
    "#                 print(f\"⚠️ No data in window around halt {halt_time}\")\n",
    "#                 continue\n",
    "\n",
    "#             window[\"Time (s)\"] = (window.index - halt_time).total_seconds()\n",
    "#             window[\"Halt Time\"] = halt_time\n",
    "#             aligned_data.append(window)\n",
    "\n",
    "#         if not aligned_data:\n",
    "#             print(f\"⚠️ No aligned data generated for {session_name}, skipping\")\n",
    "#             continue\n",
    "\n",
    "#         aligned_df = pd.concat(aligned_data, ignore_index=True)\n",
    "\n",
    "#         # Save CSV in same folder as data\n",
    "#         aligned_dir = data_path.parent / \"aligned_data\"\n",
    "#         aligned_dir.mkdir(exist_ok=True)\n",
    "\n",
    "#         aligned_file = aligned_dir / f\"{session_name}_{event_name}_aligned.csv\"\n",
    "#         aligned_df.to_csv(aligned_file, index=False)\n",
    "#         print(f\"✅ Saved aligned data to {aligned_file}\")\n",
    "\n",
    "#         # Fill in missing columns with dummy data (except required)\n",
    "#         required_columns = [\"Time (s)\", \"Photodiode_int\", \"z_470\", \"z_560\", \"Motor_Velocity\", \"Velocity_0X\", \"Velocity_0Y\"]\n",
    "#         for col in required_columns:\n",
    "#             if col not in aligned_df.columns:\n",
    "#                 print(f\"⚠️ Missing column: {col}, adding zeros\")\n",
    "#                 aligned_df[col] = 0\n",
    "\n",
    "#         # Compute group mean and SEM\n",
    "#         mean_df = aligned_df.groupby(\"Time (s)\").mean()\n",
    "#         sem_df = aligned_df.groupby(\"Time (s)\").sem()\n",
    "\n",
    "#         # Create figure\n",
    "#         print(f\"📈 Creating plot for {session_name}\")\n",
    "#         fig, axes = plt.subplots(1, 2, figsize=(14, 6), sharex=True)\n",
    "\n",
    "#         ## Plot 1: Individual Traces\n",
    "#         ax1 = axes[0]\n",
    "#         for halt in aligned_df[\"Halt Time\"].unique():\n",
    "#             subset = aligned_df[aligned_df[\"Halt Time\"] == halt]\n",
    "#             ax1.plot(subset[\"Time (s)\"], subset[\"Photodiode_int\"], color='grey', alpha=0.5)\n",
    "\n",
    "#         ax1.set_title('Photodiode, z_470, and z_560')\n",
    "#         ax1.set_xlabel(\"Time (s)\")\n",
    "#         ax1.set_ylabel(\"Photodiode\")\n",
    "\n",
    "#         ax1_2 = ax1.twinx()\n",
    "#         for halt in aligned_df[\"Halt Time\"].unique():\n",
    "#             subset = aligned_df[aligned_df[\"Halt Time\"] == halt]\n",
    "#             ax1_2.plot(subset[\"Time (s)\"], subset[\"z_470\"], color='green', alpha=0.5)\n",
    "#             ax1_2.plot(subset[\"Time (s)\"], subset[\"z_560\"], color='red', alpha=0.5)\n",
    "\n",
    "#         ax1_2.set_ylabel(\"Fluorescence (z-score)\", color='green')\n",
    "\n",
    "#         ## Plot 2: Mean + SEM\n",
    "#         ax2 = axes[1]\n",
    "#         ax2.plot(mean_df.index, mean_df[\"Photodiode_int\"], color='grey')\n",
    "#         ax2.fill_between(mean_df.index, mean_df[\"Photodiode_int\"] - sem_df[\"Photodiode_int\"],\n",
    "#                          mean_df[\"Photodiode_int\"] + sem_df[\"Photodiode_int\"], color='grey', alpha=0.2)\n",
    "#         ax2.set_xlabel(\"Time (s)\")\n",
    "#         ax2.set_ylabel(\"Photodiode\")\n",
    "#         ax2.set_title(\"Mean & SEM\")\n",
    "\n",
    "#         ax2_2 = ax2.twinx()\n",
    "#         ax2_2.plot(mean_df.index, mean_df[\"z_470\"], color='green')\n",
    "#         ax2_2.fill_between(mean_df.index, mean_df[\"z_470\"] - sem_df[\"z_470\"], \n",
    "#                            mean_df[\"z_470\"] + sem_df[\"z_470\"], color='green', alpha=0.2)\n",
    "\n",
    "#         ax2_2.plot(mean_df.index, mean_df[\"z_560\"], color='red')\n",
    "#         ax2_2.fill_between(mean_df.index, mean_df[\"z_560\"] - sem_df[\"z_560\"], \n",
    "#                            mean_df[\"z_560\"] + sem_df[\"z_560\"], color='red', alpha=0.2)\n",
    "\n",
    "#         ax2_2.set_ylabel(\"Fluorescence (z-score)\", color='green')\n",
    "\n",
    "#         # Save figure in same folder as data\n",
    "#         fig.suptitle(f\"{session_name} - {event_name}\")\n",
    "#         fig.tight_layout()\n",
    "#         figure_file = data_path.parent / f\"{session_name}_{event_name}.pdf\"\n",
    "#         fig.savefig(figure_file, dpi=300)\n",
    "#         plt.close(fig)\n",
    "#         print(f\"✅ Saved figure to {figure_file}\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         import traceback\n",
    "#         print(f\"❌ ERROR processing {data_path}: {str(e)}\")\n",
    "#         traceback.print_exc()\n",
    "\n",
    "# print(\"\\n✅ Finished all data paths.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1364a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def process_data_path(aligned_df, baseline_window, mouse_name):\n",
    "#     # ---------------- Baseline Correction ----------------\n",
    "#     baseline_df = aligned_df[\n",
    "#         (aligned_df[\"Time (s)\"] >= baseline_window[0]) & \n",
    "#         (aligned_df[\"Time (s)\"] <= baseline_window[1])\n",
    "#     ].groupby(\"Halt Time\").mean()\n",
    "\n",
    "#     for signal_name in [\"z_470\", \"z_560\", \"Motor_Velocity\", \"Velocity_0X\", \"Velocity_0Y\"]:\n",
    "#         aligned_df[f\"{signal_name}_Baseline\"] = aligned_df[signal_name] - aligned_df[\"Halt Time\"].map(baseline_df[signal_name])\n",
    "\n",
    "#     # ---------------- Mean and SEM ----------------\n",
    "#     mean_baseline_df = aligned_df.groupby(\"Time (s)\").mean()\n",
    "#     sem_baseline_df = aligned_df.groupby(\"Time (s)\").sem()\n",
    "\n",
    "#     def get_symmetric_ylim(mean_data, sem_data):\n",
    "#         max_abs_value = max(\n",
    "#             abs(mean_data).max() + sem_data.max(),\n",
    "#             abs(mean_data).min() - sem_data.min()\n",
    "#         )\n",
    "#         return (-max_abs_value, max_abs_value)\n",
    "\n",
    "#     # ---------------- Plotting ----------------\n",
    "#     fig, ax = plt.subplots(figsize=(plot_width, 6))\n",
    "\n",
    "#     ax.plot(mean_baseline_df.index, mean_baseline_df[\"Photodiode_int\"], color='grey', alpha=0.8)\n",
    "#     ax.fill_between(mean_baseline_df.index,\n",
    "#                     mean_baseline_df[\"Photodiode_int\"] - sem_baseline_df[\"Photodiode_int\"],\n",
    "#                     mean_baseline_df[\"Photodiode_int\"] + sem_baseline_df[\"Photodiode_int\"],\n",
    "#                     color='grey', alpha=0.2)\n",
    "\n",
    "#     ax.set_xlabel('Time (s) relative to halt')\n",
    "#     ax.set_ylabel('Photodiode', color='grey')\n",
    "#     ax.set_title(f'Baselined Mean & SEM of All Signals - {mouse_name}')\n",
    "\n",
    "#     # z_470 and z_560\n",
    "#     ax2 = ax.twinx()\n",
    "#     ax2.plot(mean_baseline_df.index, mean_baseline_df[\"z_470_Baseline\"], color='green', alpha=0.8)\n",
    "#     ax2.fill_between(mean_baseline_df.index,\n",
    "#                      mean_baseline_df[\"z_470_Baseline\"] - sem_baseline_df[\"z_470_Baseline\"],\n",
    "#                      mean_baseline_df[\"z_470_Baseline\"] + sem_baseline_df[\"z_470_Baseline\"],\n",
    "#                      color='green', alpha=0.2)\n",
    "#     ax2.plot(mean_baseline_df.index, mean_baseline_df[\"z_560_Baseline\"], color='red', alpha=0.8)\n",
    "#     ax2.fill_between(mean_baseline_df.index,\n",
    "#                      mean_baseline_df[\"z_560_Baseline\"] - sem_baseline_df[\"z_560_Baseline\"],\n",
    "#                      mean_baseline_df[\"z_560_Baseline\"] + sem_baseline_df[\"z_560_Baseline\"],\n",
    "#                      color='red', alpha=0.2)\n",
    "#     ax2.set_ylabel('Fluorescence (z-score, red 560nm)', color='green')\n",
    "#     ax2.set_ylim(get_symmetric_ylim(\n",
    "#         pd.concat([mean_baseline_df[\"z_470_Baseline\"], mean_baseline_df[\"z_560_Baseline\"]]),\n",
    "#         pd.concat([sem_baseline_df[\"z_470_Baseline\"], sem_baseline_df[\"z_560_Baseline\"]])\n",
    "#     ))\n",
    "#     ax2.yaxis.label.set_color('green')\n",
    "\n",
    "#     # Motor velocity\n",
    "#     ax3 = ax.twinx()\n",
    "#     ax3.spines['right'].set_position(('outward', 50))\n",
    "#     ax3.plot(mean_baseline_df.index, mean_baseline_df[\"Motor_Velocity_Baseline\"], color='#00008B', alpha=0.8)\n",
    "#     ax3.fill_between(mean_baseline_df.index,\n",
    "#                      mean_baseline_df[\"Motor_Velocity_Baseline\"] - sem_baseline_df[\"Motor_Velocity_Baseline\"],\n",
    "#                      mean_baseline_df[\"Motor_Velocity_Baseline\"] + sem_baseline_df[\"Motor_Velocity_Baseline\"],\n",
    "#                      color='#00008B', alpha=0.2)\n",
    "#     ax3.set_ylabel('Motor Velocity (deg/s²)', color='#00008B')\n",
    "#     ax3.set_ylim(get_symmetric_ylim(mean_baseline_df[\"Motor_Velocity_Baseline\"], sem_baseline_df[\"Motor_Velocity_Baseline\"]))\n",
    "#     ax3.yaxis.label.set_color('#00008B')\n",
    "\n",
    "#     # Running velocity (Velocity_0X)\n",
    "#     ax4 = ax.twinx()\n",
    "#     ax4.spines['right'].set_position(('outward', 100))\n",
    "#     ax4.plot(mean_baseline_df.index, mean_baseline_df[\"Velocity_0X_Baseline\"] * 1000, color='orange', alpha=0.8)\n",
    "#     ax4.fill_between(mean_baseline_df.index,\n",
    "#                      (mean_baseline_df[\"Velocity_0X_Baseline\"] - sem_baseline_df[\"Velocity_0X_Baseline\"]) * 1000,\n",
    "#                      (mean_baseline_df[\"Velocity_0X_Baseline\"] + sem_baseline_df[\"Velocity_0X_Baseline\"]) * 1000,\n",
    "#                      color='orange', alpha=0.2)\n",
    "#     ax4.set_ylabel('Running velocity (mm/s²) WRONG SCALE?', color='orange')\n",
    "#     ax4.set_ylim(get_symmetric_ylim(mean_baseline_df[\"Velocity_0X_Baseline\"] * 1000, sem_baseline_df[\"Velocity_0X_Baseline\"] * 1000))\n",
    "#     ax4.yaxis.label.set_color('orange')\n",
    "\n",
    "#     # Turning velocity (Velocity_0Y)\n",
    "#     ax5 = ax.twinx()\n",
    "#     ax5.spines['right'].set_position(('outward', 150))\n",
    "#     ax5.plot(mean_baseline_df.index, mean_baseline_df[\"Velocity_0Y_Baseline\"], color='#4682B4', alpha=0.8)\n",
    "#     ax5.fill_between(mean_baseline_df.index,\n",
    "#                      mean_baseline_df[\"Velocity_0Y_Baseline\"] - sem_baseline_df[\"Velocity_0Y_Baseline\"],\n",
    "#                      mean_baseline_df[\"Velocity_0Y_Baseline\"] + sem_baseline_df[\"Velocity_0Y_Baseline\"],\n",
    "#                      color='#4682B4', alpha=0.2)\n",
    "#     ax5.set_ylabel('Turning velocity (deg/s²) WRONG SCALE?', color='#4682B4')\n",
    "#     ax5.set_ylim(get_symmetric_ylim(mean_baseline_df[\"Velocity_0Y_Baseline\"], sem_baseline_df[\"Velocity_0Y_Baseline\"]))\n",
    "#     ax5.yaxis.label.set_color('#4682B4')\n",
    "\n",
    "#     fig.tight_layout()\n",
    "\n",
    "#     # Save the figure\n",
    "#     try:          \n",
    "#         figure_file = data_path.parent / f\"{session_name}_{event_name}_baselined.pdf\"\n",
    "#         fig.savefig(figure_file, dpi=1200, bbox_inches='tight')\n",
    "#         print(f\"✅ Saved figure to {figure_file}\")\n",
    "#     except Exception as e:\n",
    "#         print(f\"⚠️ ERROR saving figure: {str(e)}\")    \n",
    "\n",
    "#     plt.close(fig)\n",
    "#     return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467731ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #this iterates through data-paths to store figs from baselining function\n",
    "# for data_path in data_paths:\n",
    "\n",
    "#     fig = process_data_path(\n",
    "#         aligned_df=aligned_df,\n",
    "#         baseline_window=baseline_window,\n",
    "#         mouse_name=mouse_name\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c205cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
