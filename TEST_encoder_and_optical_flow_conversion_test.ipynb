{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry\n",
    "## Cohort 1 and 2 working, Cohort 0: onix_digital Clock column is 0, explore why and/or use timestamps instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "#import harp\n",
    "import plotly.express as px\n",
    "from scipy.stats import mode\n",
    "\n",
    "import gc # garbage collector for removing large variables from memory instantly \n",
    "import importlib #for force updating changed packages \n",
    "\n",
    "import harp_resources.process\n",
    "import harp_resources.utils\n",
    "from harp_resources import process, utils # Reassign to maintain direct references for force updating \n",
    "#from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate variables \n",
    "has_heartbeat = False\n",
    "cohort0 = False\n",
    "cohort2 = False\n",
    "onix_analog_clock_downsampled = False\n",
    "onix_analog_framecount_upsampled = False\n",
    "common_resampled_rate = 10000 #in Hz\n",
    "unit_conversions = False #\n",
    "save_full_asynchronous_data = False #saves alldata before resampling\n",
    "has_photometry = True #if photometry data is present\n",
    "has_onix_harp = True\n",
    "has_video = True\n",
    "\n",
    "#Cohort 2 tests for Encoder Test, NO photometry, No videodata1 \n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/EncoderTest/2025-02-26T15-03-34') #with ball rotations after motor rotation, first in Y, then in X\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/EncoderTest/2025-02-26T14-57-04')\n",
    "has_heartbeat = True\n",
    "has_photometry = False\n",
    "has_onix_harp = False\n",
    "has_video = False\n",
    "\n",
    "\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "#create loaders \n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "#photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.VideoReader(\"VideoData1\")\n",
    "video_reader2 = utils.VideoReader(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Load all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code\n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "\n",
    "if has_photometry:\n",
    "    print (\"Loading processed photometry\")\n",
    "    photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "    photometry_data.set_index(\"TimeStamp\", inplace=True)\n",
    "    photometry_data.index.name = 'Seconds'\n",
    "    print (\"Loading processed photometry info\")\n",
    "    photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "    print (\"Loading processed photometry events\")\n",
    "    photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "    photometry_events[\"TimeStamp\"] = photometry_events[\"TimeStamp\"] /1000 # convert to seconds from ms\n",
    "    photometry_events.set_index(\"TimeStamp\", inplace=True)\n",
    "    photometry_events.index.name = 'Seconds'\n",
    "\n",
    "if has_video:\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data\n",
    "if has_onix_harp:\n",
    "    print (\"Loading OnixDigital\")\n",
    "    onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "\n",
    "if cohort0:\n",
    "    print (\"Loading OnixAnalogFrameClock\")\n",
    "    onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "    \n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "print (\"Loading OnixAnalogData and converting to boolean photodiode array\")\n",
    "photodiode = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True, method='adaptive', refractory = 300, flip=True, verbose=False) #method adaptive or threshold (which is hard threshold at 120), refractory to avoid multiple detections\n",
    "\n",
    "#read HARP data\n",
    "print (\"Loading H1 and H2 streams, AnalogInput removed\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True, has_heartbeat = has_heartbeat, verbose = False) #loads as df, or if False, as dict\n",
    "harp_streams.drop(columns=[\"AnalogInput(39)\"], inplace=True)  # Removes AnalogInput permanently, as not currently used\n",
    "harp_streams = harp_streams.dropna(how=\"all\") # remove rows with all NaNs\n",
    "# Convert specific columns in harp_streams to boolean type\n",
    "columns_to_convert = []\n",
    "for col in columns_to_convert:\n",
    "    harp_streams[col] = harp_streams[col].astype(bool)\n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0 and has_onix_harp:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "    onix_harp[\"HarpTime\"] = onix_harp[\"HarpTime\"] + 1 # known issue with current version of ONIX, harp timestamps lag 1 second\n",
    "    print (\"❗Reminder: HarpTime was increased by 1s to account for know issue with ONIX\")\n",
    "\n",
    "print (\"✅ Done Loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy harp_streams to harp_streams_orig for later use\n",
    "harp_streams_orig = harp_streams.copy()\n",
    "\n",
    "# Calculate the minimum and maximum values in the \"Encoder(38)\" column\n",
    "encoder_min = harp_streams_orig[\"Encoder(38)\"].min()\n",
    "encoder_max = harp_streams_orig[\"Encoder(38)\"].max()\n",
    "\n",
    "# Print the minimum and maximum values\n",
    "print(f\"Minimum value in 'Encoder(38)': {encoder_min}\")\n",
    "print(f\"Maximum value in 'Encoder(38)': {encoder_max}\")\n",
    "\n",
    "# Plot the \"Encoder(38)\" column\n",
    "harp_streams_orig[\"Encoder(38)\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Convert platform position and flow sensor streams to real world units and forward fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_streams_orig[\"OpticalTrackingRead0X(46)\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_streams_orig[\"OpticalTrackingRead0Y(46)\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoder values for homing and next event positions as absolute real life 0 position \n",
    "homing_position, next_event_position = process.get_encoder_home_position(experiment_events, harp_streams)\n",
    "print (\"Encoder values for homing and next event positions\")\n",
    "print(f\"Encoder value at 'Homing platform': {homing_position}\")\n",
    "print(f\"Encoder value at the next experiment event: {next_event_position}\")\n",
    "print(\"❗ Warning: home position is determined by the time of the experiment event after 'Homing platform'. It works for e.g. 'Waiting for run threshold' which starts immediately after homing, but may not work for other session types.\")\n",
    "\n",
    "# Perform unit conversions if not already done\n",
    "if not unit_conversions:\n",
    "    harp_streams[\"OpticalTrackingRead0X(46)\"] = process.running_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead0X(46)\"].to_numpy())  # m / s\n",
    "    harp_streams[\"OpticalTrackingRead0Y(46)\"] = process.turning_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead0Y(46)\"].to_numpy())  # degrees / s\n",
    "    harp_streams[\"OpticalTrackingRead1X(46)\"] = process.running_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead1X(46)\"].to_numpy())\n",
    "    harp_streams[\"OpticalTrackingRead1Y(46)\"] = process.turning_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead1Y(46)\"].to_numpy())\n",
    "    \n",
    "    ## Forward fill then bacward fill values to remove NaNs for optical sensors after conversion \n",
    "    # columns_to_fill = [\n",
    "    #     \"OpticalTrackingRead0X(46)\", \"OpticalTrackingRead0Y(46)\",\n",
    "    #     \"OpticalTrackingRead1X(46)\", \"OpticalTrackingRead1Y(46)\"]\n",
    "    # harp_streams[columns_to_fill] = harp_streams[columns_to_fill].ffill().bfill()\n",
    "    \n",
    "    harp_streams[\"Encoder(38)\"] = harp_streams[\"Encoder(38)\"].ffill().bfill() #fill before unit conversion\n",
    "    harp_streams[\"Encoder(38)\"] = process.encoder_unit_conversion(\n",
    "        harp_streams[\"Encoder(38)\"], next_event_position)\n",
    "    \n",
    "\n",
    "\n",
    "    unit_conversions = True\n",
    "    print(\"✅ Unit conversions to real-life values done\")\n",
    "else:\n",
    "    print(\"❗ Flow sensor and encoder values already converted to real-world units, skipping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the \"Encoder(38)\" trace from harp_streams as a line plot\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=harp_streams.index,\n",
    "    y=harp_streams[\"Encoder(38)\"],\n",
    "    mode='lines+markers',\n",
    "    line=dict(dash='dash'),    \n",
    "    name='Encoder(38)',\n",
    "    yaxis='y1'\n",
    "))\n",
    "\n",
    "# Add the \"Encoder(38)\" trace from harp_streams_orig as red dots\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=harp_streams_orig.index,\n",
    "    y=harp_streams_orig[\"Encoder(38)\"],\n",
    "    mode='markers',\n",
    "    name='Encoder(38) (Original)',\n",
    "    marker=dict(color='red', size=8),\n",
    "    yaxis='y2'\n",
    "))\n",
    "\n",
    "# Update layout for secondary y-axis\n",
    "fig.update_layout(\n",
    "    title=\"Encoder Values Over Time\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis=dict(\n",
    "        title=\"Encoder(38)\",\n",
    "        side='left'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=\"Encoder(38) (Original)\",\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Open the figure in the default web browser\n",
    "pio.show(fig, renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_streams_orig[\"OpticalTrackingRead0X(46)\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_streams[\"OpticalTrackingRead0X(46)\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.integrate import cumulative_trapezoid\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "# Fill missing values with 0\n",
    "harp_streams[\"OpticalTrackingRead0X(46)\"].fillna(0, inplace=True)\n",
    "harp_streams[\"OpticalTrackingRead0X(46)\"] = harp_streams[\"OpticalTrackingRead0X(46)\"].rolling(window=3, center=True).mean()\n",
    "\n",
    "# Calculate the cumulative integral of the \"OpticalTrackingRead0X(46)\" column\n",
    "optical_tracking_values = harp_streams[\"OpticalTrackingRead0X(46)\"].to_numpy()\n",
    "time_values_seconds = (harp_streams.index - harp_streams.index[0]).total_seconds()\n",
    "\n",
    "# Use the cumulative trapezoidal rule to calculate the integral\n",
    "cumulative_integral = cumulative_trapezoid(optical_tracking_values, x=time_values_seconds, initial=0)\n",
    "\n",
    "# Create a new DataFrame with the resulting integral values and the original datetime index\n",
    "integral_df = pd.DataFrame(cumulative_integral, index=harp_streams.index, columns=[\"CumulativeIntegral_OpticalTrackingRead0X(46)\"])\n",
    "\n",
    "#------------------------------------------------\n",
    "# Create a figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add the original values trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=harp_streams.index,\n",
    "    y=harp_streams[\"OpticalTrackingRead0X(46)\"],\n",
    "    mode='lines+markers',\n",
    "    name='Original Values',\n",
    "    line=dict(color='red'),\n",
    "    marker=dict(size=8),\n",
    "    yaxis='y1'\n",
    "))\n",
    "\n",
    "# Add the cumulative integral trace\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=integral_df.index,\n",
    "    y=integral_df[\"CumulativeIntegral_OpticalTrackingRead0X(46)\"],\n",
    "    mode='lines+markers',\n",
    "    name='Cumulative Integral',\n",
    "    line=dict(color='blue'),\n",
    "    marker=dict(size=8),\n",
    "    yaxis='y2'\n",
    "))\n",
    "\n",
    "# Update layout for secondary y-axis\n",
    "fig.update_layout(\n",
    "    title=\"Cumulative Integral and Original Values\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis=dict(\n",
    "        title=\"Original Values\",\n",
    "        side='left'\n",
    "    ),\n",
    "    yaxis2=dict(\n",
    "        title=\"Cumulative Integral\",\n",
    "        overlaying='y',\n",
    "        side='right'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Open the figure in the default web browser\n",
    "pio.show(fig, renderer='browser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_tracking_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
