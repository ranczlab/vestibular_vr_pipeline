{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry\n",
    "## Cohort 1 and 2 working, Cohort 0: onix_digital Clock column is 0, explore why and/or use timestamps instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import mode\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "\n",
    "import gc # garbage collector for removing large variables from memory instantly \n",
    "import importlib #for force updating changed packages \n",
    "\n",
    "#import harp\n",
    "import harp_resources.process\n",
    "import harp_resources.utils\n",
    "from harp_resources import process, utils # Reassign to maintain direct references for force updating \n",
    "#from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate variables \n",
    "has_heartbeat = False\n",
    "cohort0 = False\n",
    "cohort2 = False\n",
    "onix_analog_clock_downsampled = False\n",
    "onix_analog_framecount_upsampled = False\n",
    "common_resampled_rate = 10000 #in Hz\n",
    "unit_conversions = False #\n",
    "save_full_asynchronous_data = False #saves alldata before resampling\n",
    "has_photometry = True #if photometry data is present\n",
    "has_onix_harp = True\n",
    "has_video = True\n",
    "\n",
    "#Cohort 2 tests for Encoder Test, NO photometry, No videodata1 \n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/EncoderTest/2025-02-26T15-03-34') #with ball rotations after motor rotation, first in Y, then in X\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/EncoderTest/2025-02-26T14-57-04')\n",
    "has_heartbeat = True\n",
    "has_photometry = False\n",
    "has_onix_harp = False\n",
    "has_video = False\n",
    "\n",
    "\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "#create loaders \n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "#photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.VideoReader(\"VideoData1\")\n",
    "video_reader2 = utils.VideoReader(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Load all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code\n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "\n",
    "if has_photometry:\n",
    "    print (\"Loading processed photometry\")\n",
    "    photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "    photometry_data.set_index(\"TimeStamp\", inplace=True)\n",
    "    photometry_data.index.name = 'Seconds'\n",
    "    print (\"Loading processed photometry info\")\n",
    "    photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "    print (\"Loading processed photometry events\")\n",
    "    photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "    photometry_events[\"TimeStamp\"] = photometry_events[\"TimeStamp\"] /1000 # convert to seconds from ms\n",
    "    photometry_events.set_index(\"TimeStamp\", inplace=True)\n",
    "    photometry_events.index.name = 'Seconds'\n",
    "\n",
    "if has_video:\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data\n",
    "if has_onix_harp:\n",
    "    print (\"Loading OnixDigital\")\n",
    "    onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "\n",
    "if cohort0:\n",
    "    print (\"Loading OnixAnalogFrameClock\")\n",
    "    onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "    \n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "print (\"Loading OnixAnalogData and converting to boolean photodiode array\")\n",
    "photodiode = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True, method='adaptive', refractory = 300, flip=True, verbose=False) #method adaptive or threshold (which is hard threshold at 120), refractory to avoid multiple detections\n",
    "\n",
    "#read HARP data\n",
    "print (\"Loading H1 and H2 streams, AnalogInput removed\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True, has_heartbeat = has_heartbeat, verbose = False) #loads as df, or if False, as dict\n",
    "harp_streams.drop(columns=[\"AnalogInput(39)\"], inplace=True)  # Removes AnalogInput permanently, as not currently used\n",
    "harp_streams = harp_streams.dropna(how=\"all\") # remove rows with all NaNs\n",
    "# Convert specific columns in harp_streams to boolean type\n",
    "columns_to_convert = []\n",
    "for col in columns_to_convert:\n",
    "    harp_streams[col] = harp_streams[col].astype(bool)\n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0 and has_onix_harp:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "    onix_harp[\"HarpTime\"] = onix_harp[\"HarpTime\"] + 1 # known issue with current version of ONIX, harp timestamps lag 1 second\n",
    "    print (\"❗Reminder: HarpTime was increased by 1s to account for know issue with ONIX\")\n",
    "\n",
    "print (\"✅ Done Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Convert platform position and flow sensor streams to real world units and forward fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_streams_orig = harp_streams.copy() #keep original data for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoder values for homing and next event positions as absolute real life 0 position \n",
    "homing_position, next_event_position = process.get_encoder_home_position(experiment_events, harp_streams)\n",
    "print (\"Encoder values for homing and next event positions\")\n",
    "print(f\"Encoder value at 'Homing platform': {homing_position}\")\n",
    "print(f\"Encoder value at the next experiment event: {next_event_position}\")\n",
    "print(\"❗ Warning: home position is determined by the time of the experiment event after 'Homing platform'. It works for e.g. 'Waiting for run threshold' which starts immediately after homing, but may not work for other session types.\")\n",
    "\n",
    "# Perform unit conversions if not already done\n",
    "if not unit_conversions:\n",
    "    harp_streams[\"OpticalTrackingRead0X(46)\"] = process.running_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead0X(46)\"].to_numpy())  # m / s\n",
    "    harp_streams[\"OpticalTrackingRead0Y(46)\"] = process.turning_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead0Y(46)\"].to_numpy())  # degrees / s\n",
    "    harp_streams[\"OpticalTrackingRead1X(46)\"] = process.running_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead1X(46)\"].to_numpy())\n",
    "    harp_streams[\"OpticalTrackingRead1Y(46)\"] = process.turning_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead1Y(46)\"].to_numpy())\n",
    "    \n",
    "    ## Forward fill then bacward fill values to remove NaNs for optical sensors after conversion \n",
    "    # columns_to_fill = [\n",
    "    #     \"OpticalTrackingRead0X(46)\", \"OpticalTrackingRead0Y(46)\",\n",
    "    #     \"OpticalTrackingRead1X(46)\", \"OpticalTrackingRead1Y(46)\"]\n",
    "    # harp_streams[columns_to_fill] = harp_streams[columns_to_fill].ffill().bfill()\n",
    "    \n",
    "    harp_streams[\"Encoder(38)\"] = harp_streams[\"Encoder(38)\"].ffill().bfill() #fill before unit conversion\n",
    "    harp_streams[\"Encoder(38)\"] = process.encoder_unit_conversion(\n",
    "        harp_streams[\"Encoder(38)\"], next_event_position)\n",
    "    \n",
    "\n",
    "\n",
    "    unit_conversions = True\n",
    "    print(\"✅ Unit conversions to real-life values done\")\n",
    "else:\n",
    "    print(\"❗ Flow sensor and encoder values already converted to real-world units, skipping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate position from X and Y optical signals \n",
    "# only processing sensor 0 at this time \n",
    "\n",
    "columns_to_process = [\"OpticalTrackingRead0X(46)\", \"OpticalTrackingRead0Y(46)\"] # for sensor 1, add \"OpticalTrackingRead1X(46)\", \"OpticalTrackingRead1Y(46)\"\n",
    "for column in columns_to_process:\n",
    "    # Drop missing values\n",
    "    optical_tracking_values = harp_streams[column].dropna().to_numpy()\n",
    "    time_values_seconds = (harp_streams[column].dropna().index - harp_streams.index[0]).total_seconds()\n",
    "\n",
    "    # Smooth the optical tracking values\n",
    "    optical_tracking_values = process.moving_average_smoothing(optical_tracking_values, 3)\n",
    "\n",
    "    # Use the cumulative trapezoidal rule to calculate the integral\n",
    "    cumulative_integral = cumulative_trapezoid(optical_tracking_values, x=time_values_seconds, initial=0)\n",
    "\n",
    "    # Create a new DataFrame with the resulting integral values and the original datetime index\n",
    "    integral_df = pd.DataFrame(cumulative_integral, index=harp_streams[column].dropna().index, columns=[f\"CumulativeIntegral_{column}\"])\n",
    "\n",
    "    # Reindex the processed data back to the original datetime index\n",
    "    integral_df = integral_df.reindex(harp_streams.index, fill_value=np.nan)\n",
    "    optical_tracking_values_reindexed = pd.Series(optical_tracking_values, index=harp_streams[column].dropna().index).reindex(harp_streams.index, fill_value=np.nan)\n",
    "\n",
    "    # Return the smoothed optical_tracking_values to the source column in harp_streams\n",
    "    harp_streams[column] = optical_tracking_values_reindexed\n",
    "    harp_streams[f\"Position_{column}\"] = integral_df[f\"CumulativeIntegral_{column}\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------\n",
    "# Encoder axes colours and labels are still wrong \n",
    "#---------------------------\n",
    "\n",
    "# Define the columns to process\n",
    "columns_to_process = [\"OpticalTrackingRead0X(46)\", \"OpticalTrackingRead0Y(46)\", \n",
    "                     \"OpticalTrackingRead0Brightness(46)\", \"Encoder(38)\"]\n",
    "\n",
    "# Create a single figure with 4 subplots (2x2 grid)\n",
    "fig = make_subplots(rows=2, cols=2, \n",
    "                   subplot_titles=columns_to_process,\n",
    "                   specs=[[{\"secondary_y\": True}, {\"secondary_y\": True}],\n",
    "                          [{\"secondary_y\": False}, {\"secondary_y\": True}]])\n",
    "\n",
    "# Define consistent colors\n",
    "primary_color = 'black'\n",
    "secondary_color = 'blue'\n",
    "\n",
    "# Process each column and add to the appropriate subplot\n",
    "for i, column in enumerate(columns_to_process):\n",
    "    row = i // 2 + 1\n",
    "    col = i % 2 + 1\n",
    "    \n",
    "    if i < 2 and f\"Position_{column}\" in harp_streams.columns:\n",
    "        # For the first two plots, use dual y-axes\n",
    "        # Add the original values trace on primary y-axis\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=harp_streams.index,\n",
    "                y=harp_streams[column],\n",
    "                mode='lines+markers',\n",
    "                name=f'raw counts',  # Simplified legend name\n",
    "                line=dict(color=primary_color),\n",
    "                marker=dict(size=4),\n",
    "                legendgroup=f'group{i}',\n",
    "                legendgrouptitle_text=column\n",
    "            ),\n",
    "            row=row, col=col, secondary_y=False\n",
    "        )\n",
    "        \n",
    "        # Add the position trace on secondary y-axis\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=harp_streams.index,\n",
    "                y=harp_streams[f\"Position_{column}\"],\n",
    "                mode='lines+markers',\n",
    "                name=f'position',  # Simplified legend name\n",
    "                line=dict(color=secondary_color),\n",
    "                marker=dict(size=4),\n",
    "                legendgroup=f'group{i}',\n",
    "                legendgrouptitle_text=column\n",
    "            ),\n",
    "            row=row, col=col, secondary_y=True\n",
    "        )\n",
    "        \n",
    "        # Set y-axis titles with matching colors\n",
    "        if column == \"OpticalTrackingRead0X(46)\":\n",
    "            fig.update_yaxes(title_text=\"Running displacement (raw counts)\", title_font=dict(color=primary_color), \n",
    "                             tickfont=dict(color=primary_color), row=row, col=col, secondary_y=False)\n",
    "            fig.update_yaxes(title_text=\"Running position (m)\", title_font=dict(color=secondary_color), \n",
    "                             tickfont=dict(color=secondary_color), row=row, col=col, secondary_y=True)\n",
    "        elif column == \"OpticalTrackingRead0Y(46)\":\n",
    "            fig.update_yaxes(title_text=\"Turning displacement (raw counts)\", title_font=dict(color=primary_color), \n",
    "                             tickfont=dict(color=primary_color), row=row, col=col, secondary_y=False)\n",
    "            fig.update_yaxes(title_text=\"Turning position (degrees)\", title_font=dict(color=secondary_color), \n",
    "                             tickfont=dict(color=secondary_color), row=row, col=col, secondary_y=True)\n",
    "            \n",
    "    else:\n",
    "        # For the other plots\n",
    "        if column == \"Encoder(38)\":\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=harp_streams.index,\n",
    "                    y=harp_streams[column],\n",
    "                    mode='lines+markers',\n",
    "                    name=f'Converted degrees',  # Simplified legend name\n",
    "                    line=dict(color=secondary_color), \n",
    "                    marker=dict(size=4),\n",
    "                    legendgroup=f'group{i}',\n",
    "                    legendgrouptitle_text=column\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "        else:\n",
    "            # For other plots, keep the original color\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=harp_streams.index,\n",
    "                    y=harp_streams[column],\n",
    "                    mode='lines+markers',\n",
    "                    name=f'Raw',  # Simplified legend name\n",
    "                    line=dict(color=primary_color),\n",
    "                    marker=dict(size=4),\n",
    "                    legendgroup=f'group{i}',\n",
    "                    legendgrouptitle_text=column\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "        \n",
    "        # Add the position trace if it exists\n",
    "        if f\"Position_{column}\" in harp_streams.columns:\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=harp_streams.index,\n",
    "                    y=harp_streams[f\"Position_{column}\"],\n",
    "                    mode='lines+markers',\n",
    "                    name=f'Position',  # Simplified legend name\n",
    "                    line=dict(color=secondary_color),\n",
    "                    marker=dict(size=4),\n",
    "                    legendgroup=f'group{i}',\n",
    "                    legendgrouptitle_text=column\n",
    "                ),\n",
    "                row=row, col=col\n",
    "            )\n",
    "        \n",
    "        # For the encoder plot, add the original values on a secondary y-axis\n",
    "        if column == \"Encoder(38)\" and \"Encoder(38)\" in harp_streams_orig.columns:\n",
    "            fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=harp_streams_orig.index,\n",
    "                y=harp_streams_orig[\"Encoder(38)\"],\n",
    "                mode='lines+markers',\n",
    "                name='Original',  # Simplified legend name\n",
    "                line=dict(color=primary_color), \n",
    "                marker=dict(size=4),\n",
    "                legendgroup=f'group{i}',\n",
    "                legendgrouptitle_text=column\n",
    "            ),\n",
    "            row=row, col=col, secondary_y=True\n",
    "            )\n",
    "            \n",
    "            # Update secondary y-axis title to match trace color (black)\n",
    "            fig.update_yaxes(title_text=\"Encoder (raw)\", title_font=dict(color=primary_color),\n",
    "                             tickfont=dict(color=primary_color), row=row, col=col, secondary_y=True)\n",
    "        \n",
    "        # Set appropriate y-axis titles based on the column with matching colors\n",
    "        if column == \"OpticalTrackingRead0Brightness(46)\":\n",
    "            fig.update_yaxes(title_text=\"Sensor Brightness (SQUAL)\", title_font=dict(color=primary_color),\n",
    "                             tickfont=dict(color=primary_color), row=row, col=col)\n",
    "        else:  # Encoder(38)\n",
    "            # Update primary y-axis title for encoder to match trace color (blue)\n",
    "            fig.update_yaxes(title_text=\"Encoder (degrees)\", title_font=dict(color=secondary_color),\n",
    "                     tickfont=dict(color=secondary_color), row=row, col=col)\n",
    "\n",
    "# Update layout for the entire figure\n",
    "fig.update_layout(\n",
    "    title=\"Sensor Readings\",\n",
    "    height=900,  # Larger height for better visibility\n",
    "    width=1200,  # Larger width\n",
    ")\n",
    "\n",
    "# Add separate legends to each subplot\n",
    "for i in range(1, 3):\n",
    "    for j in range(1, 3):\n",
    "        subplot_index = (i-1)*2 + j - 1\n",
    "        fig.update_layout(**{\n",
    "            f'legend{subplot_index+1}': dict(\n",
    "                x=0.01 + (j-1)*0.5,  # Position legends in their respective subplot areas\n",
    "                y=0.99 - (i-1)*0.5,\n",
    "                xanchor='left',\n",
    "                yanchor='top',\n",
    "                bgcolor='rgba(255, 255, 255, 0.8)',\n",
    "                bordercolor='rgba(0, 0, 0, 0.2)',\n",
    "                borderwidth=1,\n",
    "                tracegroupgap=5\n",
    "            )\n",
    "        })\n",
    "\n",
    "# Configure legend to show only in its subplot area\n",
    "for trace in fig.data:\n",
    "    trace.update(showlegend=True)\n",
    "    if hasattr(trace, 'legendgroup'):\n",
    "        group_num = int(trace.legendgroup[-1])\n",
    "        legend_num = group_num + 1\n",
    "        trace.update(legend=f'legend{legend_num}')\n",
    "\n",
    "fig.update_xaxes(title_text=\"Time\")\n",
    "\n",
    "# Open the figure in the default web browser\n",
    "pio.show(fig, renderer='browser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
