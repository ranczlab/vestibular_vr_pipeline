{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b677f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------------#\n",
    "# IMPORTS\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import cm\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.subplots as sp\n",
    "import math\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import mode, pearsonr, norm\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.signal import correlate\n",
    "import gc  # garbage collector for removing large variables from memory instantly \n",
    "import importlib  # for force updating changed packages \n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Interactive widgets for dropdowns\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display, clear_output\n",
    "    WIDGETS_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è ipywidgets not available. Install with: pip install ipywidgets\")\n",
    "    WIDGETS_AVAILABLE = False\n",
    "\n",
    "%config Completer.use_jedi = False  # Fixes autocomplete issues\n",
    "%config InlineBackend.figure_format = 'retina'  # Improves plot resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f05154b",
   "metadata": {},
   "source": [
    "# Mean, SEM, and Grand Average Analysis Notebook\n",
    "\n",
    "This notebook computes mean and SEM per mouse and grand averages across selected animals.\n",
    "\n",
    "**Usage:**\n",
    "1. Configure settings in the Configuration section below\n",
    "2. Select animals to process\n",
    "3. Choose whether to save pickle and CSV files\n",
    "4. Run the analysis cells\n",
    "5. Use interactive dropdowns for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca8b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cohort: Cohort3\n",
      "‚úÖ Available mice: ['B6J2780', 'B6J2781', 'B6J2783', 'B6J2782']\n",
      "‚úÖ Selected mice: ['B6J2780', 'B6J2781', 'B6J2783', 'B6J2782']\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION SECTION\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "# Configure all settings here before running the analysis\n",
    "\n",
    "# Cohort selection\n",
    "COHORT_OPTIONS = {\n",
    "    \"Cohort1\": {\n",
    "        \"mice\": ['B6J2717', 'B6J2718', 'B6J2719', 'B6J2721', 'B6J2722', 'B6J2723'],\n",
    "        \"identifier\": \"Cohort1\"\n",
    "    },\n",
    "    \"Cohort3\": {\n",
    "        \"mice\": [\"B6J2780\", \"B6J2781\", \"B6J2783\", \"B6J2782\"],\n",
    "        \"identifier\": \"Cohort3\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Select cohort\n",
    "cohort_identifier = \"Cohort3\"  # Options: \"Cohort1\" or \"Cohort31\n",
    "\n",
    "# Select which animals to process (subset of the cohort's available mice)\n",
    "# Leave empty list [] to process all mice in the cohort\n",
    "selected_mice = []  # Example: ['B6J2717', 'B6J2718'] or [] for all\n",
    "\n",
    "# Event name for CSV file loading\n",
    "event_name = '_Apply halt_2s_right_turns_baselined_data.csv'  # Options: '_Apply halt_2s_baselined_data.csv','_Apply halt_2s_right_turns_baselined_data', '_Apply halt_2s_left_turns_baselined_data', '_No halt_right_turns_baselined_data.csv', '_No halt_left_turns_baselined_data.csv'\n",
    "\n",
    "# Data columns to analyze\n",
    "selected_columns = [\n",
    "    'Velocity_0X_Baseline', 'Motor_Velocity_Baseline', \n",
    "    'z_470_Baseline', 'z_560_Baseline',\n",
    "    'Velocity_0X', 'Motor_Velocity', 'z_470', 'z_560'\n",
    "]\n",
    "\n",
    "# Columns to plot\n",
    "columns_to_plot = [\n",
    "    'Velocity_0X_Baseline', 'Motor_Velocity_Baseline', \n",
    "    'z_470_Baseline', 'z_560_Baseline'\n",
    "]\n",
    "\n",
    "# Save options\n",
    "SAVE_PICKLE = False  # Save results as pickle file\n",
    "SAVE_CSV = True      # Save grand averages with SEM as CSV file\n",
    "GENERATE_PLOTS = True  # Generate plots\n",
    "\n",
    "# Data directories (add your paths here)\n",
    "DATA_DIRS = [\n",
    "    # Path('/home/ikharitonov/RANCZLAB-NAS/data/ONIX/20241125_Cohort1_rotation/Visual_mismatch_day4').expanduser(),\n",
    "    Path('/home/ikharitonov/RANCZLAB-NAS/data/ONIX/20250409_Cohort3_rotation/Visual_mismatch_day3').expanduser(),\n",
    "    # Path('/Volumes/RanczLab2/20250409_Cohort3_rotation/Vestibular_mismatch_day1').expanduser(),\n",
    "    # Add more directories as needed\n",
    "]\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "# Auto-configure based on cohort selection\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "if cohort_identifier in COHORT_OPTIONS:\n",
    "    cohort_info = COHORT_OPTIONS[cohort_identifier]\n",
    "    available_mice = cohort_info[\"mice\"]\n",
    "    if not selected_mice:  # If empty, use all mice\n",
    "        selected_mice = available_mice\n",
    "    else:  # Filter to only include valid mice\n",
    "        selected_mice = [m for m in selected_mice if m in available_mice]\n",
    "    print(f\"‚úÖ Cohort: {cohort_identifier}\")\n",
    "    print(f\"‚úÖ Available mice: {available_mice}\")\n",
    "    print(f\"‚úÖ Selected mice: {selected_mice}\")\n",
    "else:\n",
    "    raise ValueError(f\"Invalid cohort_identifier: {cohort_identifier}. Must be one of {list(COHORT_OPTIONS.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ed85884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è File not found: /home/ikharitonov/RANCZLAB-NAS/data/ONIX/20250409_Cohort3_rotation/Visual_mismatch_day3/B6J2783_processedData/aligned_data/B6J2783_Apply halt_2s_right_turns_baselined_data, skipping...\n",
      "‚ö†Ô∏è File not found: /home/ikharitonov/RANCZLAB-NAS/data/ONIX/20250409_Cohort3_rotation/Visual_mismatch_day3/B6J2781-2025-04-25T12-30-52_processedData/aligned_data/B6J2781_Apply halt_2s_right_turns_baselined_data, skipping...\n",
      "‚ö†Ô∏è File not found: /home/ikharitonov/RANCZLAB-NAS/data/ONIX/20250409_Cohort3_rotation/Visual_mismatch_day3/B6J2780-2025-04-25T11-51-53_processedData/aligned_data/B6J2780_Apply halt_2s_right_turns_baselined_data, skipping...\n",
      "‚ö†Ô∏è File not found: /home/ikharitonov/RANCZLAB-NAS/data/ONIX/20250409_Cohort3_rotation/Visual_mismatch_day3/B6J2783-2025-04-25T13-41-53_processedData/aligned_data/B6J2783_Apply halt_2s_right_turns_baselined_data, skipping...\n",
      "‚ö†Ô∏è File not found: /home/ikharitonov/RANCZLAB-NAS/data/ONIX/20250409_Cohort3_rotation/Visual_mismatch_day3/B6J2780_processedData/aligned_data/B6J2780_Apply halt_2s_right_turns_baselined_data, skipping...\n",
      "‚ö†Ô∏è File not found: /home/ikharitonov/RANCZLAB-NAS/data/ONIX/20250409_Cohort3_rotation/Visual_mismatch_day3/B6J2781_processedData/aligned_data/B6J2781_Apply halt_2s_right_turns_baselined_data, skipping...\n",
      "\n",
      "üìä Loaded data for 0 mice\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADING\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "def load_aligned_data(data_dirs, event_name, selected_mice):\n",
    "    \"\"\"\n",
    "    Load aligned data from CSV files for selected mice.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data_dirs : list\n",
    "        List of data directory paths\n",
    "    event_name : str\n",
    "        Event name suffix for CSV files\n",
    "    selected_mice : list\n",
    "        List of mouse names to load\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    loaded_data : dict\n",
    "        Dictionary with data paths as keys and mouse data as values\n",
    "    \"\"\"\n",
    "    # Collect raw data paths (excluding '_processedData' dirs)\n",
    "    rawdata_paths = []\n",
    "    for data_dir in data_dirs:\n",
    "        if not Path(data_dir).exists():\n",
    "            print(f\"‚ö†Ô∏è Directory does not exist: {data_dir}\")\n",
    "            continue\n",
    "        subdirs = [p for p in Path(data_dir).iterdir() if p.is_dir() and not p.name.endswith('_processedData')]\n",
    "        rawdata_paths.extend(subdirs)\n",
    "    \n",
    "    if not rawdata_paths:\n",
    "        print(\"‚ö†Ô∏è No raw data paths found!\")\n",
    "        return {}\n",
    "    \n",
    "    # Build processed data paths\n",
    "    data_paths = [raw.parent / f\"{raw.name}_processedData/aligned_data\" for raw in rawdata_paths]\n",
    "    mouse_names = [raw.name.split('-')[0] for raw in rawdata_paths]\n",
    "    \n",
    "    # Load data\n",
    "    loaded_data = {}\n",
    "    for idx, data_path in enumerate(data_paths, start=1):\n",
    "        mouse_name = mouse_names[idx - 1]\n",
    "        \n",
    "        # Skip if mouse not in selected list\n",
    "        if selected_mice and mouse_name not in selected_mice:\n",
    "            print(f\"‚è≠Ô∏è  Skipping {mouse_name} (not in selected_mice)\")\n",
    "            continue\n",
    "        \n",
    "        if mouse_name == 'baselined':\n",
    "            print(f\"‚ö†Ô∏è Skipping directory {data_path} as it does not contain a valid mouse name.\")\n",
    "            continue\n",
    "        \n",
    "        csv_file_path = data_path / f\"{mouse_name}{event_name}\"\n",
    "        \n",
    "        try:\n",
    "            aligned_df = pd.read_csv(csv_file_path)\n",
    "            print(f\"‚úÖ [{idx}/{len(data_paths)}] Loaded {mouse_name} from {csv_file_path}\")\n",
    "            \n",
    "            loaded_data[data_path] = {\n",
    "                'mouse_name': mouse_name,\n",
    "                'data_path': data_path\n",
    "            }\n",
    "            \n",
    "            # Add each column as a separate key\n",
    "            for column in aligned_df.columns:\n",
    "                loaded_data[data_path][column] = aligned_df[column].values\n",
    "            \n",
    "            print(f\"   Data: {len(aligned_df)} rows, {len(aligned_df.columns)} columns\")\n",
    "            del aligned_df\n",
    "            gc.collect()\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            print(f\"‚ö†Ô∏è File not found: {csv_file_path}, skipping...\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nüìä Loaded data for {len(loaded_data)} mice\")\n",
    "    return loaded_data\n",
    "\n",
    "# Load the data\n",
    "loaded_data = load_aligned_data(DATA_DIRS, event_name, selected_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89dc0c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS FUNCTIONS\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def compute_mouse_means_and_grand_average(loaded_data, selected_columns, main_data_dir, selected_mice):\n",
    "    \"\"\"\n",
    "    Compute means per mouse and grand averages across selected mice for selected columns.\n",
    "    \n",
    "    Parameters:\n",
    "    loaded_data (dict): Dictionary with data paths as keys and mouse data as values\n",
    "    selected_columns (list): List of column names to analyze\n",
    "    main_data_dir (str/Path): Main directory to save results\n",
    "    selected_mice (list): List of mouse names to include in the grand average\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (mean_data_per_mouse, sem_data_per_mouse, grand_averages, grand_sems)\n",
    "    \"\"\"\n",
    "    \n",
    "    main_data_dir = Path(main_data_dir)\n",
    "    \n",
    "    print(f\"Processing selected columns: {selected_columns}\")\n",
    "    \n",
    "    # Step 1: Compute mean and SEM for each mouse\n",
    "    mean_data_per_mouse = {}\n",
    "    sem_data_per_mouse = {}\n",
    "    \n",
    "    for data_path, data in loaded_data.items():\n",
    "        mouse_name = data['mouse_name']\n",
    "        if mouse_name not in selected_mice:\n",
    "            print(f\"Skipping mouse {mouse_name} as it is not in the selected mice list.\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"Processing mouse: {mouse_name}\")\n",
    "        \n",
    "        # Create DataFrame from the loaded data\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Check which selected columns are available\n",
    "        available_columns = [col for col in selected_columns if col in df.columns]\n",
    "        missing_columns = [col for col in selected_columns if col not in df.columns]\n",
    "        \n",
    "        if missing_columns:\n",
    "            print(f\"‚ö†Ô∏è  Missing columns for {mouse_name}: {missing_columns}\")\n",
    "        \n",
    "        if 'Time (s)' not in df.columns:\n",
    "            print(f\"‚ö†Ô∏è  'Time (s)' column not found for {mouse_name}, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        # Group by time and compute mean and SEM\n",
    "        grouped = df.groupby('Time (s)')\n",
    "        \n",
    "        # Only use numeric columns that are in our selected list\n",
    "        numeric_selected = []\n",
    "        for col in available_columns:\n",
    "            if col != 'Time (s)' and pd.api.types.is_numeric_dtype(df[col]):\n",
    "                numeric_selected.append(col)\n",
    "        \n",
    "        if len(numeric_selected) == 0:\n",
    "            print(f\"‚ö†Ô∏è  No numeric columns found for {mouse_name}\")\n",
    "            continue\n",
    "        \n",
    "        mean_data_per_mouse[mouse_name] = grouped[numeric_selected].mean()\n",
    "        sem_data_per_mouse[mouse_name] = grouped[numeric_selected].sem()\n",
    "        \n",
    "        print(f\"‚úÖ Processed {len(numeric_selected)} columns for {mouse_name}\")\n",
    "    \n",
    "    # Step 2: Compute grand averages across selected mice\n",
    "    print(f\"\\nüìä Computing grand averages across {len(mean_data_per_mouse)} selected mice...\")\n",
    "    \n",
    "    # Get all unique time points\n",
    "    all_time_points = set()\n",
    "    for mouse_data in mean_data_per_mouse.values():\n",
    "        all_time_points.update(mouse_data.index)\n",
    "    all_time_points = sorted(list(all_time_points))\n",
    "    \n",
    "    # Get all columns that were successfully processed\n",
    "    all_processed_columns = set()\n",
    "    for mouse_data in mean_data_per_mouse.values():\n",
    "        all_processed_columns.update(mouse_data.columns)\n",
    "    all_processed_columns = sorted(list(all_processed_columns))\n",
    "    \n",
    "    print(f\"Time points: {len(all_time_points)} from {min(all_time_points):.2f}s to {max(all_time_points):.2f}s\")\n",
    "    print(f\"Processed columns: {all_processed_columns}\")\n",
    "    \n",
    "    # Create grand average DataFrame\n",
    "    grand_averages = pd.DataFrame(index=all_time_points, columns=all_processed_columns)\n",
    "    grand_averages.index.name = 'Time (s)'\n",
    "    \n",
    "    grand_sems = pd.DataFrame(index=all_time_points, columns=all_processed_columns)\n",
    "    grand_sems.index.name = 'Time (s)'\n",
    "    \n",
    "    # Compute grand averages for each column and time point\n",
    "    for col in all_processed_columns:\n",
    "        for time_point in all_time_points:\n",
    "            # Collect data from all selected mice for this time point and column\n",
    "            mouse_values = []\n",
    "            for mouse_name, mouse_data in mean_data_per_mouse.items():\n",
    "                if time_point in mouse_data.index and col in mouse_data.columns:\n",
    "                    value = mouse_data.loc[time_point, col]\n",
    "                    if not pd.isna(value):\n",
    "                        mouse_values.append(value)\n",
    "            \n",
    "            if len(mouse_values) > 0:\n",
    "                grand_averages.loc[time_point, col] = np.mean(mouse_values)\n",
    "                if len(mouse_values) > 1:\n",
    "                    grand_sems.loc[time_point, col] = np.std(mouse_values) / np.sqrt(len(mouse_values))\n",
    "                else:\n",
    "                    grand_sems.loc[time_point, col] = 0\n",
    "    \n",
    "    return mean_data_per_mouse, sem_data_per_mouse, grand_averages, grand_sems\n",
    "\n",
    "def analyze_mice_data(loaded_data, selected_columns, main_data_dir):\n",
    "    \"\"\"\n",
    "    Complete analysis workflow: compute means, grand averages, save CSV, and create plots.\n",
    "    \n",
    "    Parameters:\n",
    "    loaded_data (dict): Your loaded_data dictionary\n",
    "    selected_columns (list): List of column names to analyze (including 'Time (s)')\n",
    "    main_data_dir (str/Path): Main directory to save results\n",
    "    \n",
    "    Returns:\n",
    "    dict: Complete results including individual and grand averages\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"MOUSE DATA ANALYSIS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Use the selected_mice from the configuration (defined in Cell 2)\n",
    "    # Compute means and grand averages\n",
    "    mean_data_per_mouse, sem_data_per_mouse, grand_averages, grand_sems = compute_mouse_means_and_grand_average(\n",
    "        loaded_data, selected_columns, main_data_dir, selected_mice\n",
    "    )\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\nüìä ANALYSIS COMPLETE:\")\n",
    "    print(f\"   ‚Ä¢ Number of mice analyzed: {len(mean_data_per_mouse)}\")\n",
    "    print(f\"   ‚Ä¢ Mouse names: {list(mean_data_per_mouse.keys())}\")\n",
    "    print(f\"   ‚Ä¢ Columns processed: {list(grand_averages.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Time range: {grand_averages.index.min():.2f}s to {grand_averages.index.max():.2f}s\")\n",
    "    print(f\"   ‚Ä¢ Files saved in: {main_data_dir}\")\n",
    "    \n",
    "    # Return all results\n",
    "    results = {\n",
    "        'mean_data_per_mouse': mean_data_per_mouse,\n",
    "        'sem_data_per_mouse': sem_data_per_mouse,\n",
    "        'grand_averages': grand_averages,\n",
    "        'grand_sems': grand_sems,\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea8c6e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No data loaded. Please check your configuration and data paths.\n"
     ]
    }
   ],
   "source": [
    "# RUN ANALYSIS\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def save_results(results, filename='results.pkl'):\n",
    "    \"\"\"Save results to a pickle file.\"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"‚úÖ Results saved to {filename}\")\n",
    "\n",
    "# Determine main data directory\n",
    "main_data_dir = DATA_DIRS[0] if DATA_DIRS else Path.cwd()\n",
    "\n",
    "# Run analysis\n",
    "if loaded_data:\n",
    "    results = analyze_mice_data(loaded_data, selected_columns, main_data_dir)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data loaded. Please check your configuration and data paths.\")\n",
    "    results = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40b7c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≠Ô∏è  Skipping pickle save (SAVE_PICKLE=False or no results)\n"
     ]
    }
   ],
   "source": [
    "# SAVE RESULTS\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "if results and SAVE_PICKLE:\n",
    "    # Generate unique filename\n",
    "    vmm_event_name = main_data_dir.name\n",
    "    pickle_filename = f\"{cohort_identifier}_{vmm_event_name}{event_name.replace('.csv', '')}.pkl\"\n",
    "    save_results(results, pickle_filename)\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping pickle save (SAVE_PICKLE=False or no results)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a258f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTTING FUNCTIONS\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def plot_time_series_and_scatter(results, columns_to_plot, selected_mice, main_data_dir, event_name):\n",
    "    \"\"\"\n",
    "    Plot time series and scatter plots for each column.\n",
    "    \"\"\"\n",
    "    # Plot properties\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['DejaVu Sans'],\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 10,\n",
    "        'legend.fontsize': 8,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    # Generate color palette\n",
    "    color_palette = plt.cm.Set2.colors\n",
    "    mouse_colors = {mouse: color_palette[i % len(color_palette)] for i, mouse in enumerate(selected_mice)}\n",
    "    \n",
    "    for column_to_plot in columns_to_plot:\n",
    "        if column_to_plot not in results['grand_averages'].columns:\n",
    "            print(f\"‚ö†Ô∏è Column {column_to_plot} not found in results, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüìä Plotting: {column_to_plot}\")\n",
    "        \n",
    "        # Time series plot\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        mice_plotted = []\n",
    "        \n",
    "        for mouse in selected_mice:\n",
    "            if mouse in results['mean_data_per_mouse']:\n",
    "                mice_plotted.append(mouse)\n",
    "                mean_data = results['mean_data_per_mouse'][mouse][column_to_plot]\n",
    "                sem_data = results['sem_data_per_mouse'][mouse][column_to_plot]\n",
    "                \n",
    "                mean_data = pd.to_numeric(mean_data, errors='coerce')\n",
    "                sem_data = pd.to_numeric(sem_data, errors='coerce')\n",
    "                time_points = pd.to_numeric(mean_data.index, errors='coerce')\n",
    "                \n",
    "                valid_mask = ~(pd.isna(mean_data) | pd.isna(sem_data) | pd.isna(time_points))\n",
    "                mean_data_clean = mean_data[valid_mask]\n",
    "                sem_data_clean = sem_data[valid_mask]\n",
    "                time_points_clean = time_points[valid_mask]\n",
    "                \n",
    "                plt.plot(time_points_clean, mean_data_clean, label=f'{mouse} Mean', color=mouse_colors[mouse])\n",
    "                plt.fill_between(time_points_clean, mean_data_clean - sem_data_clean, \n",
    "                                mean_data_clean + sem_data_clean, color=mouse_colors[mouse], alpha=0.2)\n",
    "        \n",
    "        # Grand average\n",
    "        grand_mean = results['grand_averages'][column_to_plot]\n",
    "        grand_sem = results['grand_sems'][column_to_plot]\n",
    "        grand_mean = pd.to_numeric(grand_mean, errors='coerce')\n",
    "        grand_sem = pd.to_numeric(grand_sem, errors='coerce')\n",
    "        time_points = pd.to_numeric(grand_mean.index, errors='coerce')\n",
    "        \n",
    "        valid_mask = ~(pd.isna(grand_mean) | pd.isna(grand_sem) | pd.isna(time_points))\n",
    "        grand_mean_clean = grand_mean[valid_mask]\n",
    "        grand_sem_clean = grand_sem[valid_mask]\n",
    "        time_points_clean = time_points[valid_mask]\n",
    "        \n",
    "        plt.plot(time_points_clean, grand_mean_clean, label='Grand Average', color='black', linewidth=2)\n",
    "        plt.fill_between(time_points_clean, grand_mean_clean - grand_sem_clean, \n",
    "                        grand_mean_clean + grand_sem_clean, color='gray', alpha=0.3)\n",
    "        \n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel(column_to_plot)\n",
    "        plt.title(f'Mean and SEM of {column_to_plot} Over Time')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        try:\n",
    "            baselined_dir = main_data_dir / \"baselined\"\n",
    "            baselined_dir.mkdir(exist_ok=True)\n",
    "            plot_filename = baselined_dir / f\"{column_to_plot}{event_name.replace('.csv', '')}.pdf\"\n",
    "            plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n",
    "            print(f\"   ‚úÖ Saved: {plot_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error saving plot: {e}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Scatter plot\n",
    "        pre_time = (-2, 0)\n",
    "        post_time = (0, 2)\n",
    "        \n",
    "        pre_values, post_values, mouse_labels = [], [], []\n",
    "        \n",
    "        for mouse in selected_mice:\n",
    "            if mouse in results['mean_data_per_mouse']:\n",
    "                mean_data = results['mean_data_per_mouse'][mouse][column_to_plot]\n",
    "                pre_mean = mean_data.loc[(mean_data.index >= pre_time[0]) & (mean_data.index < pre_time[1])].mean()\n",
    "                post_mean = mean_data.loc[(mean_data.index >= post_time[0]) & (mean_data.index <= post_time[1])].mean()\n",
    "                pre_values.append(pre_mean)\n",
    "                post_values.append(post_mean)\n",
    "                mouse_labels.append(mouse)\n",
    "        \n",
    "        grand_mean = results['grand_averages'][column_to_plot]\n",
    "        pre_grand_mean = grand_mean.loc[(grand_mean.index >= pre_time[0]) & (grand_mean.index < pre_time[1])].mean()\n",
    "        post_grand_mean = grand_mean.loc[(grand_mean.index >= post_time[0]) & (grand_mean.index <= post_time[1])].mean()\n",
    "        \n",
    "        grand_sem = results['grand_sems'][column_to_plot]\n",
    "        pre_grand_sem = grand_sem.loc[(grand_sem.index >= pre_time[0]) & (grand_sem.index < pre_time[1])].mean()\n",
    "        post_grand_sem = grand_sem.loc[(grand_sem.index >= post_time[0]) & (grand_sem.index <= post_time[1])].mean()\n",
    "        \n",
    "        plt.figure(figsize=(3, 4))\n",
    "        \n",
    "        for i, mouse in enumerate(mouse_labels):\n",
    "            plt.plot([1, 2], [pre_values[i], post_values[i]], color=mouse_colors[mouse], \n",
    "                    marker='o', linewidth=1, label=mouse)\n",
    "        \n",
    "        plt.plot([1, 2], [pre_grand_mean, post_grand_mean], color='black', marker='o', \n",
    "                markersize=8, linewidth=1, label='Grand Avg')\n",
    "        plt.errorbar([1, 2], [pre_grand_mean, post_grand_mean], \n",
    "                    yerr=[pre_grand_sem, post_grand_sem], fmt='o', color='black', capsize=5)\n",
    "        \n",
    "        plt.xticks([1, 2], [pre_time, post_time])\n",
    "        plt.title(f'Mean {column_to_plot} Before and After Time 0')\n",
    "        plt.ylabel(column_to_plot)\n",
    "        plt.xlim(0.8, 2.2)\n",
    "        plt.grid(True)\n",
    "        \n",
    "        if column_to_plot == 'Velocity_0X_Baseline':\n",
    "            plt.ylim(-0.01, 0.08)\n",
    "        \n",
    "        handles, labels = plt.gca().get_legend_handles_labels()\n",
    "        unique_labels = {}\n",
    "        for h, l in zip(handles, labels):\n",
    "            if l not in unique_labels:\n",
    "                unique_labels[l] = h\n",
    "        plt.legend(unique_labels.values(), unique_labels.keys(), loc='best', fontsize='small')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        try:\n",
    "            plot_filename = baselined_dir / f\"{column_to_plot}{event_name.replace('.csv', '')}_scatterplot.pdf\"\n",
    "            plt.savefig(plot_filename, dpi=150, bbox_inches='tight')\n",
    "            print(f\"   ‚úÖ Saved scatter: {plot_filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ö†Ô∏è Error saving scatter plot: {e}\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.clf()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aea5ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # GENERATE PLOTS\n",
    "# #---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# if results and GENERATE_PLOTS:\n",
    "#     print(f\"üìä Generating plots for {len(columns_to_plot)} columns...\")\n",
    "#     print(f\"üìä Selected mice: {selected_mice}\")\n",
    "#     print(f\"üìä Available mice in results: {list(results['mean_data_per_mouse'].keys())}\")\n",
    "    \n",
    "#     missing_mice = [mouse for mouse in selected_mice if mouse not in results['mean_data_per_mouse']]\n",
    "#     if missing_mice:\n",
    "#         print(f\"‚ö†Ô∏è WARNING: These mice are in selected_mice but not in results: {missing_mice}\")\n",
    "    \n",
    "#     plot_time_series_and_scatter(results, columns_to_plot, selected_mice, main_data_dir, event_name)\n",
    "# else:\n",
    "#     print(\"‚è≠Ô∏è  Skipping plot generation (GENERATE_PLOTS=False or no results)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57ab42b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≠Ô∏è  Skipping CSV save (SAVE_CSV=False or no results)\n"
     ]
    }
   ],
   "source": [
    "# SAVE GRAND AVERAGES CSV\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "if results and SAVE_CSV:\n",
    "    # Create a DataFrame combining grand averages and SEMs\n",
    "    grand_avg_with_sem = results['grand_averages'].copy()\n",
    "    for col in results['grand_sems'].columns:\n",
    "        grand_avg_with_sem[f'{col}_SEM'] = results['grand_sems'][col]\n",
    "    \n",
    "    # Generate filename\n",
    "    csv_filename = main_data_dir / f\"grand_averages_with_sem{event_name.replace('.csv', '')}.csv\"\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    grand_avg_with_sem.to_csv(csv_filename)\n",
    "    print(f\"‚úÖ Grand averages with SEM saved to: {csv_filename}\")\n",
    "else:\n",
    "    print(\"‚è≠Ô∏è  Skipping CSV save (SAVE_CSV=False or no results)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fe0919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1377f52a8a8840feab1edbd8f4edab30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<h3>Select multiple files and columns to plot:</h3>'), HTML(value='<p><i>Add multip‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# INTERACTIVE GRAND AVERAGE PLOTTING\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def find_csv_files(base_paths):\n",
    "    \"\"\"Find all grand_averages CSV files in the given paths.\"\"\"\n",
    "    csv_files = []\n",
    "    for base_path in base_paths:\n",
    "        path = Path(base_path)\n",
    "        if path.exists():\n",
    "            # Search in the directory and subdirectories\n",
    "            for csv_file in path.rglob('grand_averages_with_sem*.csv'):\n",
    "                csv_files.append(str(csv_file))\n",
    "    return sorted(csv_files)\n",
    "\n",
    "def get_available_columns(df):\n",
    "    \"\"\"Get available data columns (excluding Time and SEM columns).\"\"\"\n",
    "    # Filter out Time column and SEM columns\n",
    "    data_cols = [col for col in df.columns \n",
    "                 if col != 'Time (s)' and not col.endswith('_SEM')]\n",
    "    return sorted(data_cols)\n",
    "\n",
    "def get_column_label(column_name):\n",
    "    \"\"\"Generate a readable label for a column.\"\"\"\n",
    "    # Map common column names to readable labels\n",
    "    label_map = {\n",
    "        'z_470': 'GRAB-5HT3.0 (z-score)',\n",
    "        'z_470_Baseline': 'GRAB-5HT3.0 (z-score)',\n",
    "        'z_560': 'RGeco1a (z-score)',\n",
    "        'z_560_Baseline': 'RGeco1a (z-score)',\n",
    "        'Velocity_0X': 'Running spped',\n",
    "        'Velocity_0X_Baseline': 'Running speed',\n",
    "        'Motor_Velocity': 'Motor Velocity',\n",
    "        'Motor_Velocity_Baseline': 'Motor Velocity',\n",
    "    }\n",
    "    return label_map.get(column_name, column_name)\n",
    "\n",
    "def get_axis_label(column_name):\n",
    "    \"\"\"Generate axis label based on column name.\"\"\"\n",
    "    if 'z_' in column_name or 'z-score' in column_name.lower():\n",
    "        return 'z-score'\n",
    "    elif 'Velocity' in column_name or 'velocity' in column_name.lower():\n",
    "        return 'Running speed (m/s)'\n",
    "    elif 'Motor' in column_name:\n",
    "        return 'Motor velocity (m/s)'\n",
    "    else:\n",
    "        return column_name\n",
    "\n",
    "def plot_grand_averages_single(df, label, y1_col=None, y2_col=None):\n",
    "    \"\"\"Plot grand averages from a single CSV file with selected columns.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['DejaVu Sans'],\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 10,\n",
    "        'legend.fontsize': 8,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax2 = None\n",
    "    \n",
    "    # Plot y1 column on left axis\n",
    "    if y1_col and y1_col in df.columns:\n",
    "        ax.plot(df['Time (s)'], df[y1_col], label=get_column_label(y1_col), \n",
    "                color='green', alpha=1)\n",
    "        if f'{y1_col}_SEM' in df.columns:\n",
    "            ax.fill_between(df['Time (s)'],\n",
    "                           df[y1_col] - df[f'{y1_col}_SEM'],\n",
    "                           df[y1_col] + df[f'{y1_col}_SEM'],\n",
    "                           color='green', alpha=0.1)\n",
    "        ax.set_ylabel(get_axis_label(y1_col), fontname='DejaVu Sans', fontsize=10, color='black')\n",
    "        ax.tick_params(axis='y', labelcolor='black')\n",
    "    \n",
    "    # Plot y2 column on right axis (if different from y1)\n",
    "    if y2_col and y2_col in df.columns and y2_col != y1_col:\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(df['Time (s)'], df[y2_col], label=get_column_label(y2_col), \n",
    "                color='slategray', alpha=1)\n",
    "        if f'{y2_col}_SEM' in df.columns:\n",
    "            ax2.fill_between(df['Time (s)'],\n",
    "                            df[y2_col] - df[f'{y2_col}_SEM'],\n",
    "                            df[y2_col] + df[f'{y2_col}_SEM'],\n",
    "                            color='slategray', alpha=0.2)\n",
    "        ax2.set_ylabel(get_axis_label(y2_col), fontname='DejaVu Sans', fontsize=10, color='slategray')\n",
    "        ax2.tick_params(axis='y', labelcolor='slategray')\n",
    "    \n",
    "    ax.axvspan(0, 2, color='gray', alpha=0.2, label='Visual mismatch (0-2s)')\n",
    "    ax.set_title(f'Grand Averages: {label}', fontname='DejaVu Sans', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)', fontname='DejaVu Sans', fontsize=10)\n",
    "    \n",
    "    # Combine legends\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    if ax2:\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines + lines2, labels + labels2, loc='upper right', \n",
    "                 prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    else:\n",
    "        ax.legend(lines, labels, loc='upper right', prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_grand_averages_comparison(df1, df2, label1, label2, y1_col=None, y2_col=None):\n",
    "    \"\"\"Plot grand averages comparing two CSV files with selected columns.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['DejaVu Sans'],\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 10,\n",
    "        'legend.fontsize': 8,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax2 = None\n",
    "    \n",
    "    # Plot y1 column on left axis\n",
    "    if y1_col:\n",
    "        if y1_col in df1.columns:\n",
    "            ax.plot(df1['Time (s)'], df1[y1_col], label=f\"{get_column_label(y1_col)} ({label1})\", \n",
    "                    color='green', alpha=1)\n",
    "            if f'{y1_col}_SEM' in df1.columns:\n",
    "                ax.fill_between(df1['Time (s)'],\n",
    "                               df1[y1_col] - df1[f'{y1_col}_SEM'],\n",
    "                               df1[y1_col] + df1[f'{y1_col}_SEM'],\n",
    "                               color='green', alpha=0.1)\n",
    "        \n",
    "        if y1_col in df2.columns:\n",
    "            ax.plot(df2['Time (s)'], df2[y1_col], label=f\"{get_column_label(y1_col)} ({label2})\", \n",
    "                    color='orange', alpha=1, linestyle='--')\n",
    "            if f'{y1_col}_SEM' in df2.columns:\n",
    "                ax.fill_between(df2['Time (s)'],\n",
    "                               df2[y1_col] - df2[f'{y1_col}_SEM'],\n",
    "                               df2[y1_col] + df2[f'{y1_col}_SEM'],\n",
    "                               color='orange', alpha=0.1)\n",
    "        \n",
    "        ax.set_ylabel(get_axis_label(y1_col), fontname='DejaVu Sans', fontsize=10, color='black')\n",
    "        ax.tick_params(axis='y', labelcolor='black')\n",
    "    \n",
    "    # Plot y2 column on right axis (if different from y1)\n",
    "    if y2_col and y2_col != y1_col:\n",
    "        ax2 = ax.twinx()\n",
    "        \n",
    "        if y2_col in df1.columns:\n",
    "            ax2.plot(df1['Time (s)'], df1[y2_col], label=f\"{get_column_label(y2_col)} ({label1})\", \n",
    "                    color='slategray', alpha=1)\n",
    "            if f'{y2_col}_SEM' in df1.columns:\n",
    "                ax2.fill_between(df1['Time (s)'],\n",
    "                                df1[y2_col] - df1[f'{y2_col}_SEM'],\n",
    "                                df1[y2_col] + df1[f'{y2_col}_SEM'],\n",
    "                                color='slategray', alpha=0.2)\n",
    "        \n",
    "        if y2_col in df2.columns:\n",
    "            ax2.plot(df2['Time (s)'], df2[y2_col], label=f\"{get_column_label(y2_col)} ({label2})\", \n",
    "                    color='slategray', alpha=1, linestyle='--')\n",
    "            if f'{y2_col}_SEM' in df2.columns:\n",
    "                ax2.fill_between(df2['Time (s)'],\n",
    "                                df2[y2_col] - df2[f'{y2_col}_SEM'],\n",
    "                                df2[y2_col] + df2[f'{y2_col}_SEM'],\n",
    "                                color='slategray', alpha=0.2)\n",
    "        \n",
    "        ax2.set_ylabel(get_axis_label(y2_col), fontname='DejaVu Sans', fontsize=10, color='slategray')\n",
    "        ax2.tick_params(axis='y', labelcolor='slategray')\n",
    "    \n",
    "    ax.axvspan(0, 2, color='gray', alpha=0.2, label='Visual mismatch (0-2s)')\n",
    "    ax.set_title('Grand Averages with SEM', fontname='DejaVu Sans', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)', fontname='DejaVu Sans', fontsize=10)\n",
    "    \n",
    "    # Combine legends\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    if ax2:\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines + lines2, labels + labels2, loc='upper right', \n",
    "                 prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    else:\n",
    "        ax.legend(lines, labels, loc='upper right', prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "# INTERACTIVE GRAND AVERAGE PLOTTING\n",
    "#---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "def find_csv_files(base_paths):\n",
    "    \"\"\"Find all grand_averages CSV files in the given paths.\"\"\"\n",
    "    csv_files = []\n",
    "    for base_path in base_paths:\n",
    "        path = Path(base_path)\n",
    "        if path.exists():\n",
    "            # Search in the directory and subdirectories\n",
    "            for csv_file in path.rglob('grand_averages_with_sem*.csv'):\n",
    "                csv_files.append(str(csv_file))\n",
    "    return sorted(csv_files)\n",
    "\n",
    "def get_available_columns(df):\n",
    "    \"\"\"Get available data columns (excluding Time and SEM columns).\"\"\"\n",
    "    # Filter out Time column and SEM columns\n",
    "    data_cols = [col for col in df.columns \n",
    "                 if col != 'Time (s)' and not col.endswith('_SEM')]\n",
    "    return sorted(data_cols)\n",
    "\n",
    "def get_column_label(column_name):\n",
    "    \"\"\"Generate a readable label for a column.\"\"\"\n",
    "    # Map common column names to readable labels\n",
    "    label_map = {\n",
    "        'z_470': 'GRAB-5HT3.0 (z-score)',\n",
    "        'z_470_Baseline': 'GRAB-5HT3.0 (z-score)',\n",
    "        'z_560': 'RGeco1a (z-score)',\n",
    "        'z_560_Baseline': 'RGeco1a (z-score)',\n",
    "        'Velocity_0X': 'Running speed',\n",
    "        'Velocity_0X_Baseline': 'Running speed',\n",
    "        'Motor_Velocity': 'Motor Velocity',\n",
    "        'Motor_Velocity_Baseline': 'Motor Velocity',\n",
    "    }\n",
    "    return label_map.get(column_name, column_name)\n",
    "\n",
    "def get_axis_label(column_name):\n",
    "    \"\"\"Generate axis label based on column name.\"\"\"\n",
    "    if 'z_' in column_name or 'z-score' in column_name.lower():\n",
    "        return 'z-score'\n",
    "    elif 'Velocity' in column_name or 'velocity' in column_name.lower():\n",
    "        return 'Running speed (m/s)'\n",
    "    elif 'Motor' in column_name:\n",
    "        return 'Motor velocity (m/s)'\n",
    "    else:\n",
    "        return column_name\n",
    "\n",
    "def should_use_right_axis(column_name):\n",
    "    \"\"\"Determine if a column should be plotted on the right axis.\"\"\"\n",
    "    # Velocity and Motor columns go on right axis\n",
    "    return 'Velocity' in column_name or 'Motor' in column_name\n",
    "\n",
    "def plot_grand_averages_multi_series(series_list):\n",
    "    \"\"\"\n",
    "    Plot multiple series from different files on the same graph.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series_list : list of dict\n",
    "        Each dict should have: {'file': file_path, 'column': column_name, 'label': optional_label}\n",
    "    \"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['DejaVu Sans'],\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 10,\n",
    "        'legend.fontsize': 8,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    if not series_list:\n",
    "        print(\"‚ö†Ô∏è No series selected for plotting.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Plotting {len(series_list)} series...\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax2 = None\n",
    "    \n",
    "    # Separate series by axis type\n",
    "    left_axis_series = []\n",
    "    right_axis_series = []\n",
    "    \n",
    "    for idx, series in enumerate(series_list):\n",
    "        file_path = series['file']\n",
    "        column = series['column']\n",
    "        label = series.get('label', None)\n",
    "        \n",
    "        print(f\"  Series {idx+1}: {Path(file_path).name} - {column}\")\n",
    "        \n",
    "        if not file_path or not column:\n",
    "            print(f\"    ‚ö†Ô∏è Skipping: missing file_path or column\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Read the CSV file fresh each time (no caching)\n",
    "            # Use absolute path to ensure we're reading the correct file\n",
    "            abs_file_path = Path(file_path).resolve()\n",
    "            print(f\"    üìÅ Reading file: {abs_file_path.name}\")\n",
    "            print(f\"    üìÅ Full path: {abs_file_path}\")\n",
    "            \n",
    "            df = pd.read_csv(abs_file_path)\n",
    "            file_label = Path(file_path).parent.name\n",
    "            \n",
    "            print(f\"    ‚úÖ Loaded file: {len(df)} rows, columns: {list(df.columns)[:5]}...\")\n",
    "            print(f\"    üìã All columns: {list(df.columns)}\")\n",
    "            \n",
    "            if column not in df.columns:\n",
    "                print(f\"    ‚ö†Ô∏è Column {column} not found in {file_path}\")\n",
    "                print(f\"    Available columns: {list(df.columns)}\")\n",
    "                continue\n",
    "            \n",
    "            # Determine which axis to use\n",
    "            use_right = should_use_right_axis(column)\n",
    "            \n",
    "            # Generate label\n",
    "            if label:\n",
    "                plot_label = label\n",
    "            else:\n",
    "                col_label = get_column_label(column)\n",
    "                plot_label = f\"{col_label} ({file_label})\"\n",
    "            \n",
    "            print(f\"    üìà Plotting on {'right' if use_right else 'left'} axis: {plot_label}\")\n",
    "            \n",
    "            # Plot on appropriate axis\n",
    "            if use_right:\n",
    "                if ax2 is None:\n",
    "                    ax2 = ax.twinx()\n",
    "                ax2.plot(df['Time (s)'], df[column], label=plot_label, \n",
    "                         color=series.get('color', 'slategray'), \n",
    "                         linestyle=series.get('linestyle', '-'),\n",
    "                         alpha=1)\n",
    "                if f'{column}_SEM' in df.columns:\n",
    "                    ax2.fill_between(df['Time (s)'],\n",
    "                                    df[column] - df[f'{column}_SEM'],\n",
    "                                    df[column] + df[f'{column}_SEM'],\n",
    "                                    color=series.get('color', 'slategray'), alpha=0.2)\n",
    "                right_axis_series.append(series)\n",
    "            else:\n",
    "                ax.plot(df['Time (s)'], df[column], label=plot_label,\n",
    "                       color=series.get('color', 'green'),\n",
    "                       linestyle=series.get('linestyle', '-'),\n",
    "                       alpha=1)\n",
    "                if f'{column}_SEM' in df.columns:\n",
    "                    ax.fill_between(df['Time (s)'],\n",
    "                                   df[column] - df[f'{column}_SEM'],\n",
    "                                   df[column] + df[f'{column}_SEM'],\n",
    "                                   color=series.get('color', 'green'), alpha=0.1)\n",
    "                left_axis_series.append(series)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö†Ô∏è Error loading {file_path}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n‚úÖ Successfully plotted: {len(left_axis_series)} left axis, {len(right_axis_series)} right axis\")\n",
    "    \n",
    "    # Set axis labels\n",
    "    if left_axis_series:\n",
    "        first_col = left_axis_series[0]['column']\n",
    "        ax.set_ylabel(get_axis_label(first_col), fontname='DejaVu Sans', fontsize=10, color='black')\n",
    "        ax.tick_params(axis='y', labelcolor='black')\n",
    "    \n",
    "    if right_axis_series and ax2:\n",
    "        first_col = right_axis_series[0]['column']\n",
    "        ax2.set_ylabel(get_axis_label(first_col), fontname='DejaVu Sans', fontsize=10, color='slategray')\n",
    "        ax2.tick_params(axis='y', labelcolor='slategray')\n",
    "    \n",
    "    ax.axvspan(0, 2, color='gray', alpha=0.2, label='Visual mismatch (0-2s)')\n",
    "    ax.set_title('Grand Averages Comparison', fontname='DejaVu Sans', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)', fontname='DejaVu Sans', fontsize=10)\n",
    "    \n",
    "    # Combine legends\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    if ax2:\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines + lines2, labels + labels2, loc='upper right', \n",
    "                 prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    else:\n",
    "        ax.legend(lines, labels, loc='upper right', prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "def plot_grand_averages_single(df, label, y1_col=None, y2_col=None):\n",
    "    \"\"\"Plot grand averages from a single CSV file with selected columns.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['DejaVu Sans'],\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 10,\n",
    "        'legend.fontsize': 8,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax2 = None\n",
    "    \n",
    "    # Plot y1 column on left axis\n",
    "    if y1_col and y1_col in df.columns:\n",
    "        ax.plot(df['Time (s)'], df[y1_col], label=get_column_label(y1_col), \n",
    "                color='green', alpha=1)\n",
    "        if f'{y1_col}_SEM' in df.columns:\n",
    "            ax.fill_between(df['Time (s)'],\n",
    "                           df[y1_col] - df[f'{y1_col}_SEM'],\n",
    "                           df[y1_col] + df[f'{y1_col}_SEM'],\n",
    "                           color='green', alpha=0.1)\n",
    "        ax.set_ylabel(get_axis_label(y1_col), fontname='DejaVu Sans', fontsize=10, color='black')\n",
    "        ax.tick_params(axis='y', labelcolor='black')\n",
    "    \n",
    "    # Plot y2 column on right axis (if different from y1)\n",
    "    if y2_col and y2_col in df.columns and y2_col != y1_col:\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.plot(df['Time (s)'], df[y2_col], label=get_column_label(y2_col), \n",
    "                color='slategray', alpha=1)\n",
    "        if f'{y2_col}_SEM' in df.columns:\n",
    "            ax2.fill_between(df['Time (s)'],\n",
    "                            df[y2_col] - df[f'{y2_col}_SEM'],\n",
    "                            df[y2_col] + df[f'{y2_col}_SEM'],\n",
    "                            color='slategray', alpha=0.2)\n",
    "        ax2.set_ylabel(get_axis_label(y2_col), fontname='DejaVu Sans', fontsize=10, color='slategray')\n",
    "        ax2.tick_params(axis='y', labelcolor='slategray')\n",
    "    \n",
    "    ax.axvspan(0, 2, color='gray', alpha=0.2, label='Visual mismatch (0-2s)')\n",
    "    ax.set_title(f'Grand Averages: {label}', fontname='DejaVu Sans', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)', fontname='DejaVu Sans', fontsize=10)\n",
    "    \n",
    "    # Combine legends\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    if ax2:\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines + lines2, labels + labels2, loc='upper right', \n",
    "                 prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    else:\n",
    "        ax.legend(lines, labels, loc='upper right', prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_grand_averages_comparison(df1, df2, label1, label2, y1_col=None, y2_col=None):\n",
    "    \"\"\"Plot grand averages comparing two CSV files with selected columns.\"\"\"\n",
    "    plt.rcParams.update({\n",
    "        'font.size': 10,\n",
    "        'font.family': 'sans-serif',\n",
    "        'font.sans-serif': ['DejaVu Sans'],\n",
    "        'axes.titlesize': 10,\n",
    "        'axes.labelsize': 10,\n",
    "        'legend.fontsize': 8,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10\n",
    "    })\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax2 = None\n",
    "    \n",
    "    # Plot y1 column on left axis\n",
    "    if y1_col:\n",
    "        if y1_col in df1.columns:\n",
    "            ax.plot(df1['Time (s)'], df1[y1_col], label=f\"{get_column_label(y1_col)} ({label1})\", \n",
    "                    color='green', alpha=1)\n",
    "            if f'{y1_col}_SEM' in df1.columns:\n",
    "                ax.fill_between(df1['Time (s)'],\n",
    "                               df1[y1_col] - df1[f'{y1_col}_SEM'],\n",
    "                               df1[y1_col] + df1[f'{y1_col}_SEM'],\n",
    "                               color='green', alpha=0.1)\n",
    "        \n",
    "        if y1_col in df2.columns:\n",
    "            ax.plot(df2['Time (s)'], df2[y1_col], label=f\"{get_column_label(y1_col)} ({label2})\", \n",
    "                    color='orange', alpha=1, linestyle='--')\n",
    "            if f'{y1_col}_SEM' in df2.columns:\n",
    "                ax.fill_between(df2['Time (s)'],\n",
    "                               df2[y1_col] - df2[f'{y1_col}_SEM'],\n",
    "                               df2[y1_col] + df2[f'{y1_col}_SEM'],\n",
    "                               color='orange', alpha=0.1)\n",
    "        \n",
    "        ax.set_ylabel(get_axis_label(y1_col), fontname='DejaVu Sans', fontsize=10, color='black')\n",
    "        ax.tick_params(axis='y', labelcolor='black')\n",
    "    \n",
    "    # Plot y2 column on right axis (if different from y1)\n",
    "    if y2_col and y2_col != y1_col:\n",
    "        ax2 = ax.twinx()\n",
    "        \n",
    "        if y2_col in df1.columns:\n",
    "            ax2.plot(df1['Time (s)'], df1[y2_col], label=f\"{get_column_label(y2_col)} ({label1})\", \n",
    "                    color='slategray', alpha=1)\n",
    "            if f'{y2_col}_SEM' in df1.columns:\n",
    "                ax2.fill_between(df1['Time (s)'],\n",
    "                                df1[y2_col] - df1[f'{y2_col}_SEM'],\n",
    "                                df1[y2_col] + df1[f'{y2_col}_SEM'],\n",
    "                                color='slategray', alpha=0.2)\n",
    "        \n",
    "        if y2_col in df2.columns:\n",
    "            ax2.plot(df2['Time (s)'], df2[y2_col], label=f\"{get_column_label(y2_col)} ({label2})\", \n",
    "                    color='slategray', alpha=1, linestyle='--')\n",
    "            if f'{y2_col}_SEM' in df2.columns:\n",
    "                ax2.fill_between(df2['Time (s)'],\n",
    "                                df2[y2_col] - df2[f'{y2_col}_SEM'],\n",
    "                                df2[y2_col] + df2[f'{y2_col}_SEM'],\n",
    "                                color='slategray', alpha=0.2)\n",
    "        \n",
    "        ax2.set_ylabel(get_axis_label(y2_col), fontname='DejaVu Sans', fontsize=10, color='slategray')\n",
    "        ax2.tick_params(axis='y', labelcolor='slategray')\n",
    "    \n",
    "    ax.axvspan(0, 2, color='gray', alpha=0.2, label='Visual mismatch (0-2s)')\n",
    "    ax.set_title('Grand Averages with SEM', fontname='DejaVu Sans', fontsize=12)\n",
    "    ax.set_xlabel('Time (s)', fontname='DejaVu Sans', fontsize=10)\n",
    "    \n",
    "    # Combine legends\n",
    "    lines, labels = ax.get_legend_handles_labels()\n",
    "    if ax2:\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        ax.legend(lines + lines2, labels + labels2, loc='upper right', \n",
    "                 prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    else:\n",
    "        ax.legend(lines, labels, loc='upper right', prop={'family': 'DejaVu Sans', 'size': 10})\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_grand_averages_interactive():\n",
    "    \"\"\"Create interactive plot with dropdowns for multiple CSV file and column selection.\"\"\"\n",
    "    \n",
    "    # Find available CSV files using the same paths as DATA_DIRS\n",
    "    base_paths = DATA_DIRS if DATA_DIRS else []\n",
    "    \n",
    "    csv_files = find_csv_files(base_paths)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"‚ö†Ô∏è No CSV files found. Please check your paths.\")\n",
    "        return\n",
    "    \n",
    "    if WIDGETS_AVAILABLE:\n",
    "        # Store series widgets\n",
    "        series_widgets = []\n",
    "        series_container = widgets.VBox([])\n",
    "        \n",
    "        # Store current figure for saving\n",
    "        current_fig = [None]  # Use list to allow modification in nested functions\n",
    "        \n",
    "        # Color options for different series\n",
    "        color_options = ['green', 'blue', 'red', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']\n",
    "        linestyle_options = ['-', '--', '-.', ':']\n",
    "        \n",
    "        def create_series_row(series_id):\n",
    "            \"\"\"Create a row of widgets for selecting file and column.\"\"\"\n",
    "            file_dropdown = widgets.Dropdown(\n",
    "                options=['None'] + csv_files,\n",
    "                value='None',\n",
    "                description=f'File {series_id}:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='400px')\n",
    "            )\n",
    "            \n",
    "            col_dropdown = widgets.Dropdown(\n",
    "                options=[''],\n",
    "                value='',\n",
    "                description='Column:',\n",
    "                style={'description_width': 'initial'},\n",
    "                layout=widgets.Layout(width='250px')\n",
    "            )\n",
    "            \n",
    "            remove_btn = widgets.Button(\n",
    "                description='Remove',\n",
    "                button_style='danger',\n",
    "                layout=widgets.Layout(width='80px', height='30px')\n",
    "            )\n",
    "            \n",
    "            def update_columns(change):\n",
    "                \"\"\"Update column dropdown when file changes.\"\"\"\n",
    "                if change['new'] and change['new'] != 'None':\n",
    "                    try:\n",
    "                        # Clear the current column value first\n",
    "                        col_dropdown.value = ''\n",
    "                        \n",
    "                        # Read the new file\n",
    "                        df = pd.read_csv(change['new'])\n",
    "                        available_cols = get_available_columns(df)\n",
    "                        \n",
    "                        # Update options and set to first available column\n",
    "                        col_dropdown.options = available_cols\n",
    "                        if available_cols:\n",
    "                            col_dropdown.value = available_cols[0]\n",
    "                        else:\n",
    "                            col_dropdown.value = ''\n",
    "                        \n",
    "                        # Debug output\n",
    "                        print(f\"üìÅ File changed to: {Path(change['new']).name}\")\n",
    "                        print(f\"   Available columns: {available_cols[:5]}...\" if len(available_cols) > 5 else f\"   Available columns: {available_cols}\")\n",
    "                        print(f\"   Selected column: {col_dropdown.value}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"‚ö†Ô∏è Error loading file: {e}\")\n",
    "                        import traceback\n",
    "                        traceback.print_exc()\n",
    "                        col_dropdown.options = ['']\n",
    "                        col_dropdown.value = ''\n",
    "                else:\n",
    "                    col_dropdown.options = ['']\n",
    "                    col_dropdown.value = ''\n",
    "            \n",
    "            def remove_series(b):\n",
    "                \"\"\"Remove this series row.\"\"\"\n",
    "                for i, (f, c, r, _) in enumerate(series_widgets):\n",
    "                    if f == file_dropdown:\n",
    "                        series_widgets.pop(i)\n",
    "                        update_series_display()\n",
    "                        break\n",
    "            \n",
    "            file_dropdown.observe(update_columns, names='value')\n",
    "            remove_btn.on_click(remove_series)\n",
    "            \n",
    "            return file_dropdown, col_dropdown, remove_btn, widgets.HBox([file_dropdown, col_dropdown, remove_btn])\n",
    "        \n",
    "        def update_series_display():\n",
    "            \"\"\"Update the display of all series rows.\"\"\"\n",
    "            children = [row[3] for row in series_widgets]\n",
    "            series_container.children = children\n",
    "        \n",
    "        def add_series(b):\n",
    "            \"\"\"Add a new series row.\"\"\"\n",
    "            series_id = len(series_widgets) + 1\n",
    "            widgets_row = create_series_row(series_id)\n",
    "            series_widgets.append(widgets_row)\n",
    "            update_series_display()\n",
    "        \n",
    "        def plot_all_series(b):\n",
    "            \"\"\"Plot all selected series.\"\"\"\n",
    "            with output:\n",
    "                clear_output(wait=True)\n",
    "                series_list = []\n",
    "                \n",
    "                for file_dropdown, col_dropdown, _, _ in series_widgets:\n",
    "                    file_path = file_dropdown.value\n",
    "                    column = col_dropdown.value\n",
    "                    \n",
    "                    # Debug: print what we're checking\n",
    "                    print(f\"Checking: file_path={file_path}, column={column}\")\n",
    "                    \n",
    "                    # Check if both file and column are valid\n",
    "                    if file_path and file_path != 'None' and column and column != '':\n",
    "                        series_list.append({\n",
    "                            'file': file_path,\n",
    "                            'column': column,\n",
    "                            'color': color_options[len(series_list) % len(color_options)],\n",
    "                            'linestyle': linestyle_options[(len(series_list) // len(color_options)) % len(linestyle_options)]\n",
    "                        })\n",
    "                        print(f\"‚úÖ Added series: {Path(file_path).name} - {column}\")\n",
    "                    else:\n",
    "                        print(f\"‚è≠Ô∏è Skipped: file_path={file_path}, column={column}\")\n",
    "                \n",
    "                print(f\"\\nüìä Total series to plot: {len(series_list)}\")\n",
    "                \n",
    "                if not series_list:\n",
    "                    print(\"‚ö†Ô∏è Please select at least one file and column combination.\")\n",
    "                    return\n",
    "                \n",
    "                try:\n",
    "                    fig = plot_grand_averages_multi_series(series_list)\n",
    "                    current_fig[0] = fig  # Store figure for saving\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Error plotting: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "        \n",
    "        def save_current_plot(b):\n",
    "            \"\"\"Save the current plot to a file.\"\"\"\n",
    "            if current_fig[0] is None:\n",
    "                with output:\n",
    "                    print(\"‚ö†Ô∏è No plot to save. Please plot first.\")\n",
    "                return\n",
    "            \n",
    "            # Generate filename based on selected series\n",
    "            series_names = []\n",
    "            first_file_path = None\n",
    "            \n",
    "            for file_dropdown, col_dropdown, _, _ in series_widgets:\n",
    "                file_path = file_dropdown.value\n",
    "                column = col_dropdown.value\n",
    "                if file_path and file_path != 'None' and column and column != '':\n",
    "                    if first_file_path is None:\n",
    "                        first_file_path = file_path\n",
    "                    file_label = Path(file_path).parent.name\n",
    "                    series_names.append(f\"{file_label}_{column}\")\n",
    "            \n",
    "            if series_names:\n",
    "                filename_base = \"_vs_\".join(series_names[:3])  # Limit filename length\n",
    "                if len(series_names) > 3:\n",
    "                    filename_base += f\"_and_{len(series_names)-3}_more\"\n",
    "            else:\n",
    "                filename_base = \"grand_averages_plot\"\n",
    "            \n",
    "            # Get save directory from the first CSV file being plotted\n",
    "            if first_file_path:\n",
    "                save_dir = Path(first_file_path).parent\n",
    "            else:\n",
    "                save_dir = Path(DATA_DIRS[0]) if DATA_DIRS else Path.cwd()\n",
    "            \n",
    "            # Save as PDF and PNG\n",
    "            pdf_path = save_dir / f\"{filename_base}.pdf\"\n",
    "            png_path = save_dir / f\"{filename_base}.png\"\n",
    "            \n",
    "            try:\n",
    "                current_fig[0].savefig(pdf_path, dpi=300, bbox_inches='tight')\n",
    "                current_fig[0].savefig(png_path, dpi=300, bbox_inches='tight')\n",
    "                with output:\n",
    "                    print(f\"‚úÖ Plot saved to:\")\n",
    "                    print(f\"   PDF: {pdf_path}\")\n",
    "                    print(f\"   PNG: {png_path}\")\n",
    "            except Exception as e:\n",
    "                with output:\n",
    "                    print(f\"‚ö†Ô∏è Error saving plot: {e}\")\n",
    "                    import traceback\n",
    "                    traceback.print_exc()\n",
    "        \n",
    "        # Create initial series row\n",
    "        add_series(None)\n",
    "        \n",
    "        # Buttons\n",
    "        add_btn = widgets.Button(\n",
    "            description='+ Add Series',\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        add_btn.on_click(add_series)\n",
    "        \n",
    "        plot_button = widgets.Button(\n",
    "            description='Plot All Series',\n",
    "            button_style='success',\n",
    "            layout=widgets.Layout(width='200px')\n",
    "        )\n",
    "        plot_button.on_click(plot_all_series)\n",
    "        \n",
    "        save_button = widgets.Button(\n",
    "            description='Save Plot',\n",
    "            button_style='warning',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        save_button.on_click(save_current_plot)\n",
    "        \n",
    "        output = widgets.Output()\n",
    "        \n",
    "        display(widgets.VBox([\n",
    "            widgets.HTML(\"<h3>Select multiple files and columns to plot:</h3>\"),\n",
    "            widgets.HTML(\"<p><i>Add multiple series to compare columns from different files on the same graph.</i></p>\"),\n",
    "            series_container,\n",
    "            widgets.HBox([add_btn, plot_button, save_button]),\n",
    "            output\n",
    "        ]))\n",
    "    else:\n",
    "        # Fallback: manual selection\n",
    "        print(\"Available CSV files:\")\n",
    "        for i, f in enumerate(csv_files, 1):\n",
    "            print(f\"{i}. {f}\")\n",
    "        print(\"\\n‚ö†Ô∏è ipywidgets not available. Please manually set file paths below.\")\n",
    "        return csv_files\n",
    "\n",
    "# Run interactive plotting\n",
    "plot_grand_averages_interactive()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a9f1bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #---------------------------------------------------------------------------------------------------#\n",
    "# # CORRELATION ANALYSIS\n",
    "# #---------------------------------------------------------------------------------------------------#\n",
    "# # This section performs correlation analysis between Velocity and z-scores (z_470, z_560)\n",
    "# # Requires loading previously saved results from pickle files for multiple cohorts\n",
    "\n",
    "# #---------------------------------------------------------------------------------------------------#\n",
    "# # Helper Functions\n",
    "# #---------------------------------------------------------------------------------------------------#\n",
    "\n",
    "# def load_results(filename):\n",
    "#     \"\"\"Load results from a pickle file.\"\"\"\n",
    "#     with open(filename, 'rb') as f:\n",
    "#         return pickle.load(f)\n",
    "\n",
    "# def fisher_z(r):\n",
    "#     \"\"\"Convert correlation coefficient to Fisher's z.\"\"\"\n",
    "#     return 0.5 * np.log((1 + r) / (1 - r))\n",
    "\n",
    "# def compare_correlations(r1, n1, r2, n2):\n",
    "#     \"\"\"Compare two correlation coefficients using Fisher's z transformation.\"\"\"\n",
    "#     z1 = fisher_z(r1)\n",
    "#     z2 = fisher_z(r2)\n",
    "#     se = np.sqrt(1 / (n1 - 3) + 1 / (n2 - 3))\n",
    "#     z = (z1 - z2) / se\n",
    "#     p = 2 * (1 - norm.cdf(abs(z)))\n",
    "#     return z, p\n",
    "\n",
    "# def extract_means(results, mice, time_window, columns=columns_to_plot):\n",
    "#     \"\"\"\n",
    "#     Extract mean values for specified columns within a given time window for a list of mice.\n",
    "\n",
    "#     Parameters:\n",
    "#     results (dict): Dictionary containing data for each mouse.\n",
    "#     mice (list): List of mouse names to extract data for.\n",
    "#     time_window (tuple): Time window (start, end) for extracting mean values.\n",
    "#     columns (list): List of column names to extract.\n",
    "\n",
    "#     Returns:\n",
    "#     tuple: Mean values for Velocity_0X, z_470, z_560, and valid mouse names.\n",
    "#     \"\"\"\n",
    "#     v_means, z470_means, z560_means, valid_mice = [], [], [], []\n",
    "#     t0, t1 = time_window\n",
    "\n",
    "#     for mouse in mice:\n",
    "#         if mouse not in results['mean_data_per_mouse']:\n",
    "#             continue\n",
    "#         df = results['mean_data_per_mouse'][mouse]\n",
    "#         if not all(col in df.columns for col in columns):\n",
    "#             continue\n",
    "\n",
    "#         df_window = df.loc[(df.index >= t0) & (df.index <= t1)]\n",
    "#         v = df_window[columns[0]].mean()\n",
    "#         z470 = df_window[columns[1]].mean()\n",
    "#         z560 = df_window[columns[2]].mean()\n",
    "\n",
    "#         if not any(pd.isnull([v, z470, z560])):\n",
    "#             v_means.append(v)\n",
    "#             z470_means.append(z470)\n",
    "#             z560_means.append(z560)\n",
    "#             valid_mice.append(mouse)\n",
    "\n",
    "#     return v_means, z470_means, z560_means, valid_mice\n",
    "\n",
    "# def move_mouse_data_fixed(v1, z470_1, z560_1, ids1, v2, z470_2, z560_2, ids2, \n",
    "#                          target_mouse, exclude_mice):\n",
    "#     \"\"\"\n",
    "#     Fixed version that maintains array consistency when moving mouse data between cohorts.\n",
    "#     \"\"\"\n",
    "#     # Convert to lists if not already (for easier manipulation)\n",
    "#     v1, z470_1, z560_1, ids1 = list(v1), list(z470_1), list(z560_1), list(ids1)\n",
    "#     v2, z470_2, z560_2, ids2 = list(v2), list(z470_2), list(z560_2), list(ids2)\n",
    "    \n",
    "#     # Exclude mice from both cohorts\n",
    "#     for mouse in exclude_mice:\n",
    "#         # Remove from cohort 1\n",
    "#         while mouse in ids1:\n",
    "#             idx = ids1.index(mouse)\n",
    "#             del v1[idx], z470_1[idx], z560_1[idx], ids1[idx]\n",
    "        \n",
    "#         # Remove from cohort 2\n",
    "#         while mouse in ids2:\n",
    "#             idx = ids2.index(mouse)\n",
    "#             del v2[idx], z470_2[idx], z560_2[idx], ids2[idx]\n",
    "    \n",
    "#     # Move target mouse data\n",
    "#     if target_mouse in ids2:\n",
    "#         idx = ids2.index(target_mouse)\n",
    "        \n",
    "#         # Store the data to move\n",
    "#         target_v = v2[idx]\n",
    "#         target_z470 = z470_2[idx]\n",
    "#         target_z560 = z560_2[idx]\n",
    "        \n",
    "#         # Remove original entry from Cohort 2\n",
    "#         del v2[idx], z470_2[idx], z560_2[idx], ids2[idx]\n",
    "        \n",
    "#         # Add to Cohort 1 (velocity and z_470, NaN for z_560)\n",
    "#         v1.append(target_v)\n",
    "#         z470_1.append(target_z470)\n",
    "#         z560_1.append(np.nan)\n",
    "#         ids1.append(target_mouse + \" (from Cohort 2)\")\n",
    "        \n",
    "#         # Keep z_560 correlation in Cohort 2 (velocity and z_560, NaN for z_470)\n",
    "#         v2.append(target_v)\n",
    "#         z470_2.append(np.nan)\n",
    "#         z560_2.append(target_z560)\n",
    "#         ids2.append(target_mouse + \" (z_560)\")\n",
    "        \n",
    "#         print(f\"‚úÖ Moved velocity & z_470 of {target_mouse} to Cohort 1.\")\n",
    "#         print(f\"‚úÖ Retained velocity & z_560 of {target_mouse} in Cohort 2.\")\n",
    "#     else:\n",
    "#         print(f\"‚ö†Ô∏è Mouse {target_mouse} not found in Cohort 2.\")\n",
    "    \n",
    "#     return v1, z470_1, z560_1, ids1, v2, z470_2, z560_2, ids2\n",
    "\n",
    "# def analyze_correlations_from_data_fixed(\n",
    "#     v1, z470_1, z560_1, ids1,\n",
    "#     v2, z470_2, z560_2, ids2,\n",
    "#     time_window=None,\n",
    "#     plot=True\n",
    "# ):\n",
    "#     \"\"\"\n",
    "#     Fixed correlation analysis function that computes correlations and compares them.\n",
    "#     \"\"\"\n",
    "#     def filter_valid_pairs(x, y, labels):\n",
    "#         x = np.array(x)\n",
    "#         y = np.array(y)\n",
    "#         labels = np.array(labels)\n",
    "        \n",
    "#         # Ensure all arrays have the same length\n",
    "#         min_len = min(len(x), len(y), len(labels))\n",
    "#         x = x[:min_len]\n",
    "#         y = y[:min_len]\n",
    "#         labels = labels[:min_len]\n",
    "        \n",
    "#         # Filter out NaN values\n",
    "#         mask = ~np.isnan(x) & ~np.isnan(y)\n",
    "#         return x[mask], y[mask], labels[mask]\n",
    "\n",
    "#     if time_window is None:\n",
    "#         time_window = (0, 2)  # Default time window if not specified\n",
    "\n",
    "#     # Filter valid pairs for each correlation\n",
    "#     v1_470, z470_1_filt, ids1_470 = filter_valid_pairs(v1, z470_1, ids1)\n",
    "#     v1_560, z560_1_filt, ids1_560 = filter_valid_pairs(v1, z560_1, ids1)\n",
    "#     v2_470, z470_2_filt, ids2_470 = filter_valid_pairs(v2, z470_2, ids2)\n",
    "#     v2_560, z560_2_filt, ids2_560 = filter_valid_pairs(v2, z560_2, ids2)\n",
    "\n",
    "#     # Calculate correlations\n",
    "#     results = {}\n",
    "#     if len(v1_470) > 1:\n",
    "#         corr1_470, p1_470 = pearsonr(v1_470, z470_1_filt)\n",
    "#         results['corr1_470'] = (corr1_470, p1_470, len(v1_470))\n",
    "#     else:\n",
    "#         results['corr1_470'] = (np.nan, np.nan, len(v1_470))\n",
    "        \n",
    "#     if len(v1_560) > 1:\n",
    "#         corr1_560, p1_560 = pearsonr(v1_560, z560_1_filt)\n",
    "#         results['corr1_560'] = (corr1_560, p1_560, len(v1_560))\n",
    "#     else:\n",
    "#         results['corr1_560'] = (np.nan, np.nan, len(v1_560))\n",
    "        \n",
    "#     if len(v2_470) > 1:\n",
    "#         corr2_470, p2_470 = pearsonr(v2_470, z470_2_filt)\n",
    "#         results['corr2_470'] = (corr2_470, p2_470, len(v2_470))\n",
    "#     else:\n",
    "#         results['corr2_470'] = (np.nan, np.nan, len(v2_470))\n",
    "        \n",
    "#     if len(v2_560) > 1:\n",
    "#         corr2_560, p2_560 = pearsonr(v2_560, z560_2_filt)\n",
    "#         results['corr2_560'] = (corr2_560, p2_560, len(v2_560))\n",
    "#     else:\n",
    "#         results['corr2_560'] = (np.nan, np.nan, len(v2_560))\n",
    "\n",
    "#     # Print results\n",
    "#     print(\"\\nüìä Correlations:\")\n",
    "#     print(f\"Cohort 1: Velocity ~ z_470: r = {results['corr1_470'][0]:.3f}, p = {results['corr1_470'][1]:.3f} (n={results['corr1_470'][2]})\")\n",
    "#     print(f\"Cohort 1: Velocity ~ z_560: r = {results['corr1_560'][0]:.3f}, p = {results['corr1_560'][1]:.3f} (n={results['corr1_560'][2]})\")\n",
    "#     print(f\"Cohort 2: Velocity ~ z_470: r = {results['corr2_470'][0]:.3f}, p = {results['corr2_470'][1]:.3f} (n={results['corr2_470'][2]})\")\n",
    "#     print(f\"Cohort 2: Velocity ~ z_560: r = {results['corr2_560'][0]:.3f}, p = {results['corr2_560'][1]:.3f} (n={results['corr2_560'][2]})\")\n",
    "\n",
    "#     # Compare correlations\n",
    "#     if results['corr1_470'][2] > 3 and results['corr2_470'][2] > 3:\n",
    "#         z_470, p_470 = compare_correlations(results['corr1_470'][0], results['corr1_470'][2], \n",
    "#                                           results['corr2_470'][0], results['corr2_470'][2])\n",
    "#         print(f\"\\nüîç Comparison of correlations for z_470:\")\n",
    "#         print(f\"z = {z_470:.3f}, p = {p_470:.3f}\")\n",
    "#     else:\n",
    "#         print(\"‚ö†Ô∏è Not enough data to compare z_470 correlations.\")\n",
    "\n",
    "#     if results['corr1_560'][2] > 3 and results['corr2_560'][2] > 3:\n",
    "#         z_560, p_560 = compare_correlations(results['corr1_560'][0], results['corr1_560'][2], \n",
    "#                                           results['corr2_560'][0], results['corr2_560'][2])\n",
    "#         print(f\"\\nüîç Comparison of correlations for z_560:\")\n",
    "#         print(f\"z = {z_560:.3f}, p = {p_560:.3f}\")\n",
    "#     else:\n",
    "#         print(\"‚ö†Ô∏è Not enough data to compare z_560 correlations.\")\n",
    "\n",
    "#     # Create plots\n",
    "#     if plot:\n",
    "#         # Plot properties\n",
    "#         plt.rcParams.update({\n",
    "#             'font.size': 10,\n",
    "#             'font.family': 'sans-serif',\n",
    "#             'font.sans-serif': ['DejaVu Sans'],\n",
    "#             'axes.titlesize': 10,\n",
    "#             'axes.labelsize': 10,\n",
    "#             'legend.fontsize': 8,\n",
    "#             'xtick.labelsize': 10,\n",
    "#             'ytick.labelsize': 10\n",
    "#         })\n",
    "        \n",
    "#         fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n",
    "#         t_str = f\"{time_window[0]} to {time_window[1]}s\"\n",
    "\n",
    "#         # Plot z_470 correlations\n",
    "#         if len(v1_470) > 0:\n",
    "#             axs[0].scatter(v1_470, z470_1_filt, color='green', label=f'Cohort 1 (n={len(v1_470)})', alpha=0.7)\n",
    "#             for i, mouse in enumerate(ids1_470):\n",
    "#                 axs[0].text(v1_470[i], z470_1_filt[i], mouse, fontsize=6, color='green', alpha=0.6)\n",
    "#             if len(v1_470) > 1:\n",
    "#                 m1, b1 = np.polyfit(v1_470, z470_1_filt, 1)\n",
    "#                 x_range = np.linspace(min(v1_470), max(v1_470), 100)\n",
    "#                 axs[0].plot(x_range, m1 * x_range + b1, color='green', linestyle='--', alpha=0.8)\n",
    "        \n",
    "#         if len(v2_470) > 0:\n",
    "#             axs[0].scatter(v2_470, z470_2_filt, color='orange', label=f'Cohort 2 (n={len(v2_470)})', alpha=0.7)\n",
    "#             for i, mouse in enumerate(ids2_470):\n",
    "#                 axs[0].text(v2_470[i], z470_2_filt[i], mouse, fontsize=6, color='orange', alpha=0.6)\n",
    "#             if len(v2_470) > 1:\n",
    "#                 m2, b2 = np.polyfit(v2_470, z470_2_filt, 1)\n",
    "#                 x_range = np.linspace(min(v2_470), max(v2_470), 100)\n",
    "#                 axs[0].plot(x_range, m2 * x_range + b2, color='orange', linestyle='--', alpha=0.8)\n",
    "        \n",
    "#         axs[0].set_title(f'Velocity vs z_470\\n({t_str})')\n",
    "#         axs[0].set_xlabel('Mean Velocity_0X (m/s)')\n",
    "#         axs[0].set_ylabel('Mean z-score (470nm)')\n",
    "#         axs[0].legend()\n",
    "#         axs[0].grid(True, alpha=0.3)\n",
    "\n",
    "#         # Plot z_560 correlations\n",
    "#         if len(v1_560) > 0:\n",
    "#             axs[1].scatter(v1_560, z560_1_filt, color='red', label=f'Cohort 1 (n={len(v1_560)})', alpha=0.7)\n",
    "#             for i, mouse in enumerate(ids1_560):\n",
    "#                 axs[1].text(v1_560[i], z560_1_filt[i], mouse, fontsize=6, color='red', alpha=0.6)\n",
    "#             if len(v1_560) > 1:\n",
    "#                 m1, b1 = np.polyfit(v1_560, z560_1_filt, 1)\n",
    "#                 x_range = np.linspace(min(v1_560), max(v1_560), 100)\n",
    "#                 axs[1].plot(x_range, m1 * x_range + b1, color='red', linestyle='--', alpha=0.8)\n",
    "        \n",
    "#         if len(v2_560) > 0:\n",
    "#             axs[1].scatter(v2_560, z560_2_filt, color='darkred', label=f'Cohort 2 (n={len(v2_560)})', alpha=0.7)\n",
    "#             for i, mouse in enumerate(ids2_560):\n",
    "#                 axs[1].text(v2_560[i], z560_2_filt[i], mouse, fontsize=6, color='darkred', alpha=0.6)\n",
    "#             if len(v2_560) > 1:\n",
    "#                 m2, b2 = np.polyfit(v2_560, z560_2_filt, 1)\n",
    "#                 x_range = np.linspace(min(v2_560), max(v2_560), 100)\n",
    "#                 axs[1].plot(x_range, m2 * x_range + b2, color='darkred', linestyle='--', alpha=0.8)\n",
    "        \n",
    "#         axs[1].set_title(f'Velocity vs z_560\\n({t_str})')\n",
    "#         axs[1].set_xlabel('Mean Velocity_0X (m/s)')\n",
    "#         axs[1].set_ylabel('Mean z-score (560nm)')\n",
    "#         axs[1].legend()\n",
    "#         axs[1].grid(True, alpha=0.3)\n",
    "\n",
    "#         plt.tight_layout()\n",
    "#         plt.show()\n",
    "    \n",
    "#     return results\n",
    "\n",
    "# #---------------------------------------------------------------------------------------------------#\n",
    "# # Load Data and Run Analysis\n",
    "# #---------------------------------------------------------------------------------------------------#\n",
    "# # Uncomment and modify paths as needed for correlation analysis\n",
    "# # Example:\n",
    "# # results_cohort1 = load_results('/path/to/Cohort1_results.pkl')\n",
    "# # results_cohort2 = load_results('/path/to/Cohort2_results.pkl')\n",
    "# # selected_mice1 = ['B6J2717', 'B6J2718', 'B6J2719', 'B6J2721', 'B6J2722']\n",
    "# # selected_mice2 = ['B6J2780', 'B6J2781', 'B6J2783', 'B6J2782']\n",
    "# # time_window = (0, 2)\n",
    "\n",
    "# # Extract means for each cohort\n",
    "# # v1, z470_1, z560_1, ids1 = extract_means(results_cohort1, selected_mice1, time_window)\n",
    "# # v2, z470_2, z560_2, ids2 = extract_means(results_cohort2, selected_mice2, time_window)\n",
    "\n",
    "# # Optional: Move mouse data between cohorts\n",
    "# # target_mouse = \"B6J2782\"  # Specify the mouse to move\n",
    "# # exclude_mice = [\"B6J2722\"]  # List of mice to exclude\n",
    "# # v1, z470_1, z560_1, ids1, v2, z470_2, z560_2, ids2 = move_mouse_data_fixed(\n",
    "# #     v1, z470_1, z560_1, ids1, v2, z470_2, z560_2, ids2, target_mouse, exclude_mice\n",
    "# # )\n",
    "\n",
    "# # Run correlation analysis\n",
    "# # correlation_results = analyze_correlations_from_data_fixed(\n",
    "# #     v1, z470_1, z560_1, ids1,\n",
    "# #     v2, z470_2, z560_2, ids2,\n",
    "# #     time_window=time_window,\n",
    "# #     plot=True\n",
    "# # )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2880d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
