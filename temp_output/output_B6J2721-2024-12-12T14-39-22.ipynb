{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [3]</a>'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "papermill": {
     "duration": 0.029915,
     "end_time": "2025-03-18T17:45:10.193738",
     "exception": false,
     "start_time": "2025-03-18T17:45:10.163823",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "Data_path = \"/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2721-2024-12-12T14-40-11\"\n",
    "Vestibular_mismatch = True\n",
    "Event_name = \"DrumWithReverseflow block started\"\n",
    "Sensor_resolution = 3100\n",
    "Ball_radius = 0.1\n",
    "Optical_filter_Hz = 40\n",
    "Common_resampled_rate = 1000\n",
    "Save_full_asynchronous_data = True\n",
    "Has_heartbeat = False\n",
    "Cohort0 = False\n",
    "Cohort2 = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "papermill": {
     "duration": 1.646757,
     "end_time": "2025-03-18T17:45:11.845045",
     "exception": false,
     "start_time": "2025-03-18T17:45:10.198288",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "\n",
    "#import harp\n",
    "import harp_resources.process\n",
    "import harp_resources.utils\n",
    "from harp_resources import process, utils # Reassign to maintain direct references for force updating \n",
    "#from sleap import load_and_process as lp\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# injected variables\n",
    "#--------------------------------------------------------------------------------\n",
    "data_path = Path(Data_path) # injects at runtime by papermill \n",
    "vestibular_mismatch = Vestibular_mismatch\n",
    "event_name = Event_name\n",
    "sensor_resolution = Sensor_resolution  \n",
    "ball_radius = Ball_radius \n",
    "optical_filter_Hz = Optical_filter_Hz \n",
    "common_resampled_rate = Common_resampled_rate \n",
    "save_full_asynchronous_data = Save_full_asynchronous_data \n",
    "has_heartbeat = Has_heartbeat\n",
    "cohort0 = Cohort0\n",
    "cohort2 = Cohort2\n",
    "\n",
    "\n",
    "# OR YOU CAN EXPLICITELY CHOOSE A data_path for example from the below list\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day4/B6J2717-2024-12-11T13-06-53')\n",
    "# data_paths = [\n",
    "#     Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day4/B6J2717-2024-12-11T13-06-53'),\n",
    "#     Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day4/B6J2718-2024-12-11T13-49-13'),\n",
    "#     Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day4/B6J2719-2024-12-11T14-26-30'),\n",
    "#     Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day4/B6J2721-2024-12-11T15-05-01'),\n",
    "#     Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day4/B6J2722-2024-12-11T15-42-27'),\n",
    "#     Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day4/B6J2723-2024-12-11T16-18-56')\n",
    "# ]\n",
    "# data_path = data_paths[2]\n",
    "\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "save_path = data_path.parent / f\"{data_path.name}_processedData\"\n",
    "session_name = \"_\".join(data_path.parts[-2:])\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# initiate variables HERE if not injected \n",
    "#-------------------------------------------------------------------------------- \n",
    "# vestibular_mismatch = True\n",
    "# event_name = \"DrumWithReverseflow block started\"\n",
    "# sensor_resolution = 3100 #cpi, inferred empirical value from unit testing notebook  \n",
    "# ball_radius = 0.1 # meters \n",
    "# optical_filter_Hz=40 #filter cutoff for Optical tracking and encoder signals\n",
    "# common_resampled_rate = 1000 #in Hz\n",
    "# save_full_asynchronous_data = True #saves alldata before resampling\n",
    "# # helper flags \n",
    "# has_heartbeat = False\n",
    "# cohort0 = False\n",
    "# cohort2 = False\n",
    "\n",
    "# runtime flags to avoid issues with reruning the same cell \n",
    "onix_analog_clock_downsampled = False\n",
    "onix_analog_framecount_upsampled = False\n",
    "unit_conversions = False #\n",
    "all_aligned = False\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# #create loaders \n",
    "#--------------------------------------------------------------------------------\n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "video_reader1 = utils.VideoReader(\"VideoData1\")\n",
    "video_reader2 = utils.VideoReader(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "papermill": {
     "duration": 1.670855,
     "end_time": "2025-03-18T17:45:13.517133",
     "exception": true,
     "start_time": "2025-03-18T17:45:11.846278",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#--------------------------------------------------------------------------------\n",
    "# LOAD AND PROCESS ALL DATA \n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path)\n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "\n",
    "print (\"Loading processed photometry\")\n",
    "photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "photometry_data.set_index(\"TimeStamp\", inplace=True)\n",
    "photometry_data.index.name = 'Seconds'\n",
    "print (\"Upsampling photometry data\")\n",
    "photometry_data = process.upsample_photometry(photometry_data, common_resampled_rate)\n",
    "print (\"Loading processed photometry info\")\n",
    "photometry_info = pd.read_csv(str(photometry_path) + '/Info.csv', header=None, names=[\"Parameter\", \"Value\"])\n",
    "print (\"Loading processed photometry events\")\n",
    "photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "photometry_events[\"TimeStamp\"] = photometry_events[\"TimeStamp\"] /1000 # convert to seconds from ms\n",
    "photometry_events.set_index(\"TimeStamp\", inplace=True)\n",
    "photometry_events.index.name = 'Seconds'\n",
    "\n",
    "if not cohort2:\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data \n",
    "print (\"Loading OnixDigital\")\n",
    "onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "\n",
    "if cohort0:\n",
    "    print (\"Loading OnixAnalogFrameClock\")\n",
    "    onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "    \n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "\n",
    "print (\"Loading OnixAnalogData and converting to boolean photodiode array\")\n",
    "#method adaptive or threshold (which is hard threshold at 120), \n",
    "#refractory in seconds (aasuming 100kHz sampling rate) to avoid multiple detections in reporting\n",
    "#first 2 minutes removed from reporting \n",
    "photodiode = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True, method='adaptive', refractory = 0.5, flip=True, verbose=True) \n",
    "\n",
    "#read HARP data\n",
    "print (\"Loading H1 and H2 streams, AnalogInput removed\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True, has_heartbeat = has_heartbeat, verbose = False) #loads as df, or if False, as dict\n",
    "harp_streams.drop(columns=[\"AnalogInput(39)\"], inplace=True)  # Removes AnalogInput permanently, as not currently used\n",
    "harp_streams = harp_streams.dropna(how=\"all\") # remove rows with all NaNs\n",
    "# Convert specific columns in harp_streams to boolean type\n",
    "columns_to_convert = [\"StartCam0(38)\", \"StartCam1(38)\", \"StopCam0(38)\", \"StopCam1(38)\"]\n",
    "for col in columns_to_convert:\n",
    "    harp_streams[col] = harp_streams[col].astype(bool)\n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "    onix_harp[\"HarpTime\"] = onix_harp[\"HarpTime\"] + 1 # known issue with current version of ONIX, harp timestamps lag 1 second\n",
    "    print (\"ℹ️Reminder: HarpTime was increased by 1s to account for know issue with ONIX\")\n",
    "\n",
    "print (\"✅ Done Loading\")\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "# Convert platform position and flow sensor streams to real world units\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "# Get encoder values for homing and next event positions as absolute real life 0 position \n",
    "homing_position, next_event_position = process.get_encoder_home_position(experiment_events, harp_streams)\n",
    "print(\"ℹ️ Warning: home position is determined by the time of the experiment event after 'Homing platform'. It works for e.g. 'Waiting for run threshold' which starts immediately after homing, but may not work for other session types.\")\n",
    "\n",
    "# Perform unit conversions if not already done\n",
    "if not unit_conversions:\n",
    "    #get raw cumulative counts as position in raw data counts for plotting only \n",
    "    harp_streams[\"CumulativeCounts_0X\"] = harp_streams[\"OpticalTrackingRead0X(46)\"].copy().cumsum()\n",
    "    harp_streams[\"CumulativeCounts_0Y\"] = harp_streams[\"OpticalTrackingRead0Y(46)\"].copy().cumsum()\n",
    "    # run conversions\n",
    "    harp_streams[\"Position_0X\"] = process.running_unit_conversion(harp_streams[\"OpticalTrackingRead0X(46)\"].copy().cumsum().ffill().bfill().to_numpy(), sensor_resolution)\n",
    "    harp_streams[\"Position_0Y\"] = process.turning_unit_conversion(harp_streams[\"OpticalTrackingRead0Y(46)\"].copy().cumsum().ffill().bfill().to_numpy(), sensor_resolution, ball_radius)\n",
    "\n",
    "    harp_streams[\"Encoder(38)\"] = harp_streams[\"Encoder(38)\"].ffill().bfill() #fill before unit conversion\n",
    "    harp_streams[\"Encoder(38)\"] = process.encoder_unit_conversion(\n",
    "        harp_streams[\"Encoder(38)\"], next_event_position)\n",
    "        \n",
    "    #convert CamXEvents to bool \n",
    "    harp_streams[\"Cam0Event(32)\"] = harp_streams[\"Cam0Event(32)\"].fillna(0).astype(bool)\n",
    "    harp_streams[\"Cam1Event(33)\"] = harp_streams[\"Cam1Event(33)\"].fillna(0).astype(bool)\n",
    "    unit_conversions = True\n",
    "    print(\"✅ Unit conversions to real-life values done\")\n",
    "else:\n",
    "    print(\"⚠️ Flow sensor and encoder values already converted to real-world units, skipping\")\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# Downsample photodiode and analog_clock to common sample rate*10 (usually 10 kHz)\n",
    "# for Cohort 0 also upsamples framecount (not used for Cohort1+_\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "# gets analog data sample rate and downsamples to common_resampled_rate * 10\n",
    "if not onix_analog_clock_downsampled:\n",
    "    onix_analog_clock_s = (onix_analog_clock * 4) * 1e-9  # convert to seconds with 250MHz DeviceClock, set in hardware\n",
    "    oac_diff = np.diff(onix_analog_clock_s)\n",
    "    onix_analog_rate = round(1 / (np.median(oac_diff)))  # to get the sampling rate (in Hz) with 250MHz DeviceClock, set in hardware\n",
    "    downsample_factor = int(onix_analog_rate / (common_resampled_rate*10))\n",
    "    print(f\"onix_analog_clock rate: {onix_analog_rate}, downsample factor: {downsample_factor}\")\n",
    "    \n",
    "    onix_analog_clock = process.downsample_numpy(onix_analog_clock, downsample_factor, method=\"mean\")\n",
    "    photodiode = process.downsample_numpy(photodiode, downsample_factor, method=\"mean\")\n",
    "    photodiode_df = pd.DataFrame({\"Photodiode\": photodiode.astype(bool)}, index=pd.Index(onix_analog_clock, name=\"onix_analog_clock\"))\n",
    "     \n",
    "    del onix_analog_clock, oac_diff, photodiode, onix_analog_clock_s\n",
    "    gc.collect()\n",
    "    onix_analog_clock_downsampled = True\n",
    "    print(\"✅ Done downsampling analog_clock and photodiode\")\n",
    "else:\n",
    "    print(\"ℹ️ onix_analog_clock & photodiode already downsampled, skipping\")\n",
    "\n",
    "# framecount upsampling, only used in Cohort 0 synchronization\n",
    "if cohort0:\n",
    "    if not onix_analog_framecount_upsampled:\n",
    "        upsample_factor = int(100 / downsample_factor)  # framecount counts every 100 analog datapoints\n",
    "        df = onix_analog_framecount\n",
    "        new_index = np.linspace(0, len(df) - 1, len(df) * upsample_factor)\n",
    "        onix_analog_framecount = pd.DataFrame(index=new_index)\n",
    "        for col in df.columns:\n",
    "            onix_analog_framecount[col] = np.interp(new_index, np.arange(len(df)), df[col])\n",
    "        del new_index\n",
    "        gc.collect()\n",
    "        # Check onix_analog shapes for consistency\n",
    "        data_len = photodiode.shape[0]\n",
    "        clock_len = onix_analog_clock.shape[0]\n",
    "        framecount_len = len(onix_analog_framecount)\n",
    "\n",
    "        if data_len != framecount_len or clock_len != framecount_len:\n",
    "            offset = framecount_len - clock_len\n",
    "            onix_analog_framecount = onix_analog_framecount.iloc[offset:]\n",
    "            print(f\"Warning: analog_data and _framecount mismatch, framecount truncated by {offset * 10}! Should be OK, but see https://github.com/neurogears/vestibular-vr/issues/81 for more information.\")\n",
    "        else:\n",
    "            print(\"onix_analog shapes are consistent!\")\n",
    "        onix_analog_framecount_upsampled = True\n",
    "        print(\"✅ Done upsampling analog_frameclock\")\n",
    "    else:\n",
    "        print(\"ℹ️ onix_analog_framecount already upsampled, skipping\")\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# align photodiode_df to harptime\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "if not all_aligned:\n",
    "    ( \n",
    "        conversions, \n",
    "        photometry_aligned,\n",
    "        photodiode_aligned\n",
    "    ) = process.photometry_harp_onix_synchronisation(\n",
    "        onix_digital=onix_digital,\n",
    "        onix_harp=onix_harp,\n",
    "        photometry_events=photometry_events,\n",
    "        photometry_data = photometry_data,\n",
    "        photodiode_df = photodiode_df,\n",
    "        verbose=False\n",
    "    )\n",
    "    del photodiode_df\n",
    "    gc.collect()\n",
    "    all_aligned = True   \n",
    "    print(\"✅ Done aligning photometry and photodiode to harp time\")\n",
    "else:\n",
    "    print(\"ℹ️ Photometry and photodiode already aligned, skipping\")\n",
    "\n",
    "#Set all values of photodiode_aligned before the first \"Check halt probability\" to True\n",
    "next_event_after_homing = experiment_events[experiment_events[\"Event\"] == \"Check halt probability\"].index[0]\n",
    "photodiode_aligned.loc[photodiode_aligned.index < next_event_after_homing, \"Photodiode\"] = True\n",
    "print (\"ℹ️ Reminder: Photodiode is funky at startup and is set to True before the first 'Check halt probability' event, may not work with all experiment types\")\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# pad to global maximum times \n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "#finding global first and last timestamps\n",
    "streams_dict = {\n",
    "    'session_settings': {'session_settings': session_settings},\n",
    "    'experiment_events': {'experiment_events': experiment_events},\n",
    "    'video_data1': {'video_data1': video_data1},\n",
    "    'video_data2': {'video_data2': video_data2},\n",
    "    'harp_streams': {'harp_streams': harp_streams},\n",
    "    'onix_harp': {'onix_harp': onix_harp},\n",
    "    'onix_digital': {'onix_digital': onix_digital},\n",
    "    'harp_streams': {'harp_streams': harp_streams},\n",
    "    'photodiode_aligned': {'photodiode_aligned': photodiode_aligned},\n",
    "    'photometry_aligned': {'photometry_aligned': photometry_aligned}\n",
    "}\n",
    "if cohort0:\n",
    "    streams_dict['onix_analog_framecount'] = {'onix_analog_framecount': onix_analog_framecount}\n",
    "\n",
    "global_first_timestamp, global_last_timestamp, streams_dict = process.get_global_minmax_timestamps(streams_dict, print_all=False, verbose=False)\n",
    "\n",
    "# Extract all DataFrames dynamically\n",
    "for source_name, registers in streams_dict.items():\n",
    "    for register_name, df in registers.items():\n",
    "        globals()[register_name] = df  # Create variables dynamically\n",
    "\n",
    "del registers, onix_digital, onix_harp, photometry_events, photometry_data\n",
    "gc.collect()\n",
    "\n",
    "# padding these dataframes to global first and last timestamp and bringing under new alldata dataframe \n",
    "dataframes = [video_data1, video_data2, harp_streams, photometry_aligned, photodiode_aligned]\n",
    "padded_dataframes = [process.pad_dataframe_with_global_timestamps(df, global_first_timestamp, global_last_timestamp) for df in dataframes]\n",
    "video_data1, video_data2, harp_streams, photometry_aligned, photodiode_aligned = padded_dataframes\n",
    "\n",
    "del padded_dataframes, streams_dict, dataframes\n",
    "gc.collect()\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# combine everything to single async. alldata df and save\n",
    "# after this, raw datafiles can be compressed / archived \n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Rename columns in harp_streams by removing \"OpticalTrackingRead\" and removing register numbers\n",
    "video_data1 = video_data1.rename(columns=lambda x: f\"{x}_1\" if not x.endswith(\"_1\") else x)\n",
    "video_data2 = video_data2.rename(columns=lambda x: f\"{x}_2\" if not x.endswith(\"_2\") else x)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(\"OpticalTrackingRead\", \"Displacement_\", regex=False)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(r\"\\(.*\\)\", \"\", regex=True)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(\"Position_Displacement_\", \"Position_\", regex=False)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(\"Displacement_0Brightness\", \"Brightness_0\", regex=False)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(\"Displacement_1Brightness\", \"Brightness_1\", regex=False)\n",
    "\n",
    "# Concatenate the dataframes\n",
    "alldata = pd.concat([video_data1, video_data2, harp_streams, photometry_aligned, photodiode_aligned], axis=1)\n",
    "\n",
    "# Define photodiode_int DataFrame and add to alldata\n",
    "photodiode_int = pd.DataFrame(dtype=int)  # Ensure DataFrame defaults to int\n",
    "photodiode_int[\"Photodiode_int\"] = photodiode_aligned[\"Photodiode\"].astype(\"int8\").copy()\n",
    "photodiode_int = photodiode_int.reindex(alldata.index, method='ffill') ## Reindex photodiode_int to match alldata's index, filling missing values with the preceding value\n",
    "alldata = pd.concat([alldata, photodiode_int], axis=1)\n",
    "alldata[\"Photodiode_int\"] = alldata[\"Photodiode_int\"].astype(\"int8\") # insure it is int8\n",
    "\n",
    "# Ensure boolean columns retain their dtype\n",
    "bool_columns = [\"Cam0Event\", \"Cam1Event\", \"StartCam0\", \"StartCam1\", \"StopCam0\", \"StopCam1\", \"Photodiode\"]\n",
    "for col in bool_columns:\n",
    "    if col in alldata.columns:\n",
    "        if col == \"Photodiode\":\n",
    "            pd.set_option('future.no_silent_downcasting', True)  # Enable future behavior\n",
    "            alldata[col] = alldata[col].infer_objects(copy=False)  # Convert object columns properly\n",
    "            alldata[col] = alldata[col].ffill().astype(bool)\n",
    "        else:\n",
    "            alldata[col] = alldata[col].fillna(0).astype(bool)\n",
    "\n",
    "print(\"✅ Concatenated all data streams into alldata\")\n",
    "\n",
    "if save_full_asynchronous_data:\n",
    "    filename = \"alldata_asynchronous.parquet\"\n",
    "    full_path = save_path / filename\n",
    "    alldata.to_parquet(full_path, engine=\"pyarrow\", compression=\"snappy\")   \n",
    "    print(\"✅ Saved full asynchronous data to alldata_asynchronous.parquet\")\n",
    "\n",
    "# Clean up and delete the column OpticalTrackingRead0X(46) and camera start/stop and H2 ImmediatePulses\n",
    "del video_data1, video_data2, photometry_aligned, harp_streams\n",
    "del photodiode_aligned, photodiode_int\n",
    "gc.collect()    \n",
    "\n",
    "columns_to_delete = [\n",
    "    \"Displacement_0X\",\n",
    "    \"Displacement_0Y\",\n",
    "    \"Displacement_1X\",\n",
    "    \"Displacement_1Y\",\n",
    "    \"Brightness_0\",\n",
    "    \"Brightness_1\",\n",
    "    \"StartCam0\", \n",
    "    \"StartCam1\", \n",
    "    \"StopCam0\",\n",
    "    \"StopCam1\", \n",
    "    \"ImmediatePulses\"\n",
    "]\n",
    "alldata.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "#---------------------------------------------------\n",
    "# Separate data streams to be resampled from the ones to keep for now with original datetime indices \n",
    "#---------------------------------------------------\n",
    "\n",
    "columns_to_select = [\n",
    "    'HardwareCounter_1', 'HardwareTimestamp_1', \n",
    "    'HardwareCounter_2', 'HardwareTimestamp_2',\n",
    "    'Cam0Event', 'Cam1Event', 'Photodiode'\n",
    "]\n",
    "\n",
    "camera_photodiode_data = alldata[columns_to_select].copy()\n",
    "camera_photodiode_data.index = alldata.index\n",
    "\n",
    "#Remove the selected columns from alldata\n",
    "for col in columns_to_select:\n",
    "    alldata.pop(col)\n",
    "\n",
    "photometry_tracking_encoder_data = alldata\n",
    "del alldata\n",
    "gc.collect()\n",
    "print(\"✅ Done separating and data streams to float and bool/Int64\")\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# downsample photometry_tracking_encoder_data\n",
    "#--------------------------------------------------------------------------------\n",
    "print(\"⚠️ Starting downsampling, this will take a while...\")\n",
    "photometry_tracking_encoder_data = process.resample_dataframe(photometry_tracking_encoder_data, common_resampled_rate, optical_filter_Hz)\n",
    "print(\"✅ Resampled data to common rate\", common_resampled_rate, \"Hz\")\n",
    "\n",
    "#--------------------------------------------------------------------------------\n",
    "# Calculate velocity and acceleration from position data\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Calculate motor velocity and acceleration from encoder position data\n",
    "#FIXME optical_filter_Hz / 40 and optical_filter_Hz / 80 LOOKS HUGELY LOW FITERING - CHECK \n",
    "# Unwrap the encoder values to handle the 0-360 degree wrap-around\n",
    "photometry_tracking_encoder_data[\"Encoder_Unwrapped\"] = np.unwrap(np.deg2rad(photometry_tracking_encoder_data[\"Encoder\"])) * (180 / np.pi)\n",
    "\n",
    "# Calculate motor velocity and acceleration from unwrapped encoder position data\n",
    "photometry_tracking_encoder_data[\"Motor_Velocity\"] = np.gradient(photometry_tracking_encoder_data[\"Encoder_Unwrapped\"], edge_order=2) * common_resampled_rate\n",
    "photometry_tracking_encoder_data[\"Motor_Velocity\"] = process.low_pass_filter(photometry_tracking_encoder_data[\"Motor_Velocity\"].dropna(), optical_filter_Hz / 40, common_resampled_rate)\n",
    "photometry_tracking_encoder_data[\"Motor_Acceleration\"] = np.gradient(photometry_tracking_encoder_data[\"Motor_Velocity\"], edge_order=2) * common_resampled_rate\n",
    "photometry_tracking_encoder_data[\"Motor_Acceleration\"] = process.low_pass_filter(photometry_tracking_encoder_data[\"Motor_Acceleration\"].dropna(), optical_filter_Hz / 80, common_resampled_rate)\n",
    "\n",
    "# Calculate animal running and turning velocity and acceleration from X and Y position \n",
    "position_columns = [col for col in photometry_tracking_encoder_data.columns if col.startswith(\"Position_\")]\n",
    "for col in position_columns:\n",
    "    # Calculate velocity as the first derivative of position using central difference\n",
    "    velocity_col = col.replace(\"Position_\", \"Velocity_\")\n",
    "    photometry_tracking_encoder_data[velocity_col] = np.gradient(photometry_tracking_encoder_data[col], edge_order=2) * common_resampled_rate\n",
    "    \n",
    "    # Apply low-pass filter to the velocity data\n",
    "    photometry_tracking_encoder_data[velocity_col] = process.low_pass_filter(photometry_tracking_encoder_data[velocity_col].dropna(), optical_filter_Hz / 40, common_resampled_rate)\n",
    "    \n",
    "    # Calculate acceleration as the first derivative of filtered velocity using central difference\n",
    "    acceleration_col = col.replace(\"Position_\", \"Acceleration_\")\n",
    "    photometry_tracking_encoder_data[acceleration_col] = np.gradient(photometry_tracking_encoder_data[velocity_col], edge_order=2) * common_resampled_rate\n",
    "    \n",
    "    # Apply low-pass filter to the acceleration data\n",
    "    photometry_tracking_encoder_data[acceleration_col] = process.low_pass_filter(photometry_tracking_encoder_data[acceleration_col].dropna(), optical_filter_Hz / 80, common_resampled_rate)\n",
    "\n",
    "print(\"✅ Calculated velocity and acceleration from position data\")\n",
    "\n",
    "# Store downsampled data in separate directory \n",
    "output_dir = \"downsampled_data\"\n",
    "full_path = save_path / output_dir\n",
    "os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "# Save each DataFrame separately\n",
    "dfs = {\"photometry_tracking_encoder_data\": photometry_tracking_encoder_data, \"camera_photodiode_data\": camera_photodiode_data, \"experiment_events\": experiment_events, \"photometry_info\": photometry_info}\n",
    "for name, df in dfs.items():\n",
    "    df.to_parquet(full_path / f\"{name}.parquet\", engine='pyarrow', compression='snappy')\n",
    "\n",
    "del dfs\n",
    "gc.collect()\n",
    "\n",
    "# Convert metadata column properly\n",
    "session_settings[\"metadata\"] = session_settings[\"metadata\"].apply(process.safe_to_json)\n",
    "# Save DataFrame to Parquet\n",
    "parquet_path = full_path / \"session_settings.parquet\"\n",
    "session_settings.to_parquet(parquet_path, engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "print(f\"✅ Saved all processed data to {full_path}\")\n",
    "\n",
    "df_to_analyze = photometry_tracking_encoder_data[\"Photodiode_int\"] #using downsampled values in common time grid \n",
    "if vestibular_mismatch: #determine halt times based on experiment events \n",
    "    photodiode_halts = experiment_events[experiment_events[\"Event\"] == event_name].index.tolist()\n",
    "    nearest_indices = photometry_tracking_encoder_data.index.get_indexer(photodiode_halts, method='nearest')\n",
    "    photodiode_halts = photometry_tracking_encoder_data.index[nearest_indices] # as experiment events timestamps are not in the same time grid as downsampled data\n",
    "    print (\"INFO: vestibular mismatch data without MM signal in the photodiode, using experiment events for MM times\")\n",
    "else: #determine exact halt times based on photodiode signal\n",
    "    photodiode_halts, photodiode_delay_min, photodiode_delay_avg, photodiode_delay_max = process.analyze_photodiode(df_to_analyze, experiment_events, event_name, plot = True)\n",
    "\n",
    "\n",
    "del df_to_analyze\n",
    "gc.collect()\n",
    "\n",
    "process.plot_figure_1(photometry_tracking_encoder_data, session_name, save_path, common_resampled_rate, photodiode_halts, save_figure = True, show_figure = True, downsample_factor=50)\n",
    "print(\"✅ Got photodiode events, saved Figure 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib #for force updating changed packages \n",
    "# Force reload the modules\n",
    "importlib.reload(harp_resources.process)\n",
    "importlib.reload(harp_resources.utils)\n",
    "# Reassign after reloading to ensure updated references\n",
    "process = harp_resources.process\n",
    "utils = harp_resources.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4.912279,
   "end_time": "2025-03-18T17:45:14.038256",
   "environment_variables": {},
   "exception": true,
   "input_path": "1_Loading_and_Sync_Cohort1.ipynb",
   "output_path": "temp_output/output_B6J2721-2024-12-12T14-39-22.ipynb",
   "parameters": {
    "Ball_radius": 0.1,
    "Cohort0": false,
    "Cohort2": false,
    "Common_resampled_rate": 1000,
    "Data_path": "/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2721-2024-12-12T14-39-22",
    "Event_name": "DrumWithReverseflow block started",
    "Has_heartbeat": false,
    "Optical_filter_Hz": 40,
    "Save_full_asynchronous_data": true,
    "Sensor_resolution": 3100,
    "Vestibular_mismatch": true
   },
   "start_time": "2025-03-18T17:45:09.125977",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
