{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Cohort Running and Turning Behavior Analysis\n",
    "\n",
    "This notebook analyzes multiple cohort behavioral analysis CSV files (merged together) and generates summary plots showing:\n",
    "- Running velocity (cm/s) with average and SEM per experiment day\n",
    "- Total run distance per experiment day **normalized by session duration (m/minute)**\n",
    "- Time spent running (percentage) per experiment day\n",
    "- Turning velocity (deg/s) with average and SEM per experiment day\n",
    "- Total turn distance per experiment day **normalized by session duration (deg/minute)**\n",
    "- Time spent turning (percentage) per experiment day\n",
    "\n",
    "Individual mouse values are shown with consistent colors across days and cohorts. Analysis is performed across all cohorts grouped by experiment day type.\n",
    "\n",
    "**Note:** Distance metrics are normalized by total recording time to account for differences in session duration across experiment days. This ensures fair comparison between training days and experiment days with different recording lengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "from scipy.stats import ttest_rel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "plt.rcParams['font.size'] = 15\n",
    "plt.rcParams['font.family'] = 'Arial'\n",
    "plt.rcParams['font.sans-serif'] = ['Arial', 'DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cohort CSV files: 2\n",
      "  Cohort 1: /Users/nora/Desktop/for_poster/cohort_1/cohort_behavioral_analysis.csv\n",
      "  Cohort 2: /Users/nora/Desktop/for_poster/cohort_3/cohort_behavioral_analysis.csv\n",
      "\n",
      "Output directory: /Users/nora/Desktop/for_poster/cohort_1\n",
      "\n",
      "Exclude visual mismatch from main analysis: True\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "#----------------------------\n",
    "# Paths to cohort CSV files (can specify multiple cohorts)\n",
    "# CSV files should be located 2 levels above _processedData folder\n",
    "cohort_csv_paths = [\n",
    "    Path('/Users/nora/Desktop/for_poster/cohort_1/cohort_behavioral_analysis.csv').expanduser(),\n",
    "    Path('/Users/nora/Desktop/for_poster/cohort_3/cohort_behavioral_analysis.csv').expanduser(),\n",
    "    # Add more cohort CSV paths here as needed\n",
    "    # Path('/path/to/cohort2/cohort_behavioral_analysis.csv').expanduser(),\n",
    "]\n",
    "\n",
    "# Analysis options\n",
    "EXCLUDE_VISUAL_MISMATCH = True  # Set to True to exclude visual mismatch experiments from main analysis (they will be analyzed separately)\n",
    "\n",
    "# Output directory for plots (use first cohort's parent directory or specify a common location)\n",
    "if len(cohort_csv_paths) > 0:\n",
    "    # Use parent directory of first cohort\n",
    "    output_dir = cohort_csv_paths[0].parent\n",
    "else:\n",
    "    output_dir = Path('.')\n",
    "\n",
    "print(f\"Number of cohort CSV files: {len(cohort_csv_paths)}\")\n",
    "for i, path in enumerate(cohort_csv_paths, 1):\n",
    "    print(f\"  Cohort {i}: {path}\")\n",
    "print(f\"\\nOutput directory: {output_dir}\")\n",
    "print(f\"\\nExclude visual mismatch from main analysis: {EXCLUDE_VISUAL_MISMATCH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded cohort_1 CSV: 38 rows from cohort_behavioral_analysis.csv\n",
      "âœ… Loaded cohort_3 CSV: 30 rows from cohort_behavioral_analysis.csv\n",
      "\n",
      "âœ… Merged 2 cohort CSV files\n",
      "   Total rows: 68\n",
      "   Cohorts: cohort_1, cohort_3\n",
      "\n",
      "Columns: ['Animal_ID', 'Experiment_Day', 'running_threshold_m_per_s', 'running_velocity_avg_m_per_s', 'running_velocity_sd_m_per_s', 'running_time_percentage', 'running_distance_travelled_m', 'running_time_seconds', 'running_total_time_seconds', 'turning_threshold_m_per_s', 'turning_velocity_avg_m_per_s', 'turning_velocity_sd_m_per_s', 'turning_time_percentage', 'turning_distance_turned_m', 'turning_left_percentage', 'turning_right_percentage', 'turning_time_seconds', 'turning_total_time_seconds', 'platform_cross_corr_lag_samples', 'platform_cross_corr_lag_seconds', 'platform_cross_corr_pearson_r', 'platform_cross_corr_p_value', 'platform_gain_encoder_to_turning', 'platform_mean_motor_velocity_m_per_s', 'platform_mean_turning_velocity_m_per_s', 'last_block_platform_mean_motor_velocity_m_per_s', 'first_block_platform_cross_corr_pearson_r', 'first_block_platform_cross_corr_p_value', 'last_block_turning_time_seconds', 'last_block_turning_distance_turned_m', 'first_block_turning_time_seconds', 'last_block_running_time_seconds', 'last_block_turning_threshold_m_per_s', 'first_block_turning_distance_turned_m', 'first_block_turning_right_percentage', 'last_block_platform_cross_corr_pearson_r', 'first_block_running_distance_travelled_m', 'first_block_running_total_time_seconds', 'first_block_platform_cross_corr_lag_seconds', 'first_block_running_velocity_sd_m_per_s', 'first_block_turning_threshold_m_per_s', 'first_block_turning_total_time_seconds', 'first_block_running_velocity_avg_m_per_s', 'first_block_running_threshold_m_per_s', 'first_block_running_time_percentage', 'last_block_platform_mean_turning_velocity_m_per_s', 'first_block_platform_cross_corr_lag_samples', 'last_block_turning_velocity_avg_m_per_s', 'first_block_turning_velocity_avg_m_per_s', 'last_block_turning_total_time_seconds', 'last_block_running_velocity_avg_m_per_s', 'first_block_turning_velocity_sd_m_per_s', 'last_block_turning_right_percentage', 'last_block_running_threshold_m_per_s', 'last_block_turning_velocity_sd_m_per_s', 'last_block_turning_left_percentage', 'last_block_platform_cross_corr_lag_samples', 'last_block_running_total_time_seconds', 'last_block_platform_cross_corr_lag_seconds', 'last_block_platform_gain_encoder_to_turning', 'first_block_turning_time_percentage', 'last_block_running_time_percentage', 'last_block_platform_cross_corr_p_value', 'first_block_platform_gain_encoder_to_turning', 'last_block_running_distance_travelled_m', 'last_block_turning_time_percentage', 'first_block_running_time_seconds', 'first_block_platform_mean_motor_velocity_m_per_s', 'first_block_platform_mean_turning_velocity_m_per_s', 'first_block_turning_left_percentage', 'last_block_running_velocity_sd_m_per_s', 'Cohort', 'running_threshold_cm_per_s', 'running_velocity_avg_cm_per_s', 'running_velocity_sd_cm_per_s', 'running_distance_travelled_cm', 'turning_threshold_cm_per_s', 'turning_velocity_avg_cm_per_s', 'turning_velocity_sd_cm_per_s', 'turning_distance_turned_cm', 'platform_mean_turning_velocity_cm_per_s', 'platform_mean_motor_velocity_cm_per_s']\n",
      "\n",
      "First few rows:\n",
      "  Animal_ID        Experiment_Day  running_threshold_m_per_s  \\\n",
      "0   B6J2717         Training_day3                   0.024237   \n",
      "1   B6J2717         Training_day4                   0.024132   \n",
      "2   B6J2717         Training_day5                   0.026155   \n",
      "3   B6J2717         Training_day6                   0.029461   \n",
      "4   B6J2717  Visual_mismatch_day3                        NaN   \n",
      "\n",
      "   running_velocity_avg_m_per_s  running_velocity_sd_m_per_s  \\\n",
      "0                      0.082828                     0.037675   \n",
      "1                      0.097990                     0.044882   \n",
      "2                      0.092656                     0.040883   \n",
      "3                      0.112472                     0.049593   \n",
      "4                           NaN                          NaN   \n",
      "\n",
      "   running_time_percentage  running_distance_travelled_m  \\\n",
      "0                34.741442                     18.249608   \n",
      "1                30.905115                     19.071881   \n",
      "2                31.885447                     18.688783   \n",
      "3                19.285801                     13.709657   \n",
      "4                      NaN                           NaN   \n",
      "\n",
      "   running_time_seconds  running_total_time_seconds  \\\n",
      "0               208.449                     600.001   \n",
      "1               185.431                     600.001   \n",
      "2               191.313                     600.001   \n",
      "3               115.715                     600.001   \n",
      "4                   NaN                         NaN   \n",
      "\n",
      "   turning_threshold_m_per_s  ...  running_threshold_cm_per_s  \\\n",
      "0                   0.877762  ...                         NaN   \n",
      "1                   0.754364  ...                         NaN   \n",
      "2                   0.752139  ...                         NaN   \n",
      "3                   0.367311  ...                         NaN   \n",
      "4                        NaN  ...                         NaN   \n",
      "\n",
      "   running_velocity_avg_cm_per_s  running_velocity_sd_cm_per_s  \\\n",
      "0                            NaN                           NaN   \n",
      "1                            NaN                           NaN   \n",
      "2                            NaN                           NaN   \n",
      "3                            NaN                           NaN   \n",
      "4                            NaN                           NaN   \n",
      "\n",
      "   running_distance_travelled_cm  turning_threshold_cm_per_s  \\\n",
      "0                            NaN                         NaN   \n",
      "1                            NaN                         NaN   \n",
      "2                            NaN                         NaN   \n",
      "3                            NaN                         NaN   \n",
      "4                            NaN                         NaN   \n",
      "\n",
      "   turning_velocity_avg_cm_per_s  turning_velocity_sd_cm_per_s  \\\n",
      "0                            NaN                           NaN   \n",
      "1                            NaN                           NaN   \n",
      "2                            NaN                           NaN   \n",
      "3                            NaN                           NaN   \n",
      "4                            NaN                           NaN   \n",
      "\n",
      "   turning_distance_turned_cm  platform_mean_turning_velocity_cm_per_s  \\\n",
      "0                         NaN                                      NaN   \n",
      "1                         NaN                                      NaN   \n",
      "2                         NaN                                      NaN   \n",
      "3                         NaN                                      NaN   \n",
      "4                         NaN                                      NaN   \n",
      "\n",
      "   platform_mean_motor_velocity_cm_per_s  \n",
      "0                                    NaN  \n",
      "1                                    NaN  \n",
      "2                                    NaN  \n",
      "3                                    NaN  \n",
      "4                                    NaN  \n",
      "\n",
      "[5 rows x 82 columns]\n",
      "\n",
      "Experiment days: ['Training_day1', 'Training_day2', 'Training_day3', 'Training_day4', 'Training_day5', 'Training_day6', 'Visual_mismatch_day3', 'Visual_mismatch_day4']\n",
      "\n",
      "Number of animals per cohort:\n",
      "Cohort\n",
      "cohort_1    6\n",
      "cohort_3    4\n",
      "Name: Animal_ID, dtype: int64\n",
      "\n",
      "Total unique animals: 10\n"
     ]
    }
   ],
   "source": [
    "# Load and merge multiple cohort CSV files\n",
    "#----------------------------\n",
    "dfs = []\n",
    "cohort_names = []\n",
    "\n",
    "for i, csv_path in enumerate(cohort_csv_paths, 1):\n",
    "    if not csv_path.exists():\n",
    "        print(f\"âš ï¸ Warning: Cohort CSV not found at {csv_path}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Load CSV\n",
    "    df_temp = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Extract cohort directory name from path (e.g., \"20250409_Cohort3_rotation\" or \"Cohort1_rotation\")\n",
    "    # Use the parent directory name as the cohort identifier\n",
    "    cohort_name = csv_path.parent.name\n",
    "    \n",
    "    # If parent is just the filename or empty, try grandparent\n",
    "    if not cohort_name or cohort_name == csv_path.parent:\n",
    "        cohort_name = csv_path.parent.parent.name\n",
    "    \n",
    "    # If still not found, use a default name\n",
    "    if not cohort_name or cohort_name == '.':\n",
    "        cohort_name = f\"Cohort{i}\"\n",
    "    \n",
    "    # Add cohort identifier column\n",
    "    df_temp['Cohort'] = cohort_name\n",
    "    \n",
    "    dfs.append(df_temp)\n",
    "    cohort_names.append(cohort_name)\n",
    "    \n",
    "    print(f\"âœ… Loaded {cohort_name} CSV: {len(df_temp)} rows from {csv_path.name}\")\n",
    "\n",
    "# Merge all dataframes\n",
    "if len(dfs) == 0:\n",
    "    raise ValueError(\"No valid cohort CSV files found!\")\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(f\"\\nâœ… Merged {len(dfs)} cohort CSV files\")\n",
    "print(f\"   Total rows: {len(df)}\")\n",
    "print(f\"   Cohorts: {', '.join(cohort_names)}\")\n",
    "print(f\"\\nColumns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nExperiment days: {sorted(df['Experiment_Day'].unique())}\")\n",
    "print(f\"\\nNumber of animals per cohort:\")\n",
    "print(df.groupby('Cohort')['Animal_ID'].nunique())\n",
    "print(f\"\\nTotal unique animals: {df['Animal_ID'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created normalized running distance (m/minute)\n",
      "âœ… Created normalized turning distance (deg/minute)\n",
      "\n",
      "ðŸ“Š Session duration summary (minutes):\n",
      "   Mean: 9.82 minutes\n",
      "   Min: 4.81 minutes\n",
      "   Max: 10.00 minutes\n",
      "\n",
      "   By experiment day:\n",
      "   Training_day1: 10.00 Â± 0.00 minutes (n=4)\n",
      "   Training_day2: 10.00 Â± 0.00 minutes (n=9)\n",
      "   Training_day3: 9.09 Â± 1.95 minutes (n=10)\n",
      "   Training_day4: 10.00 Â± 0.00 minutes (n=9)\n",
      "   Training_day5: 10.00 Â± 0.00 minutes (n=8)\n",
      "   Training_day6: 10.00 Â± 0.00 minutes (n=10)\n",
      "   Visual_mismatch_day3: nan Â± nan minutes (n=9)\n",
      "   Visual_mismatch_day4: nan Â± nan minutes (n=9)\n",
      "\n",
      "ðŸ“Š Visual mismatch experiment days detected: ['Visual_mismatch_day3', 'Visual_mismatch_day4']\n",
      "   Main analysis dataset: 50 rows (excluding visual mismatch)\n",
      "   Visual mismatch dataset: 18 rows (will be analyzed separately)\n",
      "\n",
      "âœ… All required columns found (including normalized distances)\n"
     ]
    }
   ],
   "source": [
    "# Data preparation and conversion\n",
    "#----------------------------\n",
    "# Convert running velocity from m/s to cm/s (multiply by 100)\n",
    "if 'running_velocity_avg_m_per_s' in df.columns:\n",
    "    df['running_velocity_avg_cm_per_s'] = df['running_velocity_avg_m_per_s'] * 100\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: 'running_velocity_avg_m_per_s' column not found\")\n",
    "\n",
    "if 'running_velocity_sd_m_per_s' in df.columns:\n",
    "    df['running_velocity_sd_cm_per_s'] = df['running_velocity_sd_m_per_s'] * 100\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: 'running_velocity_sd_m_per_s' column not found\")\n",
    "\n",
    "# Note: Turning velocity is already in degrees/s (despite column name suggesting m/s)\n",
    "# The column name is misleading but the values are in degrees/s\n",
    "if 'turning_velocity_avg_m_per_s' in df.columns:\n",
    "    # Keep as is - values are already in degrees/s\n",
    "    df['turning_velocity_avg_deg_per_s'] = df['turning_velocity_avg_m_per_s']\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: 'turning_velocity_avg_m_per_s' column not found\")\n",
    "\n",
    "# Normalize cumulative metrics by total recording time\n",
    "# This accounts for different session durations across experiment days\n",
    "# Use running_total_time_seconds or turning_total_time_seconds (they should be the same)\n",
    "if 'running_total_time_seconds' in df.columns:\n",
    "    total_time_col = 'running_total_time_seconds'\n",
    "elif 'turning_total_time_seconds' in df.columns:\n",
    "    total_time_col = 'turning_total_time_seconds'\n",
    "else:\n",
    "    total_time_col = None\n",
    "    print(\"âš ï¸ Warning: No total time column found. Cannot normalize distances.\")\n",
    "\n",
    "if total_time_col is not None:\n",
    "    # Convert seconds to minutes for normalization\n",
    "    df['total_time_minutes'] = df[total_time_col] / 60.0\n",
    "    \n",
    "    # Normalize running distance: m per minute\n",
    "    if 'running_distance_travelled_m' in df.columns:\n",
    "        df['running_distance_travelled_m_per_minute'] = df['running_distance_travelled_m'] / df['total_time_minutes']\n",
    "        print(\"âœ… Created normalized running distance (m/minute)\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Warning: 'running_distance_travelled_m' column not found\")\n",
    "    \n",
    "    # Normalize turning distance: degrees per minute (note: turning_distance_turned_m is actually in degrees)\n",
    "    if 'turning_distance_turned_m' in df.columns:\n",
    "        df['turning_distance_turned_deg_per_minute'] = df['turning_distance_turned_m'] / df['total_time_minutes']\n",
    "        print(\"âœ… Created normalized turning distance (deg/minute)\")\n",
    "    else:\n",
    "        print(\"âš ï¸ Warning: 'turning_distance_turned_m' column not found\")\n",
    "    \n",
    "    # Display summary of session durations\n",
    "    print(f\"\\nðŸ“Š Session duration summary (minutes):\")\n",
    "    print(f\"   Mean: {df['total_time_minutes'].mean():.2f} minutes\")\n",
    "    print(f\"   Min: {df['total_time_minutes'].min():.2f} minutes\")\n",
    "    print(f\"   Max: {df['total_time_minutes'].max():.2f} minutes\")\n",
    "    print(f\"\\n   By experiment day:\")\n",
    "    for day in sorted(df['Experiment_Day'].unique()):\n",
    "        day_times = df[df['Experiment_Day'] == day]['total_time_minutes']\n",
    "        print(f\"   {day}: {day_times.mean():.2f} Â± {day_times.std():.2f} minutes (n={len(day_times)})\")\n",
    "else:\n",
    "    # Create dummy normalized columns if normalization not possible\n",
    "    df['running_distance_travelled_m_per_minute'] = df.get('running_distance_travelled_m', np.nan)\n",
    "    df['turning_distance_turned_deg_per_minute'] = df.get('turning_distance_turned_m', np.nan)\n",
    "    print(\"âš ï¸ Using non-normalized distances (no time normalization available)\")\n",
    "\n",
    "# Separate visual mismatch experiments if configured\n",
    "#----------------------------\n",
    "if EXCLUDE_VISUAL_MISMATCH:\n",
    "    # Identify visual mismatch experiment days\n",
    "    visual_mismatch_days = [day for day in df['Experiment_Day'].unique() if 'visual_mismatch' in day.lower() or 'Visual_mismatch' in day]\n",
    "    \n",
    "    if visual_mismatch_days:\n",
    "        print(f\"\\nðŸ“Š Visual mismatch experiment days detected: {visual_mismatch_days}\")\n",
    "        df_visual_mismatch = df[df['Experiment_Day'].isin(visual_mismatch_days)].copy()\n",
    "        df_main = df[~df['Experiment_Day'].isin(visual_mismatch_days)].copy()\n",
    "        print(f\"   Main analysis dataset: {len(df_main)} rows (excluding visual mismatch)\")\n",
    "        print(f\"   Visual mismatch dataset: {len(df_visual_mismatch)} rows (will be analyzed separately)\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ No visual mismatch experiment days found in data\")\n",
    "        df_visual_mismatch = pd.DataFrame()\n",
    "        df_main = df.copy()\n",
    "else:\n",
    "    df_main = df.copy()\n",
    "    df_visual_mismatch = pd.DataFrame()\n",
    "    print(f\"\\nâš ï¸ Visual mismatch exclusion is disabled - all experiments will be included in main analysis\")\n",
    "\n",
    "# Check required columns\n",
    "required_cols = ['Animal_ID', 'Experiment_Day', 'running_velocity_avg_cm_per_s', \n",
    "                 'running_distance_travelled_m_per_minute', 'running_time_percentage',\n",
    "                 'turning_velocity_avg_deg_per_s', 'turning_distance_turned_deg_per_minute', \n",
    "                 'turning_time_percentage']\n",
    "missing_cols = [col for col in required_cols if col not in df_main.columns]\n",
    "\n",
    "if missing_cols:\n",
    "    print(f\"âš ï¸ Warning: Missing columns: {missing_cols}\")\n",
    "    print(f\"Available columns: {list(df_main.columns)}\")\n",
    "else:\n",
    "    print(\"\\nâœ… All required columns found (including normalized distances)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cohort Summary Statistics (Mean Â± SEM) - Normalized by session duration:\n",
      "experiment_day  n_mice  running_velocity_avg_cm_per_s_mean  running_velocity_avg_cm_per_s_sem  running_distance_travelled_m_per_minute_mean  running_distance_travelled_m_per_minute_sem  running_time_percentage_mean  running_time_percentage_sem  turning_velocity_avg_deg_per_s_mean  turning_velocity_avg_deg_per_s_sem  turning_distance_turned_deg_per_minute_mean  turning_distance_turned_deg_per_minute_sem  turning_time_percentage_mean  turning_time_percentage_sem\n",
      " Training_day1       4                            7.316906                           0.383844                                      1.026585                                     0.120098                     20.683632                     2.461653                             6.902476                            0.669350                                   145.540430                                   15.561920                     26.522289                     2.228745\n",
      " Training_day2       9                            8.053943                           0.559272                                      1.050914                                     0.142323                     19.552190                     2.303734                             5.451331                            0.550105                                   112.853352                                   12.830892                     26.283549                     1.678704\n",
      " Training_day3      10                            8.621088                           0.270600                                      1.203361                                     0.156611                     21.515188                     2.827214                             5.147758                            0.465965                                   108.319903                                   10.829800                     26.728771                     1.373242\n",
      " Training_day4       9                            9.672202                           0.655125                                      1.456778                                     0.146743                     23.664998                     2.348501                             6.006699                            0.446916                                   117.204580                                   11.930743                     25.763087                     1.704061\n",
      " Training_day5       8                            9.560673                           0.529000                                      1.586745                                     0.215715                     25.959936                     3.020775                             6.138909                            0.677496                                   122.099373                                   15.810508                     24.087293                     1.312541\n",
      " Training_day6      10                            9.996771                           0.699987                                      1.375085                                     0.197564                     20.498833                     2.431246                             5.576069                            0.501722                                   105.862738                                   12.114401                     23.899377                     1.558236\n"
     ]
    }
   ],
   "source": [
    "# Calculate summary statistics per experiment day\n",
    "#----------------------------\n",
    "def calculate_cohort_stats(df: pd.DataFrame, experiment_day: str) -> Dict:\n",
    "    \"\"\"Calculate mean and SEM for all mice on a given experiment day.\"\"\"\n",
    "    day_data = df[df['Experiment_Day'] == experiment_day].copy()\n",
    "    \n",
    "    if len(day_data) == 0:\n",
    "        return None\n",
    "    \n",
    "    n = len(day_data)\n",
    "    \n",
    "    # Calculate SEM = SD / sqrt(n)\n",
    "    def sem(x):\n",
    "        return x.std() / np.sqrt(n) if n > 1 else 0\n",
    "    \n",
    "    stats = {\n",
    "        'experiment_day': experiment_day,\n",
    "        'n_mice': n,\n",
    "        # Running stats\n",
    "        'running_velocity_avg_cm_per_s_mean': day_data['running_velocity_avg_cm_per_s'].mean(),\n",
    "        'running_velocity_avg_cm_per_s_sem': sem(day_data['running_velocity_avg_cm_per_s']),\n",
    "        'running_distance_travelled_m_per_minute_mean': day_data['running_distance_travelled_m_per_minute'].mean(),\n",
    "        'running_distance_travelled_m_per_minute_sem': sem(day_data['running_distance_travelled_m_per_minute']),\n",
    "        'running_time_percentage_mean': day_data['running_time_percentage'].mean(),\n",
    "        'running_time_percentage_sem': sem(day_data['running_time_percentage']),\n",
    "        # Turning stats\n",
    "        'turning_velocity_avg_deg_per_s_mean': day_data['turning_velocity_avg_deg_per_s'].mean(),\n",
    "        'turning_velocity_avg_deg_per_s_sem': sem(day_data['turning_velocity_avg_deg_per_s']),\n",
    "        'turning_distance_turned_deg_per_minute_mean': day_data['turning_distance_turned_deg_per_minute'].mean(),\n",
    "        'turning_distance_turned_deg_per_minute_sem': sem(day_data['turning_distance_turned_deg_per_minute']),\n",
    "        'turning_time_percentage_mean': day_data['turning_time_percentage'].mean(),\n",
    "        'turning_time_percentage_sem': sem(day_data['turning_time_percentage'])\n",
    "    }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Calculate stats for all experiment days (excluding visual mismatch if configured)\n",
    "experiment_days = sorted(df_main['Experiment_Day'].unique())\n",
    "cohort_stats = []\n",
    "\n",
    "for day in experiment_days:\n",
    "    stats = calculate_cohort_stats(df_main, day)\n",
    "    if stats:\n",
    "        cohort_stats.append(stats)\n",
    "\n",
    "cohort_stats_df = pd.DataFrame(cohort_stats)\n",
    "print(\"\\nCohort Summary Statistics (Mean Â± SEM) - Normalized by session duration:\")\n",
    "print(cohort_stats_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Assigned colors to 10 mice using gnuplot2 palette\n",
      "\n",
      "Mouse colors:\n",
      "  B6J2717: [0. 0. 0. 1.]\n",
      "  B6J2718: [0.         0.         0.42352941 1.        ]\n",
      "  B6J2719: [0.         0.         0.84705882 1.        ]\n",
      "  B6J2721: [0.21139706 0.         1.         1.        ]\n",
      "  B6J2722: [0.54227941 0.00705882 0.99294118 1.        ]\n",
      "  B6J2723: [0.87316176 0.21882353 0.78117647 1.        ]\n",
      "  B6J2780: [1.         0.43058824 0.56941176 1.        ]\n",
      "  B6J2781: [1.         0.64235294 0.35764706 1.        ]\n",
      "  B6J2782: [1.         0.85411765 0.14588235 1.        ]\n",
      "  B6J2783: [1.         1.         0.41176471 1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Assign consistent colors to each mouse using gnuplot2 palette\n",
    "#----------------------------\n",
    "def assign_mouse_colors(df: pd.DataFrame) -> Dict[str, str]:\n",
    "    \"\"\"Assign a consistent color to each mouse across all days using gnuplot2 palette.\"\"\"\n",
    "    unique_mice = sorted(df['Animal_ID'].unique())\n",
    "    n_colors = len(unique_mice)\n",
    "    \n",
    "    # Use gnuplot2 color palette (similar to gnuplot's default palette)\n",
    "    # gnuplot2 is a rainbow-like palette going from blue to red\n",
    "    # Avoid the white end (value 1.0) by using 0 to 0.95 instead of 0 to 1\n",
    "    # This ensures all colors are visible and distinct\n",
    "    colors = plt.cm.gnuplot2(np.linspace(0, 0.95, n_colors))\n",
    "    \n",
    "    mouse_colors = {mouse: colors[i] for i, mouse in enumerate(unique_mice)}\n",
    "    return mouse_colors\n",
    "\n",
    "mouse_colors = assign_mouse_colors(df_main)\n",
    "print(f\"âœ… Assigned colors to {len(mouse_colors)} mice using gnuplot2 palette\")\n",
    "print(f\"\\nMouse colors:\")\n",
    "for mouse, color in list(mouse_colors.items())[:10]:  # Show first 10\n",
    "    print(f\"  {mouse}: {color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved plot to: /Users/nora/Desktop/for_poster/cohort_1/cohort_1_cohort_3_averages.svg\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive plot\n",
    "#----------------------------\n",
    "def plot_cohort_behavioral_analysis(df: pd.DataFrame, cohort_stats_df: pd.DataFrame, \n",
    "                                     mouse_colors: Dict[str, str], output_path: Path):\n",
    "    \"\"\"Create a comprehensive plot showing all running and turning metrics with individual mice and cohort averages.\"\"\"\n",
    "    \n",
    "    experiment_days = sorted(df['Experiment_Day'].unique())\n",
    "    n_days = len(experiment_days)\n",
    "    \n",
    "    # Create figure with 2 rows and 3 columns (6 subplots total)\n",
    "    # Total height should be 19 cm including x-axis labels\n",
    "    # Convert cm to inches: 19 cm = 7.48 inches\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(17,9))\n",
    "    \n",
    "    x_pos = np.arange(n_days)\n",
    "    \n",
    "    # Helper function to plot a single metric\n",
    "    def plot_metric(ax, means, sems, individual_data_dict, title, ylabel):\n",
    "        \"\"\"Helper function to plot a metric with individual mice and mean Â± SEM.\"\"\"\n",
    "        # Plot individual mice\n",
    "        for mouse, mouse_values in individual_data_dict.items():\n",
    "            color = mouse_colors[mouse]\n",
    "            ax.plot(x_pos, mouse_values, 'o-', color=color, alpha=0.7, \n",
    "                    linewidth=1.5, markersize=5, label=mouse)\n",
    "        \n",
    "        # Plot mean line (black)\n",
    "        ax.plot(x_pos, means, '-', color='black', linewidth=2.5, zorder=10)\n",
    "        \n",
    "        # Plot SEM as opaque grey fill\n",
    "        ax.fill_between(x_pos, means - sems, means + sems, \n",
    "                       color='grey', alpha=0.5, zorder=9)\n",
    "        \n",
    "        ax.set_title(title, fontsize=15, fontweight='bold')\n",
    "        ax.set_ylabel(ylabel, fontsize=15, fontweight='bold')\n",
    "        ax.set_xticks(x_pos)\n",
    "        ax.set_xticklabels(experiment_days, rotation=20, ha='right', fontsize=15)\n",
    "        # Remove grid\n",
    "        ax.grid(False)\n",
    "    \n",
    "    # Collect individual mouse data for each metric\n",
    "    \n",
    "    # ========== ROW 1: RUNNING METRICS ==========\n",
    "    \n",
    "    # Plot 1: Running Velocity (cm/s)\n",
    "    ax1 = axes[0, 0]\n",
    "    running_velocities_dict = {}\n",
    "    for mouse in df['Animal_ID'].unique():\n",
    "        mouse_data = df[df['Animal_ID'] == mouse]\n",
    "        mouse_velocities = []\n",
    "        for day in experiment_days:\n",
    "            day_mouse_data = mouse_data[mouse_data['Experiment_Day'] == day]\n",
    "            if len(day_mouse_data) > 0:\n",
    "                mouse_velocities.append(day_mouse_data['running_velocity_avg_cm_per_s'].values[0])\n",
    "            else:\n",
    "                mouse_velocities.append(np.nan)\n",
    "        running_velocities_dict[mouse] = mouse_velocities\n",
    "    \n",
    "    means = cohort_stats_df['running_velocity_avg_cm_per_s_mean'].values\n",
    "    sems = cohort_stats_df['running_velocity_avg_cm_per_s_sem'].values\n",
    "    plot_metric(ax1, means, sems, running_velocities_dict, \n",
    "               'Running Velocity per Experiment Day', 'Running Velocity (cm/s)')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8, ncol=2)\n",
    "    \n",
    "    # Plot 2: Total Run Distance (m/minute) - Normalized by session duration\n",
    "    ax2 = axes[0, 1]\n",
    "    running_distances_dict = {}\n",
    "    for mouse in df['Animal_ID'].unique():\n",
    "        mouse_data = df[df['Animal_ID'] == mouse]\n",
    "        mouse_distances = []\n",
    "        for day in experiment_days:\n",
    "            day_mouse_data = mouse_data[mouse_data['Experiment_Day'] == day]\n",
    "            if len(day_mouse_data) > 0:\n",
    "                mouse_distances.append(day_mouse_data['running_distance_travelled_m_per_minute'].values[0])\n",
    "            else:\n",
    "                mouse_distances.append(np.nan)\n",
    "        running_distances_dict[mouse] = mouse_distances\n",
    "    \n",
    "    means = cohort_stats_df['running_distance_travelled_m_per_minute_mean'].values\n",
    "    sems = cohort_stats_df['running_distance_travelled_m_per_minute_sem'].values\n",
    "    plot_metric(ax2, means, sems, running_distances_dict,\n",
    "               'Total Run Distance per Experiment Day (Normalized)', 'Run Distance (m/min)')\n",
    "    \n",
    "    # Plot 3: Time Spent Running (Percentage)\n",
    "    ax3 = axes[0, 2]\n",
    "    running_percentages_dict = {}\n",
    "    for mouse in df['Animal_ID'].unique():\n",
    "        mouse_data = df[df['Animal_ID'] == mouse]\n",
    "        mouse_percentages = []\n",
    "        for day in experiment_days:\n",
    "            day_mouse_data = mouse_data[mouse_data['Experiment_Day'] == day]\n",
    "            if len(day_mouse_data) > 0:\n",
    "                mouse_percentages.append(day_mouse_data['running_time_percentage'].values[0])\n",
    "            else:\n",
    "                mouse_percentages.append(np.nan)\n",
    "        running_percentages_dict[mouse] = mouse_percentages\n",
    "    \n",
    "    means = cohort_stats_df['running_time_percentage_mean'].values\n",
    "    sems = cohort_stats_df['running_time_percentage_sem'].values\n",
    "    plot_metric(ax3, means, sems, running_percentages_dict,\n",
    "               'Time Spent Running per Experiment Day', 'Time Spent Running (%)')\n",
    "    \n",
    "    # ========== ROW 2: TURNING METRICS ==========\n",
    "    \n",
    "    # Plot 4: Turning Velocity (deg/s)\n",
    "    ax4 = axes[1, 0]\n",
    "    turning_velocities_dict = {}\n",
    "    for mouse in df['Animal_ID'].unique():\n",
    "        mouse_data = df[df['Animal_ID'] == mouse]\n",
    "        mouse_velocities = []\n",
    "        for day in experiment_days:\n",
    "            day_mouse_data = mouse_data[mouse_data['Experiment_Day'] == day]\n",
    "            if len(day_mouse_data) > 0:\n",
    "                mouse_velocities.append(day_mouse_data['turning_velocity_avg_deg_per_s'].values[0])\n",
    "            else:\n",
    "                mouse_velocities.append(np.nan)\n",
    "        turning_velocities_dict[mouse] = mouse_velocities\n",
    "    \n",
    "    means = cohort_stats_df['turning_velocity_avg_deg_per_s_mean'].values\n",
    "    sems = cohort_stats_df['turning_velocity_avg_deg_per_s_sem'].values\n",
    "    plot_metric(ax4, means, sems, turning_velocities_dict,\n",
    "               'Turning Velocity per Experiment Day', 'Turning Velocity (deg/s)')\n",
    "    \n",
    "    # Plot 5: Total Turn Distance (deg/minute) - Normalized by session duration\n",
    "    ax5 = axes[1, 1]\n",
    "    turning_distances_dict = {}\n",
    "    for mouse in df['Animal_ID'].unique():\n",
    "        mouse_data = df[df['Animal_ID'] == mouse]\n",
    "        mouse_distances = []\n",
    "        for day in experiment_days:\n",
    "            day_mouse_data = mouse_data[mouse_data['Experiment_Day'] == day]\n",
    "            if len(day_mouse_data) > 0:\n",
    "                mouse_distances.append(day_mouse_data['turning_distance_turned_deg_per_minute'].values[0])\n",
    "            else:\n",
    "                mouse_distances.append(np.nan)\n",
    "        turning_distances_dict[mouse] = mouse_distances\n",
    "    \n",
    "    means = cohort_stats_df['turning_distance_turned_deg_per_minute_mean'].values\n",
    "    sems = cohort_stats_df['turning_distance_turned_deg_per_minute_sem'].values\n",
    "    plot_metric(ax5, means, sems, turning_distances_dict,\n",
    "               'Total Turn Distance per Experiment Day (Normalized)', 'Turn Distance (deg/min)')\n",
    "    \n",
    "    # Plot 6: Time Spent Turning (Percentage)\n",
    "    ax6 = axes[1, 2]\n",
    "    turning_percentages_dict = {}\n",
    "    for mouse in df['Animal_ID'].unique():\n",
    "        mouse_data = df[df['Animal_ID'] == mouse]\n",
    "        mouse_percentages = []\n",
    "        for day in experiment_days:\n",
    "            day_mouse_data = mouse_data[mouse_data['Experiment_Day'] == day]\n",
    "            if len(day_mouse_data) > 0:\n",
    "                mouse_percentages.append(day_mouse_data['turning_time_percentage'].values[0])\n",
    "            else:\n",
    "                mouse_percentages.append(np.nan)\n",
    "        turning_percentages_dict[mouse] = mouse_percentages\n",
    "    \n",
    "    means = cohort_stats_df['turning_time_percentage_mean'].values\n",
    "    sems = cohort_stats_df['turning_time_percentage_sem'].values\n",
    "    plot_metric(ax6, means, sems, turning_percentages_dict,\n",
    "               'Time Spent Turning per Experiment Day', 'Time Spent Turning (%)')\n",
    "    \n",
    "    # Only add xlabel to bottom row plots\n",
    "    for ax in [ax4, ax5, ax6]:\n",
    "        ax.set_xlabel('')  # Remove xlabel as requested\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, format='svg', bbox_inches='tight')\n",
    "    print(f\"âœ… Saved plot to: {output_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# Create the plot (using main dataframe, excluding visual mismatch if configured)\n",
    "# Use simplified filename based on cohort directory names\n",
    "cohort_str = \"_\".join(cohort_names)\n",
    "plot_path = output_dir / f\"{cohort_str}_averages.svg\"\n",
    "plot_cohort_behavioral_analysis(df_main, cohort_stats_df, mouse_colors, plot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved summary statistics to: /Users/nora/Desktop/for_poster/cohort_1/cohort_1_cohort_3_averages.csv\n",
      "\n",
      "Summary Statistics (Mean Â± SEM) - Combined across all cohorts:\n",
      "experiment_day  n_mice  running_velocity_avg_cm_per_s_mean  running_velocity_avg_cm_per_s_sem  running_distance_travelled_m_per_minute_mean  running_distance_travelled_m_per_minute_sem  running_time_percentage_mean  running_time_percentage_sem  turning_velocity_avg_deg_per_s_mean  turning_velocity_avg_deg_per_s_sem  turning_distance_turned_deg_per_minute_mean  turning_distance_turned_deg_per_minute_sem  turning_time_percentage_mean  turning_time_percentage_sem\n",
      " Training_day1       4                            7.316906                           0.383844                                      1.026585                                     0.120098                     20.683632                     2.461653                             6.902476                            0.669350                                   145.540430                                   15.561920                     26.522289                     2.228745\n",
      " Training_day2       9                            8.053943                           0.559272                                      1.050914                                     0.142323                     19.552190                     2.303734                             5.451331                            0.550105                                   112.853352                                   12.830892                     26.283549                     1.678704\n",
      " Training_day3      10                            8.621088                           0.270600                                      1.203361                                     0.156611                     21.515188                     2.827214                             5.147758                            0.465965                                   108.319903                                   10.829800                     26.728771                     1.373242\n",
      " Training_day4       9                            9.672202                           0.655125                                      1.456778                                     0.146743                     23.664998                     2.348501                             6.006699                            0.446916                                   117.204580                                   11.930743                     25.763087                     1.704061\n",
      " Training_day5       8                            9.560673                           0.529000                                      1.586745                                     0.215715                     25.959936                     3.020775                             6.138909                            0.677496                                   122.099373                                   15.810508                     24.087293                     1.312541\n",
      " Training_day6      10                            9.996771                           0.699987                                      1.375085                                     0.197564                     20.498833                     2.431246                             5.576069                            0.501722                                   105.862738                                   12.114401                     23.899377                     1.558236\n",
      "\n",
      "\n",
      "Breakdown by Cohort and Experiment Day:\n",
      "\n",
      "cohort_1:\n",
      "  Number of animals: 6\n",
      "  Experiment days: ['Training_day2', 'Training_day3', 'Training_day4', 'Training_day5', 'Training_day6']\n",
      "\n",
      "cohort_3:\n",
      "  Number of animals: 4\n",
      "  Experiment days: ['Training_day1', 'Training_day2', 'Training_day3', 'Training_day4', 'Training_day5', 'Training_day6']\n"
     ]
    }
   ],
   "source": [
    "# Save summary statistics to CSV\n",
    "#----------------------------\n",
    "# Use simplified filename based on cohort directory names\n",
    "cohort_str = \"_\".join(cohort_names)\n",
    "summary_csv_path = output_dir / f\"{cohort_str}_averages.csv\"\n",
    "cohort_stats_df.to_csv(summary_csv_path, index=False)\n",
    "print(f\"âœ… Saved summary statistics to: {summary_csv_path}\")\n",
    "\n",
    "# Display the summary\n",
    "print(\"\\nSummary Statistics (Mean Â± SEM) - Combined across all cohorts:\")\n",
    "print(cohort_stats_df.to_string(index=False))\n",
    "\n",
    "# Also show breakdown by cohort if multiple cohorts\n",
    "if len(cohort_names) > 1:\n",
    "    print(f\"\\n\\nBreakdown by Cohort and Experiment Day:\")\n",
    "    for cohort in cohort_names:\n",
    "        cohort_data = df_main[df_main['Cohort'] == cohort]\n",
    "        print(f\"\\n{cohort}:\")\n",
    "        print(f\"  Number of animals: {cohort_data['Animal_ID'].nunique()}\")\n",
    "        print(f\"  Experiment days: {sorted(cohort_data['Experiment_Day'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VISUAL MISMATCH ANALYSIS: First Block vs Last Block Comparison\n",
      "================================================================================\n",
      "\n",
      "âœ… Prepared visual mismatch data for 18 rows\n",
      "\n",
      "ðŸ“Š Checking distance calculations:\n",
      "   first_block_running_distance_m_per_minute: 18/18 non-NaN\n",
      "   last_block_running_distance_m_per_minute: 18/18 non-NaN\n",
      "   first_block_turning_distance_deg_per_minute: 18/18 non-NaN\n",
      "   last_block_turning_distance_deg_per_minute: 18/18 non-NaN\n"
     ]
    }
   ],
   "source": [
    "# Visual Mismatch Analysis: First Block vs Last Block Comparison\n",
    "#----------------------------\n",
    "if EXCLUDE_VISUAL_MISMATCH and len(df_visual_mismatch) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VISUAL MISMATCH ANALYSIS: First Block vs Last Block Comparison\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Prepare first_block and last_block data\n",
    "    # Convert velocities from m/s to cm/s for first_block\n",
    "    if 'first_block_running_velocity_avg_m_per_s' in df_visual_mismatch.columns:\n",
    "        df_visual_mismatch['first_block_running_velocity_avg_cm_per_s'] = df_visual_mismatch['first_block_running_velocity_avg_m_per_s'] * 100\n",
    "    \n",
    "    # Convert last_block running velocity from m/s to cm/s\n",
    "    if 'last_block_running_velocity_avg_m_per_s' in df_visual_mismatch.columns:\n",
    "        df_visual_mismatch['last_block_running_velocity_avg_cm_per_s'] = df_visual_mismatch['last_block_running_velocity_avg_m_per_s'] * 100\n",
    "    \n",
    "    # Prepare turning velocities (already in deg/s)\n",
    "    if 'first_block_turning_velocity_avg_m_per_s' in df_visual_mismatch.columns:\n",
    "        df_visual_mismatch['first_block_turning_velocity_avg_deg_per_s'] = df_visual_mismatch['first_block_turning_velocity_avg_m_per_s']\n",
    "    \n",
    "    if 'last_block_turning_velocity_avg_m_per_s' in df_visual_mismatch.columns:\n",
    "        df_visual_mismatch['last_block_turning_velocity_avg_deg_per_s'] = df_visual_mismatch['last_block_turning_velocity_avg_m_per_s']\n",
    "    \n",
    "    # Normalize distances by block time for first_block\n",
    "    if 'first_block_running_total_time_seconds' in df_visual_mismatch.columns:\n",
    "        df_visual_mismatch['first_block_total_time_minutes'] = df_visual_mismatch['first_block_running_total_time_seconds'] / 60.0\n",
    "        if 'first_block_running_distance_travelled_m' in df_visual_mismatch.columns:\n",
    "            df_visual_mismatch['first_block_running_distance_m_per_minute'] = (\n",
    "                df_visual_mismatch['first_block_running_distance_travelled_m'] / \n",
    "                df_visual_mismatch['first_block_total_time_minutes']\n",
    "            )\n",
    "        if 'first_block_turning_distance_turned_m' in df_visual_mismatch.columns:\n",
    "            df_visual_mismatch['first_block_turning_distance_deg_per_minute'] = (\n",
    "                df_visual_mismatch['first_block_turning_distance_turned_m'] / \n",
    "                df_visual_mismatch['first_block_total_time_minutes']\n",
    "            )\n",
    "    \n",
    "    # For last_block - calculate time and normalize distances\n",
    "    # First, ensure we have last_block time\n",
    "    if 'last_block_running_time_seconds' in df_visual_mismatch.columns:\n",
    "        # Use last_block_running_time_seconds directly if available\n",
    "        df_visual_mismatch['last_block_total_time_minutes'] = df_visual_mismatch['last_block_running_time_seconds'] / 60.0\n",
    "    elif 'first_block_running_total_time_seconds' in df_visual_mismatch.columns and 'running_total_time_seconds' in df_visual_mismatch.columns:\n",
    "        # Calculate as difference between total and first block\n",
    "        df_visual_mismatch['last_block_total_time_minutes'] = (\n",
    "            (df_visual_mismatch['running_total_time_seconds'] - \n",
    "             df_visual_mismatch['first_block_running_total_time_seconds']) / 60.0\n",
    "        ).clip(lower=0.1)  # Avoid division by zero\n",
    "    else:\n",
    "        # Fallback: assume equal time distribution\n",
    "        if 'first_block_running_total_time_seconds' in df_visual_mismatch.columns:\n",
    "            df_visual_mismatch['last_block_total_time_minutes'] = df_visual_mismatch['first_block_running_total_time_seconds'] / 60.0\n",
    "        else:\n",
    "            df_visual_mismatch['last_block_total_time_minutes'] = 5.0  # Default fallback\n",
    "    \n",
    "    # Calculate last_block running distance - prioritize direct column, then calculation\n",
    "    if 'last_block_running_distance_travelled_m' in df_visual_mismatch.columns:\n",
    "        # Use direct last_block distance column\n",
    "        df_visual_mismatch['last_block_running_distance_m_per_minute'] = (\n",
    "            df_visual_mismatch['last_block_running_distance_travelled_m'] / \n",
    "            df_visual_mismatch['last_block_total_time_minutes']\n",
    "        )\n",
    "    elif all(col in df_visual_mismatch.columns for col in ['running_distance_travelled_m', 'first_block_running_distance_travelled_m']):\n",
    "        # Calculate as difference between total and first block\n",
    "        last_block_distance = (\n",
    "            df_visual_mismatch['running_distance_travelled_m'] - \n",
    "            df_visual_mismatch['first_block_running_distance_travelled_m']\n",
    "        )\n",
    "        df_visual_mismatch['last_block_running_distance_m_per_minute'] = (\n",
    "            last_block_distance / df_visual_mismatch['last_block_total_time_minutes']\n",
    "        )\n",
    "        # Handle negative values (shouldn't happen, but safety check)\n",
    "        df_visual_mismatch['last_block_running_distance_m_per_minute'] = df_visual_mismatch['last_block_running_distance_m_per_minute'].clip(lower=0)\n",
    "    \n",
    "    # Calculate last_block turning distance - prioritize direct column, then calculation\n",
    "    if 'last_block_turning_distance_turned_m' in df_visual_mismatch.columns:\n",
    "        # Use direct last_block distance column\n",
    "        df_visual_mismatch['last_block_turning_distance_deg_per_minute'] = (\n",
    "            df_visual_mismatch['last_block_turning_distance_turned_m'] / \n",
    "            df_visual_mismatch['last_block_total_time_minutes']\n",
    "        )\n",
    "    elif all(col in df_visual_mismatch.columns for col in ['turning_distance_turned_m', 'first_block_turning_distance_turned_m']):\n",
    "        # Calculate as difference between total and first block\n",
    "        last_block_turn_distance = (\n",
    "            df_visual_mismatch['turning_distance_turned_m'] - \n",
    "            df_visual_mismatch['first_block_turning_distance_turned_m']\n",
    "        )\n",
    "        df_visual_mismatch['last_block_turning_distance_deg_per_minute'] = (\n",
    "            last_block_turn_distance / df_visual_mismatch['last_block_total_time_minutes']\n",
    "        )\n",
    "        # Handle negative values (shouldn't happen, but safety check)\n",
    "        df_visual_mismatch['last_block_turning_distance_deg_per_minute'] = df_visual_mismatch['last_block_turning_distance_deg_per_minute'].clip(lower=0)\n",
    "    \n",
    "    # Debug: Check if all columns were created\n",
    "    print(f\"\\nâœ… Prepared visual mismatch data for {len(df_visual_mismatch)} rows\")\n",
    "    print(f\"\\nðŸ“Š Checking velocity calculations:\")\n",
    "    print(f\"   first_block_running_velocity_avg_cm_per_s: {df_visual_mismatch.get('first_block_running_velocity_avg_cm_per_s', pd.Series()).notna().sum() if 'first_block_running_velocity_avg_cm_per_s' in df_visual_mismatch.columns else 0}/{len(df_visual_mismatch)} non-NaN\")\n",
    "    print(f\"   last_block_running_velocity_avg_cm_per_s: {df_visual_mismatch.get('last_block_running_velocity_avg_cm_per_s', pd.Series()).notna().sum() if 'last_block_running_velocity_avg_cm_per_s' in df_visual_mismatch.columns else 0}/{len(df_visual_mismatch)} non-NaN\")\n",
    "    print(f\"\\nðŸ“Š Checking distance calculations:\")\n",
    "    print(f\"   first_block_running_distance_m_per_minute: {df_visual_mismatch.get('first_block_running_distance_m_per_minute', pd.Series()).notna().sum() if 'first_block_running_distance_m_per_minute' in df_visual_mismatch.columns else 0}/{len(df_visual_mismatch)} non-NaN\")\n",
    "    print(f\"   last_block_running_distance_m_per_minute: {df_visual_mismatch.get('last_block_running_distance_m_per_minute', pd.Series()).notna().sum() if 'last_block_running_distance_m_per_minute' in df_visual_mismatch.columns else 0}/{len(df_visual_mismatch)} non-NaN\")\n",
    "    print(f\"   first_block_turning_distance_deg_per_minute: {df_visual_mismatch.get('first_block_turning_distance_deg_per_minute', pd.Series()).notna().sum() if 'first_block_turning_distance_deg_per_minute' in df_visual_mismatch.columns else 0}/{len(df_visual_mismatch)} non-NaN\")\n",
    "    print(f\"   last_block_turning_distance_deg_per_minute: {df_visual_mismatch.get('last_block_turning_distance_deg_per_minute', pd.Series()).notna().sum() if 'last_block_turning_distance_deg_per_minute' in df_visual_mismatch.columns else 0}/{len(df_visual_mismatch)} non-NaN\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Visual mismatch analysis skipped\")\n",
    "    df_vm_melted = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VISUAL MISMATCH ANALYSIS: First Block vs Last Block Comparison\n",
      "================================================================================\n",
      "\n",
      "âœ… Prepared visual mismatch data:\n",
      "   Total rows: 36\n",
      "   Animals: 10\n",
      "   Experiment days: ['Visual_mismatch_day3', 'Visual_mismatch_day4']\n",
      "\n",
      "Available metrics:\n",
      "   Running velocity: True\n",
      "   Running distance: True\n",
      "   Running time %: True\n",
      "   Turning velocity: True\n",
      "   Turning distance: True\n",
      "   Turning time %: True\n",
      "\n",
      "ðŸ“Š Visual Mismatch Statistics: First Block vs Last Block\n",
      "            metric_label  first_block_mean  first_block_sem  last_block_mean  last_block_sem  difference  p_value\n",
      "        Running Time (%)         14.651928         2.131890        26.334851        1.548218   11.682923 0.000230\n",
      "Turning Velocity (deg/s)          6.599623         0.620398         7.147321        0.529589    0.547698 0.165735\n",
      "        Turning Time (%)         20.795259         1.646818        28.524643        0.856342    7.729385 0.001159\n",
      "\n",
      "ðŸ“ˆ Paired t-test results:\n",
      "   Running Time (%): t=-4.649, p=0.0002 *** (n=18)\n",
      "   Turning Velocity (deg/s): t=-1.448, p=0.1657 ns (n=18)\n",
      "   Turning Time (%): t=-3.897, p=0.0012 ** (n=18)\n"
     ]
    }
   ],
   "source": [
    "# Visual Mismatch Analysis: First Block vs Last Block Comparison\n",
    "#----------------------------\n",
    "# Note: Cell 9 already prepared the data with all conversions. \n",
    "# This cell creates the melted dataframe and calculates statistics.\n",
    "if EXCLUDE_VISUAL_MISMATCH and len(df_visual_mismatch) > 0:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"VISUAL MISMATCH ANALYSIS: First Block vs Last Block Comparison\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Ensure we have the necessary conversions (Cell 9 should have done this, but double-check)\n",
    "    # Convert last_block running velocity from m/s to cm/s if not already done\n",
    "    if 'last_block_running_velocity_avg_m_per_s' in df_visual_mismatch.columns and 'last_block_running_velocity_avg_cm_per_s' not in df_visual_mismatch.columns:\n",
    "        df_visual_mismatch['last_block_running_velocity_avg_cm_per_s'] = df_visual_mismatch['last_block_running_velocity_avg_m_per_s'] * 100\n",
    "        print(\"âœ… Converted last_block_running_velocity to cm/s\")\n",
    "    \n",
    "    # Debug: Check what columns we have\n",
    "    print(f\"\\nðŸ” Debug: Checking available columns in df_visual_mismatch:\")\n",
    "    last_block_cols = [col for col in df_visual_mismatch.columns if 'last_block' in col.lower()]\n",
    "    print(f\"   Last block columns: {len(last_block_cols)}\")\n",
    "    for col in ['last_block_running_velocity_avg_cm_per_s', 'last_block_running_distance_m_per_minute', \n",
    "                'last_block_turning_distance_deg_per_minute', 'last_block_turning_velocity_avg_deg_per_s']:\n",
    "        if col in df_visual_mismatch.columns:\n",
    "            non_nan = df_visual_mismatch[col].notna().sum()\n",
    "            print(f\"   âœ“ {col}: {non_nan}/{len(df_visual_mismatch)} non-NaN\")\n",
    "        else:\n",
    "            print(f\"   âœ— {col}: NOT FOUND\")\n",
    "    \n",
    "    # Data should already be prepared by Cell 9, but ensure distances are calculated if missing\n",
    "    # (Cell 9 handles this, so this is just a safety check)\n",
    "    if 'last_block_running_distance_m_per_minute' not in df_visual_mismatch.columns:\n",
    "        # This shouldn't happen if Cell 9 ran correctly, but handle it just in case\n",
    "        print(\"âš ï¸ Warning: last_block distances not found, attempting to calculate...\")\n",
    "        # Use the same logic as Cell 9\n",
    "        if 'last_block_running_time_seconds' in df_visual_mismatch.columns:\n",
    "            if 'first_block_running_total_time_seconds' in df_visual_mismatch.columns and 'running_total_time_seconds' in df_visual_mismatch.columns:\n",
    "                df_visual_mismatch['last_block_total_time_minutes'] = (\n",
    "                    (df_visual_mismatch['running_total_time_seconds'] - \n",
    "                     df_visual_mismatch['first_block_running_total_time_seconds']) / 60.0\n",
    "                ).clip(lower=0.1)\n",
    "            else:\n",
    "                df_visual_mismatch['last_block_total_time_minutes'] = df_visual_mismatch['last_block_running_time_seconds'] / 60.0\n",
    "            \n",
    "            if 'last_block_running_distance_travelled_m' in df_visual_mismatch.columns:\n",
    "                df_visual_mismatch['last_block_running_distance_m_per_minute'] = (\n",
    "                    df_visual_mismatch['last_block_running_distance_travelled_m'] / \n",
    "                    df_visual_mismatch['last_block_total_time_minutes']\n",
    "                )\n",
    "            elif all(col in df_visual_mismatch.columns for col in ['running_distance_travelled_m', 'first_block_running_distance_travelled_m']):\n",
    "                last_block_distance = (\n",
    "                    df_visual_mismatch['running_distance_travelled_m'] - \n",
    "                    df_visual_mismatch['first_block_running_distance_travelled_m']\n",
    "                )\n",
    "                df_visual_mismatch['last_block_running_distance_m_per_minute'] = (\n",
    "                    last_block_distance / df_visual_mismatch['last_block_total_time_minutes']\n",
    "                ).clip(lower=0)\n",
    "            \n",
    "            if 'last_block_turning_distance_turned_m' in df_visual_mismatch.columns:\n",
    "                df_visual_mismatch['last_block_turning_distance_deg_per_minute'] = (\n",
    "                    df_visual_mismatch['last_block_turning_distance_turned_m'] / \n",
    "                    df_visual_mismatch['last_block_total_time_minutes']\n",
    "                )\n",
    "            elif all(col in df_visual_mismatch.columns for col in ['turning_distance_turned_m', 'first_block_turning_distance_turned_m']):\n",
    "                last_block_turn_distance = (\n",
    "                    df_visual_mismatch['turning_distance_turned_m'] - \n",
    "                    df_visual_mismatch['first_block_turning_distance_turned_m']\n",
    "                )\n",
    "                df_visual_mismatch['last_block_turning_distance_deg_per_minute'] = (\n",
    "                    last_block_turn_distance / df_visual_mismatch['last_block_total_time_minutes']\n",
    "                ).clip(lower=0)\n",
    "    \n",
    "    # Create a long-format dataframe for easier plotting (first_block vs last_block)\n",
    "    vm_melted_data = []\n",
    "    \n",
    "    for _, row in df_visual_mismatch.iterrows():\n",
    "        animal_id = row['Animal_ID']\n",
    "        exp_day = row['Experiment_Day']\n",
    "        cohort = row['Cohort']\n",
    "        \n",
    "        # First block metrics\n",
    "        vm_melted_data.append({\n",
    "            'Animal_ID': animal_id,\n",
    "            'Experiment_Day': exp_day,\n",
    "            'Cohort': cohort,\n",
    "            'Block': 'First Block',\n",
    "            'running_velocity_cm_per_s': row.get('first_block_running_velocity_avg_cm_per_s', np.nan),\n",
    "            'running_distance_m_per_minute': row.get('first_block_running_distance_m_per_minute', np.nan),\n",
    "            'running_time_percentage': row.get('first_block_running_time_percentage', np.nan),\n",
    "            'turning_velocity_deg_per_s': row.get('first_block_turning_velocity_avg_deg_per_s', np.nan),\n",
    "            'turning_distance_deg_per_minute': row.get('first_block_turning_distance_deg_per_minute', np.nan),\n",
    "            'turning_time_percentage': row.get('first_block_turning_time_percentage', np.nan) if 'first_block_turning_time_percentage' in row.index else np.nan,\n",
    "        })\n",
    "        \n",
    "        # Last block metrics\n",
    "        vm_melted_data.append({\n",
    "            'Animal_ID': animal_id,\n",
    "            'Experiment_Day': exp_day,\n",
    "            'Cohort': cohort,\n",
    "            'Block': 'Last Block',\n",
    "            'running_velocity_cm_per_s': row.get('last_block_running_velocity_avg_cm_per_s', np.nan),\n",
    "            'running_distance_m_per_minute': row.get('last_block_running_distance_m_per_minute', np.nan),\n",
    "            'running_time_percentage': row.get('last_block_running_time_percentage', np.nan) if 'last_block_running_time_percentage' in row.index else np.nan,\n",
    "            'turning_velocity_deg_per_s': row.get('last_block_turning_velocity_avg_deg_per_s', np.nan),\n",
    "            'turning_distance_deg_per_minute': row.get('last_block_turning_distance_deg_per_minute', np.nan),\n",
    "            'turning_time_percentage': row.get('last_block_turning_time_percentage', np.nan) if 'last_block_turning_time_percentage' in row.index else np.nan,\n",
    "        })\n",
    "    \n",
    "    df_vm_melted = pd.DataFrame(vm_melted_data)\n",
    "    \n",
    "    print(f\"\\nâœ… Prepared visual mismatch data:\")\n",
    "    print(f\"   Total rows: {len(df_vm_melted)}\")\n",
    "    print(f\"   Animals: {df_vm_melted['Animal_ID'].nunique()}\")\n",
    "    print(f\"   Experiment days: {sorted(df_vm_melted['Experiment_Day'].unique())}\")\n",
    "    print(f\"\\nAvailable metrics:\")\n",
    "    print(f\"   Running velocity: {'running_velocity_cm_per_s' in df_vm_melted.columns}\")\n",
    "    print(f\"   Running distance: {'running_distance_m_per_minute' in df_vm_melted.columns}\")\n",
    "    print(f\"   Running time %: {'running_time_percentage' in df_vm_melted.columns}\")\n",
    "    print(f\"   Turning velocity: {'turning_velocity_deg_per_s' in df_vm_melted.columns}\")\n",
    "    print(f\"   Turning distance: {'turning_distance_deg_per_minute' in df_vm_melted.columns}\")\n",
    "    print(f\"   Turning time %: {'turning_time_percentage' in df_vm_melted.columns}\")\n",
    "    \n",
    "    # Debug: Check last_block data in melted dataframe\n",
    "    print(f\"\\nðŸ” Debugging last_block data in df_vm_melted:\")\n",
    "    for metric in ['running_velocity_cm_per_s', 'running_distance_m_per_minute', 'turning_distance_deg_per_minute']:\n",
    "        if metric in df_vm_melted.columns:\n",
    "            last_block_data = df_vm_melted[(df_vm_melted['Block'] == 'Last Block')][metric]\n",
    "            first_block_data = df_vm_melted[(df_vm_melted['Block'] == 'First Block')][metric]\n",
    "            last_non_nan = last_block_data.notna().sum()\n",
    "            first_non_nan = first_block_data.notna().sum()\n",
    "            total_count = len(last_block_data)\n",
    "            print(f\"   {metric}:\")\n",
    "            print(f\"      First Block: {first_non_nan}/{total_count} non-NaN\")\n",
    "            print(f\"      Last Block: {last_non_nan}/{total_count} non-NaN\")\n",
    "            if last_non_nan == 0:\n",
    "                print(f\"      âš ï¸ All last_block values are NaN!\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Visual mismatch analysis skipped (EXCLUDE_VISUAL_MISMATCH=False or no visual mismatch data found)\")\n",
    "    df_vm_melted = pd.DataFrame()\n",
    "\n",
    "# Calculate statistics for visual mismatch: First Block vs Last Block\n",
    "#----------------------------\n",
    "if EXCLUDE_VISUAL_MISMATCH and len(df_vm_melted) > 0 and 'Block' in df_vm_melted.columns:\n",
    "    def calculate_block_stats(df_melted: pd.DataFrame, metric: str, block: str) -> Dict:\n",
    "        \"\"\"Calculate mean and SEM for a given metric and block.\"\"\"\n",
    "        block_data = df_melted[(df_melted['Block'] == block) & (df_melted[metric].notna())]\n",
    "        if len(block_data) == 0:\n",
    "            return None\n",
    "        \n",
    "        n = len(block_data)\n",
    "        def sem(x):\n",
    "            return x.std() / np.sqrt(n) if n > 1 and x.std() > 0 else 0\n",
    "        \n",
    "        values = block_data[metric]\n",
    "        return {\n",
    "            'block': block,\n",
    "            'n': n,\n",
    "            'mean': values.mean(),\n",
    "            'sem': sem(values),\n",
    "            'std': values.std()\n",
    "        }\n",
    "    \n",
    "    # Calculate stats for each metric and block\n",
    "    metrics_to_analyze = {\n",
    "        'running_velocity_cm_per_s': 'Running Velocity (cm/s)',\n",
    "        'running_distance_m_per_minute': 'Running Distance (m/min)',\n",
    "        'running_time_percentage': 'Running Time (%)',\n",
    "        'turning_velocity_deg_per_s': 'Turning Velocity (deg/s)',\n",
    "        'turning_distance_deg_per_minute': 'Turning Distance (deg/min)',\n",
    "        'turning_time_percentage': 'Turning Time (%)'\n",
    "    }\n",
    "    \n",
    "    vm_stats = []\n",
    "    for metric, metric_label in metrics_to_analyze.items():\n",
    "        if metric in df_vm_melted.columns:\n",
    "            # Prepare paired data for t-test (matching by Animal_ID and Experiment_Day)\n",
    "            paired_data = []\n",
    "            for animal_id in df_vm_melted['Animal_ID'].unique():\n",
    "                for exp_day in df_vm_melted['Experiment_Day'].unique():\n",
    "                    animal_day_data = df_vm_melted[\n",
    "                        (df_vm_melted['Animal_ID'] == animal_id) & \n",
    "                        (df_vm_melted['Experiment_Day'] == exp_day)\n",
    "                    ]\n",
    "                    first_val = animal_day_data[(animal_day_data['Block'] == 'First Block')][metric].values\n",
    "                    last_val = animal_day_data[(animal_day_data['Block'] == 'Last Block')][metric].values\n",
    "                    if len(first_val) > 0 and len(last_val) > 0 and not np.isnan(first_val[0]) and not np.isnan(last_val[0]):\n",
    "                        paired_data.append({\n",
    "                            'Animal_ID': animal_id,\n",
    "                            'Experiment_Day': exp_day,\n",
    "                            'first_block': first_val[0],\n",
    "                            'last_block': last_val[0]\n",
    "                        })\n",
    "            \n",
    "            if len(paired_data) > 1:\n",
    "                paired_df = pd.DataFrame(paired_data)\n",
    "                first_vals = paired_df['first_block'].values\n",
    "                last_vals = paired_df['last_block'].values\n",
    "                \n",
    "                # Perform paired t-test\n",
    "                t_stat, p_value = ttest_rel(first_vals, last_vals)\n",
    "                \n",
    "                first_stats = calculate_block_stats(df_vm_melted, metric, 'First Block')\n",
    "                last_stats = calculate_block_stats(df_vm_melted, metric, 'Last Block')\n",
    "                \n",
    "                if first_stats and last_stats:\n",
    "                    vm_stats.append({\n",
    "                        'metric': metric,\n",
    "                        'metric_label': metric_label,\n",
    "                        'first_block_mean': first_stats['mean'],\n",
    "                        'first_block_sem': first_stats['sem'],\n",
    "                        'first_block_n': first_stats['n'],\n",
    "                        'last_block_mean': last_stats['mean'],\n",
    "                        'last_block_sem': last_stats['sem'],\n",
    "                        'last_block_n': last_stats['n'],\n",
    "                        'difference': last_stats['mean'] - first_stats['mean'],\n",
    "                        't_statistic': t_stat,\n",
    "                        'p_value': p_value,\n",
    "                        'n_paired': len(paired_data)\n",
    "                    })\n",
    "    \n",
    "    vm_stats_df = pd.DataFrame(vm_stats)\n",
    "    if len(vm_stats_df) > 0:\n",
    "        print(\"\\nðŸ“Š Visual Mismatch Statistics: First Block vs Last Block\")\n",
    "        display_cols = ['metric_label', 'first_block_mean', 'first_block_sem', 'last_block_mean', 'last_block_sem', 'difference', 'p_value']\n",
    "        print(vm_stats_df[display_cols].to_string(index=False))\n",
    "        print(\"\\nðŸ“ˆ Paired t-test results:\")\n",
    "        for _, row in vm_stats_df.iterrows():\n",
    "            sig = \"***\" if row['p_value'] < 0.001 else \"**\" if row['p_value'] < 0.01 else \"*\" if row['p_value'] < 0.05 else \"ns\"\n",
    "            print(f\"   {row['metric_label']}: t={row['t_statistic']:.3f}, p={row['p_value']:.4f} {sig} (n={row['n_paired']})\")\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ No statistics calculated - check available metrics\")\n",
    "        vm_stats_df = pd.DataFrame()\n",
    "else:\n",
    "    vm_stats_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved visual mismatch plot to: /Users/nora/Desktop/for_poster/cohort_1/cohort_1_cohort_3_visual_mismatch_blocks_comparison.svg\n",
      "âœ… Saved visual mismatch statistics to: /Users/nora/Desktop/for_poster/cohort_1/cohort_1_cohort_3_visual_mismatch_stats.csv\n"
     ]
    }
   ],
   "source": [
    "# Visualize Visual Mismatch: First Block vs Last Block Comparison\n",
    "#----------------------------\n",
    "if EXCLUDE_VISUAL_MISMATCH and len(df_vm_melted) > 0 and 'Block' in df_vm_melted.columns:\n",
    "    def plot_vm_block_comparison(df_melted: pd.DataFrame, vm_stats_df: pd.DataFrame, output_dir: Path):\n",
    "        \"\"\"Create plots comparing first block vs last block for visual mismatch experiments.\"\"\"\n",
    "        \n",
    "        metrics_to_plot = {\n",
    "            'running_velocity_cm_per_s': ('Running Velocity', 'Running Velocity (cm/s)'),\n",
    "            'running_distance_m_per_minute': ('Running Distance', 'Distance (m/min)'),\n",
    "            'running_time_percentage': ('Running Time', 'Time (%)'),\n",
    "            'turning_velocity_deg_per_s': ('Turning Velocity', 'Turning Velocity (deg/s)'),\n",
    "            'turning_distance_deg_per_minute': ('Turning Distance', 'Distance (deg/min)'),\n",
    "            'turning_time_percentage': ('Turning Time', 'Time (%)')\n",
    "        }\n",
    "        \n",
    "        # Get available metrics\n",
    "        available_metrics = {k: v for k, v in metrics_to_plot.items() if k in df_melted.columns}\n",
    "        \n",
    "        if len(available_metrics) == 0:\n",
    "            print(\"âš ï¸ No metrics available for plotting\")\n",
    "            return\n",
    "        \n",
    "        # Create figure with subplots\n",
    "        n_metrics = len(available_metrics)\n",
    "        n_cols = 3\n",
    "        n_rows = (n_metrics + n_cols - 1) // n_cols\n",
    "        \n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(18, 6 * n_rows))\n",
    "        if n_metrics == 1:\n",
    "            axes = [axes]\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        # Assign colors to mice for consistency\n",
    "        vm_mouse_colors = assign_mouse_colors(df_visual_mismatch)\n",
    "        \n",
    "        for idx, (metric, (title, ylabel)) in enumerate(available_metrics.items()):\n",
    "            ax = axes[idx]\n",
    "            \n",
    "            # Get data for this metric\n",
    "            metric_data = df_melted[df_melted[metric].notna()].copy()\n",
    "            \n",
    "            if len(metric_data) == 0:\n",
    "                ax.text(0.5, 0.5, f'No data for {title}', ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "                continue\n",
    "            \n",
    "            # Prepare data for comparison plot (no bars, just points and lines)\n",
    "            blocks = ['First Block', 'Last Block']\n",
    "            x_pos = np.arange(len(blocks))\n",
    "            \n",
    "            # Get unique mice and experiment days\n",
    "            unique_mice = sorted(metric_data['Animal_ID'].unique())\n",
    "            exp_days = sorted(metric_data['Experiment_Day'].unique())\n",
    "            \n",
    "            # Plot individual mouse lines (like main plot style)\n",
    "            for mouse in unique_mice:\n",
    "                mouse_data = metric_data[metric_data['Animal_ID'] == mouse]\n",
    "                mouse_values = []\n",
    "                for block in blocks:\n",
    "                    block_mouse_data = mouse_data[mouse_data['Block'] == block]\n",
    "                    if len(block_mouse_data) > 0:\n",
    "                        # Average across experiment days if multiple\n",
    "                        mouse_values.append(block_mouse_data[metric].mean())\n",
    "                    else:\n",
    "                        mouse_values.append(np.nan)\n",
    "                \n",
    "                color = vm_mouse_colors.get(mouse, 'gray')\n",
    "                ax.plot(x_pos, mouse_values, 'o-', color=color, alpha=0.7, \n",
    "                       linewidth=1.5, markersize=5, label=mouse if idx == 0 else \"\")\n",
    "            \n",
    "            # Plot mean Â± SEM line (like main plot style, no bars)\n",
    "            if len(vm_stats_df) > 0 and metric in vm_stats_df['metric'].values:\n",
    "                stats_row = vm_stats_df[vm_stats_df['metric'] == metric].iloc[0]\n",
    "                \n",
    "                means = [stats_row['first_block_mean'], stats_row['last_block_mean']]\n",
    "                sems = [stats_row['first_block_sem'], stats_row['last_block_sem']]\n",
    "                \n",
    "                # Plot mean line (black)\n",
    "                ax.plot(x_pos, means, '-', color='black', linewidth=2.5, zorder=10)\n",
    "                \n",
    "                # Plot SEM as opaque grey fill\n",
    "                ax.fill_between(x_pos, np.array(means) - np.array(sems), np.array(means) + np.array(sems), \n",
    "                               color='grey', alpha=0.5, zorder=9)\n",
    "                \n",
    "                # Add p-value annotation if significant\n",
    "                if stats_row['p_value'] < 0.05:\n",
    "                    sig_text = \"***\" if stats_row['p_value'] < 0.001 else \"**\" if stats_row['p_value'] < 0.01 else \"*\"\n",
    "                    y_max = max(means) + max(sems)\n",
    "                    ax.text(0.5, y_max * 1.1, sig_text, ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            ax.set_xlabel('Block', fontsize=15, fontweight='bold')\n",
    "            ax.set_ylabel(ylabel, fontsize=15, fontweight='bold')\n",
    "            ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "            ax.set_xticks(x_pos)\n",
    "            ax.set_xticklabels(blocks, fontsize=12, rotation=20, ha='right')\n",
    "            ax.grid(False)  # Match main plot style\n",
    "            ax.spines['top'].set_visible(False)\n",
    "            ax.spines['right'].set_visible(False)\n",
    "            \n",
    "            if idx == 0 and len(unique_mice) <= 15:\n",
    "                ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8, ncol=1)\n",
    "        \n",
    "        # Hide unused subplots\n",
    "        for idx in range(len(available_metrics), len(axes)):\n",
    "            axes[idx].set_visible(False)\n",
    "        \n",
    "        plt.suptitle('Visual Mismatch: First Block vs Last Block Comparison', \n",
    "                    fontsize=16, fontweight='bold', y=0.995)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save plot\n",
    "        cohort_str = \"_\".join(cohort_names)\n",
    "        plot_path = output_dir / f\"{cohort_str}_visual_mismatch_blocks_comparison.svg\"\n",
    "        plt.savefig(plot_path, format='svg', bbox_inches='tight')\n",
    "        print(f\"âœ… Saved visual mismatch plot to: {plot_path}\")\n",
    "        plt.close(fig)\n",
    "    \n",
    "    # Create the plot\n",
    "    plot_vm_block_comparison(df_vm_melted, vm_stats_df, output_dir)\n",
    "    \n",
    "    # Save visual mismatch statistics to CSV\n",
    "    if len(vm_stats_df) > 0:\n",
    "        cohort_str = \"_\".join(cohort_names)\n",
    "        vm_stats_csv_path = output_dir / f\"{cohort_str}_visual_mismatch_stats.csv\"\n",
    "        vm_stats_df.to_csv(vm_stats_csv_path, index=False)\n",
    "        print(f\"âœ… Saved visual mismatch statistics to: {vm_stats_csv_path}\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ Visual mismatch visualization skipped (no data available)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Optional: Create individual plots for each metric (larger, more detailed)\n",
    "#----------------------------\n",
    "def plot_individual_metric(df: pd.DataFrame, cohort_stats_df: pd.DataFrame,\n",
    "                          mouse_colors: Dict[str, str], metric: str, \n",
    "                          metric_label: str, ylabel: str, output_path: Path):\n",
    "    \"\"\"Create a detailed plot for a single metric.\"\"\"\n",
    "    \n",
    "    experiment_days = sorted(df['Experiment_Day'].unique())\n",
    "    n_days = len(experiment_days)\n",
    "    x_pos = np.arange(n_days)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    # Plot individual mice\n",
    "    for mouse in df['Animal_ID'].unique():\n",
    "        mouse_data = df[df['Animal_ID'] == mouse]\n",
    "        mouse_values = []\n",
    "        \n",
    "        for day in experiment_days:\n",
    "            day_mouse_data = mouse_data[mouse_data['Experiment_Day'] == day]\n",
    "            if len(day_mouse_data) > 0:\n",
    "                mouse_values.append(day_mouse_data[metric].values[0])\n",
    "            else:\n",
    "                mouse_values.append(np.nan)\n",
    "        \n",
    "        color = mouse_colors[mouse]\n",
    "        ax.plot(x_pos, mouse_values, 'o-', color=color, alpha=0.7, \n",
    "                linewidth=2, markersize=8, label=mouse)\n",
    "    \n",
    "    # Plot cohort average Â± SEM\n",
    "    mean_col = f\"{metric}_mean\"\n",
    "    sem_col = f\"{metric}_sem\"\n",
    "    \n",
    "    if mean_col in cohort_stats_df.columns and sem_col in cohort_stats_df.columns:\n",
    "        means = cohort_stats_df[mean_col].values\n",
    "        sems = cohort_stats_df[sem_col].values\n",
    "        \n",
    "        ax.errorbar(x_pos, means, yerr=sems, fmt='o-', color='black', \n",
    "                   linewidth=4, markersize=12, capsize=8, capthick=3, \n",
    "                   label='Cohort Mean Â± SEM', zorder=10)\n",
    "    \n",
    "    ax.set_xlabel('Experiment Day', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel(ylabel, fontsize=14, fontweight='bold')\n",
    "    ax.set_title(f'{metric_label} per Experiment Day', fontsize=16, fontweight='bold')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(experiment_days, rotation=45, ha='right', fontsize=12)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10, ncol=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path, format='svg', bbox_inches='tight')\n",
    "    print(f\"âœ… Saved plot to: {output_path}\")\n",
    "    plt.close(fig)\n",
    "\n",
    "# Create individual plots (optional - uncomment if needed)\n",
    "# plot_individual_metric(df, cohort_stats_df, mouse_colors, \n",
    "#                       'running_velocity_avg_cm_per_s', 'Running Velocity', \n",
    "#                       'Running Velocity (cm/s)', \n",
    "#                       output_dir / \"running_velocity_detailed.svg\")\n",
    "# \n",
    "# plot_individual_metric(df, cohort_stats_df, mouse_colors,\n",
    "#                       'running_distance_travelled_m_per_minute', 'Total Run Distance (Normalized)',\n",
    "#                       'Run Distance (m/min)',\n",
    "#                       output_dir / \"running_distance_detailed.svg\")\n",
    "# \n",
    "# plot_individual_metric(df, cohort_stats_df, mouse_colors,\n",
    "#                       'running_time_percentage', 'Time Spent Running',\n",
    "#                       'Time Spent Running (%)',\n",
    "#                       output_dir / \"running_time_percentage_detailed.svg\")\n",
    "# \n",
    "# plot_individual_metric(df, cohort_stats_df, mouse_colors,\n",
    "#                       'turning_velocity_avg_deg_per_s', 'Turning Velocity',\n",
    "#                       'Turning Velocity (deg/s)',\n",
    "#                       output_dir / \"turning_velocity_detailed.svg\")\n",
    "# \n",
    "# plot_individual_metric(df, cohort_stats_df, mouse_colors,\n",
    "#                       'turning_distance_turned_deg_per_minute', 'Total Turn Distance (Normalized)',\n",
    "#                       'Turn Distance (deg/min)',\n",
    "#                       output_dir / \"turning_distance_detailed.svg\")\n",
    "# \n",
    "# plot_individual_metric(df, cohort_stats_df, mouse_colors,\n",
    "#                       'turning_time_percentage', 'Time Spent Turning',\n",
    "#                       'Time Spent Turning (%)',\n",
    "#                       output_dir / \"turning_time_percentage_detailed.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "aeon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
