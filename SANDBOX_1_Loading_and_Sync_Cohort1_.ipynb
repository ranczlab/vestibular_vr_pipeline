{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry\n",
    "## Cohort 1 and 2 working, Cohort 0: onix_digital Clock column is 0, explore why and/or use timestamps instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "#import harp\n",
    "import plotly.express as px\n",
    "from scipy.stats import mode\n",
    "\n",
    "import gc # garbage collector for removing large variables from memory instantly \n",
    "\n",
    "import importlib #for force updating changed packages \n",
    "import harp_resources.process\n",
    "import harp_resources.utils\n",
    "from harp_resources import process, utils # Reassign to maintain direct references for force updating \n",
    "from sleap import load_and_process as lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate variables \n",
    "has_heartbeat = False\n",
    "cohort0 = False\n",
    "cohort2 = False\n",
    "onix_analog_clock_downsampled = False\n",
    "onix_analog_framecount_upsampled = False\n",
    "common_resampled_rate = 10000 #in Hz\n",
    "unit_conversions = False #\n",
    "save_full_asynchronous_data = False #saves alldata before resampling\n",
    "\n",
    "#Cohort 1 vestibular mismatch, multiple OnixDigital files \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2718-2024-12-12T13-28-14') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 vestibular mismatch, with clock accumulation issue marked on google sheet, seems fine though\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2719-2024-12-12T13-59-38') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 vestibular mismatch\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2717-2024-12-12T13-00-21')\n",
    "\n",
    "#Cohort 1 visual mismatch \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day3/B6J2718-2024-12-10T12-57-02') \n",
    "\n",
    "#Cohort 1 visual mismatch THIS\n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day3/B6J2717-2024-12-10T12-17-03')\n",
    "\n",
    "#Cohort 0 (no OnixHarp in this Cohort)\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort0/Cohort0_GCaMP_example/B3M3xx-2024-08-08T10-05-26')\n",
    "#cohort0 = True\n",
    "\n",
    "#Cohort 2 (Cohort 1 animal) \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test/2025-02-13T12-41-57')\n",
    "#has_heartbeat = True\n",
    "\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "\n",
    "#h1_datafolder = data_path / 'HarpDataH1' #only if reading separate registers\n",
    "#h2_datafolder = data_path / 'HarpDataH2' #only if reading separate registers\n",
    "#h1 and h2 only needed if timestamps are readed separately and not as all harp_streams\n",
    "#h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "#h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "\n",
    "#create loaders \n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "#photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.VideoReader(\"VideoData1\")\n",
    "video_reader2 = utils.VideoReader(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Load all data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code\n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "\n",
    "print (\"Loading processed photometry\")\n",
    "photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "photometry_data.set_index(\"TimeStamp\", inplace=True)\n",
    "photometry_data.index.name = 'Seconds'\n",
    "print (\"Loading processed photometry info\")\n",
    "photometry_info=pd.read_csv(str(photometry_path)+'/Info.csv')\n",
    "print (\"Loading processed photometry events\")\n",
    "photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "photometry_events[\"TimeStamp\"] = photometry_events[\"TimeStamp\"] /1000 # convert to seconds from ms\n",
    "photometry_events.set_index(\"TimeStamp\", inplace=True)\n",
    "photometry_events.index.name = 'Seconds'\n",
    "\n",
    "if not cohort2:\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data \n",
    "print (\"Loading OnixDigital\")\n",
    "onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "\n",
    "if cohort0:\n",
    "    print (\"Loading OnixAnalogFrameClock\")\n",
    "    onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "    \n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "print (\"Loading OnixAnalogData and converting to boolean photodiode array\")\n",
    "photodiode = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True, method='adaptive', refractory = 300, flip=True, verbose=False) #method adaptive or threshold (which is hard threshold at 120), refractory to avoid multiple detections\n",
    "\n",
    "#read HARP data\n",
    "print (\"Loading H1 and H2 streams, AnalogInput removed\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True, has_heartbeat = has_heartbeat, verbose = False) #loads as df, or if False, as dict\n",
    "harp_streams.drop(columns=[\"AnalogInput(39)\"], inplace=True)  # Removes AnalogInput permanently, as not currently used\n",
    "harp_streams = harp_streams.dropna(how=\"all\") # remove rows with all NaNs\n",
    "# Convert specific columns in harp_streams to boolean type\n",
    "columns_to_convert = [\"StartCam0(38)\", \"StartCam1(38)\", \"StopCam0(38)\", \"StopCam1(38)\"]\n",
    "for col in columns_to_convert:\n",
    "    harp_streams[col] = harp_streams[col].astype(bool)\n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "    onix_harp[\"HarpTime\"] = onix_harp[\"HarpTime\"] + 1 # known issue with current version of ONIX, harp timestamps lag 1 second\n",
    "    print (\"❗Reminder: HarpTime was increased by 1s to account for know issue with ONIX\")\n",
    "\n",
    "print (\"✅ Done Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Convert platform position and flow sensor streams to real world units and forward fill "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoder values for homing and next event positions as absolute real life 0 position \n",
    "homing_position, next_event_position = process.get_encoder_home_position(experiment_events, harp_streams)\n",
    "print (\"Encoder values for homing and next event positions\")\n",
    "print(f\"Encoder value at 'Homing platform': {homing_position}\")\n",
    "print(f\"Encoder value at the next experiment event: {next_event_position}\")\n",
    "print(\"❗ Warning: home position not tested. Likely the next event after homing reports the home position. \"\n",
    "      \"Alternatively, save a separate experiment event when homing is finished\")\n",
    "\n",
    "# Perform unit conversions if not already done\n",
    "if not unit_conversions:\n",
    "    harp_streams[\"OpticalTrackingRead0X(46)\"] = process.running_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead0X(46)\"].to_numpy())  # m / s\n",
    "    harp_streams[\"OpticalTrackingRead0Y(46)\"] = process.turning_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead0Y(46)\"].to_numpy())  # degrees / s\n",
    "    harp_streams[\"OpticalTrackingRead1X(46)\"] = process.running_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead1X(46)\"].to_numpy())\n",
    "    harp_streams[\"OpticalTrackingRead1Y(46)\"] = process.turning_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead1Y(46)\"].to_numpy())\n",
    "    harp_streams[\"Encoder(38)\"] = process.encoder_unit_conversion(\n",
    "        harp_streams[\"Encoder(38)\"], next_event_position)  # FIXME: what is the real home position?\n",
    "\n",
    "    # Forward fill all values to remove NaNs\n",
    "    columns_to_fill = [\n",
    "        \"OpticalTrackingRead0X(46)\", \"OpticalTrackingRead0Y(46)\",\n",
    "        \"OpticalTrackingRead1X(46)\", \"OpticalTrackingRead1Y(46)\",\n",
    "        \"Encoder(38)\"\n",
    "    ]\n",
    "    harp_streams[columns_to_fill] = harp_streams[columns_to_fill].ffill()\n",
    "    unit_conversions = True\n",
    "    print(\"✅ Unit conversions to real-life values done\")\n",
    "else:\n",
    "    print(\"❗ Flow sensor and encoder values already converted to real-world units, skipping\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Downsamples photodiode and analog_clock to common rate (10 kHz) and aligned photodiode_df to harptime - for Cohort 0 also upsamples framecount, not used for Cohort1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets analog data sample rate and downsamples to common_resampled_rate\n",
    "if not onix_analog_clock_downsampled:\n",
    "    onix_analog_clock = (onix_analog_clock * 4) * 1e-9  # convert to seconds with 250MHz DeviceClock, set in hardware\n",
    "    oac_diff = np.diff(onix_analog_clock)\n",
    "    onix_analog_rate = round(1 / (np.median(oac_diff)))  # to get to sampling rate (in Hz) with 250MHz DeviceClock, set in hardware\n",
    "    downsample_factor = int(onix_analog_rate / common_resampled_rate)\n",
    "    print(f\"onix_analog_clock rate: {onix_analog_rate}, downsample factor: {downsample_factor}\")\n",
    "    \n",
    "    onix_analog_clock = process.downsample_numpy(onix_analog_clock, downsample_factor, method=\"mean\")\n",
    "    photodiode = process.downsample_numpy(photodiode, downsample_factor, method=\"mean\")\n",
    "    photodiode_df = pd.DataFrame({\"Photodiode\": photodiode.astype(bool)}, index=pd.Index(onix_analog_clock, name=\"Seconds\"))\n",
    "    \n",
    "    # Get the timestamp when the sync signal started\n",
    "    sync_start_time = experiment_events[experiment_events == \"Sync signal started\"].index[0]\n",
    "    seconds_index = photodiode_df.index.values\n",
    "\n",
    "    # Convert the seconds index to timedelta and add to the sync start time using vectorized operations\n",
    "    timedelta_index = pd.to_timedelta(seconds_index, unit='s')\n",
    "    datetime_index = sync_start_time + timedelta_index\n",
    "\n",
    "    # Create a new DataFrame with the datetime index\n",
    "    photodiode_df.index = datetime_index\n",
    "    photodiode_df.index.name = 'Time'\n",
    "    \n",
    "    del onix_analog_clock, oac_diff, photodiode\n",
    "    gc.collect()\n",
    "    onix_analog_clock_downsampled = True\n",
    "    print(\"✅ Done downsampling analog_clock and photodiode, photodiode_df is now indexed to harp time\")\n",
    "else:\n",
    "    print(\"❗ onix_analog_clock & photodiode already downsampled, skipping\")\n",
    "\n",
    "# framecount upsampling, only used in Cohort 0 synchronization\n",
    "if cohort0:\n",
    "    if not onix_analog_framecount_upsampled:\n",
    "        upsample_factor = int(100 / downsample_factor)  # framecount counts every 100 analog datapoints\n",
    "        df = onix_analog_framecount\n",
    "        new_index = np.linspace(0, len(df) - 1, len(df) * upsample_factor)\n",
    "        onix_analog_framecount = pd.DataFrame(index=new_index)\n",
    "        for col in df.columns:\n",
    "            onix_analog_framecount[col] = np.interp(new_index, np.arange(len(df)), df[col])\n",
    "        del new_index\n",
    "        gc.collect()\n",
    "        # Check onix_analog shapes for consistency\n",
    "        data_len = photodiode.shape[0]\n",
    "        clock_len = onix_analog_clock.shape[0]\n",
    "        framecount_len = len(onix_analog_framecount)\n",
    "\n",
    "        if data_len != framecount_len or clock_len != framecount_len:\n",
    "            offset = framecount_len - clock_len\n",
    "            onix_analog_framecount = onix_analog_framecount.iloc[offset:]\n",
    "            print(f\"Warning: analog_data and _framecount mismatch, framecount truncated by {offset * 10}! Should be OK, but see https://github.com/neurogears/vestibular-vr/issues/81 for more information.\")\n",
    "        else:\n",
    "            print(\"onix_analog shapes are consistent!\")\n",
    "        onix_analog_framecount_upsampled = True\n",
    "        print(\"✅ Done upsampling analog_frameclock\")\n",
    "    else:\n",
    "        print(\"❗ onix_analog_framecount already upsampled, skipping\")\n",
    "\n",
    "del timedelta_index, datetime_index, seconds_index\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "( \n",
    "    onix_to_harp, \n",
    "    harp_to_onix, \n",
    "    photometry_to_onix, \n",
    "    photometry_to_harp, \n",
    "    conversions, #FIXME used?\n",
    "    photometry_aligned\n",
    ") = process.photometry_harp_onix_synchronisation(\n",
    "    onix_digital=onix_digital,\n",
    "    onix_harp=onix_harp,\n",
    "    photometry_events=photometry_events,\n",
    "    photometry_data = photometry_data,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "harp_streams.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding global first and last timestamp \n",
    "streams_dict = {\n",
    "    'session_settings': {'session_settings': session_settings},\n",
    "    'experiment_events': {'experiment_events': experiment_events},\n",
    "    'video_data1': {'video_data1': video_data1},\n",
    "    'video_data2': {'video_data2': video_data2},\n",
    "    'harp_streams': {'harp_streams': harp_streams},\n",
    "    'onix_harp': {'onix_harp': onix_harp},\n",
    "    'onix_digital': {'onix_digital': onix_digital},\n",
    "    'harp_streams': {'harp_streams': harp_streams},\n",
    "    'photodiode_df': {'photodiode_df': photodiode_df},\n",
    "    'photometry_aligned': {'photometry_aligned': photometry_aligned}\n",
    "}\n",
    "if cohort0:\n",
    "    streams_dict['onix_analog_framecount'] = {'onix_analog_framecount': onix_analog_framecount}\n",
    "\n",
    "global_first_timestamp, global_last_timestamp, _, _ = process.get_global_minmax_timestamps(streams_dict, print_all=False, verbose=True)\n",
    "\n",
    "del onix_digital, onix_harp, photometry_events, photometry_data\n",
    "gc.collect()\n",
    "\n",
    "# padding these dataframes to global first and last timestamp and bringing under new alldata dataframe \n",
    "dataframes = [video_data1, video_data2, harp_streams, photometry_aligned, photodiode_df]\n",
    "padded_dataframes = [process.pad_dataframe_with_global_timestamps(df, global_first_timestamp, global_last_timestamp) for df in dataframes]\n",
    "video_data1, video_data2, harp_streams, photometry_aligned, photodiode_df = padded_dataframes\n",
    "\n",
    "del padded_dataframes, streams_dict, dataframes\n",
    "gc.collect()\n",
    "\n",
    "if save_full_asynchronous_data: #FIXME is this correct?\n",
    "    alldata = pd.concat([video_data1, video_data2, harp_streams, photometry_aligned, photodiode_df], axis=1)\n",
    "    alldata.to_csv(data_path / \"full_asynchronous_data.csv\")\n",
    "    print(\"✅ Saved full asynchronous data to full_asynchronous_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes into a single dataframe\n",
    "video_data1 = video_data1.rename(columns=lambda x: f\"{x}_1\")\n",
    "video_data2 = video_data2.rename(columns=lambda x: f\"{x}_2\")\n",
    "alldata = pd.concat([video_data1, video_data2, harp_streams, photometry_aligned, photodiode_df], axis=1)\n",
    "alldata.info()\n",
    "\n",
    "del video_data1, video_data2, harp_streams, photometry_aligned, photodiode_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert startCam etc to bool at load, check if it propagates \n",
    "# convert photodiode (or propagate) as bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reload the modules\n",
    "importlib.reload(harp_resources.process)\n",
    "importlib.reload(harp_resources.utils)\n",
    "# Reassign after reloading to ensure updated references\n",
    "process = harp_resources.process\n",
    "utils = harp_resources.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def resample_to_1khz_grid(experiment_events, photometry_data, onix_analog_clock, photodiode, harp_streams):\n",
    "    \"\"\"\n",
    "    Resamples all datasets to a uniform 1 kHz (1 ms resolution) time grid while preserving alignment.\n",
    "    - Numeric signals are resampled using interpolation.\n",
    "    - Boolean signals retain original timestamps.\n",
    "\n",
    "    Parameters:\n",
    "        experiment_events (DataFrame): Original event timestamps.\n",
    "        photometry_data (DataFrame): Photometry data (with a \"TimeStamp\" column in seconds).\n",
    "        onix_analog_clock (ndarray): ONIX timestamps (nanoseconds).\n",
    "        photodiode (ndarray): ONIX data.\n",
    "        harp_streams (DataFrame): HARP-streamed data (both numeric and boolean).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of aligned datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert photometry timestamps from seconds to datetime\n",
    "    photometry_data[\"Datetime\"] = pd.to_datetime(photometry_data[\"TimeStamp\"], unit=\"s\", origin=\"1900-01-01\")\n",
    "    photometry_data = photometry_data.set_index(\"Datetime\").drop(columns=[\"TimeStamp\"])\n",
    "\n",
    "    # Convert ONIX timestamps from nanoseconds to datetime\n",
    "    onix_time_index = pd.to_datetime(onix_analog_clock, unit=\"ns\", origin=\"1900-01-01\")\n",
    "\n",
    "    # Define a uniform 1 kHz time grid spanning the full experiment\n",
    "    min_time = min(\n",
    "        experiment_events.index.min(),\n",
    "        photometry_data.index.min(),\n",
    "        onix_time_index.min(),\n",
    "        harp_streams.index.min()\n",
    "    )\n",
    "    max_time = max(\n",
    "        experiment_events.index.max(),\n",
    "        photometry_data.index.max(),\n",
    "        onix_time_index.max(),\n",
    "        harp_streams.index.max()\n",
    "    )\n",
    "\n",
    "    # Create the 1 kHz common time grid\n",
    "    common_time_grid = pd.date_range(start=min_time, end=max_time, freq=\"1ms\")\n",
    "\n",
    "    # Debugging print to confirm grid size\n",
    "    print(f\"⚡ Resampling to 1 kHz grid: {len(common_time_grid)} time points\")\n",
    "\n",
    "    # Split harp_streams into numeric and boolean columns\n",
    "    harp_numeric = harp_streams.select_dtypes(exclude=['bool'])\n",
    "    harp_bool = harp_streams.select_dtypes(include=['bool'])\n",
    "\n",
    "    # Resample numeric data to the 1 kHz grid\n",
    "    def resample_numeric(df):\n",
    "        \"\"\"Interpolates numeric data to match the 1 kHz time grid.\"\"\"\n",
    "        return df.reindex(df.index.union(common_time_grid)).interpolate(method='time').reindex(common_time_grid)\n",
    "\n",
    "    # Resample event timestamps, photometry, and ONIX signals\n",
    "    experiment_events_resampled = resample_numeric(experiment_events)\n",
    "    photometry_data_resampled = resample_numeric(photometry_data)\n",
    "\n",
    "    # Interpolate ONIX analog data\n",
    "    photodiode_resampled = pd.DataFrame(\n",
    "        index=common_time_grid,\n",
    "        data=np.interp(\n",
    "            common_time_grid.astype('int64') / 1e9,  # Convert ms timestamps to seconds\n",
    "            onix_analog_clock / 1e9,  # Convert ONIX timestamps to seconds\n",
    "            photodiode\n",
    "        ),\n",
    "        columns=[\"photodiode\"]\n",
    "    )\n",
    "\n",
    "    # Resample numeric columns of harp_streams to the 1 kHz grid\n",
    "    harp_numeric_resampled = resample_numeric(harp_numeric)\n",
    "\n",
    "    # Keep boolean columns at original timestamps (no downsampling)\n",
    "    harp_bool_aligned = harp_bool.reindex(harp_bool.index.union(common_time_grid)).fillna(method='ffill')\n",
    "\n",
    "    return {\n",
    "        \"experiment_events_resampled\": experiment_events_resampled,\n",
    "        \"photometry_data_resampled\": photometry_data_resampled,\n",
    "        \"photodiode_resampled\": photodiode_resampled,\n",
    "        \"harp_numeric_resampled\": harp_numeric_resampled,\n",
    "        \"harp_bool_aligned\": harp_bool_aligned\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage:\n",
    "aligned_data = resample_to_1khz_grid(experiment_events, photometry_data, onix_analog_clock, photodiode, harp_streams)\n",
    "\n",
    "# Access the resampled datasets:\n",
    "experiment_events_resampled = aligned_data[\"experiment_events_resampled\"]\n",
    "photometry_data_resampled = aligned_data[\"photometry_data_resampled\"]\n",
    "photodiode_resampled = aligned_data[\"photodiode_resampled\"]\n",
    "harp_numeric_resampled = aligned_data[\"harp_numeric_resampled\"]\n",
    "harp_bool_aligned = aligned_data[\"harp_bool_aligned\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_events = experiment_events[\"Event\"].unique()\n",
    "print(unique_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plotting Parameters ----\n",
    "window_start = -1  # seconds, analysis window to plot and average\n",
    "window_stop = 5\n",
    "how_many_to_plot = -1  # -1 plots all or X plots first x halt events \n",
    "\n",
    "\n",
    "if \"Visual_mismatch\" in str(data_path):    \n",
    "    block_start_event = \"DrumWithReverseHalt block started\"\n",
    "    halt_event = \"Apply halt: 2s\"\n",
    "    block_end_event = \"Block timer elapsed\" # Set to \"no_end\" to scan all events\n",
    "\n",
    "if \"VestibularMismatch\" in str(data_path):\n",
    "    block_start_event = \"Sync signal started\"\n",
    "    halt_event = \"DrumWithReverseflow block started\"\n",
    "    block_end_event = \"no_end\"\n",
    "    \n",
    "if \"Cohort2_test\" in str(data_path):    \n",
    "    block_start_event = \"DrumWithReverseHalt block started\"\n",
    "    halt_event = \"Apply halt: 2s\"\n",
    "    block_end_event = \"Block timer elapsed\" # Set to \"no_end\" to scan all events\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def pad_arrays(array_list):\n",
    "    \"\"\"Pads a list of 1D NumPy arrays to the same length using NaN padding.\"\"\"\n",
    "    max_len = max(map(len, array_list))  # Efficient max length calculation\n",
    "    padded_array = np.empty((len(array_list), max_len), dtype=np.float64)  # Preallocate array\n",
    "    padded_array.fill(np.nan)  # Fill with NaNs in one operation\n",
    "\n",
    "    for i, arr in enumerate(array_list):\n",
    "        padded_array[i, :len(arr)] = arr  # Vectorized assignment\n",
    "\n",
    "    return padded_array\n",
    "\n",
    "def set_axis_limits(ax_run, ax_turn, data_run, data_turn):\n",
    "    \"\"\"Set axis limits with minimum ranges that expand if data requires\"\"\"\n",
    "    run_min, run_max = np.nanmin(data_run), np.nanmax(data_run)\n",
    "    turn_min, turn_max = np.nanmin(data_turn), np.nanmax(data_turn)\n",
    "    \n",
    "    # Set running axis limits (minimum range: -0.02 to +0.10)\n",
    "    ax_run.set_ylim([min(-0.02, run_min), max(0.10, run_max)])\n",
    "    \n",
    "    # Set turning axis limits (minimum range: -45 to +45)\n",
    "    ax_turn.set_ylim([min(-45, turn_min), max(45, turn_max)])\n",
    "\n",
    "\n",
    "# ---- Extract Halt Events Efficiently ----\n",
    "block_starts = experiment_events.query(\"Event == @block_start_event\").index.to_numpy()\n",
    "\n",
    "halt_events_list = []\n",
    "for block_start in block_starts:\n",
    "    if block_end_event == \"no_end\":\n",
    "        block_halts = experiment_events.query(\"Event == @halt_event and index > @block_start\")\n",
    "    else:\n",
    "        block_end = experiment_events.query(\"Event == @block_end_event and index > @block_start\").index.min()\n",
    "        if pd.notna(block_end):\n",
    "            block_halts = experiment_events.query(\"Event == @halt_event and index > @block_start and index < @block_end\")\n",
    "        else:\n",
    "            block_halts = pd.DataFrame()  # No valid end event found\n",
    "    \n",
    "    if not block_halts.empty:\n",
    "        halt_events_list.append(block_halts)\n",
    "\n",
    "block_halts = pd.concat(halt_events_list) if halt_events_list else pd.DataFrame()\n",
    "\n",
    "if block_halts.empty:\n",
    "    raise ValueError(f\"⚠️ No [{halt_event}] events found between [{block_start_event}] and [{block_end_event}]. \"\n",
    "                     f\"Check if the event names are correct and exist in experiment_events.\")\n",
    "\n",
    "# Convert Halt Times to NumPy for Efficiency\n",
    "halt_event_times = block_halts.index.to_numpy()\n",
    "\n",
    "# Adjust how_many_to_plot if it exceeds available events\n",
    "if how_many_to_plot > len(block_halts):\n",
    "    print(f\"⚠️ Warning: Requested {how_many_to_plot} halts, but only {len(block_halts)} are available. \"\n",
    "          \"Adjusting how_many_to_plot accordingly.\")\n",
    "    how_many_to_plot = len(block_halts)\n",
    "\n",
    "if how_many_to_plot == -1:\n",
    "    how_many_to_plot = len(block_halts)  # Limit to avoid excessive plots\n",
    "print(f\"Found {len(block_halts)} halt events within valid blocks, plotting {how_many_to_plot}.\")\n",
    "\n",
    "# Define colors\n",
    "flow_x_color, flow_y_color, photodiode_color = \"blue\", \"orange\", \"grey\"  # Changed photodiode to grey\n",
    "z_470_color, z_560_color = \"green\", \"red\"\n",
    "\n",
    "# Initialize lists for aligned data\n",
    "aligned_time = np.linspace(window_start, window_stop, 500)  \n",
    "flow_x_aligned, flow_y_aligned, photodiode_aligned, z_470_aligned, z_560_aligned = [], [], [], [], []\n",
    "\n",
    "# ----------------------\n",
    "# First Plot: Individual Trials\n",
    "# ----------------------\n",
    "fig, ax_run = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create axes for turning, photodiode and fluorescence\n",
    "ax_turn = ax_run.twinx()\n",
    "ax_turn.spines.left.set_position(('outward', 60))\n",
    "ax_turn.yaxis.set_label_position('left')\n",
    "ax_turn.yaxis.set_ticks_position('left')\n",
    "\n",
    "ax_photo = ax_run.twinx()\n",
    "ax_photo.spines.right.set_position(('outward', 60))\n",
    "\n",
    "ax_fluor = ax_run.twinx()\n",
    "ax_fluor.spines.right.set_position(('outward', 120))\n",
    "\n",
    "all_plotted_x_values = []\n",
    "all_plotted_y_values = []\n",
    "\n",
    "for idx, halt_time in enumerate(block_halts.index[:how_many_to_plot]):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "    min_time, max_time = halt_time + pd.DateOffset(seconds=window_start), halt_time + pd.DateOffset(seconds=window_stop)\n",
    "\n",
    "    # Extract Optical Tracking Data\n",
    "    optical_x = harp_streams['OpticalTrackingRead0X(46)'].loc[min_time:max_time].dropna()\n",
    "    optical_y = harp_streams['OpticalTrackingRead0Y(46)'].loc[min_time:max_time].dropna()\n",
    "\n",
    "    if not optical_x.empty and not optical_y.empty:\n",
    "        optical_x_rel = (optical_x.index.astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "        optical_y_rel = (optical_y.index.astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "        \n",
    "        if not optical_x.empty and not optical_y.empty:\n",
    "            all_plotted_x_values.extend(optical_x.values)\n",
    "            all_plotted_y_values.extend(optical_y.values)\n",
    "\n",
    "        label_x = \"Running (Flow X)\" if idx == 0 else None\n",
    "        label_y = \"Turning (Flow Y)\" if idx == 0 else None\n",
    "        ax_run.plot(optical_x_rel, optical_x, color=flow_x_color, alpha=0.3, label=label_x)\n",
    "        ax_turn.plot(optical_y_rel, optical_y, color=flow_y_color, alpha=0.3, label=label_y)\n",
    "\n",
    "        # Restrict aligned_time to the valid range of optical_x_rel\n",
    "        valid_mask = (aligned_time >= optical_x_rel.min()) & (aligned_time <= optical_x_rel.max())\n",
    "        aligned_time_valid = aligned_time[valid_mask]\n",
    "\n",
    "        # Interpolate only within the valid time range\n",
    "        flow_x_interp = np.interp(aligned_time_valid, optical_x_rel, optical_x, left=np.nan, right=np.nan)\n",
    "        flow_y_interp = np.interp(aligned_time_valid, optical_y_rel, optical_y, left=np.nan, right=np.nan)\n",
    "\n",
    "        # Append only the valid interpolated values\n",
    "        flow_x_aligned.append(flow_x_interp)\n",
    "        flow_y_aligned.append(flow_y_interp)\n",
    "        \n",
    "# Set axis limits using only the plotted data\n",
    "all_plotted_x_values = np.array(all_plotted_x_values)\n",
    "all_plotted_y_values = np.array(all_plotted_y_values)\n",
    "set_axis_limits(ax_run, ax_turn, all_plotted_x_values, all_plotted_y_values)\n",
    "\n",
    "ax_run.set_xlabel(\"Relative Time (s)\")\n",
    "ax_run.set_ylabel(\"Running X (m/s)\")\n",
    "ax_turn.set_ylabel(\"Turning Y (deg/s)\")\n",
    "ax_photo.set_ylabel(\"Photodiode Signal\")\n",
    "ax_photo.set_ylim([0, 1.2])\n",
    "ax_fluor.set_ylabel(\"Fluorescence Signal\")\n",
    "\n",
    "for idx, halt_time in enumerate(block_halts.index[:how_many_to_plot]):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "\n",
    "    onix_sec_start_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_start)\n",
    "    onix_sec_stop_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_stop)\n",
    "\n",
    "    onix_sec_start_index = np.searchsorted(onix_analog_clock, onix_sec_start_time)\n",
    "    onix_sec_stop_index = np.searchsorted(onix_analog_clock, onix_sec_stop_time)\n",
    "\n",
    "    onix_time_rel = (onix_to_harp_timestamp(onix_analog_clock[onix_sec_start_index:onix_sec_stop_index])\n",
    "                     .astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "\n",
    "    photodiode_signal = photodiode[onix_sec_start_index:onix_sec_stop_index]\n",
    "\n",
    "    label_photodiode = \"Photodiode\" if idx == 0 else None\n",
    "    ax_photo.plot(onix_time_rel, photodiode_signal, color=photodiode_color, alpha=0.5, label=label_photodiode)\n",
    "\n",
    "    # Restrict aligned_time to valid range of onix_time_rel\n",
    "    valid_mask = (aligned_time >= onix_time_rel.min()) & (aligned_time <= onix_time_rel.max())\n",
    "    aligned_time_valid = aligned_time[valid_mask]\n",
    "\n",
    "    # Interpolate photodiode on the valid time range\n",
    "    photodiode_interp = np.interp(aligned_time_valid, onix_time_rel, photodiode_signal, left=np.nan, right=np.nan)\n",
    "    photodiode_aligned.append(photodiode_interp)\n",
    "    \n",
    "\n",
    "if \"TimeStamp\" in photometry_data.columns:\n",
    "    photometry_data = photometry_data.set_index(\"TimeStamp\")\n",
    "\n",
    "for idx, halt_time in enumerate(block_halts.index[:how_many_to_plot]):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "\n",
    "    photometry_sec_start_time = onix_time_to_photometry(harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_start))\n",
    "    photometry_sec_stop_time = onix_time_to_photometry(harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_stop))\n",
    "\n",
    "    photometry_sec = photometry_data.loc[photometry_sec_start_time:photometry_sec_stop_time]\n",
    "\n",
    "    if not photometry_sec.empty:\n",
    "        photometry_time_rel = (photometry_to_harp_time(photometry_sec.index).astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "\n",
    "        label_560, label_470 = \"z_560\" if idx == 0 else None, \"z_470\" if idx == 0 else None\n",
    "        ax_fluor.plot(photometry_time_rel, photometry_sec['z_560'], color=z_560_color, alpha=0.3, label=label_560)\n",
    "        ax_fluor.plot(photometry_time_rel, photometry_sec['z_470'], color=z_470_color, alpha=0.3, label=label_470)\n",
    "        \n",
    "        # Restrict aligned_time to the valid range of photometry_time_rel\n",
    "        valid_mask = (aligned_time >= photometry_time_rel.min()) & (aligned_time <= photometry_time_rel.max())\n",
    "        aligned_time_valid = aligned_time[valid_mask]\n",
    "\n",
    "        # Perform interpolation on the adjusted time range\n",
    "        z_560_interp = np.interp(aligned_time_valid, photometry_time_rel, photometry_sec['z_560'], left=np.nan, right=np.nan)\n",
    "        z_470_interp = np.interp(aligned_time_valid, photometry_time_rel, photometry_sec['z_470'], left=np.nan, right=np.nan)\n",
    "        \n",
    "        # Append only the valid interpolated values\n",
    "        z_560_aligned.append(z_560_interp)\n",
    "        z_470_aligned.append(z_470_interp)\n",
    "\n",
    "ax_run.legend(loc=\"upper left\")\n",
    "ax_turn.legend(loc=\"upper left\", bbox_to_anchor=(0, 0.9))\n",
    "ax_photo.legend(loc=\"center right\")\n",
    "ax_fluor.legend(loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Individual Trials\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------\n",
    "# Second Plot: Averages with Error Shading (Proper Axes Labels & No Overlap)\n",
    "# ----------------------\n",
    "fig, ax_run = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create axes for turning, photodiode and fluorescence\n",
    "ax_turn = ax_run.twinx()\n",
    "ax_turn.spines.left.set_position(('outward', 60))\n",
    "ax_turn.yaxis.set_label_position('left')\n",
    "ax_turn.yaxis.set_ticks_position('left')\n",
    "\n",
    "ax_photo = ax_run.twinx()\n",
    "ax_photo.spines.right.set_position(('outward', 60))\n",
    "\n",
    "ax_fluor = ax_run.twinx()\n",
    "ax_fluor.spines.right.set_position(('outward', 120))\n",
    "\n",
    "# Pad all signal data to ensure uniform shape\n",
    "flow_x_aligned_padded = pad_arrays(flow_x_aligned)\n",
    "flow_y_aligned_padded = pad_arrays(flow_y_aligned)\n",
    "photodiode_aligned_padded = pad_arrays(photodiode_aligned)\n",
    "z_560_aligned_padded = pad_arrays(z_560_aligned)\n",
    "z_470_aligned_padded = pad_arrays(z_470_aligned)\n",
    "\n",
    "# Ensure all arrays have the same length\n",
    "# Get the number of valid (non-NaN) values per time point across trials\n",
    "valid_counts_560 = np.sum(~np.isnan(z_560_aligned_padded), axis=0)\n",
    "valid_counts_470 = np.sum(~np.isnan(z_470_aligned_padded), axis=0)\n",
    "\n",
    "# Find the last point where at least 80% of trials still have data\n",
    "threshold = 0.8 * len(z_560_aligned_padded)  # Adjustable threshold (80%)\n",
    "adaptive_cutoff = np.where(valid_counts_560 >= threshold)[0][-1]  # Last valid index\n",
    "\n",
    "# Use the smaller of (1) standard min_length, (2) adaptive cutoff\n",
    "min_length = min(\n",
    "    aligned_time.shape[0], \n",
    "    photodiode_aligned_padded.shape[1], \n",
    "    z_560_aligned_padded.shape[1], \n",
    "    z_470_aligned_padded.shape[1], \n",
    "    flow_x_aligned_padded.shape[1],  \n",
    "    flow_y_aligned_padded.shape[1],\n",
    "    adaptive_cutoff  # Ensure we include this index\n",
    ")\n",
    "\n",
    "print(f\"🔍 Adaptive cutoff applied at index {adaptive_cutoff}, using min_length = {min_length}\")\n",
    "\n",
    "# Compute means after padding\n",
    "flow_x_mean = np.nanmean(flow_x_aligned_padded, axis=0)\n",
    "flow_y_mean = np.nanmean(flow_y_aligned_padded, axis=0)\n",
    "photodiode_mean = np.nanmean(photodiode_aligned_padded, axis=0)\n",
    "z_560_mean = np.nanmean(z_560_aligned_padded, axis=0)\n",
    "z_470_mean = np.nanmean(z_470_aligned_padded, axis=0)\n",
    "\n",
    "# Compute SEM\n",
    "flow_x_sem = np.nanstd(flow_x_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(flow_x_aligned_padded), axis=0))\n",
    "flow_y_sem = np.nanstd(flow_y_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(flow_y_aligned_padded), axis=0))\n",
    "photodiode_sem = np.nanstd(photodiode_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(photodiode_aligned_padded), axis=0))\n",
    "z_560_sem = np.nanstd(z_560_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(z_560_aligned_padded), axis=0))\n",
    "z_470_sem = np.nanstd(z_470_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(z_470_aligned_padded), axis=0))\n",
    "\n",
    "## Truncate all arrays to match min_length\n",
    "aligned_time = aligned_time[:min_length]\n",
    "flow_x_mean = flow_x_mean[:min_length]\n",
    "flow_y_mean = flow_y_mean[:min_length]\n",
    "photodiode_mean = photodiode_mean[:min_length]\n",
    "z_560_mean = z_560_mean[:min_length]\n",
    "z_470_mean = z_470_mean[:min_length]\n",
    "\n",
    "# Truncate SEM values to match min_length\n",
    "flow_x_sem = flow_x_sem[:min_length]\n",
    "flow_y_sem = flow_y_sem[:min_length]\n",
    "photodiode_sem = photodiode_sem[:min_length]\n",
    "z_560_sem = z_560_sem[:min_length]\n",
    "z_470_sem = z_470_sem[:min_length]\n",
    "\n",
    "# Plot running mean and SEM\n",
    "ax_run.plot(aligned_time, flow_x_mean, color=flow_x_color, label=\"Running (Mean)\")\n",
    "ax_run.fill_between(aligned_time, flow_x_mean - flow_x_sem, flow_x_mean + flow_x_sem, color=flow_x_color, alpha=0.2)\n",
    "\n",
    "# Plot turning mean and SEM\n",
    "ax_turn.plot(aligned_time, flow_y_mean, color=flow_y_color, label=\"Turning (Mean)\")\n",
    "ax_turn.fill_between(aligned_time, flow_y_mean - flow_y_sem, flow_y_mean + flow_y_sem, color=flow_y_color, alpha=0.2)\n",
    "\n",
    "# Plot photodiode mean and SEM\n",
    "ax_photo.plot(aligned_time, photodiode_mean, color=photodiode_color, label=\"Photodiode (Mean)\")\n",
    "ax_photo.fill_between(aligned_time, photodiode_mean - photodiode_sem, photodiode_mean + photodiode_sem, \n",
    "                      color=photodiode_color, alpha=0.2)\n",
    "\n",
    "# Plot fluorescence means and SEM\n",
    "ax_fluor.plot(aligned_time, z_560_mean, color=z_560_color, label=\"z_560 (Mean)\")\n",
    "ax_fluor.fill_between(aligned_time, z_560_mean - z_560_sem, z_560_mean + z_560_sem, color=z_560_color, alpha=0.2)\n",
    "ax_fluor.plot(aligned_time, z_470_mean, color=z_470_color, label=\"z_470 (Mean)\")\n",
    "ax_fluor.fill_between(aligned_time, z_470_mean - z_470_sem, z_470_mean + z_470_sem, color=z_470_color, alpha=0.2)\n",
    "\n",
    "set_axis_limits(ax_run, ax_turn, \n",
    "                np.concatenate([flow_x_mean - flow_x_sem, flow_x_mean + flow_x_sem]),\n",
    "                np.concatenate([flow_y_mean - flow_y_sem, flow_y_mean + flow_y_sem]))\n",
    "\n",
    "ax_run.set_xlabel(\"Relative Time (s)\")\n",
    "ax_run.set_ylabel(\"Running X (m/s)\")\n",
    "ax_turn.set_ylabel(\"Turning Y (deg/s)\")\n",
    "ax_photo.set_ylabel(\"Photodiode Signal\")\n",
    "ax_fluor.set_ylabel(\"Fluorescence Signal\")\n",
    "\n",
    "ax_run.legend(loc=\"upper left\")\n",
    "ax_turn.legend(loc=\"upper left\", bbox_to_anchor=(0, 0.9))\n",
    "ax_photo.legend(loc=\"center right\")\n",
    "ax_fluor.legend(loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Trial Averages\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "pympler_memory_df = utils.get_pympler_memory_usage()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del onix_analog_clock\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
