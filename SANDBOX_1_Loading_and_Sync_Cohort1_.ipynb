{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Extract and align data from Onix, Harp, Sleap, and photometry\n",
    "## Cohort 1 and 2 working, Cohort 0: onix_digital Clock column is 0, explore why and/or use timestamps instead "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy.stats import mode\n",
    "from scipy.integrate import cumulative_trapezoid\n",
    "from scipy.signal import correlate\n",
    "import json\n",
    "from dotmap import DotMap\n",
    "\n",
    "import gc # garbage collector for removing large variables from memory instantly \n",
    "import importlib #for force updating changed packages \n",
    "\n",
    "#import harp\n",
    "import harp_resources.process\n",
    "import harp_resources.utils\n",
    "from harp_resources import process, utils # Reassign to maintain direct references for force updating \n",
    "#from sleap import load_and_process as lp\n",
    "\n",
    "%config Completer.use_jedi = False  # Fixes autocomplete issues\n",
    "%config InlineBackend.figure_format = 'retina'  # Improves plot resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate variables\n",
    "event_name = \"Apply halt: 2s\" #event to align data to, can make into list in the future?\n",
    "optical_filter_Hz=40 #filter cutoff for Optical tracking and encoder signals\n",
    "common_resampled_rate = 1000 #in Hz\n",
    "save_full_asynchronous_data = True #saves alldata before resampling\n",
    "\n",
    "# helper flags \n",
    "has_heartbeat = False\n",
    "cohort0 = False\n",
    "cohort2 = False\n",
    "onix_analog_clock_downsampled = False\n",
    "onix_analog_framecount_upsampled = False\n",
    "unit_conversions = False #\n",
    "all_aligned = False\n",
    "\n",
    "#Cohort 1 vestibular mismatch, multiple OnixDigital files \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2718-2024-12-12T13-28-14') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 vestibular mismatch, with clock accumulation issue marked on google sheet, seems fine though\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2719-2024-12-12T13-59-38') #multiple onix_digital file\n",
    "\n",
    "#Cohort 1 vestibular mismatch\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/VestibularMismatch_day1/B6J2717-2024-12-12T13-00-21')\n",
    "\n",
    "#Cohort 1 visual mismatch \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day3/B6J2718-2024-12-10T12-57-02') \n",
    "\n",
    "#Cohort 1 visual mismatch THIS\n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/Visual_mismatch_day3/B6J2717-2024-12-10T12-17-03')\n",
    "\n",
    "#Cohort 0 (no OnixHarp in this Cohort)\n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort0/Cohort0_GCaMP_example/B3M3xx-2024-08-08T10-05-26')\n",
    "#cohort0 = True\n",
    "\n",
    "#Cohort 2 (Cohort 1 animal) \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort2_test/2025-02-13T12-41-57')\n",
    "#has_heartbeat = True\n",
    "\n",
    "photometry_path = data_path.parent / f\"{data_path.name}_processedData\" / \"photometry\"\n",
    "save_path = data_path.parent / f\"{data_path.name}_processedData\"\n",
    "session_name = \"_\".join(data_path.parts[-2:])\n",
    "\n",
    "#h1_datafolder = data_path / 'HarpDataH1' #only if reading separate registers\n",
    "#h2_datafolder = data_path / 'HarpDataH2' #only if reading separate registers\n",
    "#h1 and h2 only needed if timestamps are readed separately and not as all harp_streams\n",
    "#h1_reader = harp.create_reader('harp_resources/h1-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "#h2_reader = harp.create_reader('harp_resources/h2-device.yml', epoch=harp.REFERENCE_EPOCH)\n",
    "\n",
    "#create loaders \n",
    "session_settings_reader = utils.SessionData(\"SessionSettings\")\n",
    "experiment_events_reader = utils.TimestampedCsvReader(\"ExperimentEvents\", columns=[\"Event\"])\n",
    "onix_framecount_reader = utils.TimestampedCsvReader(\"OnixAnalogFrameCount\", columns=[\"Index\"])\n",
    "#photometry_reader = utils.PhotometryReader(\"Processed_fluorescence\")\n",
    "video_reader1 = utils.VideoReader(\"VideoData1\")\n",
    "video_reader2 = utils.VideoReader(\"VideoData2\")\n",
    "onix_digital_reader = utils.OnixDigitalReader(\"OnixDigital\", columns=[\"Value.Clock\", \"Value.HubClock\", \n",
    "                                                                         \"Value.DigitalInputs\",\n",
    "                                                                         \"Seconds\"])\n",
    "onix_harp_reader = utils.TimestampedCsvReader(\"OnixHarp\", columns=[\"Clock\", \"HubClock\", \"HarpTime\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Loading session settings\")\n",
    "session_settings = utils.load_2(session_settings_reader, data_path) #Andrew's, creates ugly df, but used in further analysis code perhaps\n",
    "print (\"Loading experiment events\")\n",
    "experiment_events = utils.load_2(experiment_events_reader, data_path)\n",
    "\n",
    "print (\"Loading processed photometry\")\n",
    "photometry_data=pd.read_csv(str(photometry_path)+'/Processed_fluorescence.csv')\n",
    "photometry_data.set_index(\"TimeStamp\", inplace=True)\n",
    "photometry_data.index.name = 'Seconds'\n",
    "print (\"Upsampling photometry data\")\n",
    "photometry_data = process.upsample_photometry(photometry_data, common_resampled_rate)\n",
    "print (\"Loading processed photometry info\")\n",
    "photometry_info = pd.read_csv(str(photometry_path) + '/Info.csv', header=None, names=[\"Parameter\", \"Value\"])\n",
    "print (\"Loading processed photometry events\")\n",
    "photometry_events=pd.read_csv(str(photometry_path)+'/Events.csv')\n",
    "photometry_events[\"TimeStamp\"] = photometry_events[\"TimeStamp\"] /1000 # convert to seconds from ms\n",
    "photometry_events.set_index(\"TimeStamp\", inplace=True)\n",
    "photometry_events.index.name = 'Seconds'\n",
    "\n",
    "if not cohort2:\n",
    "    print (\"Loading video data 1\")\n",
    "    video_data1 = utils.load_2(video_reader1, data_path)\n",
    "    print (\"Loading video data 2\")\n",
    "    video_data2 = utils.load_2(video_reader2, data_path)\n",
    "\n",
    "# read Onix data \n",
    "print (\"Loading OnixDigital\")\n",
    "onix_digital = utils.load_2(onix_digital_reader, data_path)\n",
    "\n",
    "if cohort0:\n",
    "    print (\"Loading OnixAnalogFrameClock\")\n",
    "    onix_analog_framecount = utils.load_2(onix_framecount_reader, data_path)\n",
    "    \n",
    "print (\"Loading OnixAnalogClock\")\n",
    "onix_analog_clock = utils.read_OnixAnalogClock(data_path)\n",
    "\n",
    "print (\"Loading OnixAnalogData and converting to boolean photodiode array\")\n",
    "#method adaptive or threshold (which is hard threshold at 120), \n",
    "#refractory in seconds (aasuming 100kHz sampling rate) to avoid multiple detections in reporting\n",
    "#first 2 minutes removed from reporting \n",
    "photodiode = utils.read_OnixAnalogData(data_path, channels = [0], binarise=True, method='adaptive', refractory = 0.5, flip=True, verbose=True) \n",
    "\n",
    "#read HARP data\n",
    "print (\"Loading H1 and H2 streams, AnalogInput removed\")\n",
    "harp_streams = utils.load_registers(data_path, dataframe = True, has_heartbeat = has_heartbeat, verbose = False) #loads as df, or if False, as dict\n",
    "harp_streams.drop(columns=[\"AnalogInput(39)\"], inplace=True)  # Removes AnalogInput permanently, as not currently used\n",
    "harp_streams = harp_streams.dropna(how=\"all\") # remove rows with all NaNs\n",
    "# Convert specific columns in harp_streams to boolean type\n",
    "columns_to_convert = [\"StartCam0(38)\", \"StartCam1(38)\", \"StopCam0(38)\", \"StopCam1(38)\"]\n",
    "for col in columns_to_convert:\n",
    "    harp_streams[col] = harp_streams[col].astype(bool)\n",
    "\n",
    "#read syncronising signal between HARP and ONIX\n",
    "if not cohort0:\n",
    "    print (\"Loading OnixHarp\")\n",
    "    onix_harp = utils.load_2(onix_harp_reader, data_path)\n",
    "    onix_harp = utils.detect_and_remove_outliers(\n",
    "    df=onix_harp,\n",
    "    x_column=\"HarpTime\",\n",
    "    y_column=\"Clock\",\n",
    "    verbose=False  # True prints all outliers\n",
    "    )\n",
    "    onix_harp[\"HarpTime\"] = onix_harp[\"HarpTime\"] + 1 # known issue with current version of ONIX, harp timestamps lag 1 second\n",
    "    print (\"❗Reminder: HarpTime was increased by 1s to account for know issue with ONIX\")\n",
    "\n",
    "print (\"✅ Done Loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Convert platform position and flow sensor streams to real world units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get encoder values for homing and next event positions as absolute real life 0 position \n",
    "homing_position, next_event_position = process.get_encoder_home_position(experiment_events, harp_streams)\n",
    "print(\"❗ Warning: home position is determined by the time of the experiment event after 'Homing platform'. It works for e.g. 'Waiting for run threshold' which starts immediately after homing, but may not work for other session types.\")\n",
    "\n",
    "# Perform unit conversions if not already done\n",
    "if not unit_conversions:\n",
    "    harp_streams[\"OpticalTrackingRead0X(46)\"] = process.running_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead0X(46)\"].ffill().bfill().to_numpy())  \n",
    "    harp_streams[\"OpticalTrackingRead0Y(46)\"] = process.turning_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead0Y(46)\"].ffill().bfill().to_numpy())\n",
    "    harp_streams[\"OpticalTrackingRead1X(46)\"] = process.running_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead1X(46)\"].ffill().bfill().to_numpy())\n",
    "    harp_streams[\"OpticalTrackingRead1Y(46)\"] = process.turning_unit_conversion(\n",
    "        harp_streams[\"OpticalTrackingRead1Y(46)\"].ffill().bfill().to_numpy())\n",
    "\n",
    "    harp_streams[\"Encoder(38)\"] = harp_streams[\"Encoder(38)\"].ffill().bfill() #fill before unit conversion\n",
    "    harp_streams[\"Encoder(38)\"] = process.encoder_unit_conversion(\n",
    "        harp_streams[\"Encoder(38)\"], next_event_position)\n",
    "    \n",
    "    # calculate position from X and Y optical signals \n",
    "    columns_to_process = [\"OpticalTrackingRead0X(46)\", \"OpticalTrackingRead0Y(46)\", \"OpticalTrackingRead1X(46)\", \"OpticalTrackingRead1Y(46)\"]\n",
    "    for column in columns_to_process:\n",
    "        # Drop missing values\n",
    "        optical_tracking_values = harp_streams[column].dropna().to_numpy()\n",
    "        time_values_seconds = (harp_streams[column].dropna().index - harp_streams.index[0]).total_seconds()\n",
    "\n",
    "        # Smooth the optical tracking values\n",
    "        optical_tracking_values = process.moving_average_smoothing(optical_tracking_values, 3)\n",
    "\n",
    "        # Use the cumulative trapezoidal rule to calculate the integral\n",
    "        cumulative_integral = cumulative_trapezoid(optical_tracking_values, x=time_values_seconds, initial=0)\n",
    "\n",
    "        # Create a new DataFrame with the resulting integral values and the original datetime index\n",
    "        integral_df = pd.DataFrame(cumulative_integral, index=harp_streams[column].dropna().index, columns=[f\"CumulativeIntegral_{column}\"])\n",
    "\n",
    "        # Reindex the processed data back to the original datetime index\n",
    "        integral_df = integral_df.reindex(harp_streams.index, fill_value=np.nan)\n",
    "        optical_tracking_values_reindexed = pd.Series(optical_tracking_values, index=harp_streams[column].dropna().index).reindex(harp_streams.index, fill_value=np.nan)\n",
    "\n",
    "        # Return the smoothed optical_tracking_values to the source column in harp_streams\n",
    "        harp_streams[column] = optical_tracking_values_reindexed\n",
    "        harp_streams[f\"Position_{column}\"] = integral_df[f\"CumulativeIntegral_{column}\"]\n",
    "    \n",
    "    #convert CamXEvents to bool \n",
    "    harp_streams[\"Cam0Event(32)\"] = harp_streams[\"Cam0Event(32)\"].fillna(0).astype(bool)\n",
    "    harp_streams[\"Cam1Event(33)\"] = harp_streams[\"Cam1Event(33)\"].fillna(0).astype(bool)\n",
    "    del integral_df, optical_tracking_values_reindexed, optical_tracking_values, time_values_seconds, cumulative_integral\n",
    "    gc.collect()\n",
    "    unit_conversions = True\n",
    "    print(\"✅ Unit conversions to real-life values done\")\n",
    "else:\n",
    "    print(\"❗ Flow sensor and encoder values already converted to real-world units, skipping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Downsamples photodiode and analog_clock to common rate (10 kHz) and aligned photodiode_df to harptime - for Cohort 0 also upsamples framecount, not used for Cohort1+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets analog data sample rate and downsamples to common_resampled_rate * 10\n",
    "if not onix_analog_clock_downsampled:\n",
    "    onix_analog_clock_s = (onix_analog_clock * 4) * 1e-9  # convert to seconds with 250MHz DeviceClock, set in hardware\n",
    "    oac_diff = np.diff(onix_analog_clock_s)\n",
    "    onix_analog_rate = round(1 / (np.median(oac_diff)))  # to get the sampling rate (in Hz) with 250MHz DeviceClock, set in hardware\n",
    "    downsample_factor = int(onix_analog_rate / (common_resampled_rate*10))\n",
    "    print(f\"onix_analog_clock rate: {onix_analog_rate}, downsample factor: {downsample_factor}\")\n",
    "    \n",
    "    onix_analog_clock = process.downsample_numpy(onix_analog_clock, downsample_factor, method=\"mean\")\n",
    "    photodiode = process.downsample_numpy(photodiode, downsample_factor, method=\"mean\")\n",
    "    photodiode_df = pd.DataFrame({\"Photodiode\": photodiode.astype(bool)}, index=pd.Index(onix_analog_clock, name=\"onix_analog_clock\"))\n",
    "     \n",
    "    del onix_analog_clock, oac_diff, photodiode, onix_analog_clock_s\n",
    "    gc.collect()\n",
    "    onix_analog_clock_downsampled = True\n",
    "    print(\"✅ Done downsampling analog_clock and photodiode\")\n",
    "else:\n",
    "    print(\"❗ onix_analog_clock & photodiode already downsampled, skipping\")\n",
    "\n",
    "# framecount upsampling, only used in Cohort 0 synchronization\n",
    "if cohort0:\n",
    "    if not onix_analog_framecount_upsampled:\n",
    "        upsample_factor = int(100 / downsample_factor)  # framecount counts every 100 analog datapoints\n",
    "        df = onix_analog_framecount\n",
    "        new_index = np.linspace(0, len(df) - 1, len(df) * upsample_factor)\n",
    "        onix_analog_framecount = pd.DataFrame(index=new_index)\n",
    "        for col in df.columns:\n",
    "            onix_analog_framecount[col] = np.interp(new_index, np.arange(len(df)), df[col])\n",
    "        del new_index\n",
    "        gc.collect()\n",
    "        # Check onix_analog shapes for consistency\n",
    "        data_len = photodiode.shape[0]\n",
    "        clock_len = onix_analog_clock.shape[0]\n",
    "        framecount_len = len(onix_analog_framecount)\n",
    "\n",
    "        if data_len != framecount_len or clock_len != framecount_len:\n",
    "            offset = framecount_len - clock_len\n",
    "            onix_analog_framecount = onix_analog_framecount.iloc[offset:]\n",
    "            print(f\"Warning: analog_data and _framecount mismatch, framecount truncated by {offset * 10}! Should be OK, but see https://github.com/neurogears/vestibular-vr/issues/81 for more information.\")\n",
    "        else:\n",
    "            print(\"onix_analog shapes are consistent!\")\n",
    "        onix_analog_framecount_upsampled = True\n",
    "        print(\"✅ Done upsampling analog_frameclock\")\n",
    "    else:\n",
    "        print(\"❗ onix_analog_framecount already upsampled, skipping\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all_aligned:\n",
    "    ( \n",
    "        conversions, \n",
    "        photometry_aligned,\n",
    "        photodiode_aligned\n",
    "    ) = process.photometry_harp_onix_synchronisation(\n",
    "        onix_digital=onix_digital,\n",
    "        onix_harp=onix_harp,\n",
    "        photometry_events=photometry_events,\n",
    "        photometry_data = photometry_data,\n",
    "        photodiode_df = photodiode_df,\n",
    "        verbose=True\n",
    "    )\n",
    "    del photodiode_df\n",
    "    gc.collect()\n",
    "    all_aligned = True   \n",
    "    print(\"✅ Done aligning photometry and photodiode\")\n",
    "else:\n",
    "    print(\"❗ Photometry and photodiode already aligned, skipping\")\n",
    "\n",
    "#Set all values of photodiode_aligned before the first \"Check halt probability\" to True\n",
    "next_event_after_homing = experiment_events[experiment_events[\"Event\"] == \"Check halt probability\"].index[0]\n",
    "photodiode_aligned.loc[photodiode_aligned.index < next_event_after_homing, \"Photodiode\"] = True\n",
    "print (\"❗ Reminder: Photodiode is funky at startup and is set to True before the first 'Check halt probability' event, may not work with all experiment types\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding global first and last timestamp \n",
    "streams_dict = {\n",
    "    'session_settings': {'session_settings': session_settings},\n",
    "    'experiment_events': {'experiment_events': experiment_events},\n",
    "    'video_data1': {'video_data1': video_data1},\n",
    "    'video_data2': {'video_data2': video_data2},\n",
    "    'harp_streams': {'harp_streams': harp_streams},\n",
    "    'onix_harp': {'onix_harp': onix_harp},\n",
    "    'onix_digital': {'onix_digital': onix_digital},\n",
    "    'harp_streams': {'harp_streams': harp_streams},\n",
    "    'photodiode_aligned': {'photodiode_aligned': photodiode_aligned},\n",
    "    'photometry_aligned': {'photometry_aligned': photometry_aligned}\n",
    "}\n",
    "if cohort0:\n",
    "    streams_dict['onix_analog_framecount'] = {'onix_analog_framecount': onix_analog_framecount}\n",
    "\n",
    "global_first_timestamp, global_last_timestamp, _, _ = process.get_global_minmax_timestamps(streams_dict, print_all=False, verbose=False)\n",
    "\n",
    "del onix_digital, onix_harp, photometry_events, photometry_data\n",
    "gc.collect()\n",
    "\n",
    "# padding these dataframes to global first and last timestamp and bringing under new alldata dataframe \n",
    "dataframes = [video_data1, video_data2, harp_streams, photometry_aligned, photodiode_aligned]\n",
    "padded_dataframes = [process.pad_dataframe_with_global_timestamps(df, global_first_timestamp, global_last_timestamp) for df in dataframes]\n",
    "video_data1, video_data2, harp_streams, photometry_aligned, photodiode_aligned = padded_dataframes\n",
    "\n",
    "del padded_dataframes, streams_dict, dataframes\n",
    "gc.collect()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### combine alldata to single df and save \n",
    "use this to load it when necessary:\n",
    "df = pd.read_parquet(\"path/to/my_data.parquet\", engine=\"pyarrow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all dataframes into a single dataframe\n",
    "\n",
    "# Rename columns in harp_streams by removing \"OpticalTrackingRead\" and removing register numbers\n",
    "video_data1 = video_data1.rename(columns=lambda x: f\"{x}_1\" if not x.endswith(\"_1\") else x)\n",
    "video_data2 = video_data2.rename(columns=lambda x: f\"{x}_2\" if not x.endswith(\"_2\") else x)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(\"OpticalTrackingRead\", \"Displacement_\", regex=False)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(r\"\\(.*\\)\", \"\", regex=True)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(\"Position_Displacement_\", \"Position_\", regex=False)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(\"Displacement_0Brightness\", \"Brightness_0\", regex=False)\n",
    "harp_streams.columns = harp_streams.columns.str.replace(\"Displacement_1Brightness\", \"Brightness_1\", regex=False)\n",
    "\n",
    "# Concatenate the dataframes\n",
    "alldata = pd.concat([video_data1, video_data2, harp_streams, photometry_aligned, photodiode_aligned], axis=1)\n",
    "\n",
    "# Define photodiode_int DataFrame and add to alldata\n",
    "photodiode_int = pd.DataFrame(dtype=int)  # Ensure DataFrame defaults to int\n",
    "photodiode_int[\"Photodiode_int\"] = photodiode_aligned[\"Photodiode\"].astype(\"int8\").copy()\n",
    "photodiode_int = photodiode_int.reindex(alldata.index, method='ffill') ## Reindex photodiode_int to match alldata's index, filling missing values with the preceding value\n",
    "alldata = pd.concat([alldata, photodiode_int], axis=1)\n",
    "alldata[\"Photodiode_int\"] = alldata[\"Photodiode_int\"].astype(\"int8\") # insure it is int8\n",
    "\n",
    "# Ensure boolean columns retain their dtype\n",
    "bool_columns = [\"Cam0Event\", \"Cam1Event\", \"StartCam0\", \"StartCam1\", \"StopCam0\", \"StopCam1\", \"Photodiode\"]\n",
    "for col in bool_columns:\n",
    "    if col in alldata.columns:\n",
    "        if col == \"Photodiode\":\n",
    "            pd.set_option('future.no_silent_downcasting', True)  # Enable future behavior\n",
    "            alldata[col] = alldata[col].infer_objects(copy=False)  # Convert object columns properly\n",
    "            alldata[col] = alldata[col].ffill().astype(bool)\n",
    "        else:\n",
    "            alldata[col] = alldata[col].fillna(0).astype(bool)\n",
    "\n",
    "print(\"✅ Concatenated all data streams into alldata\")\n",
    "\n",
    "if save_full_asynchronous_data:\n",
    "    filename = \"alldata_asynchronous.parquet\"\n",
    "    full_path = save_path / filename\n",
    "    alldata.to_parquet(full_path, engine=\"pyarrow\", compression=\"snappy\")   \n",
    "    print(\"✅ Saved full asynchronous data to alldata_asynchronous.parquet\")\n",
    "\n",
    "# Clean up and delete the column OpticalTrackingRead0X(46) and camera start/stop and H2 ImmediatePulses\n",
    "del video_data1, video_data2, photometry_aligned, harp_streams\n",
    "del photodiode_aligned, photodiode_int\n",
    "\n",
    "columns_to_delete = [\n",
    "    \"Displacement_0X\",\n",
    "    \"Displacement_0Y\",\n",
    "    \"Displacement_1X\",\n",
    "    \"Displacement_1Y\",\n",
    "    \"Brightness_0\",\n",
    "    \"Brightness_1\",\n",
    "    \"StartCam0\", \n",
    "    \"StartCam1\", \n",
    "    \"StopCam0\",\n",
    "    \"StopCam1\", \n",
    "    \"ImmediatePulses\"\n",
    "]\n",
    "alldata.drop(columns=columns_to_delete, inplace=True)\n",
    "\n",
    "#---------------------------------------------------\n",
    "# Separate data streams to be resampled from the ones to keep for now with original datetime indices \n",
    "#---------------------------------------------------\n",
    "\n",
    "columns_to_select = [\n",
    "    'HardwareCounter_1', 'HardwareTimestamp_1', \n",
    "    'HardwareCounter_2', 'HardwareTimestamp_2',\n",
    "    'Cam0Event', 'Cam1Event', 'Photodiode'\n",
    "]\n",
    "\n",
    "camera_photodiode_data = alldata[columns_to_select].copy()\n",
    "camera_photodiode_data.index = alldata.index\n",
    "\n",
    "#Remove the selected columns from alldata\n",
    "for col in columns_to_select:\n",
    "    alldata.pop(col)\n",
    "\n",
    "photometry_tracking_encoder_data = alldata\n",
    "del alldata\n",
    "gc.collect()\n",
    "print(\"✅ Done separating and data streams to float and bool/Int64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Downsample to common_sample_rate (1 kHz), takes a long time, then calculate veloity and acceleartion, photodiode events  \n",
    "### Save all downsampled data and  plot all data and save figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_tracking_encoder_data = process.resample_dataframe(photometry_tracking_encoder_data, common_resampled_rate, optical_filter_Hz)\n",
    "print(\"✅ Resampled data to common rate\", common_resampled_rate, \"Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reload the modules\n",
    "importlib.reload(harp_resources.process)\n",
    "importlib.reload(harp_resources.utils)\n",
    "# Reassign after reloading to ensure updated references\n",
    "process = harp_resources.process\n",
    "utils = harp_resources.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate motor velocity and acceleration from encoder position data\n",
    "\n",
    "#FIXME optical_filter_Hz / 40 and optical_filter_Hz / 80 LOOKS HUGELY LOW FITERING - CHECK \n",
    "photometry_tracking_encoder_data[\"Motor_Velocity\"] = photometry_tracking_encoder_data[\"Encoder\"].copy()\n",
    "photometry_tracking_encoder_data[\"Motor_Velocity\"] = np.gradient(photometry_tracking_encoder_data[\"Encoder\"], edge_order=2) * common_resampled_rate\n",
    "photometry_tracking_encoder_data[\"Motor_Velocity\"] = process.low_pass_filter(photometry_tracking_encoder_data[\"Motor_Velocity\"].dropna(), optical_filter_Hz / 40, common_resampled_rate)\n",
    "photometry_tracking_encoder_data[\"Motor_Acceleration\"] = photometry_tracking_encoder_data[\"Encoder\"].copy()\n",
    "photometry_tracking_encoder_data[\"Motor_Acceleration\"] = np.gradient(photometry_tracking_encoder_data[\"Motor_Velocity\"], edge_order=2) * common_resampled_rate\n",
    "photometry_tracking_encoder_data[\"Motor_Acceleration\"] = process.low_pass_filter(photometry_tracking_encoder_data[\"Motor_Acceleration\"].dropna(), optical_filter_Hz / 40, common_resampled_rate)\n",
    "\n",
    "# Calculate animal running and turning velocity and acceleration from X and Y position \n",
    "position_columns = [col for col in photometry_tracking_encoder_data.columns if col.startswith(\"Position_\")]\n",
    "for col in position_columns:\n",
    "    # Calculate velocity as the first derivative of position using central difference\n",
    "    velocity_col = col.replace(\"Position_\", \"Velocity_\")\n",
    "    photometry_tracking_encoder_data[velocity_col] = np.gradient(photometry_tracking_encoder_data[col], edge_order=2) * common_resampled_rate\n",
    "    \n",
    "    # Apply low-pass filter to the velocity data\n",
    "    photometry_tracking_encoder_data[velocity_col] = process.low_pass_filter(photometry_tracking_encoder_data[velocity_col].dropna(), optical_filter_Hz / 40, common_resampled_rate)\n",
    "    \n",
    "    # Calculate acceleration as the first derivative of filtered velocity using central difference\n",
    "    acceleration_col = col.replace(\"Position_\", \"Acceleration_\")\n",
    "    photometry_tracking_encoder_data[acceleration_col] = np.gradient(photometry_tracking_encoder_data[velocity_col], edge_order=2) * common_resampled_rate\n",
    "    \n",
    "    # Apply low-pass filter to the acceleration data\n",
    "    photometry_tracking_encoder_data[acceleration_col] = process.low_pass_filter(photometry_tracking_encoder_data[acceleration_col].dropna(), optical_filter_Hz / 80, common_resampled_rate)\n",
    "\n",
    "print(\"✅ Calculated velocity and acceleration from position data\")\n",
    "\n",
    "# Store downsampled data in separate directory \n",
    "output_dir = \"downsampled_data\"\n",
    "full_path = save_path / output_dir\n",
    "os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "# Save each DataFrame separately\n",
    "dfs = {\"photometry_tracking_encoder_data\": photometry_tracking_encoder_data, \"camera_photodiode_data\": camera_photodiode_data, \"experiment_events\": experiment_events, \"photometry_info\": photometry_info}\n",
    "for name, df in dfs.items():\n",
    "    df.to_parquet(full_path / f\"{name}.parquet\", engine='pyarrow', compression='snappy')\n",
    "\n",
    "del dfs\n",
    "gc.collect()\n",
    "\n",
    "# Convert metadata column properly\n",
    "session_settings[\"metadata\"] = session_settings[\"metadata\"].apply(process.safe_to_json)\n",
    "# Save DataFrame to Parquet\n",
    "parquet_path = full_path / \"session_settings.parquet\"\n",
    "session_settings.to_parquet(parquet_path, engine=\"pyarrow\", compression=\"snappy\")\n",
    "\n",
    "print(f\"✅ Saved all processed data to {full_path}\")\n",
    "\n",
    "df_to_analyze = photometry_tracking_encoder_data[\"Photodiode_int\"] #using downsampled values in common time grid \n",
    "#df_to_analyze = camera_photodiode_data[\"Photodiode\"] #use async raw values if needed for troubleshooting, but the nearest indices needs to be found , see couple of lines below\n",
    "photodiode_halts, photodiode_delay_min, photodiode_delay_avg, photodiode_delay_max = process.analyze_photodiode(df_to_analyze, experiment_events, event_name, plot = True)\n",
    "# nearest_indices = photometry_tracking_encoder_data.index.get_indexer(photodiode_halts, method='nearest')\n",
    "# photodiode_halts = photometry_tracking_encoder_data.index[nearest_indices]\n",
    "\n",
    "del df_to_analyze\n",
    "gc.collect()\n",
    "\n",
    "process.plot_figure_1(photometry_tracking_encoder_data, session_name, save_path, common_resampled_rate, photodiode_halts, save_figure = True, show_figure = True, downsample_factor=50)\n",
    "print(\"✅ Got photodiode events, saved Figure 1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "photometry_tracking_encoder_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "NEXT - get event triggered averages of all relevant data and reproduce figure below \n",
    "\n",
    "NEXT - think about / run some correlation analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### OLD CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def resample_to_1khz_grid(experiment_events, photometry_data, onix_analog_clock, photodiode, harp_streams):\n",
    "    \"\"\"\n",
    "    Resamples all datasets to a uniform 1 kHz (1 ms resolution) time grid while preserving alignment.\n",
    "    - Numeric signals are resampled using interpolation.\n",
    "    - Boolean signals retain original timestamps.\n",
    "\n",
    "    Parameters:\n",
    "        experiment_events (DataFrame): Original event timestamps.\n",
    "        photometry_data (DataFrame): Photometry data (with a \"TimeStamp\" column in seconds).\n",
    "        onix_analog_clock (ndarray): ONIX timestamps (nanoseconds).\n",
    "        photodiode (ndarray): ONIX data.\n",
    "        harp_streams (DataFrame): HARP-streamed data (both numeric and boolean).\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary of aligned datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert photometry timestamps from seconds to datetime\n",
    "    photometry_data[\"Datetime\"] = pd.to_datetime(photometry_data[\"TimeStamp\"], unit=\"s\", origin=\"1900-01-01\")\n",
    "    photometry_data = photometry_data.set_index(\"Datetime\").drop(columns=[\"TimeStamp\"])\n",
    "\n",
    "    # Convert ONIX timestamps from nanoseconds to datetime\n",
    "    onix_time_index = pd.to_datetime(onix_analog_clock, unit=\"ns\", origin=\"1900-01-01\")\n",
    "\n",
    "    # Define a uniform 1 kHz time grid spanning the full experiment\n",
    "    min_time = min(\n",
    "        experiment_events.index.min(),\n",
    "        photometry_data.index.min(),\n",
    "        onix_time_index.min(),\n",
    "        harp_streams.index.min()\n",
    "    )\n",
    "    max_time = max(\n",
    "        experiment_events.index.max(),\n",
    "        photometry_data.index.max(),\n",
    "        onix_time_index.max(),\n",
    "        harp_streams.index.max()\n",
    "    )\n",
    "\n",
    "    # Create the 1 kHz common time grid\n",
    "    common_time_grid = pd.date_range(start=min_time, end=max_time, freq=\"1ms\")\n",
    "\n",
    "    # Debugging print to confirm grid size\n",
    "    print(f\"⚡ Resampling to 1 kHz grid: {len(common_time_grid)} time points\")\n",
    "\n",
    "    # Split harp_streams into numeric and boolean columns\n",
    "    harp_numeric = harp_streams.select_dtypes(exclude=['bool'])\n",
    "    harp_bool = harp_streams.select_dtypes(include=['bool'])\n",
    "\n",
    "    # Resample numeric data to the 1 kHz grid\n",
    "    def resample_numeric(df):\n",
    "        \"\"\"Interpolates numeric data to match the 1 kHz time grid.\"\"\"\n",
    "        return df.reindex(df.index.union(common_time_grid)).interpolate(method='time').reindex(common_time_grid)\n",
    "\n",
    "    # Resample event timestamps, photometry, and ONIX signals\n",
    "    experiment_events_resampled = resample_numeric(experiment_events)\n",
    "    photometry_data_resampled = resample_numeric(photometry_data)\n",
    "\n",
    "    # Interpolate ONIX analog data\n",
    "    photodiode_resampled = pd.DataFrame(\n",
    "        index=common_time_grid,\n",
    "        data=np.interp(\n",
    "            common_time_grid.astype('int64') / 1e9,  # Convert ms timestamps to seconds\n",
    "            onix_analog_clock / 1e9,  # Convert ONIX timestamps to seconds\n",
    "            photodiode\n",
    "        ),\n",
    "        columns=[\"photodiode\"]\n",
    "    )\n",
    "\n",
    "    # Resample numeric columns of harp_streams to the 1 kHz grid\n",
    "    harp_numeric_resampled = resample_numeric(harp_numeric)\n",
    "\n",
    "    # Keep boolean columns at original timestamps (no downsampling)\n",
    "    harp_bool_aligned = harp_bool.reindex(harp_bool.index.union(common_time_grid)).fillna(method='ffill')\n",
    "\n",
    "    return {\n",
    "        \"experiment_events_resampled\": experiment_events_resampled,\n",
    "        \"photometry_data_resampled\": photometry_data_resampled,\n",
    "        \"photodiode_resampled\": photodiode_resampled,\n",
    "        \"harp_numeric_resampled\": harp_numeric_resampled,\n",
    "        \"harp_bool_aligned\": harp_bool_aligned\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Usage:\n",
    "aligned_data = resample_to_1khz_grid(experiment_events, photometry_data, onix_analog_clock, photodiode, harp_streams)\n",
    "\n",
    "# Access the resampled datasets:\n",
    "experiment_events_resampled = aligned_data[\"experiment_events_resampled\"]\n",
    "photometry_data_resampled = aligned_data[\"photometry_data_resampled\"]\n",
    "photodiode_resampled = aligned_data[\"photodiode_resampled\"]\n",
    "harp_numeric_resampled = aligned_data[\"harp_numeric_resampled\"]\n",
    "harp_bool_aligned = aligned_data[\"harp_bool_aligned\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_events = experiment_events[\"Event\"].unique()\n",
    "print(unique_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Plotting Parameters ----\n",
    "window_start = -1  # seconds, analysis window to plot and average\n",
    "window_stop = 5\n",
    "how_many_to_plot = -1  # -1 plots all or X plots first x halt events \n",
    "\n",
    "\n",
    "if \"Visual_mismatch\" in str(data_path):    \n",
    "    block_start_event = \"DrumWithReverseHalt block started\"\n",
    "    halt_event = \"Apply halt: 2s\"\n",
    "    block_end_event = \"Block timer elapsed\" # Set to \"no_end\" to scan all events\n",
    "\n",
    "if \"VestibularMismatch\" in str(data_path):\n",
    "    block_start_event = \"Sync signal started\"\n",
    "    halt_event = \"DrumWithReverseflow block started\"\n",
    "    block_end_event = \"no_end\"\n",
    "    \n",
    "if \"Cohort2_test\" in str(data_path):    \n",
    "    block_start_event = \"DrumWithReverseHalt block started\"\n",
    "    halt_event = \"Apply halt: 2s\"\n",
    "    block_end_event = \"Block timer elapsed\" # Set to \"no_end\" to scan all events\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def pad_arrays(array_list):\n",
    "    \"\"\"Pads a list of 1D NumPy arrays to the same length using NaN padding.\"\"\"\n",
    "    max_len = max(map(len, array_list))  # Efficient max length calculation\n",
    "    padded_array = np.empty((len(array_list), max_len), dtype=np.float64)  # Preallocate array\n",
    "    padded_array.fill(np.nan)  # Fill with NaNs in one operation\n",
    "\n",
    "    for i, arr in enumerate(array_list):\n",
    "        padded_array[i, :len(arr)] = arr  # Vectorized assignment\n",
    "\n",
    "    return padded_array\n",
    "\n",
    "def set_axis_limits(ax_run, ax_turn, data_run, data_turn):\n",
    "    \"\"\"Set axis limits with minimum ranges that expand if data requires\"\"\"\n",
    "    run_min, run_max = np.nanmin(data_run), np.nanmax(data_run)\n",
    "    turn_min, turn_max = np.nanmin(data_turn), np.nanmax(data_turn)\n",
    "    \n",
    "    # Set running axis limits (minimum range: -0.02 to +0.10)\n",
    "    ax_run.set_ylim([min(-0.02, run_min), max(0.10, run_max)])\n",
    "    \n",
    "    # Set turning axis limits (minimum range: -45 to +45)\n",
    "    ax_turn.set_ylim([min(-45, turn_min), max(45, turn_max)])\n",
    "\n",
    "\n",
    "# ---- Extract Halt Events Efficiently ----\n",
    "block_starts = experiment_events.query(\"Event == @block_start_event\").index.to_numpy()\n",
    "\n",
    "halt_events_list = []\n",
    "for block_start in block_starts:\n",
    "    if block_end_event == \"no_end\":\n",
    "        block_halts = experiment_events.query(\"Event == @halt_event and index > @block_start\")\n",
    "    else:\n",
    "        block_end = experiment_events.query(\"Event == @block_end_event and index > @block_start\").index.min()\n",
    "        if pd.notna(block_end):\n",
    "            block_halts = experiment_events.query(\"Event == @halt_event and index > @block_start and index < @block_end\")\n",
    "        else:\n",
    "            block_halts = pd.DataFrame()  # No valid end event found\n",
    "    \n",
    "    if not block_halts.empty:\n",
    "        halt_events_list.append(block_halts)\n",
    "\n",
    "block_halts = pd.concat(halt_events_list) if halt_events_list else pd.DataFrame()\n",
    "\n",
    "if block_halts.empty:\n",
    "    raise ValueError(f\"⚠️ No [{halt_event}] events found between [{block_start_event}] and [{block_end_event}]. \"\n",
    "                     f\"Check if the event names are correct and exist in experiment_events.\")\n",
    "\n",
    "# Convert Halt Times to NumPy for Efficiency\n",
    "halt_event_times = block_halts.index.to_numpy()\n",
    "\n",
    "# Adjust how_many_to_plot if it exceeds available events\n",
    "if how_many_to_plot > len(block_halts):\n",
    "    print(f\"⚠️ Warning: Requested {how_many_to_plot} halts, but only {len(block_halts)} are available. \"\n",
    "          \"Adjusting how_many_to_plot accordingly.\")\n",
    "    how_many_to_plot = len(block_halts)\n",
    "\n",
    "if how_many_to_plot == -1:\n",
    "    how_many_to_plot = len(block_halts)  # Limit to avoid excessive plots\n",
    "print(f\"Found {len(block_halts)} halt events within valid blocks, plotting {how_many_to_plot}.\")\n",
    "\n",
    "# Define colors\n",
    "flow_x_color, flow_y_color, photodiode_color = \"blue\", \"orange\", \"grey\"  # Changed photodiode to grey\n",
    "z_470_color, z_560_color = \"green\", \"red\"\n",
    "\n",
    "# Initialize lists for aligned data\n",
    "aligned_time = np.linspace(window_start, window_stop, 500)  \n",
    "flow_x_aligned, flow_y_aligned, photodiode_aligned, z_470_aligned, z_560_aligned = [], [], [], [], []\n",
    "\n",
    "# ----------------------\n",
    "# First Plot: Individual Trials\n",
    "# ----------------------\n",
    "fig, ax_run = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create axes for turning, photodiode and fluorescence\n",
    "ax_turn = ax_run.twinx()\n",
    "ax_turn.spines.left.set_position(('outward', 60))\n",
    "ax_turn.yaxis.set_label_position('left')\n",
    "ax_turn.yaxis.set_ticks_position('left')\n",
    "\n",
    "ax_photo = ax_run.twinx()\n",
    "ax_photo.spines.right.set_position(('outward', 60))\n",
    "\n",
    "ax_fluor = ax_run.twinx()\n",
    "ax_fluor.spines.right.set_position(('outward', 120))\n",
    "\n",
    "all_plotted_x_values = []\n",
    "all_plotted_y_values = []\n",
    "\n",
    "for idx, halt_time in enumerate(block_halts.index[:how_many_to_plot]):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "    min_time, max_time = halt_time + pd.DateOffset(seconds=window_start), halt_time + pd.DateOffset(seconds=window_stop)\n",
    "\n",
    "    # Extract Optical Tracking Data\n",
    "    optical_x = harp_streams['OpticalTrackingRead0X(46)'].loc[min_time:max_time].dropna()\n",
    "    optical_y = harp_streams['OpticalTrackingRead0Y(46)'].loc[min_time:max_time].dropna()\n",
    "\n",
    "    if not optical_x.empty and not optical_y.empty:\n",
    "        optical_x_rel = (optical_x.index.astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "        optical_y_rel = (optical_y.index.astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "        \n",
    "        if not optical_x.empty and not optical_y.empty:\n",
    "            all_plotted_x_values.extend(optical_x.values)\n",
    "            all_plotted_y_values.extend(optical_y.values)\n",
    "\n",
    "        label_x = \"Running (Flow X)\" if idx == 0 else None\n",
    "        label_y = \"Turning (Flow Y)\" if idx == 0 else None\n",
    "        ax_run.plot(optical_x_rel, optical_x, color=flow_x_color, alpha=0.3, label=label_x)\n",
    "        ax_turn.plot(optical_y_rel, optical_y, color=flow_y_color, alpha=0.3, label=label_y)\n",
    "\n",
    "        # Restrict aligned_time to the valid range of optical_x_rel\n",
    "        valid_mask = (aligned_time >= optical_x_rel.min()) & (aligned_time <= optical_x_rel.max())\n",
    "        aligned_time_valid = aligned_time[valid_mask]\n",
    "\n",
    "        # Interpolate only within the valid time range\n",
    "        flow_x_interp = np.interp(aligned_time_valid, optical_x_rel, optical_x, left=np.nan, right=np.nan)\n",
    "        flow_y_interp = np.interp(aligned_time_valid, optical_y_rel, optical_y, left=np.nan, right=np.nan)\n",
    "\n",
    "        # Append only the valid interpolated values\n",
    "        flow_x_aligned.append(flow_x_interp)\n",
    "        flow_y_aligned.append(flow_y_interp)\n",
    "        \n",
    "# Set axis limits using only the plotted data\n",
    "all_plotted_x_values = np.array(all_plotted_x_values)\n",
    "all_plotted_y_values = np.array(all_plotted_y_values)\n",
    "set_axis_limits(ax_run, ax_turn, all_plotted_x_values, all_plotted_y_values)\n",
    "\n",
    "ax_run.set_xlabel(\"Relative Time (s)\")\n",
    "ax_run.set_ylabel(\"Running X (m/s)\")\n",
    "ax_turn.set_ylabel(\"Turning Y (deg/s)\")\n",
    "ax_photo.set_ylabel(\"Photodiode Signal\")\n",
    "ax_photo.set_ylim([0, 1.2])\n",
    "ax_fluor.set_ylabel(\"Fluorescence Signal\")\n",
    "\n",
    "for idx, halt_time in enumerate(block_halts.index[:how_many_to_plot]):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "\n",
    "    onix_sec_start_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_start)\n",
    "    onix_sec_stop_time = harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_stop)\n",
    "\n",
    "    onix_sec_start_index = np.searchsorted(onix_analog_clock, onix_sec_start_time)\n",
    "    onix_sec_stop_index = np.searchsorted(onix_analog_clock, onix_sec_stop_time)\n",
    "\n",
    "    onix_time_rel = (onix_to_harp_timestamp(onix_analog_clock[onix_sec_start_index:onix_sec_stop_index])\n",
    "                     .astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "\n",
    "    photodiode_signal = photodiode[onix_sec_start_index:onix_sec_stop_index]\n",
    "\n",
    "    label_photodiode = \"Photodiode\" if idx == 0 else None\n",
    "    ax_photo.plot(onix_time_rel, photodiode_signal, color=photodiode_color, alpha=0.5, label=label_photodiode)\n",
    "\n",
    "    # Restrict aligned_time to valid range of onix_time_rel\n",
    "    valid_mask = (aligned_time >= onix_time_rel.min()) & (aligned_time <= onix_time_rel.max())\n",
    "    aligned_time_valid = aligned_time[valid_mask]\n",
    "\n",
    "    # Interpolate photodiode on the valid time range\n",
    "    photodiode_interp = np.interp(aligned_time_valid, onix_time_rel, photodiode_signal, left=np.nan, right=np.nan)\n",
    "    photodiode_aligned.append(photodiode_interp)\n",
    "    \n",
    "\n",
    "if \"TimeStamp\" in photometry_data.columns:\n",
    "    photometry_data = photometry_data.set_index(\"TimeStamp\")\n",
    "\n",
    "for idx, halt_time in enumerate(block_halts.index[:how_many_to_plot]):\n",
    "    halt_time_seconds = halt_time.timestamp()\n",
    "\n",
    "    photometry_sec_start_time = onix_time_to_photometry(harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_start))\n",
    "    photometry_sec_stop_time = onix_time_to_photometry(harp_to_onix_clock(block_halts.iloc[idx][\"Seconds\"] + window_stop))\n",
    "\n",
    "    photometry_sec = photometry_data.loc[photometry_sec_start_time:photometry_sec_stop_time]\n",
    "\n",
    "    if not photometry_sec.empty:\n",
    "        photometry_time_rel = (photometry_to_harp_time(photometry_sec.index).astype(\"int64\") / 1e9) - halt_time_seconds\n",
    "\n",
    "        label_560, label_470 = \"z_560\" if idx == 0 else None, \"z_470\" if idx == 0 else None\n",
    "        ax_fluor.plot(photometry_time_rel, photometry_sec['z_560'], color=z_560_color, alpha=0.3, label=label_560)\n",
    "        ax_fluor.plot(photometry_time_rel, photometry_sec['z_470'], color=z_470_color, alpha=0.3, label=label_470)\n",
    "        \n",
    "        # Restrict aligned_time to the valid range of photometry_time_rel\n",
    "        valid_mask = (aligned_time >= photometry_time_rel.min()) & (aligned_time <= photometry_time_rel.max())\n",
    "        aligned_time_valid = aligned_time[valid_mask]\n",
    "\n",
    "        # Perform interpolation on the adjusted time range\n",
    "        z_560_interp = np.interp(aligned_time_valid, photometry_time_rel, photometry_sec['z_560'], left=np.nan, right=np.nan)\n",
    "        z_470_interp = np.interp(aligned_time_valid, photometry_time_rel, photometry_sec['z_470'], left=np.nan, right=np.nan)\n",
    "        \n",
    "        # Append only the valid interpolated values\n",
    "        z_560_aligned.append(z_560_interp)\n",
    "        z_470_aligned.append(z_470_interp)\n",
    "\n",
    "ax_run.legend(loc=\"upper left\")\n",
    "ax_turn.legend(loc=\"upper left\", bbox_to_anchor=(0, 0.9))\n",
    "ax_photo.legend(loc=\"center right\")\n",
    "ax_fluor.legend(loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Individual Trials\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ----------------------\n",
    "# Second Plot: Averages with Error Shading (Proper Axes Labels & No Overlap)\n",
    "# ----------------------\n",
    "fig, ax_run = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create axes for turning, photodiode and fluorescence\n",
    "ax_turn = ax_run.twinx()\n",
    "ax_turn.spines.left.set_position(('outward', 60))\n",
    "ax_turn.yaxis.set_label_position('left')\n",
    "ax_turn.yaxis.set_ticks_position('left')\n",
    "\n",
    "ax_photo = ax_run.twinx()\n",
    "ax_photo.spines.right.set_position(('outward', 60))\n",
    "\n",
    "ax_fluor = ax_run.twinx()\n",
    "ax_fluor.spines.right.set_position(('outward', 120))\n",
    "\n",
    "# Pad all signal data to ensure uniform shape\n",
    "flow_x_aligned_padded = pad_arrays(flow_x_aligned)\n",
    "flow_y_aligned_padded = pad_arrays(flow_y_aligned)\n",
    "photodiode_aligned_padded = pad_arrays(photodiode_aligned)\n",
    "z_560_aligned_padded = pad_arrays(z_560_aligned)\n",
    "z_470_aligned_padded = pad_arrays(z_470_aligned)\n",
    "\n",
    "# Ensure all arrays have the same length\n",
    "# Get the number of valid (non-NaN) values per time point across trials\n",
    "valid_counts_560 = np.sum(~np.isnan(z_560_aligned_padded), axis=0)\n",
    "valid_counts_470 = np.sum(~np.isnan(z_470_aligned_padded), axis=0)\n",
    "\n",
    "# Find the last point where at least 80% of trials still have data\n",
    "threshold = 0.8 * len(z_560_aligned_padded)  # Adjustable threshold (80%)\n",
    "adaptive_cutoff = np.where(valid_counts_560 >= threshold)[0][-1]  # Last valid index\n",
    "\n",
    "# Use the smaller of (1) standard min_length, (2) adaptive cutoff\n",
    "min_length = min(\n",
    "    aligned_time.shape[0], \n",
    "    photodiode_aligned_padded.shape[1], \n",
    "    z_560_aligned_padded.shape[1], \n",
    "    z_470_aligned_padded.shape[1], \n",
    "    flow_x_aligned_padded.shape[1],  \n",
    "    flow_y_aligned_padded.shape[1],\n",
    "    adaptive_cutoff  # Ensure we include this index\n",
    ")\n",
    "\n",
    "print(f\"🔍 Adaptive cutoff applied at index {adaptive_cutoff}, using min_length = {min_length}\")\n",
    "\n",
    "# Compute means after padding\n",
    "flow_x_mean = np.nanmean(flow_x_aligned_padded, axis=0)\n",
    "flow_y_mean = np.nanmean(flow_y_aligned_padded, axis=0)\n",
    "photodiode_mean = np.nanmean(photodiode_aligned_padded, axis=0)\n",
    "z_560_mean = np.nanmean(z_560_aligned_padded, axis=0)\n",
    "z_470_mean = np.nanmean(z_470_aligned_padded, axis=0)\n",
    "\n",
    "# Compute SEM\n",
    "flow_x_sem = np.nanstd(flow_x_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(flow_x_aligned_padded), axis=0))\n",
    "flow_y_sem = np.nanstd(flow_y_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(flow_y_aligned_padded), axis=0))\n",
    "photodiode_sem = np.nanstd(photodiode_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(photodiode_aligned_padded), axis=0))\n",
    "z_560_sem = np.nanstd(z_560_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(z_560_aligned_padded), axis=0))\n",
    "z_470_sem = np.nanstd(z_470_aligned_padded, axis=0) / np.sqrt(np.sum(~np.isnan(z_470_aligned_padded), axis=0))\n",
    "\n",
    "## Truncate all arrays to match min_length\n",
    "aligned_time = aligned_time[:min_length]\n",
    "flow_x_mean = flow_x_mean[:min_length]\n",
    "flow_y_mean = flow_y_mean[:min_length]\n",
    "photodiode_mean = photodiode_mean[:min_length]\n",
    "z_560_mean = z_560_mean[:min_length]\n",
    "z_470_mean = z_470_mean[:min_length]\n",
    "\n",
    "# Truncate SEM values to match min_length\n",
    "flow_x_sem = flow_x_sem[:min_length]\n",
    "flow_y_sem = flow_y_sem[:min_length]\n",
    "photodiode_sem = photodiode_sem[:min_length]\n",
    "z_560_sem = z_560_sem[:min_length]\n",
    "z_470_sem = z_470_sem[:min_length]\n",
    "\n",
    "# Plot running mean and SEM\n",
    "ax_run.plot(aligned_time, flow_x_mean, color=flow_x_color, label=\"Running (Mean)\")\n",
    "ax_run.fill_between(aligned_time, flow_x_mean - flow_x_sem, flow_x_mean + flow_x_sem, color=flow_x_color, alpha=0.2)\n",
    "\n",
    "# Plot turning mean and SEM\n",
    "ax_turn.plot(aligned_time, flow_y_mean, color=flow_y_color, label=\"Turning (Mean)\")\n",
    "ax_turn.fill_between(aligned_time, flow_y_mean - flow_y_sem, flow_y_mean + flow_y_sem, color=flow_y_color, alpha=0.2)\n",
    "\n",
    "# Plot photodiode mean and SEM\n",
    "ax_photo.plot(aligned_time, photodiode_mean, color=photodiode_color, label=\"Photodiode (Mean)\")\n",
    "ax_photo.fill_between(aligned_time, photodiode_mean - photodiode_sem, photodiode_mean + photodiode_sem, \n",
    "                      color=photodiode_color, alpha=0.2)\n",
    "\n",
    "# Plot fluorescence means and SEM\n",
    "ax_fluor.plot(aligned_time, z_560_mean, color=z_560_color, label=\"z_560 (Mean)\")\n",
    "ax_fluor.fill_between(aligned_time, z_560_mean - z_560_sem, z_560_mean + z_560_sem, color=z_560_color, alpha=0.2)\n",
    "ax_fluor.plot(aligned_time, z_470_mean, color=z_470_color, label=\"z_470 (Mean)\")\n",
    "ax_fluor.fill_between(aligned_time, z_470_mean - z_470_sem, z_470_mean + z_470_sem, color=z_470_color, alpha=0.2)\n",
    "\n",
    "set_axis_limits(ax_run, ax_turn, \n",
    "                np.concatenate([flow_x_mean - flow_x_sem, flow_x_mean + flow_x_sem]),\n",
    "                np.concatenate([flow_y_mean - flow_y_sem, flow_y_mean + flow_y_sem]))\n",
    "\n",
    "ax_run.set_xlabel(\"Relative Time (s)\")\n",
    "ax_run.set_ylabel(\"Running X (m/s)\")\n",
    "ax_turn.set_ylabel(\"Turning Y (deg/s)\")\n",
    "ax_photo.set_ylabel(\"Photodiode Signal\")\n",
    "ax_fluor.set_ylabel(\"Fluorescence Signal\")\n",
    "\n",
    "ax_run.legend(loc=\"upper left\")\n",
    "ax_turn.legend(loc=\"upper left\", bbox_to_anchor=(0, 0.9))\n",
    "ax_photo.legend(loc=\"center right\")\n",
    "ax_fluor.legend(loc=\"upper right\")\n",
    "\n",
    "plt.title(\"Trial Averages\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pympler_memory_df = utils.get_pympler_memory_usage(top_n=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
