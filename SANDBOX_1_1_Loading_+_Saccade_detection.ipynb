{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "import gc\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import LogNorm\n",
    "from fastkde.fastKDE import fastKDE\n",
    "from scipy.stats import linregress\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.signal import correlate\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "from harp_resources import process, utils\n",
    "from sleap import load_and_process as lp\n",
    "\n",
    "# symbols to use ✅ ℹ️ ⚠️ ❗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables and load data \n",
    "############################################################################################################\n",
    "\n",
    "plot_timeseries = False\n",
    "score_cutoff = 0.2 # for filtering out inferred points with low confidence, they get interpolated \n",
    "outlier_sd_threshold = 10 # for removing outliers from the data, they get interpolated \n",
    "NaNs_removed = False # for checking if NaNs already removed in the notebook\n",
    "cutoff = 10  # Hz for pupil diameter filtering \n",
    "\n",
    "# Parameters for blink detection\n",
    "min_blink_duration_ms = 50  # minimum blink duration in milliseconds\n",
    "max_blink_duration_ms = 500  # maximum blink duration in milliseconds\n",
    "blink_merge_window_ms = 100  # merge blinks within this window (for double blinks) - shall this be longer? \n",
    "\n",
    "# for saccades\n",
    "refractory_period = 0.1  # sec\n",
    "k = 5  # for adaptive saccade threshold - Number of standard deviations (adjustable: 2-4 range works well) \n",
    "onset_offset_fraction = 0.2  # to determine saccade onset and offset, i.e. o.2 is 20% of the peak velocity\n",
    "n_before = 10  # Number of points before detection peak to extract for peri-saccade-segments, points, so independent of FPS \n",
    "n_after = 30   # Number of points after detection peak to extract\n",
    "\n",
    "plot_saccade_detection_QC = True\n",
    "\n",
    "data_path = Path('/Users/rancze/Documents/Data/vestVR/20250409_Cohort3_rotation/Visual_mismatch_day4/B6J2782-2025-04-28T14-22-03') \n",
    "#data_path = Path('/Users/rancze/Documents/Data/vestVR/Cohort1/No_iso_correction/Visual_mismatch_day3/B6J2717-2024-12-10T12-17-03') # only has sleap data 1\n",
    "save_path = data_path.parent / f\"{data_path.name}_processedData\"\n",
    "\n",
    "print (\"\\n❗ 20251025 NOT sure I understand this Ede ---- if SleapData.csv was already saved in the VideoData folder, this may break. Delete the file if you want to rerun processing\\n\")\n",
    "VideoData1, VideoData2, VideoData1_Has_Sleap, VideoData2_Has_Sleap = lp.load_videography_data(data_path)\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "\n",
    "if VideoData1_Has_Sleap:\n",
    "    VideoData1 = VideoData1.drop(columns=['track']) # drop the track column as it is empty\n",
    "    coordinates_dict1_raw=lp.get_coordinates_dict(VideoData1, columns_of_interest)\n",
    "    FPS_1 = 1 / VideoData1[\"Seconds\"].diff().mean()  # frame rate for VideoData1 TODO where to save it, is it useful?\n",
    "    print(f\"FPS_1: {FPS_1}\")\n",
    "\n",
    "if VideoData2_Has_Sleap:\n",
    "    VideoData2 = VideoData2.drop(columns=['track']) # drop the track column as it is empty\n",
    "    coordinates_dict2_raw=lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "    FPS_2 = 1 / VideoData2[\"Seconds\"].diff().mean()  # frame rate for VideoData2\n",
    "    print(f\"FPS_2: {FPS_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot timeseries of coordinates in browser for both VideoData1 and VideoData2\n",
    "############################################################################################################\n",
    "if plot_timeseries:\n",
    "    print(f'⚠️ Check for long discontinuities and outliers in the data, we will try to deal with them later')\n",
    "    print(f'ℹ️ Figures open in browser window, takes a bit of time.')\n",
    "\n",
    "    # Helper list variables\n",
    "    subplot_titles = (\n",
    "        \"X coordinates for pupil centre and left-right eye corner\",\n",
    "        \"Y coordinates for pupil centre and left-right eye corner\",\n",
    "        \"X coordinates for iris points\",\n",
    "        \"Y coordinates for iris points\"\n",
    "    )\n",
    "    eye_x = ['left.x', 'center.x', 'right.x']\n",
    "    eye_y = ['left.y', 'center.y', 'right.y']\n",
    "    iris_x = ['p1.x', 'p2.x', 'p3.x', 'p4.x', 'p5.x', 'p6.x', 'p7.x', 'p8.x']\n",
    "    iris_y = ['p1.y', 'p2.y', 'p3.y', 'p4.y', 'p5.y', 'p6.y', 'p7.y', 'p8.y']\n",
    "\n",
    "    # --- VideoData1 ---\n",
    "    if VideoData1_Has_Sleap:\n",
    "        fig1 = make_subplots(\n",
    "            rows=4, cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=subplot_titles\n",
    "        )\n",
    "\n",
    "        # Row 1: left.x, center.x, right.x\n",
    "        for col in eye_x:\n",
    "            fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=1, col=1)\n",
    "        # Row 2: left.y, center.y, right.y\n",
    "        for col in eye_y:\n",
    "            fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=2, col=1)\n",
    "        # Row 3: p1.x ... p8.x\n",
    "        for col in iris_x:\n",
    "            fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=3, col=1)\n",
    "        # Row 4: p1.y ... p8.y\n",
    "        for col in iris_y:\n",
    "            fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=4, col=1)\n",
    "\n",
    "        fig1.update_layout(\n",
    "            height=1200,\n",
    "            title_text=\"Time series subplots for coordinates [VideoData1]\",\n",
    "            showlegend=True\n",
    "        )\n",
    "        fig1.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "        fig1.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "        fig1.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "        fig1.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "        fig1.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "        fig1.show(renderer='browser')\n",
    "\n",
    "    # --- VideoData2 ---\n",
    "    if VideoData2_Has_Sleap:\n",
    "        fig2 = make_subplots(\n",
    "            rows=4, cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=subplot_titles\n",
    "        )\n",
    "        # Row 1: left.x, center.x, right.x\n",
    "        for col in eye_x:\n",
    "            fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2[col], mode='lines', name=col), row=1, col=1)\n",
    "        # Row 2: left.y, center.y, right.y\n",
    "        for col in eye_y:\n",
    "            fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2[col], mode='lines', name=col), row=2, col=1)\n",
    "        # Row 3: p1.x ... p8.x\n",
    "        for col in iris_x:\n",
    "            fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2[col], mode='lines', name=col), row=3, col=1)\n",
    "        # Row 4: p1.y ... p8.y\n",
    "        for col in iris_y:\n",
    "            fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2[col], mode='lines', name=col), row=4, col=1)\n",
    "\n",
    "        fig2.update_layout(\n",
    "            height=1200,\n",
    "            title_text=\"Time series subplots for coordinates [VideoData2]\",\n",
    "            showlegend=True\n",
    "        )\n",
    "        fig2.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "        fig2.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "        fig2.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "        fig2.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "        fig2.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "        fig2.show(renderer='browser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC plot XY coordinate distributions to visualize outliers \n",
    "############################################################################################################\n",
    "\n",
    "columns_of_interest = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "\n",
    "# Filter out NaN values and calculate the min and max values for X and Y coordinates for both dict1 and dict2\n",
    "\n",
    "def min_max_dict(coordinates_dict):\n",
    "    x_min = min([coordinates_dict[f'{col}.x'][~np.isnan(coordinates_dict[f'{col}.x'])].min() for col in columns_of_interest])\n",
    "    x_max = max([coordinates_dict[f'{col}.x'][~np.isnan(coordinates_dict[f'{col}.x'])].max() for col in columns_of_interest])\n",
    "    y_min = min([coordinates_dict[f'{col}.y'][~np.isnan(coordinates_dict[f'{col}.y'])].min() for col in columns_of_interest])\n",
    "    y_max = max([coordinates_dict[f'{col}.y'][~np.isnan(coordinates_dict[f'{col}.y'])].max() for col in columns_of_interest])\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "# Only plot panels for 1 and 2 if VideoData1_Has_Sleap and/or VideoData2_Has_Sleap are true\n",
    "\n",
    "# Compute min/max as before for global axes limits\n",
    "if VideoData1_Has_Sleap:\n",
    "    x_min1, x_max1, y_min1, y_max1 = min_max_dict(coordinates_dict1_raw)\n",
    "if VideoData2_Has_Sleap:\n",
    "    x_min2, x_max2, y_min2, y_max2 = min_max_dict(coordinates_dict2_raw)\n",
    "\n",
    "# Use global min and max for consistency only if both VideoData1_Has_Sleap and VideoData2_Has_Sleap are True\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    x_min = min(x_min1, x_min2)\n",
    "    x_max = max(x_max1, x_max2)\n",
    "    y_min = min(y_min1, y_min2)\n",
    "    y_max = max(y_max1, y_max2)\n",
    "elif VideoData1_Has_Sleap:\n",
    "    x_min, x_max, y_min, y_max = x_min1, x_max1, y_min1, y_max1\n",
    "elif VideoData2_Has_Sleap:\n",
    "    x_min, x_max, y_min, y_max = x_min2, x_max2, y_min2, y_max2\n",
    "else:\n",
    "    raise ValueError(\"Neither VideoData1 nor VideoData2 has Sleap data available.\")\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))\n",
    "fig.suptitle('XY coordinate distribution of different points for VideoData1 (_dict1) and VideoData2 (_dict2) before outlier removal and NaN interpolation', fontsize=14)\n",
    "\n",
    "# Define colormap for p1-p8\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'orange']\n",
    "\n",
    "# Panel 1: left, right, center (dict1)\n",
    "if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "    ax[0, 0].set_title('VideoData1 (_dict1): left, right, center')\n",
    "    ax[0, 0].scatter(coordinates_dict1_raw['left.x'], coordinates_dict1_raw['left.y'], color='black', label='left', s=10)\n",
    "    ax[0, 0].scatter(coordinates_dict1_raw['right.x'], coordinates_dict1_raw['right.y'], color='grey', label='right', s=10)\n",
    "    ax[0, 0].scatter(coordinates_dict1_raw['center.x'], coordinates_dict1_raw['center.y'], color='red', label='center', s=10)\n",
    "    ax[0, 0].set_xlim([x_min, x_max])\n",
    "    ax[0, 0].set_ylim([y_min, y_max])\n",
    "    ax[0, 0].set_xlabel('x coordinates (pixels)')\n",
    "    ax[0, 0].set_ylabel('y coordinates (pixels)')\n",
    "    ax[0, 0].legend(loc='upper right')\n",
    "else:\n",
    "    ax[0, 0].axis('off')\n",
    "\n",
    "# Panel 2: p1 to p8 (dict1)\n",
    "if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "    ax[0, 1].set_title('VideoData1 (_dict1): p1 to p8')\n",
    "    for idx, col in enumerate(columns_of_interest[3:]):\n",
    "        ax[0, 1].scatter(coordinates_dict1_raw[f'{col}.x'], coordinates_dict1_raw[f'{col}.y'], color=colors[idx], label=col, s=5)\n",
    "    ax[0, 1].set_xlim([x_min, x_max])\n",
    "    ax[0, 1].set_ylim([y_min, y_max])\n",
    "    ax[0, 1].set_xlabel('x coordinates (pixels)')\n",
    "    ax[0, 1].set_ylabel('y coordinates (pixels)')\n",
    "    ax[0, 1].legend(loc='upper right')\n",
    "else:\n",
    "    ax[0, 1].axis('off')\n",
    "\n",
    "# Panel 3: left, right, center (dict2)\n",
    "if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "    ax[1, 0].set_title('VideoData2 (_dict2): left, right, center')\n",
    "    ax[1, 0].scatter(coordinates_dict2_raw['left.x'], coordinates_dict2_raw['left.y'], color='black', label='left', s=10)\n",
    "    ax[1, 0].scatter(coordinates_dict2_raw['right.x'], coordinates_dict2_raw['right.y'], color='grey', label='right', s=10)\n",
    "    ax[1, 0].scatter(coordinates_dict2_raw['center.x'], coordinates_dict2_raw['center.y'], color='red', label='center', s=10)\n",
    "    ax[1, 0].set_xlim([x_min, x_max])\n",
    "    ax[1, 0].set_ylim([y_min, y_max])\n",
    "    ax[1, 0].set_xlabel('x coordinates (pixels)')\n",
    "    ax[1, 0].set_ylabel('y coordinates (pixels)')\n",
    "    ax[1, 0].legend(loc='upper right')\n",
    "else:\n",
    "    ax[1, 0].axis('off')\n",
    "\n",
    "# Panel 4: p1 to p8 (dict2)\n",
    "if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "    ax[1, 1].set_title('VideoData2 (_dict2): p1 to p8')\n",
    "    for idx, col in enumerate(columns_of_interest[3:]):\n",
    "        ax[1, 1].scatter(coordinates_dict2_raw[f'{col}.x'], coordinates_dict2_raw[f'{col}.y'], color=colors[idx], label=col, s=5)\n",
    "    ax[1, 1].set_xlim([x_min, x_max])\n",
    "    ax[1, 1].set_ylim([y_min, y_max])\n",
    "    ax[1, 1].set_xlabel('x coordinates (pixels)')\n",
    "    ax[1, 1].set_ylabel('y coordinates (pixels)')\n",
    "    ax[1, 1].legend(loc='upper right')\n",
    "else:\n",
    "    ax[1, 1].axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC for consecutive NaN and low confidence inference frames TODO - not sure what to do, what threshold to use to send it back to SLEAP inference \n",
    "############################################################################################################\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "\n",
    "# VideoData1 NaN analysis\n",
    "if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "    all_nan_df = VideoData1[VideoData1[columns_of_interest].isnull().all(1)]\n",
    "    all_nan_index_array = all_nan_df.index.values\n",
    "\n",
    "    # print the groups of sequential NaNs\n",
    "    group_counts = {'1-5': 0, '6-10': 0, '>10': 0}\n",
    "    i = 1\n",
    "    for group in lp.find_sequential_groups(all_nan_index_array):\n",
    "        #print(f'NaN frame group {i} with {len(group)} elements')\n",
    "        if 1 <= len(group) <= 5:\n",
    "            group_counts['1-5'] += 1\n",
    "        elif 6 <= len(group) <= 10:\n",
    "            group_counts['6-10'] += 1\n",
    "        else:\n",
    "            group_counts['>10'] += 1\n",
    "            print(f'\\n⚠️ VideoData1 Framegroup {i} has {len(group)} consecutive all NaN frames  with indices {group}. If this is a long group, consider rerunning SLEAP inference.')\n",
    "        i += 1\n",
    "\n",
    "    print(f\"\\nVideoData1 - Framegroups with 1-5 consecutive all NaN frames: {group_counts['1-5']}\")\n",
    "    print(f\"VideoData1 - Framegroups with 6-10 consecutive all NaN frames: {group_counts['6-10']}\")\n",
    "    print(f\"VideoData1 - Framegroups with >10 consecutive all NaN frames: {group_counts['>10']}\")\n",
    "\n",
    "# VideoData2 NaN analysis\n",
    "if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "    all_nan_df2 = VideoData2[VideoData2[columns_of_interest].isnull().all(1)]\n",
    "    all_nan_index_array2 = all_nan_df2.index.values\n",
    "\n",
    "    # print the groups of sequential NaNs for VideoData2\n",
    "    group_counts2 = {'1-5': 0, '6-10': 0, '>10': 0}\n",
    "    i = 1\n",
    "    for group in lp.find_sequential_groups(all_nan_index_array2):\n",
    "        #print(f'NaN frame group {i} with {len(group)} elements')\n",
    "        if 1 <= len(group) <= 5:\n",
    "            group_counts2['1-5'] += 1\n",
    "        elif 6 <= len(group) <= 10:\n",
    "            group_counts2['6-10'] += 1\n",
    "        else:\n",
    "            group_counts2['>10'] += 1\n",
    "            print(f'\\n⚠️ VideoData2 Framegroup {i} has {len(group)} consecutive all NaN frames  with indices {group}. If this is a long group, consider rerunning SLEAP inference.')\n",
    "        i += 1\n",
    "\n",
    "    print(f\"\\nVideoData2 - Framegroups with 1-5 consecutive all NaN frames: {group_counts2['1-5']}\")\n",
    "    print(f\"VideoData2 - Framegroups with 6-10 consecutive all NaN frames: {group_counts2['6-10']}\")\n",
    "    print(f\"VideoData2 - Framegroups with >10 consecutive all NaN frames: {group_counts2['>10']}\")\n",
    "\n",
    "############################################################################################################\n",
    "# check if we can use some filtering on scores to remove bad frames\n",
    "############################################################################################################\n",
    "\n",
    "columns_of_interest = ['left.score','center.score','right.score','p1.score','p2.score','p3.score','p4.score','p5.score','p6.score','p7.score','p8.score']\n",
    "\n",
    "# VideoData1 confidence score analysis\n",
    "if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "    total_points1 = len(VideoData1)\n",
    "    print(f'\\nℹ️ VideoData1 - Top 3 columns with most frames below {score_cutoff} confidence score:')\n",
    "\n",
    "    # Calculate statistics for all columns\n",
    "    video1_stats = []\n",
    "    for col in columns_of_interest:\n",
    "        count_below_threshold = (VideoData1[col] < score_cutoff).sum()\n",
    "        percentage_below_threshold = (count_below_threshold / total_points1) * 100\n",
    "\n",
    "        # Find the longest consecutive series below threshold\n",
    "        below_threshold = VideoData1[col] < score_cutoff\n",
    "        longest_series = 0\n",
    "        current_series = 0\n",
    "\n",
    "        for value in below_threshold:\n",
    "            if value:\n",
    "                current_series += 1\n",
    "                if current_series > longest_series:\n",
    "                    longest_series = current_series\n",
    "            else:\n",
    "                current_series = 0\n",
    "\n",
    "        video1_stats.append((col, count_below_threshold, percentage_below_threshold, longest_series))\n",
    "\n",
    "    # Sort by count_below_threshold and show top 3\n",
    "    video1_stats.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i, (col, count, percentage, longest) in enumerate(video1_stats[:3]):\n",
    "        print(f\"VideoData1 - #{i+1}: {col} | Values below {score_cutoff}: {count} ({percentage:.2f}%) | Longest consecutive frame series: {longest}\")\n",
    "\n",
    "# VideoData2 confidence score analysis\n",
    "if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "    total_points2 = len(VideoData2)\n",
    "    print(f'\\nℹ️ VideoData2 - Top 3 columns with most frames below {score_cutoff} confidence score:')\n",
    "\n",
    "    # Calculate statistics for all columns\n",
    "    video2_stats = []\n",
    "    for col in columns_of_interest:\n",
    "        count_below_threshold = (VideoData2[col] < score_cutoff).sum()\n",
    "        percentage_below_threshold = (count_below_threshold / total_points2) * 100\n",
    "        \n",
    "        # Find the longest consecutive series below threshold\n",
    "        below_threshold = VideoData2[col] < score_cutoff\n",
    "        longest_series = 0\n",
    "        current_series = 0\n",
    "        \n",
    "        for value in below_threshold:\n",
    "            if value:\n",
    "                current_series += 1\n",
    "                if current_series > longest_series:\n",
    "                    longest_series = current_series\n",
    "            else:\n",
    "                current_series = 0\n",
    "        \n",
    "        video2_stats.append((col, count_below_threshold, percentage_below_threshold, longest_series))\n",
    "\n",
    "    # Sort by count_below_threshold and show top 3\n",
    "    video2_stats.sort(key=lambda x: x[1], reverse=True)\n",
    "    for i, (col, count, percentage, longest) in enumerate(video2_stats[:3]):\n",
    "        print(f\"VideoData2 - #{i+1}: {col} | Values below {score_cutoff}: {count} ({percentage:.2f}%) | Longest consecutive frame series: {longest}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8734f85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of instance scores IN VIEW OF removing those as well! \n",
    "# Likely problem is that when instance score is low, that's because of a blink or similar, as there are long sequences of low scores\n",
    "# which is perfeect to exclude and linearly interpolate (or keep it NaN?) -> but need to make sure it is really a blink an not model-issues \n",
    "# Now using an adaptive percentile threshold to ensure the maximum number of consecutively excluded frames <= max_consecutive_lowscore (default=6)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "max_consecutive_lowscore = 120  # in frames TODO make it depend on FPS_1 and FPS_2 \n",
    "\n",
    "def find_longest_lowscore_sections(scores, threshold, top_n=5):\n",
    "    \"\"\"\n",
    "    Finds the top_n longest consecutive segments where scores < threshold.\n",
    "    Returns list of dict: {'start_idx', 'end_idx', 'length', 'start_time', 'end_time' (if available)}\n",
    "    \"\"\"\n",
    "    is_low = scores < threshold\n",
    "    diff = is_low.astype(int).diff().fillna(0)\n",
    "    starts = np.where((diff == 1))[0]\n",
    "    ends = np.where((diff == -1))[0]\n",
    "\n",
    "    if is_low.iloc[0]:\n",
    "        starts = np.insert(starts, 0, 0)\n",
    "    if is_low.iloc[-1]:\n",
    "        ends = np.append(ends, len(is_low))\n",
    "\n",
    "    sections = []\n",
    "    for s, e in zip(starts, ends):\n",
    "        sections.append({'start_idx': s, 'end_idx': e-1, 'length': e-s})\n",
    "\n",
    "    top_sections = sorted(sections, key=lambda x: x['length'], reverse=True)[:top_n]\n",
    "    return top_sections\n",
    "\n",
    "def find_percentile_for_consecutive_limit(scores, max_consecutive):\n",
    "    \"\"\"\n",
    "    Binary search for the lowest percentile so that the maximum number of\n",
    "    consecutively excluded frames (scores below the percentile) does not exceed max_consecutive.\n",
    "    Returns: percentile and threshold value.\n",
    "    \"\"\"\n",
    "    sorted_scores = scores.dropna().sort_values()\n",
    "    n = len(sorted_scores)\n",
    "    low, high = 0.0, 0.2  # Search up to the 20th percentile; adjust as needed\n",
    "    tol = 0.0001\n",
    "\n",
    "    found_pct = None\n",
    "    found_value = None\n",
    "\n",
    "    while (high - low) > tol:\n",
    "        mid = (low + high) / 2\n",
    "        thr = sorted_scores.quantile(mid)\n",
    "        sections = find_longest_lowscore_sections(scores, thr, top_n=1)\n",
    "        longest = sections[0]['length'] if sections else 0\n",
    "        if longest > max_consecutive:\n",
    "            high = mid\n",
    "        else:\n",
    "            found_pct = mid\n",
    "            found_value = thr\n",
    "            low = mid\n",
    "\n",
    "    return found_pct, found_value\n",
    "\n",
    "# ---- User parameter: maximum allowed consecutive low-score frames ----\n",
    "\n",
    "# Only analyze for dataset(s) that exist\n",
    "has_v1 = \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap\n",
    "has_v2 = \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap\n",
    "\n",
    "fig = None\n",
    "if has_v1 or has_v2:\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plot_index = 1\n",
    "\n",
    "# Find adaptive percentile and threshold for each present VideoData\n",
    "if has_v1:\n",
    "    adaptive_pct_v1, adaptive_thr_v1 = find_percentile_for_consecutive_limit(VideoData1['instance.score'], max_consecutive_lowscore)\n",
    "    plt.subplot(1, 2 if has_v2 else 1, plot_index)\n",
    "    plt.hist(VideoData1['instance.score'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
    "    plt.axvline(adaptive_thr_v1, color='red', linestyle='--', label=f'Adaptive threshold ({adaptive_pct_v1*100:.2f} percentile)\\nlimit {max_consecutive_lowscore} consecutive')\n",
    "    plt.title(\"Distribution of instance.score (VideoData1)\")\n",
    "    plt.xlabel(\"instance.score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plot_index += 1\n",
    "\n",
    "if has_v2:\n",
    "    adaptive_pct_v2, adaptive_thr_v2 = find_percentile_for_consecutive_limit(VideoData2['instance.score'], max_consecutive_lowscore)\n",
    "    plt.subplot(1, 2 if has_v1 else 1, plot_index)\n",
    "    plt.hist(VideoData2['instance.score'].dropna(), bins=30, color='salmon', edgecolor='black')\n",
    "    plt.axvline(adaptive_thr_v2, color='red', linestyle='--', label=f'Adaptive threshold ({adaptive_pct_v2*100:.2f} percentile)\\nlimit {max_consecutive_lowscore} consecutive')\n",
    "    plt.title(\"Distribution of instance.score (VideoData2)\")\n",
    "    plt.xlabel(\"instance.score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.legend()\n",
    "    plot_index += 1\n",
    "\n",
    "if has_v1 or has_v2:\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Report the statistics for available VideoData\n",
    "if has_v1:\n",
    "    v1_num_low = (VideoData1['instance.score'] < adaptive_thr_v1).sum()\n",
    "    print(f\"\\nVideoData1: Total number of points with instance.score < adaptive threshold: {v1_num_low}\")\n",
    "if has_v2:\n",
    "    v2_num_low = (VideoData2['instance.score'] < adaptive_thr_v2).sum()\n",
    "    print(f\"VideoData2: Total number of points with instance.score < adaptive threshold: {v2_num_low}\")\n",
    "\n",
    "# Report the top 5 longest consecutive sections with instance.score < adaptive threshold\n",
    "if has_v1:\n",
    "    print(f\"\\nVideoData1: Top 5 longest consecutive sections where instance.score < adaptive threshold:\")\n",
    "    low_sections_v1 = find_longest_lowscore_sections(VideoData1['instance.score'], adaptive_thr_v1, top_n=5)\n",
    "    for i, sec in enumerate(low_sections_v1, 1):\n",
    "        start_idx = sec['start_idx']\n",
    "        end_idx = sec['end_idx']\n",
    "        start_time = VideoData1.index[start_idx] if isinstance(VideoData1.index, pd.DatetimeIndex) else start_idx\n",
    "        end_time = VideoData1.index[end_idx] if isinstance(VideoData1.index, pd.DatetimeIndex) else end_idx\n",
    "        print(f\"  Section {i}: index {start_idx}-{end_idx} (length {sec['length']})\")\n",
    "if has_v2:\n",
    "    print(f\"\\nVideoData2: Top 5 longest consecutive sections where instance.score < adaptive threshold:\")\n",
    "    low_sections_v2 = find_longest_lowscore_sections(VideoData2['instance.score'], adaptive_thr_v2, top_n=5)\n",
    "    for i, sec in enumerate(low_sections_v2, 1):\n",
    "        start_idx = sec['start_idx']\n",
    "        end_idx = sec['end_idx']\n",
    "        start_time = VideoData2.index[start_idx] if isinstance(VideoData2.index, pd.DatetimeIndex) else start_idx\n",
    "        end_time = VideoData2.index[end_idx] if isinstance(VideoData2.index, pd.DatetimeIndex) else end_idx\n",
    "        print(f\"  Section {i}: index {start_idx}-{end_idx} (length {sec['length']})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# center coordinates on median pupil centre, removing outliers, low confidence points (fill these two NaNs by interpolation), then mark low instances as blinks and remove them - keep them NaN\n",
    "############################################################################################################\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "\n",
    "print(\"=== Centering ===\")\n",
    "# VideoData1 processing\n",
    "if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "    # Calculate the mean of the center x and y points\n",
    "    mean_center_x1 = VideoData1['center.x'].median()\n",
    "    mean_center_y1 = VideoData1['center.y'].median()\n",
    "\n",
    "    print(f\"VideoData1 - Centering on median pupil centre: \\nMean center.x: {mean_center_x1}, Mean center.y: {mean_center_y1}\")\n",
    "\n",
    "    # Translate the coordinates\n",
    "    for col in columns_of_interest:\n",
    "        if '.x' in col:\n",
    "            VideoData1[col] = VideoData1[col] - mean_center_x1\n",
    "        elif '.y' in col:\n",
    "            VideoData1[col] = VideoData1[col] - mean_center_y1\n",
    "\n",
    "    VideoData1_centered = VideoData1.copy()\n",
    "\n",
    "# VideoData2 processing\n",
    "if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "    # Calculate the mean of the center x and y points\n",
    "    mean_center_x2 = VideoData2['center.x'].median()\n",
    "    mean_center_y2 = VideoData2['center.y'].median()\n",
    "\n",
    "    print(f\"VideoData2 - Centering on median pupil centre: \\nMean center.x: {mean_center_x2}, Mean center.y: {mean_center_y2}\")\n",
    "\n",
    "    # Translate the coordinates\n",
    "    for col in columns_of_interest:\n",
    "        if '.x' in col:\n",
    "            VideoData2[col] = VideoData2[col] - mean_center_x2\n",
    "        elif '.y' in col:\n",
    "            VideoData2[col] = VideoData2[col] - mean_center_y2\n",
    "\n",
    "    VideoData2_centered = VideoData2.copy()\n",
    "\n",
    "############################################################################################################\n",
    "# remove low confidence points (score < threshold)\n",
    "############################################################################################################\n",
    "if not NaNs_removed:\n",
    "    print(\"\\n=== Score-based Filtering ===\")\n",
    "    print(f\"Score threshold: {score_cutoff}\")\n",
    "    # List of point names (without .x, .y, .score)\n",
    "    point_names = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "\n",
    "    # VideoData1 score-based filtering\n",
    "    if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "        total_low_score1 = 0\n",
    "        low_score_counts1 = {}\n",
    "        for point in point_names:\n",
    "            if f'{point}.score' in VideoData1.columns:\n",
    "                # Find indices where score is below threshold\n",
    "                low_score_mask = VideoData1[f'{point}.score'] < score_cutoff\n",
    "                low_score_count = low_score_mask.sum()\n",
    "                low_score_counts1[f'{point}.x'] = low_score_count\n",
    "                low_score_counts1[f'{point}.y'] = low_score_count\n",
    "                total_low_score1 += low_score_count * 2  # *2 because we're removing both x and y\n",
    "                \n",
    "                # Set x and y to NaN for low confidence points\n",
    "                VideoData1.loc[low_score_mask, f'{point}.x'] = np.nan\n",
    "                VideoData1.loc[low_score_mask, f'{point}.y'] = np.nan\n",
    "        \n",
    "        # Find the channel with the maximum number of low-score points\n",
    "        max_low_score_channel1 = max(low_score_counts1, key=low_score_counts1.get)\n",
    "        max_low_score_count1 = low_score_counts1[max_low_score_channel1]\n",
    "        \n",
    "        # Print the channel with the maximum number of low-score points\n",
    "        print(f\"VideoData1 - Channel with the maximum number of low-confidence points: {max_low_score_channel1}, Number of low-confidence points: {max_low_score_count1}\")\n",
    "        print(f\"VideoData1 - A total number of {total_low_score1} low-confidence coordinate values were replaced by interpolation\")\n",
    "\n",
    "    # VideoData2 score-based filtering\n",
    "    if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "        total_low_score2 = 0\n",
    "        low_score_counts2 = {}\n",
    "        for point in point_names:\n",
    "            if f'{point}.score' in VideoData2.columns:\n",
    "                # Find indices where score is below threshold\n",
    "                low_score_mask = VideoData2[f'{point}.score'] < score_cutoff\n",
    "                low_score_count = low_score_mask.sum()\n",
    "                low_score_counts2[f'{point}.x'] = low_score_count\n",
    "                low_score_counts2[f'{point}.y'] = low_score_count\n",
    "                total_low_score2 += low_score_count * 2  # *2 because we're removing both x and y\n",
    "                \n",
    "                # Set x and y to NaN for low confidence points\n",
    "                VideoData2.loc[low_score_mask, f'{point}.x'] = np.nan\n",
    "                VideoData2.loc[low_score_mask, f'{point}.y'] = np.nan\n",
    "        \n",
    "        # Find the channel with the maximum number of low-score points\n",
    "        max_low_score_channel2 = max(low_score_counts2, key=low_score_counts2.get)\n",
    "        max_low_score_count2 = low_score_counts2[max_low_score_channel2]\n",
    "        \n",
    "        # Print the channel with the maximum number of low-score points\n",
    "        print(f\"VideoData2 - Channel with the maximum number of low-confidence points: {max_low_score_channel2}, Number of low-confidence points: {max_low_score_count2}\")\n",
    "        print(f\"VideoData2 - A total number of {total_low_score2} low-confidence coordinate values were replaced by interpolation\")\n",
    "\n",
    "    ############################################################################################################\n",
    "    # remove outliers (x times SD)\n",
    "    # then interpolates on all NaN values (skipped frames, low confidence inference points, outliers)\n",
    "    ############################################################################################################\n",
    "\n",
    "    print(\"\\n=== Outlier Analysis ===\")\n",
    "\n",
    "    # VideoData1 outlier analysis and interpolation\n",
    "    if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "        # Calculate the standard deviation for each column of interest\n",
    "        std_devs1 = {col: VideoData1[col].std() for col in columns_of_interest}\n",
    "\n",
    "        # Calculate the number of outliers for each column\n",
    "        outliers1 = {col: ((VideoData1[col] - VideoData1[col].mean()).abs() > outlier_sd_threshold * std_devs1[col]).sum() for col in columns_of_interest}\n",
    "\n",
    "        # Find the channel with the maximum number of outliers\n",
    "        max_outliers_channel1 = max(outliers1, key=outliers1.get)\n",
    "        max_outliers_count1 = outliers1[max_outliers_channel1]\n",
    "\n",
    "        # Print the channel with the maximum number of outliers and the number\n",
    "        print(f\"VideoData1 - Channel with the maximum number of outliers: {max_outliers_channel1}, Number of outliers: {max_outliers_count1}\")\n",
    "\n",
    "        # Print the total number of outliers\n",
    "        total_outliers1 = sum(outliers1.values())\n",
    "        print(f\"VideoData1 - A total number of {total_outliers1} outliers were replaced by interpolation\")\n",
    "\n",
    "        # Replace outliers by interpolating between the previous and subsequent non-NaN value\n",
    "        for col in columns_of_interest:\n",
    "            outlier_indices = VideoData1[((VideoData1[col] - VideoData1[col].mean()).abs() > outlier_sd_threshold * std_devs1[col])].index\n",
    "            VideoData1.loc[outlier_indices, col] = np.nan\n",
    "\n",
    "        #VideoData1.interpolate(inplace=True)\n",
    "        VideoData1 = VideoData1.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # VideoData2 outlier analysis and interpolation\n",
    "    if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "        # Calculate the standard deviation for each column of interest\n",
    "        std_devs2 = {col: VideoData2[col].std() for col in columns_of_interest}\n",
    "\n",
    "        # Calculate the number of outliers for each column\n",
    "        outliers2 = {col: ((VideoData2[col] - VideoData2[col].mean()).abs() > outlier_sd_threshold * std_devs2[col]).sum() for col in columns_of_interest}\n",
    "\n",
    "        # Find the channel with the maximum number of outliers\n",
    "        max_outliers_channel2 = max(outliers2, key=outliers2.get)\n",
    "        max_outliers_count2 = outliers2[max_outliers_channel2]\n",
    "\n",
    "        # Print the channel with the maximum number of outliers and the number\n",
    "        print(f\"VideoData2 - Channel with the maximum number of outliers: {max_outliers_channel2}, Number of outliers: {max_outliers_count2}\")\n",
    "\n",
    "        # Print the total number of outliers\n",
    "        total_outliers2 = sum(outliers2.values())\n",
    "        print(f\"VideoData2 - A total number of {total_outliers2} outliers were replaced by interpolation\")\n",
    "\n",
    "        # Replace outliers by interpolating between the previous and subsequent non-NaN value\n",
    "        for col in columns_of_interest:\n",
    "            outlier_indices = VideoData2[((VideoData2[col] - VideoData2[col].mean()).abs() > outlier_sd_threshold * std_devs2[col])].index\n",
    "            VideoData2.loc[outlier_indices, col] = np.nan\n",
    "\n",
    "        #VideoData2.interpolate(inplace=True)\n",
    "        VideoData2 = VideoData2.interpolate(method='linear', limit_direction='both')\n",
    "\n",
    "    # Set flag after both VideoData1 and VideoData2 processing is complete\n",
    "    NaNs_removed = True\n",
    "else:\n",
    "    print(\"=== Interpolation already done, skipping ===\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6f002",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blink detection using instance.score - mark blinks and set coordinates to NaN (keep them as NaN, no interpolation)\n",
    "############################################################################################################\n",
    "\n",
    "print(\"\\n=== Blink Detection ===\")\n",
    "\n",
    "# Helper function to find consecutive segments with low instance.score\n",
    "def find_blink_segments(instance_scores, threshold, min_frames, max_frames):\n",
    "    \"\"\"\n",
    "    Find consecutive segments where instance.score < threshold.\n",
    "    Filters by duration and returns valid blink segments.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    instance_scores : pd.Series\n",
    "        Series of instance.score values\n",
    "    threshold : float\n",
    "        Score threshold below which to consider a blink\n",
    "    min_frames : int\n",
    "        Minimum number of consecutive frames to consider a blink\n",
    "    max_frames : int\n",
    "        Maximum number of consecutive frames to consider a blink\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list of dicts with keys: 'start_idx', 'end_idx', 'length', 'mean_score'\n",
    "    \"\"\"\n",
    "    is_low = instance_scores < threshold\n",
    "    diff = is_low.astype(int).diff().fillna(0)\n",
    "    starts = np.where((diff == 1))[0]\n",
    "    ends = np.where((diff == -1))[0]\n",
    "    \n",
    "    if is_low.iloc[0]:\n",
    "        starts = np.insert(starts, 0, 0)\n",
    "    if is_low.iloc[-1]:\n",
    "        ends = np.append(ends, len(is_low))\n",
    "    \n",
    "    segments = []\n",
    "    for s, e in zip(starts, ends):\n",
    "        length = e - s\n",
    "        if min_frames <= length <= max_frames:\n",
    "            mean_score = instance_scores.iloc[s:e].mean()\n",
    "            segments.append({\n",
    "                'start_idx': s,\n",
    "                'end_idx': e - 1,  # inclusive end\n",
    "                'length': length,\n",
    "                'mean_score': mean_score\n",
    "            })\n",
    "    \n",
    "    return segments\n",
    "\n",
    "def format_time_from_start(seconds_from_start):\n",
    "    \"\"\"\n",
    "    Format seconds as MM:SS from the start of recording.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    seconds_from_start : float\n",
    "        Time in seconds from the beginning of the recording\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Formatted as \"MM:SS\" or \"M:SS\" if minutes < 10\n",
    "    \"\"\"\n",
    "    minutes = int(seconds_from_start // 60)\n",
    "    seconds = int(seconds_from_start % 60)\n",
    "    return f\"{minutes}:{seconds:02d}\"\n",
    "\n",
    "def merge_nearby_blinks(segments, merge_window_frames):\n",
    "    \"\"\"\n",
    "    Merge blink segments that are within merge_window_frames of each other.\n",
    "    \"\"\"\n",
    "    if not segments:\n",
    "        return segments\n",
    "    \n",
    "    # Sort by start_idx\n",
    "    sorted_segments = sorted(segments, key=lambda x: x['start_idx'])\n",
    "    merged = [sorted_segments[0]]\n",
    "    \n",
    "    for seg in sorted_segments[1:]:\n",
    "        last = merged[-1]\n",
    "        gap = seg['start_idx'] - last['end_idx'] - 1\n",
    "        \n",
    "        if gap <= merge_window_frames:\n",
    "            # Merge: extend the last segment\n",
    "            merged[-1]['end_idx'] = seg['end_idx']\n",
    "            merged[-1]['length'] = merged[-1]['end_idx'] - merged[-1]['start_idx'] + 1\n",
    "            merged[-1]['mean_score'] = (last['mean_score'] * last['length'] + \n",
    "                                       seg['mean_score'] * seg['length']) / merged[-1]['length']\n",
    "        else:\n",
    "            merged.append(seg)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "# VideoData1 blink detection\n",
    "if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "    print(f\"\\nVideoData1 - Blink Detection\")\n",
    "    \n",
    "    # Calculate frame-based durations (using FPS_1 if available, otherwise estimate)\n",
    "    if 'FPS_1' in globals():\n",
    "        fps_1 = FPS_1\n",
    "    else:\n",
    "        fps_1 = 1 / VideoData1[\"Seconds\"].diff().mean()\n",
    "    \n",
    "    # Use np.ceil to ensure minimum duration is always met (round up to ensure >= min duration)\n",
    "    min_blink_frames = max(1, int(np.ceil(min_blink_duration_ms / 1000 * fps_1)))\n",
    "    max_blink_frames = int(max_blink_duration_ms / 1000 * fps_1)\n",
    "    merge_window_frames = int(blink_merge_window_ms / 1000 * fps_1)\n",
    "    \n",
    "    print(f\"  FPS: {fps_1:.2f}\")\n",
    "    print(f\"  Min blink duration: {min_blink_frames} frames ({min_blink_duration_ms}ms)\")\n",
    "    print(f\"  Max blink duration: {max_blink_frames} frames ({max_blink_duration_ms}ms)\")\n",
    "    print(f\"  Merge window: {merge_window_frames} frames ({blink_merge_window_ms}ms)\")\n",
    "    \n",
    "    # Use adaptive threshold from cell 6 if available, otherwise use percentile\n",
    "    if 'adaptive_thr_v1' in globals():\n",
    "        blink_threshold_v1 = adaptive_thr_v1\n",
    "        print(f\"  Using adaptive threshold: {blink_threshold_v1:.4f} (from cell 6)\")\n",
    "    else:\n",
    "        # Calculate 10th percentile as fallback\n",
    "        blink_threshold_v1 = VideoData1['instance.score'].quantile(0.10)\n",
    "        print(f\"  Using 10th percentile threshold: {blink_threshold_v1:.4f}\")\n",
    "    \n",
    "    # Find blink segments\n",
    "    blink_segments_v1 = find_blink_segments(\n",
    "        VideoData1['instance.score'], \n",
    "        blink_threshold_v1, \n",
    "        min_blink_frames, \n",
    "        max_blink_frames\n",
    "    )\n",
    "    \n",
    "    # Merge nearby blinks\n",
    "    blink_segments_v1 = merge_nearby_blinks(blink_segments_v1, merge_window_frames)\n",
    "    \n",
    "    # Post-merge filter: Remove segments that don't meet minimum duration in actual milliseconds\n",
    "    # (because merging might create segments that are still too short)\n",
    "    filtered_blinks_v1 = []\n",
    "    for blink in blink_segments_v1:\n",
    "        start_idx = blink['start_idx']\n",
    "        end_idx = blink['end_idx']\n",
    "        start_time = VideoData1['Seconds'].iloc[start_idx]\n",
    "        end_time = VideoData1['Seconds'].iloc[end_idx]\n",
    "        duration_ms = (end_time - start_time) * 1000\n",
    "        \n",
    "        # Only keep if duration meets minimum and maximum requirements\n",
    "        if min_blink_duration_ms <= duration_ms <= max_blink_duration_ms:\n",
    "            filtered_blinks_v1.append(blink)\n",
    "        # else: skip this blink (it doesn't meet duration requirements)\n",
    "    blink_segments_v1 = filtered_blinks_v1\n",
    "    \n",
    "    print(f\"  Detected {len(blink_segments_v1)} blink segment(s)\")\n",
    "    \n",
    "    if len(blink_segments_v1) > 0:\n",
    "        # Get start time of recording (for calculating time from beginning)\n",
    "        recording_start_time = VideoData1['Seconds'].iloc[0]\n",
    "        \n",
    "        # Mark blinks by setting coordinates to NaN\n",
    "        total_blink_frames_v1 = 0\n",
    "        for i, blink in enumerate(blink_segments_v1, 1):\n",
    "            start_idx = blink['start_idx']\n",
    "            end_idx = blink['end_idx']\n",
    "            VideoData1.loc[VideoData1.index[start_idx:end_idx+1], columns_of_interest] = np.nan\n",
    "            total_blink_frames_v1 += blink['length']\n",
    "            \n",
    "            # Calculate time range\n",
    "            start_time = VideoData1['Seconds'].iloc[start_idx]\n",
    "            end_time = VideoData1['Seconds'].iloc[end_idx]\n",
    "            duration_ms = (end_time - start_time) * 1000\n",
    "            \n",
    "            # Calculate time from start of recording\n",
    "            start_time_from_start = start_time - recording_start_time\n",
    "            end_time_from_start = end_time - recording_start_time\n",
    "            \n",
    "            # Format times as MM:SS\n",
    "            start_time_str = format_time_from_start(start_time_from_start)\n",
    "            end_time_str = format_time_from_start(end_time_from_start)\n",
    "            \n",
    "            print(f\"    Blink {i}: frames {start_idx}-{end_idx} ({blink['length']} frames, \"\n",
    "                  f\"{duration_ms:.1f}ms) at {start_time_str}-{end_time_str}, \"\n",
    "                  f\"mean score: {blink['mean_score']:.4f}\")\n",
    "        \n",
    "        print(f\"  Total blink frames marked: {total_blink_frames_v1} frames \"\n",
    "              f\"({total_blink_frames_v1/fps_1*1000:.1f}ms)\")\n",
    "        \n",
    "        # Calculate blink rate\n",
    "        recording_duration_min = (VideoData1['Seconds'].iloc[-1] - VideoData1['Seconds'].iloc[0]) / 60\n",
    "        blink_rate = len(blink_segments_v1) / recording_duration_min if recording_duration_min > 0 else 0\n",
    "        print(f\"  Blink rate: {blink_rate:.2f} blinks/minute\")\n",
    "    else:\n",
    "        print(\"  No blinks detected\")\n",
    "\n",
    "# VideoData2 blink detection\n",
    "if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "    print(f\"\\nVideoData2 - Blink Detection\")\n",
    "    \n",
    "    # Calculate frame-based durations (using FPS_2 if available, otherwise estimate)\n",
    "    if 'FPS_2' in globals():\n",
    "        fps_2 = FPS_2\n",
    "    else:\n",
    "        fps_2 = 1 / VideoData2[\"Seconds\"].diff().mean()\n",
    "    \n",
    "    # Use np.ceil to ensure minimum duration is always met (round up to ensure >= min duration)\n",
    "    min_blink_frames = max(1, int(np.ceil(min_blink_duration_ms / 1000 * fps_2)))\n",
    "    max_blink_frames = int(max_blink_duration_ms / 1000 * fps_2)\n",
    "    merge_window_frames = int(blink_merge_window_ms / 1000 * fps_2)\n",
    "    \n",
    "    print(f\"  FPS: {fps_2:.2f}\")\n",
    "    print(f\"  Min blink duration: {min_blink_frames} frames ({min_blink_duration_ms}ms)\")\n",
    "    print(f\"  Max blink duration: {max_blink_frames} frames ({max_blink_duration_ms}ms)\")\n",
    "    print(f\"  Merge window: {merge_window_frames} frames ({blink_merge_window_ms}ms)\")\n",
    "    \n",
    "    # Use adaptive threshold from cell 6 if available, otherwise use percentile\n",
    "    if 'adaptive_thr_v2' in globals():\n",
    "        blink_threshold_v2 = adaptive_thr_v2\n",
    "        print(f\"  Using adaptive threshold: {blink_threshold_v2:.4f} (from cell 6)\")\n",
    "    else:\n",
    "        # Calculate 10th percentile as fallback\n",
    "        blink_threshold_v2 = VideoData2['instance.score'].quantile(0.10)\n",
    "        print(f\"  Using 10th percentile threshold: {blink_threshold_v2:.4f}\")\n",
    "    \n",
    "    # Find blink segments\n",
    "    blink_segments_v2 = find_blink_segments(\n",
    "        VideoData2['instance.score'], \n",
    "        blink_threshold_v2, \n",
    "        min_blink_frames, \n",
    "        max_blink_frames\n",
    "    )\n",
    "    \n",
    "    # Merge nearby blinks\n",
    "    blink_segments_v2 = merge_nearby_blinks(blink_segments_v2, merge_window_frames)\n",
    "    \n",
    "    # Post-merge filter: Remove segments that don't meet minimum duration in actual milliseconds\n",
    "    # (because merging might create segments that are still too short)\n",
    "    filtered_blinks_v2 = []\n",
    "    for blink in blink_segments_v2:\n",
    "        start_idx = blink['start_idx']\n",
    "        end_idx = blink['end_idx']\n",
    "        start_time = VideoData2['Seconds'].iloc[start_idx]\n",
    "        end_time = VideoData2['Seconds'].iloc[end_idx]\n",
    "        duration_ms = (end_time - start_time) * 1000\n",
    "        \n",
    "        # Only keep if duration meets minimum and maximum requirements\n",
    "        if min_blink_duration_ms <= duration_ms <= max_blink_duration_ms:\n",
    "            filtered_blinks_v2.append(blink)\n",
    "        # else: skip this blink (it doesn't meet duration requirements)\n",
    "    blink_segments_v2 = filtered_blinks_v2\n",
    "    \n",
    "    print(f\"  Detected {len(blink_segments_v2)} blink segment(s)\")\n",
    "    \n",
    "    if len(blink_segments_v2) > 0:\n",
    "        # Get start time of recording (for calculating time from beginning)\n",
    "        recording_start_time = VideoData2['Seconds'].iloc[0]\n",
    "        \n",
    "        # Mark blinks by setting coordinates to NaN\n",
    "        total_blink_frames_v2 = 0\n",
    "        for i, blink in enumerate(blink_segments_v2, 1):\n",
    "            start_idx = blink['start_idx']\n",
    "            end_idx = blink['end_idx']\n",
    "            VideoData2.loc[VideoData2.index[start_idx:end_idx+1], columns_of_interest] = np.nan\n",
    "            total_blink_frames_v2 += blink['length']\n",
    "            \n",
    "            # Calculate time range\n",
    "            start_time = VideoData2['Seconds'].iloc[start_idx]\n",
    "            end_time = VideoData2['Seconds'].iloc[end_idx]\n",
    "            duration_ms = (end_time - start_time) * 1000\n",
    "            \n",
    "            # Calculate time from start of recording\n",
    "            start_time_from_start = start_time - recording_start_time\n",
    "            end_time_from_start = end_time - recording_start_time\n",
    "            \n",
    "            # Format times as MM:SS\n",
    "            start_time_str = format_time_from_start(start_time_from_start)\n",
    "            end_time_str = format_time_from_start(end_time_from_start)\n",
    "            \n",
    "            print(f\"    Blink {i}: frames {start_idx}-{end_idx} ({blink['length']} frames, \"\n",
    "                  f\"{duration_ms:.1f}ms) at {start_time_str}-{end_time_str}, \"\n",
    "                  f\"mean score: {blink['mean_score']:.4f}\")\n",
    "        \n",
    "        print(f\"  Total blink frames marked: {total_blink_frames_v2} frames \"\n",
    "              f\"({total_blink_frames_v2/fps_2*1000:.1f}ms)\")\n",
    "        \n",
    "        # Calculate blink rate\n",
    "        recording_duration_min = (VideoData2['Seconds'].iloc[-1] - VideoData2['Seconds'].iloc[0]) / 60\n",
    "        blink_rate = len(blink_segments_v2) / recording_duration_min if recording_duration_min > 0 else 0\n",
    "        print(f\"  Blink rate: {blink_rate:.2f} blinks/minute\")\n",
    "    else:\n",
    "        print(\"  No blinks detected\")\n",
    "\n",
    "print(\"\\n✅ Blink detection complete. Blink periods remain as NaN (not interpolated).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC plot timeseries of interpolation corrected NaN and (TODO low confidence coordinates in browser \n",
    "############################################################################################################\n",
    "\n",
    "if plot_timeseries:\n",
    "    print(f'ℹ️ Figure opens in browser window, takes a bit of time.')\n",
    "    \n",
    "    # VideoData1 QC Plot\n",
    "    if 'VideoData1_Has_Sleap' in globals() and VideoData1_Has_Sleap:\n",
    "        fig1 = make_subplots(\n",
    "            rows=4, cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=(\n",
    "                \"VideoData1 - X coordinates for pupil centre and left-right eye corner\",\n",
    "                \"VideoData1 - Y coordinates for pupil centre and left-right eye corner\",\n",
    "                \"VideoData1 - X coordinates for iris points\",\n",
    "                \"VideoData1 - Y coordinates for iris points\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Row 1: Plot left.x, center.x, right.x\n",
    "        fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['left.x'], mode='lines', name='left.x'), row=1, col=1)\n",
    "        fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['center.x'], mode='lines', name='center.x'), row=1, col=1)\n",
    "        fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['right.x'], mode='lines', name='right.x'), row=1, col=1)\n",
    "\n",
    "        # Row 2: Plot left.y, center.y, right.y\n",
    "        fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['left.y'], mode='lines', name='left.y'), row=2, col=1)\n",
    "        fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['center.y'], mode='lines', name='center.y'), row=2, col=1)\n",
    "        fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1['right.y'], mode='lines', name='right.y'), row=2, col=1)\n",
    "\n",
    "        # Row 3: Plot p.x coordinates for p1 to p8\n",
    "        for col in ['p1.x', 'p2.x', 'p3.x', 'p4.x', 'p5.x', 'p6.x', 'p7.x', 'p8.x']:\n",
    "            fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=3, col=1)\n",
    "\n",
    "        # Row 4: Plot p.y coordinates for p1 to p8\n",
    "        for col in ['p1.y', 'p2.y', 'p3.y', 'p4.y', 'p5.y', 'p6.y', 'p7.y', 'p8.y']:\n",
    "            fig1.add_trace(go.Scatter(x=VideoData1['Seconds'], y=VideoData1[col], mode='lines', name=col), row=4, col=1)\n",
    "\n",
    "        fig1.update_layout(\n",
    "            height=1200,\n",
    "            title_text=\"VideoData1 - Time series subplots for coordinates (QC after interpolation)\",\n",
    "            showlegend=True\n",
    "        )\n",
    "        fig1.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "        fig1.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "        fig1.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "        fig1.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "        fig1.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "        fig1.show(renderer='browser')\n",
    "    \n",
    "    # VideoData2 QC Plot\n",
    "    if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "        fig2 = make_subplots(\n",
    "            rows=4, cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=(\n",
    "                \"VideoData2 - X coordinates for pupil centre and left-right eye corner\",\n",
    "                \"VideoData2 - Y coordinates for pupil centre and left-right eye corner\",\n",
    "                \"VideoData2 - X coordinates for iris points\",\n",
    "                \"VideoData2 - Y coordinates for iris points\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Row 1: Plot left.x, center.x, right.x\n",
    "        fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2['left.x'], mode='lines', name='left.x'), row=1, col=1)\n",
    "        fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2['center.x'], mode='lines', name='center.x'), row=1, col=1)\n",
    "        fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2['right.x'], mode='lines', name='right.x'), row=1, col=1)\n",
    "\n",
    "        # Row 2: Plot left.y, center.y, right.y\n",
    "        fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2['left.y'], mode='lines', name='left.y'), row=2, col=1)\n",
    "        fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2['center.y'], mode='lines', name='center.y'), row=2, col=1)\n",
    "        fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2['right.y'], mode='lines', name='right.y'), row=2, col=1)\n",
    "\n",
    "        # Row 3: Plot p.x coordinates for p1 to p8\n",
    "        for col in ['p1.x', 'p2.x', 'p3.x', 'p4.x', 'p5.x', 'p6.x', 'p7.x', 'p8.x']:\n",
    "            fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2[col], mode='lines', name=col), row=3, col=1)\n",
    "\n",
    "        # Row 4: Plot p.y coordinates for p1 to p8\n",
    "        for col in ['p1.y', 'p2.y', 'p3.y', 'p4.y', 'p5.y', 'p6.y', 'p7.y', 'p8.y']:\n",
    "            fig2.add_trace(go.Scatter(x=VideoData2['Seconds'], y=VideoData2[col], mode='lines', name=col), row=4, col=1)\n",
    "\n",
    "        fig2.update_layout(\n",
    "            height=1200,\n",
    "            title_text=\"VideoData2 - Time series subplots for coordinates (QC after interpolation)\",\n",
    "            showlegend=True\n",
    "        )\n",
    "        fig2.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "        fig2.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "        fig2.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "        fig2.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "        fig2.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "        fig2.show(renderer='browser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC plot XY coordinate distributions after NaN and ( TODO - low confidence inference points) are interpolated \n",
    "##############################################################################################################\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "\n",
    "# Create coordinates_dict for both datasets\n",
    "if VideoData1_Has_Sleap:\n",
    "    coordinates_dict1_processed = lp.get_coordinates_dict(VideoData1, columns_of_interest)\n",
    "if VideoData2_Has_Sleap:\n",
    "    coordinates_dict2_processed = lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "\n",
    "columns_of_interest = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "\n",
    "# Filter out NaN values and calculate the min and max values for X and Y coordinates for both dict1 and dict2\n",
    "def min_max_dict(coordinates_dict):\n",
    "    x_min = min([coordinates_dict[f'{col}.x'][~np.isnan(coordinates_dict[f'{col}.x'])].min() for col in columns_of_interest])\n",
    "    x_max = max([coordinates_dict[f'{col}.x'][~np.isnan(coordinates_dict[f'{col}.x'])].max() for col in columns_of_interest])\n",
    "    y_min = min([coordinates_dict[f'{col}.y'][~np.isnan(coordinates_dict[f'{col}.y'])].min() for col in columns_of_interest])\n",
    "    y_max = max([coordinates_dict[f'{col}.y'][~np.isnan(coordinates_dict[f'{col}.y'])].max() for col in columns_of_interest])\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "if VideoData1_Has_Sleap:\n",
    "    x_min1, x_max1, y_min1, y_max1 = min_max_dict(coordinates_dict1_processed)\n",
    "if VideoData2_Has_Sleap:\n",
    "    x_min2, x_max2, y_min2, y_max2 = min_max_dict(coordinates_dict2_processed)\n",
    "\n",
    "# Use global min and max for consistency across subplots\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    x_min = min(x_min1, x_min2)\n",
    "    x_max = max(x_max1, x_max2)\n",
    "    y_min = min(y_min1, y_min2)\n",
    "    y_max = max(y_max1, y_max2)\n",
    "elif VideoData1_Has_Sleap:\n",
    "    x_min, x_max, y_min, y_max = x_min1, x_max1, y_min1, y_max1\n",
    "elif VideoData2_Has_Sleap:\n",
    "    x_min, x_max, y_min, y_max = x_min2, x_max2, y_min2, y_max2\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))\n",
    "fig.suptitle('XY coordinate distribution of different points for VideoData1 and VideoData2 post outlier removal and NaN interpolation)', fontsize=14)\n",
    "\n",
    "# Define colormap for p1-p8\n",
    "colors = ['blue', 'green', 'red', 'cyan', 'magenta', 'yellow', 'black', 'orange']\n",
    "\n",
    "# Panel 1: left, right, center (VideoData1)\n",
    "if VideoData1_Has_Sleap:\n",
    "    ax[0, 0].set_title('VideoData1: left, right, center')\n",
    "    ax[0, 0].scatter(coordinates_dict1_processed['left.x'], coordinates_dict1_processed['left.y'], color='black', label='left', s=10)\n",
    "    ax[0, 0].scatter(coordinates_dict1_processed['right.x'], coordinates_dict1_processed['right.y'], color='grey', label='right', s=10)\n",
    "    ax[0, 0].scatter(coordinates_dict1_processed['center.x'], coordinates_dict1_processed['center.y'], color='red', label='center', s=10)\n",
    "    ax[0, 0].set_xlim([x_min, x_max])\n",
    "    ax[0, 0].set_ylim([y_min, y_max])\n",
    "    ax[0, 0].set_xlabel('x coordinates (pixels)')\n",
    "    ax[0, 0].set_ylabel('y coordinates (pixels)')\n",
    "    ax[0, 0].legend(loc='upper right')\n",
    "\n",
    "    # Panel 2: p1 to p8 (VideoData1)\n",
    "    ax[0, 1].set_title('VideoData1: p1 to p8')\n",
    "    for idx, col in enumerate(columns_of_interest[3:]):\n",
    "        ax[0, 1].scatter(coordinates_dict1_processed[f'{col}.x'], coordinates_dict1_processed[f'{col}.y'], color=colors[idx], label=col, s=5)\n",
    "    ax[0, 1].set_xlim([x_min, x_max])\n",
    "    ax[0, 1].set_ylim([y_min, y_max])\n",
    "    ax[0, 1].set_xlabel('x coordinates (pixels)')\n",
    "    ax[0, 1].set_ylabel('y coordinates (pixels)')\n",
    "    ax[0, 1].legend(loc='upper right')\n",
    "\n",
    "# Panel 3: left, right, center (VideoData2)\n",
    "if VideoData2_Has_Sleap:\n",
    "    ax[1, 0].set_title('VideoData2: left, right, center')\n",
    "    ax[1, 0].scatter(coordinates_dict2_processed['left.x'], coordinates_dict2_processed['left.y'], color='black', label='left', s=10)\n",
    "    ax[1, 0].scatter(coordinates_dict2_processed['right.x'], coordinates_dict2_processed['right.y'], color='grey', label='right', s=10)\n",
    "    ax[1, 0].scatter(coordinates_dict2_processed['center.x'], coordinates_dict2_processed['center.y'], color='red', label='center', s=10)\n",
    "    ax[1, 0].set_xlim([x_min, x_max])\n",
    "    ax[1, 0].set_ylim([y_min, y_max])\n",
    "    ax[1, 0].set_xlabel('x coordinates (pixels)')\n",
    "    ax[1, 0].set_ylabel('y coordinates (pixels)')\n",
    "    ax[1, 0].legend(loc='upper right')\n",
    "\n",
    "    # Panel 4: p1 to p8 (VideoData2)\n",
    "    ax[1, 1].set_title('VideoData2: p1 to p8')\n",
    "    for idx, col in enumerate(columns_of_interest[3:]):\n",
    "        ax[1, 1].scatter(coordinates_dict2_processed[f'{col}.x'], coordinates_dict2_processed[f'{col}.y'], color=colors[idx], label=col, s=5)\n",
    "    ax[1, 1].set_xlim([x_min, x_max])\n",
    "    ax[1, 1].set_ylim([y_min, y_max])\n",
    "    ax[1, 1].set_xlabel('x coordinates (pixels)')\n",
    "    ax[1, 1].set_ylabel('y coordinates (pixels)')\n",
    "    ax[1, 1].legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit ellipses on the 8 points to determine pupil centre and diameter\n",
    "############################################################################################################\n",
    "\n",
    "columns_of_interest = ['left.x','left.y','center.x','center.y','right.x','right.y','p1.x','p1.y','p2.x','p2.y','p3.x','p3.y','p4.x','p4.y','p5.x','p5.y','p6.x','p6.y','p7.x','p7.y','p8.x','p8.y']\n",
    "\n",
    "# VideoData1 processing\n",
    "if VideoData1_Has_Sleap:\n",
    "    print(\"=== VideoData1 Ellipse Fitting for Pupil Diameter ===\")\n",
    "    coordinates_dict1_processed = lp.get_coordinates_dict(VideoData1, columns_of_interest)\n",
    "\n",
    "    theta1 = lp.find_horizontal_axis_angle(VideoData1, 'left', 'center')\n",
    "    center_point1 = lp.get_left_right_center_point(coordinates_dict1_processed)\n",
    "\n",
    "    columns_of_interest_reformatted = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "    remformatted_coordinates_dict1 = lp.get_reformatted_coordinates_dict(coordinates_dict1_processed, columns_of_interest_reformatted)\n",
    "    centered_coordinates_dict1 = lp.get_centered_coordinates_dict(remformatted_coordinates_dict1, center_point1)\n",
    "    rotated_coordinates_dict1 = lp.get_rotated_coordinates_dict(centered_coordinates_dict1, theta1)\n",
    "\n",
    "    columns_of_interest_ellipse = ['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "    ellipse_parameters_data1, ellipse_center_points_data1 = lp.get_fitted_ellipse_parameters(rotated_coordinates_dict1, columns_of_interest_ellipse)\n",
    "\n",
    "    average_diameter1 = np.mean([ellipse_parameters_data1[:,0], ellipse_parameters_data1[:,1]], axis=0)\n",
    "\n",
    "    SleapVideoData1 = process.convert_arrays_to_dataframe(['Seconds', 'Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'], [VideoData1['Seconds'].values, average_diameter1, ellipse_parameters_data1[:,2], ellipse_center_points_data1[:,0], ellipse_center_points_data1[:,1]])\n",
    "\n",
    "# VideoData2 processing\n",
    "if VideoData2_Has_Sleap:\n",
    "    print(\"=== VideoData2 Ellipse Fitting for Pupil Diameter ===\")\n",
    "    coordinates_dict2_processed = lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "\n",
    "    theta2 = lp.find_horizontal_axis_angle(VideoData2, 'left', 'center')\n",
    "    center_point2 = lp.get_left_right_center_point(coordinates_dict2_processed)\n",
    "\n",
    "    columns_of_interest_reformatted = ['left', 'right', 'center', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "    remformatted_coordinates_dict2 = lp.get_reformatted_coordinates_dict(coordinates_dict2_processed, columns_of_interest_reformatted)\n",
    "    centered_coordinates_dict2 = lp.get_centered_coordinates_dict(remformatted_coordinates_dict2, center_point2)\n",
    "    rotated_coordinates_dict2 = lp.get_rotated_coordinates_dict(centered_coordinates_dict2, theta2)\n",
    "\n",
    "    columns_of_interest_ellipse = ['p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7', 'p8']\n",
    "    ellipse_parameters_data2, ellipse_center_points_data2 = lp.get_fitted_ellipse_parameters(rotated_coordinates_dict2, columns_of_interest_ellipse)\n",
    "\n",
    "    average_diameter2 = np.mean([ellipse_parameters_data2[:,0], ellipse_parameters_data2[:,1]], axis=0)\n",
    "\n",
    "    SleapVideoData2 = process.convert_arrays_to_dataframe(['Seconds', 'Ellipse.Diameter', 'Ellipse.Angle', 'Ellipse.Center.X', 'Ellipse.Center.Y'], [VideoData2['Seconds'].values, average_diameter2, ellipse_parameters_data2[:,2], ellipse_center_points_data2[:,0], ellipse_center_points_data2[:,1]])\n",
    "\n",
    "############################################################################################################\n",
    "# some aggressive filtering of the pupil diameter\n",
    "############################################################################################################\n",
    "\n",
    "# VideoData1 filtering\n",
    "if VideoData1_Has_Sleap:\n",
    "    print(\"\\n=== VideoData1 Filtering ===\")\n",
    "    # Butterworth filter parameters\n",
    "    fs1 = 1 / np.median(np.diff(SleapVideoData1['Seconds']))  # Sampling frequency (Hz)\n",
    "    order = 6\n",
    "\n",
    "    b1, a1 = butter(order, cutoff / (0.5 * fs1), btype='low')\n",
    "    \n",
    "    # Handle NaN values before filtering (from blink detection)\n",
    "    # Replace NaN with forward-fill for filtering purposes only (to avoid filtfilt issues)\n",
    "    diameter_data = SleapVideoData1['Ellipse.Diameter'].copy()\n",
    "    # Use ffill() and bfill() instead of deprecated fillna(method='ffill')\n",
    "    diameter_data_filled = diameter_data.ffill().bfill()\n",
    "    \n",
    "    # Apply filter\n",
    "    if not diameter_data_filled.isna().all():\n",
    "        filtered = filtfilt(b1, a1, diameter_data_filled)\n",
    "        # Restore NaN values at original NaN positions (from blinks)\n",
    "        filtered = pd.Series(filtered, index=diameter_data.index)\n",
    "        filtered[diameter_data.isna()] = np.nan\n",
    "        SleapVideoData1['Ellipse.Diameter.Filt'] = filtered\n",
    "    else:\n",
    "        # If all values are NaN, just copy\n",
    "        SleapVideoData1['Ellipse.Diameter.Filt'] = diameter_data\n",
    "\n",
    "    SleapVideoData1['Ellipse.Diameter'] = SleapVideoData1['Ellipse.Diameter'].rolling(window=12, center=True, min_periods=1).median()\n",
    "\n",
    "# VideoData2 filtering\n",
    "if VideoData2_Has_Sleap:\n",
    "    print(\"=== VideoData2 Filtering ===\")\n",
    "    fs2 = 1 / np.median(np.diff(SleapVideoData2['Seconds']))  # Sampling frequency (Hz)\n",
    "    order = 6\n",
    "\n",
    "    b2, a2 = butter(order, cutoff / (0.5 * fs2), btype='low')\n",
    "    \n",
    "    # Handle NaN values before filtering (from blink detection)\n",
    "    # Replace NaN with forward-fill for filtering purposes only (to avoid filtfilt issues)\n",
    "    diameter_data = SleapVideoData2['Ellipse.Diameter'].copy()\n",
    "    # Use ffill() and bfill() instead of deprecated fillna(method='ffill')\n",
    "    diameter_data_filled = diameter_data.ffill().bfill()\n",
    "    \n",
    "    # Apply filter\n",
    "    if not diameter_data_filled.isna().all():\n",
    "        filtered = filtfilt(b2, a2, diameter_data_filled)\n",
    "        # Restore NaN values at original NaN positions (from blinks)\n",
    "        filtered = pd.Series(filtered, index=diameter_data.index)\n",
    "        filtered[diameter_data.isna()] = np.nan\n",
    "        SleapVideoData2['Ellipse.Diameter.Filt'] = filtered\n",
    "    else:\n",
    "        # If all values are NaN, just copy\n",
    "        SleapVideoData2['Ellipse.Diameter.Filt'] = diameter_data\n",
    "\n",
    "    SleapVideoData2['Ellipse.Diameter'] = SleapVideoData2['Ellipse.Diameter'].rolling(window=12, center=True, min_periods=1).median()\n",
    "\n",
    "print(\"✅ Done calculating pupil diameter and angle for both VideoData1 and VideoData2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-correlate pupil diameter for left and right eye \n",
    "############################################################################################################\n",
    "\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    # Create subplots for both comparison and cross-correlation\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=[\"Pupil Diameter Comparison\", \"Cross-Correlation Analysis\"],\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "\n",
    "    # Add SleapVideoData1 pupil diameter\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=SleapVideoData1['Seconds'],\n",
    "            y=SleapVideoData1['Ellipse.Diameter'],\n",
    "            mode='lines',\n",
    "            name=\"VideoData1 Pupil Diameter\",\n",
    "            line=dict(color='blue')\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Add SleapVideoData2 pupil diameter\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=SleapVideoData2['Seconds'],\n",
    "            y=SleapVideoData2['Ellipse.Diameter'],\n",
    "            mode='lines',\n",
    "            name=\"VideoData2 Pupil Diameter\",\n",
    "            line=dict(color='red')\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "\n",
    "    # Cross-correlation analysis\n",
    "    print(\"=== Cross-Correlation Analysis ===\")\n",
    "\n",
    "    # Get pupil diameter data\n",
    "    # Use filtered diameter data (with NaN restored at blink positions)\n",
    "    pupil1 = SleapVideoData1['Ellipse.Diameter.Filt'].values\n",
    "    pupil2 = SleapVideoData2['Ellipse.Diameter.Filt'].values\n",
    "\n",
    "    # Handle different lengths by using the shorter dataset length\n",
    "    min_length = min(len(pupil1), len(pupil2))\n",
    "\n",
    "    # Truncate both datasets to the same length (preserving time alignment)\n",
    "    pupil1_truncated = pupil1[:min_length]\n",
    "    pupil2_truncated = pupil2[:min_length]\n",
    "\n",
    "    # Remove NaN values for correlation - preserve time alignment by only keeping pairs where BOTH are valid\n",
    "    # This ensures cross-correlation is computed on temporally aligned data\n",
    "    valid_mask1 = ~np.isnan(pupil1_truncated)\n",
    "    valid_mask2 = ~np.isnan(pupil2_truncated)\n",
    "    valid_mask = valid_mask1 & valid_mask2  # Only use indices where both arrays have valid data\n",
    "\n",
    "    # Extract aligned pairs (preserves temporal alignment)\n",
    "    pupil1_clean = pupil1_truncated[valid_mask]\n",
    "    pupil2_clean = pupil2_truncated[valid_mask]\n",
    "\n",
    "    # Check if we have enough data\n",
    "    if len(pupil1_clean) < 2 or len(pupil2_clean) < 2:\n",
    "        print(\"❌ Error: Not enough valid data points for correlation analysis\")\n",
    "    else:\n",
    "        # Calculate cross-correlation\n",
    "        try:\n",
    "            correlation = correlate(pupil1_clean, pupil2_clean, mode='full')\n",
    "            \n",
    "            # Calculate lags (in samples)\n",
    "            lags = np.arange(-len(pupil2_clean) + 1, len(pupil1_clean))\n",
    "            \n",
    "            # Convert lags to time (assuming same sampling rate)\n",
    "            dt = np.median(np.diff(SleapVideoData1['Seconds']))\n",
    "            lag_times = lags * dt\n",
    "            \n",
    "            # Find peak correlation and corresponding lag\n",
    "            peak_idx = np.argmax(correlation)\n",
    "            peak_correlation = correlation[peak_idx]\n",
    "            peak_lag_samples = lags[peak_idx]\n",
    "            peak_lag_time = lag_times[peak_idx]\n",
    "            peak_lag_time_display = peak_lag_time # for final QC figure \n",
    "            \n",
    "            print(f\"Peak lag (time): {peak_lag_time:.4f} seconds\")\n",
    "\n",
    "        \n",
    "            # Normalize correlation to [-1, 1] range\n",
    "            norm_factor = np.sqrt(np.sum(pupil1_clean**2) * np.sum(pupil2_clean**2))\n",
    "            if norm_factor > 0:\n",
    "                correlation_normalized = correlation / norm_factor\n",
    "                peak_correlation_normalized = correlation_normalized[peak_idx]\n",
    "                print(f\"Peak normalized correlation: {peak_correlation_normalized:.4f}\")\n",
    "            else:\n",
    "                print(\"❌ Error: Cannot normalize correlation (zero variance)\")\n",
    "                correlation_normalized = correlation\n",
    "                peak_correlation_normalized = 0\n",
    "            \n",
    "            # Plot cross-correlation\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=lag_times,\n",
    "                    y=correlation_normalized,\n",
    "                    mode='lines',\n",
    "                    name=\"Cross-Correlation\",\n",
    "                    line=dict(color='green')\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "            # Add vertical line at peak\n",
    "            fig.add_vline(\n",
    "                x=peak_lag_time,\n",
    "                line_dash=\"dash\",\n",
    "                line_color=\"red\",\n",
    "                annotation_text=f\"Peak: {peak_correlation_normalized:.3f}\",\n",
    "                row=2, col=1\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in cross-correlation calculation: {e}\")\n",
    "            # Add empty trace to maintain plot structure\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[0], y=[0],\n",
    "                    mode='lines',\n",
    "                    name=\"Cross-Correlation (Error)\",\n",
    "                    line=dict(color='gray')\n",
    "                ),\n",
    "                row=2, col=1\n",
    "            )\n",
    "\n",
    "    # Update axes labels\n",
    "    fig.update_xaxes(title_text=\"Time (seconds)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Pupil Diameter\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Lag (seconds)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Normalized Correlation\", row=2, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=800,\n",
    "        width=1000,\n",
    "        title_text=\"SLEAP Pupil Diameter Analysis: Comparison & Cross-Correlation\"\n",
    "    )\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    # Additional correlation statistics\n",
    "    if len(pupil1_clean) >= 2 and len(pupil2_clean) >= 2:\n",
    "        try:\n",
    "            # Calculate Pearson correlation coefficient\n",
    "            pearson_r, pearson_p = pearsonr(pupil1_clean, pupil2_clean)\n",
    "            pearson_r_display = pearson_r\n",
    "            pearson_p_display = pearson_p\n",
    "            \n",
    "            print(f\"\\n=== Additional Statistics ===\")\n",
    "            print(f\"Pearson correlation coefficient: {pearson_r:.2f}\")\n",
    "\n",
    "            # Handle extremely small p-values\n",
    "            if pearson_p < 1e-300:\n",
    "                print(f'Pearson p-value: < 1e-300 (extremely significant)')\n",
    "            else:\n",
    "                print(f'Pearson p-value: {pearson_p:.5e}')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in additional statistics: {e}\")\n",
    "            pearson_r_display = None\n",
    "            pearson_p_display = None\n",
    "    else:\n",
    "        print(\"❌ Cannot calculate additional statistics - insufficient data\")\n",
    "else:\n",
    "    print(\"Only one eye is present, no pupil diameter cross-correlation can be done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Second values match 1:1 between VideoData and SleapVideoData then merge them into VideoData\n",
    "############################################################################################################\n",
    "\n",
    "if VideoData1_Has_Sleap is True:\n",
    "    if VideoData1['Seconds'].equals(SleapVideoData1['Seconds']) is False:\n",
    "        print(\"❗ Video1: The 'Seconds' columns DO NOT correspond 1:1 between the two DataFrames. This should not happen\")\n",
    "    else:\n",
    "        VideoData1 = VideoData1.merge(SleapVideoData1, on='Seconds', how='outer')\n",
    "        del SleapVideoData1\n",
    "\n",
    "if VideoData2_Has_Sleap is True:\n",
    "    if VideoData2['Seconds'].equals(SleapVideoData2['Seconds']) is False:\n",
    "        print(\"❗ Video2: The 'Seconds' columns DO NOT correspond 1:1 between the two DataFrames. This should not happen\")\n",
    "    else:\n",
    "        VideoData2 = VideoData2.merge(SleapVideoData2, on='Seconds', how='outer')\n",
    "        del SleapVideoData2\n",
    "gc.collect()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare SLEAP center.x and .y with fitted ellipse centre distributions for both VideoData1 and VideoData2\n",
    "############################################################################################################\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Compute correlations for VideoData1\n",
    "# ------------------------------------------------------------------\n",
    "if VideoData1_Has_Sleap is True:\n",
    "    print(\"=== VideoData1 Analysis ===\")\n",
    "    slope_x1, intercept_x1, r_value_x1, p_value_x1, std_err_x1 = linregress(\n",
    "        VideoData1[\"Ellipse.Center.X\"], \n",
    "        VideoData1[\"center.x\"]\n",
    "    )\n",
    "    r_squared_x1 = r_value_x1**2\n",
    "    print(f\"VideoData1 - R^2 between center point and ellipse center X data: {r_squared_x1:.4f}\")\n",
    "\n",
    "    slope_y1, intercept_y1, r_value_y1, p_value_y1, std_err_y1 = linregress(\n",
    "        VideoData1[\"Ellipse.Center.Y\"], \n",
    "        VideoData1[\"center.y\"]\n",
    "    )\n",
    "    r_squared_y1 = r_value_y1**2\n",
    "    print(f\"VideoData1 - R^2 between center point and ellipse center Y data: {r_squared_y1:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Compute correlations for VideoData2\n",
    "# ------------------------------------------------------------------\n",
    "if VideoData2_Has_Sleap is True:\n",
    "    print(\"\\n=== VideoData2 Analysis ===\")\n",
    "    slope_x2, intercept_x2, r_value_x2, p_value_x2, std_err_x2 = linregress(\n",
    "        VideoData2[\"Ellipse.Center.X\"], \n",
    "        VideoData2[\"center.x\"]\n",
    "    )\n",
    "    r_squared_x2 = r_value_x2**2\n",
    "    print(f\"VideoData2 - R^2 between center point and ellipse center X data: {r_squared_x2:.4f}\")\n",
    "\n",
    "    slope_y2, intercept_y2, r_value_y2, p_value_y2, std_err_y2 = linregress(\n",
    "        VideoData2[\"Ellipse.Center.Y\"], \n",
    "        VideoData2[\"center.y\"]\n",
    "    )\n",
    "    r_squared_y2 = r_value_y2**2\n",
    "    print(f\"VideoData2 - R^2 between center point and ellipse center Y data: {r_squared_y2:.4f}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) Center of Mass Analysis (if both VideoData1 and VideoData2 are available)\n",
    "# ------------------------------------------------------------------\n",
    "if VideoData1_Has_Sleap is True and VideoData2_Has_Sleap is True:\n",
    "    print(\"\\n=== Center of Mass Distance Analysis ===\")\n",
    "    \n",
    "    # Calculate center of mass (mean) for VideoData1\n",
    "    com_center_x1 = VideoData1[\"center.x\"].mean()\n",
    "    com_center_y1 = VideoData1[\"center.y\"].mean()\n",
    "    com_ellipse_x1 = VideoData1[\"Ellipse.Center.X\"].mean()\n",
    "    com_ellipse_y1 = VideoData1[\"Ellipse.Center.Y\"].mean()\n",
    "    \n",
    "    # Calculate absolute distances for VideoData1\n",
    "    dist_x1 = abs(com_center_x1 - com_ellipse_x1)\n",
    "    dist_y1 = abs(com_center_y1 - com_ellipse_y1)\n",
    "    \n",
    "    print(f\"\\nVideoData1:\")\n",
    "    print(f\"  Center of mass for center.x/y: ({com_center_x1:.4f}, {com_center_y1:.4f})\")\n",
    "    print(f\"  Center of mass for Ellipse.Center.X/Y: ({com_ellipse_x1:.4f}, {com_ellipse_y1:.4f})\")\n",
    "    print(f\"  Absolute distance in X: {dist_x1:.4f} pixels\")\n",
    "    print(f\"  Absolute distance in Y: {dist_y1:.4f} pixels\")\n",
    "    \n",
    "    # Calculate center of mass (mean) for VideoData2\n",
    "    com_center_x2 = VideoData2[\"center.x\"].mean()\n",
    "    com_center_y2 = VideoData2[\"center.y\"].mean()\n",
    "    com_ellipse_x2 = VideoData2[\"Ellipse.Center.X\"].mean()\n",
    "    com_ellipse_y2 = VideoData2[\"Ellipse.Center.Y\"].mean()\n",
    "    \n",
    "    # Calculate absolute distances for VideoData2\n",
    "    dist_x2 = abs(com_center_x2 - com_ellipse_x2)\n",
    "    dist_y2 = abs(com_center_y2 - com_ellipse_y2)\n",
    "    \n",
    "    print(f\"\\nVideoData2:\")\n",
    "    print(f\"  Center of mass for center.x/y: ({com_center_x2:.4f}, {com_center_y2:.4f})\")\n",
    "    print(f\"  Center of mass for Ellipse.Center.X/Y: ({com_ellipse_x2:.4f}, {com_ellipse_y2:.4f})\")\n",
    "    print(f\"  Absolute distance in X: {dist_x2:.4f} pixels\")\n",
    "    print(f\"  Absolute distance in Y: {dist_y2:.4f} pixels\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) Re-center Ellipse.Center.X and Ellipse.Center.Y using median\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n=== Re-centering Ellipse.Center coordinates ===\")\n",
    "\n",
    "# Re-center VideoData1 Ellipse.Center coordinates\n",
    "if VideoData1_Has_Sleap is True:\n",
    "    # Calculate median\n",
    "    median_ellipse_x1 = VideoData1[\"Ellipse.Center.X\"].median()\n",
    "    median_ellipse_y1 = VideoData1[\"Ellipse.Center.Y\"].median()\n",
    "    \n",
    "    # Center the coordinates\n",
    "    VideoData1[\"Ellipse.Center.X\"] = VideoData1[\"Ellipse.Center.X\"] - median_ellipse_x1\n",
    "    VideoData1[\"Ellipse.Center.Y\"] = VideoData1[\"Ellipse.Center.Y\"] - median_ellipse_y1\n",
    "    \n",
    "    print(f\"VideoData1 - Re-centered Ellipse.Center using median: ({median_ellipse_x1:.4f}, {median_ellipse_y1:.4f})\")\n",
    "\n",
    "# Re-center VideoData2 Ellipse.Center coordinates\n",
    "if VideoData2_Has_Sleap is True:\n",
    "    # Calculate median\n",
    "    median_ellipse_x2 = VideoData2[\"Ellipse.Center.X\"].median()\n",
    "    median_ellipse_y2 = VideoData2[\"Ellipse.Center.Y\"].median()\n",
    "    \n",
    "    # Center the coordinates\n",
    "    VideoData2[\"Ellipse.Center.X\"] = VideoData2[\"Ellipse.Center.X\"] - median_ellipse_x2\n",
    "    VideoData2[\"Ellipse.Center.Y\"] = VideoData2[\"Ellipse.Center.Y\"] - median_ellipse_y2\n",
    "    \n",
    "    print(f\"VideoData2 - Re-centered Ellipse.Center using median: ({median_ellipse_x2:.4f}, {median_ellipse_y2:.4f})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and save summary QC plot using matplotlib with scatter plots for 2D distributions\n",
    "\n",
    "# Initialize the statistics variables (these are calculated in Cell 11)\n",
    "try:\n",
    "    pearson_r_display\n",
    "except NameError:\n",
    "    pearson_r_display = None\n",
    "    pearson_p_display = None\n",
    "    peak_lag_time_display = None\n",
    "    print(\"⚠️ Note: Statistics not found. They should be calculated in Cell 11.\")\n",
    "\n",
    "# Calculate correlation for Ellipse.Center.X between VideoData1 and VideoData2 (if both exist)\n",
    "pearson_r_center = None\n",
    "pearson_p_center = None\n",
    "peak_lag_time_center = None\n",
    "\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    # Get the Center.X data\n",
    "    center_x1 = VideoData1['Ellipse.Center.X'].values\n",
    "    center_x2 = VideoData2['Ellipse.Center.X'].values\n",
    "    \n",
    "    min_length = min(len(center_x1), len(center_x2))\n",
    "    center_x1_truncated = center_x1[:min_length]\n",
    "    center_x2_truncated = center_x2[:min_length]\n",
    "    \n",
    "    valid_mask1 = ~np.isnan(center_x1_truncated)\n",
    "    valid_mask2 = ~np.isnan(center_x2_truncated)\n",
    "    valid_mask = valid_mask1 & valid_mask2\n",
    "    \n",
    "    center_x1_clean = center_x1_truncated[valid_mask]\n",
    "    center_x2_clean = center_x2_truncated[valid_mask]\n",
    "    \n",
    "    if len(center_x1_clean) >= 2 and len(center_x2_clean) >= 2:\n",
    "        try:\n",
    "            # Calculate Pearson correlation\n",
    "            pearson_r_center, pearson_p_center = pearsonr(center_x1_clean, center_x2_clean)\n",
    "            \n",
    "            # Calculate cross-correlation for peak lag\n",
    "            correlation = correlate(center_x1_clean, center_x2_clean, mode='full')\n",
    "            lags = np.arange(-len(center_x2_clean) + 1, len(center_x1_clean))\n",
    "            dt = np.median(np.diff(VideoData1['Seconds']))\n",
    "            lag_times = lags * dt\n",
    "            peak_idx = np.argmax(correlation)\n",
    "            peak_lag_time_center = lag_times[peak_idx]\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error calculating Ellipse.Center.X correlation stats: {e}\")\n",
    "\n",
    "# Create the QC summary figure using matplotlib with custom grid layout\n",
    "fig = plt.figure(figsize=(20, 18))\n",
    "fig.suptitle(str(data_path), fontsize=16, y=0.995)\n",
    "\n",
    "# Create a grid layout:\n",
    "# - Top row (full width): VideoData1 Time Series\n",
    "# - Second row (full width): VideoData2 Time Series  \n",
    "# - Third row (two columns): 2D scatter plots (VideoData1 left, VideoData2 right)\n",
    "# - Fourth row (two columns): Pupil diameter (left), Ellipse.Center.X correlation (right)\n",
    "\n",
    "gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Panel 1: VideoData1 center coordinates - Time Series (full width)\n",
    "if VideoData1_Has_Sleap:\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(VideoData1_centered['Seconds'], VideoData1_centered['center.x'],\n",
    "            linewidth=0.5, c='blue', alpha=0.6, label='center.x original')\n",
    "    ax1.plot(VideoData1['Seconds'], VideoData1['Ellipse.Center.X'],\n",
    "            linewidth=0.5, c='red', alpha=0.6, label='Ellipse Center.X')\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Position (pixels)')\n",
    "    ax1.set_title('VideoData1 - center.X Time Series')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: VideoData2 center coordinates - Time Series (full width)\n",
    "if VideoData2_Has_Sleap:\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    ax2.plot(VideoData2_centered['Seconds'], VideoData2_centered['center.x'],\n",
    "            linewidth=0.5, c='blue', alpha=0.6, label='center.x original')\n",
    "    ax2.plot(VideoData2['Seconds'], VideoData2['Ellipse.Center.X'],\n",
    "            linewidth=0.5, c='red', alpha=0.6, label='Ellipse Center.X')\n",
    "    ax2.set_xlabel('Time (s)')\n",
    "    ax2.set_ylabel('Position (pixels)')\n",
    "    ax2.set_title('VideoData2 - center.X Time Series')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: VideoData1 center coordinates - Scatter plot (left half)\n",
    "if VideoData1_Has_Sleap:\n",
    "    ax3 = fig.add_subplot(gs[2, 0])\n",
    "    \n",
    "    # Ellipse.Center (blue)\n",
    "    x_ellipse1 = VideoData1['Ellipse.Center.X'].to_numpy()\n",
    "    y_ellipse1 = VideoData1['Ellipse.Center.Y'].to_numpy()\n",
    "    mask1 = ~(np.isnan(x_ellipse1) | np.isnan(y_ellipse1))\n",
    "    \n",
    "    ax3.scatter(x_ellipse1[mask1], y_ellipse1[mask1],\n",
    "               s=1, alpha=0.3, c='blue', label='Ellipse.Center')\n",
    "    \n",
    "    # Center (red) - from centered data\n",
    "    x_center1 = VideoData1_centered['center.x'].to_numpy()\n",
    "    y_center1 = VideoData1_centered['center.y'].to_numpy()\n",
    "    mask2 = ~(np.isnan(x_center1) | np.isnan(y_center1))\n",
    "    \n",
    "    ax3.scatter(x_center1[mask2], y_center1[mask2],\n",
    "               s=1, alpha=0.3, c='red', label='center.x original')\n",
    "    \n",
    "    ax3.set_xlabel('Center X (pixels)')\n",
    "    ax3.set_ylabel('Center Y (pixels)')\n",
    "    ax3.set_title('VideoData1 - Center X-Y Distribution (center.X vs Ellipse)')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add R² statistics for VideoData1 (bottom left)\n",
    "    try:\n",
    "        if 'r_squared_x1' in globals() and 'r_squared_y1' in globals():\n",
    "            stats_text = f'R² X: {r_squared_x1:.2g}\\nR² Y: {r_squared_y1:.2g}'\n",
    "            ax3.text(0.02, 0.02, stats_text, transform=ax3.transAxes,\n",
    "                    verticalalignment='bottom', horizontalalignment='left',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "                    fontsize=9, family='monospace')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Add center of mass distance for VideoData1 (bottom right)\n",
    "    try:\n",
    "        if 'dist_x1' in globals() and 'dist_y1' in globals():\n",
    "            distance_text = f'COM Dist X: {dist_x1:.3g}\\nCOM Dist Y: {dist_y1:.3g}'\n",
    "            ax3.text(0.98, 0.02, distance_text, transform=ax3.transAxes,\n",
    "                    verticalalignment='bottom', horizontalalignment='right',\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "                    fontsize=9, family='monospace')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Panel 4: VideoData2 center coordinates - Scatter plot (right half)\n",
    "if VideoData2_Has_Sleap:\n",
    "    ax4 = fig.add_subplot(gs[2, 1])\n",
    "    \n",
    "    # Ellipse.Center (blue)\n",
    "    x_ellipse2 = VideoData2['Ellipse.Center.X'].to_numpy()\n",
    "    y_ellipse2 = VideoData2['Ellipse.Center.Y'].to_numpy()\n",
    "    mask3 = ~(np.isnan(x_ellipse2) | np.isnan(y_ellipse2))\n",
    "    \n",
    "    ax4.scatter(x_ellipse2[mask3], y_ellipse2[mask3],\n",
    "               s=1, alpha=0.3, c='blue', label='Ellipse.Center')\n",
    "    \n",
    "    # Center (red) - from centered data\n",
    "    x_center2 = VideoData2_centered['center.x'].to_numpy()\n",
    "    y_center2 = VideoData2_centered['center.y'].to_numpy()\n",
    "    mask4 = ~(np.isnan(x_center2) | np.isnan(y_center2))\n",
    "    \n",
    "    ax4.scatter(x_center2[mask4], y_center2[mask4],\n",
    "               s=1, alpha=0.3, c='red', label='center.X Center')\n",
    "    \n",
    "    ax4.set_xlabel('Center X (pixels)')\n",
    "    ax4.set_ylabel('Center Y (pixels)')\n",
    "    ax4.set_title('VideoData2 - Center X-Y Distribution (center.X vs Ellipse)')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add R² statistics for VideoData2 (bottom left)\n",
    "    try:\n",
    "        if 'r_squared_x2' in globals() and 'r_squared_y2' in globals():\n",
    "            stats_text = f'R² X: {r_squared_x2:.2g}\\nR² Y: {r_squared_y2:.2g}'\n",
    "            ax4.text(0.02, 0.02, stats_text, transform=ax4.transAxes,\n",
    "                    verticalalignment='bottom', horizontalalignment='left',\n",
    "                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "                    fontsize=9, family='monospace')\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Add center of mass distance for VideoData2 (bottom right)\n",
    "    try:\n",
    "        if 'dist_x2' in globals() and 'dist_y2' in globals():\n",
    "            distance_text = f'COM Dist X: {dist_x2:.3g}\\nCOM Dist Y: {dist_y2:.3g}'\n",
    "            ax4.text(0.98, 0.02, distance_text, transform=ax4.transAxes,\n",
    "                    verticalalignment='bottom', horizontalalignment='right',\n",
    "                    bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8),\n",
    "                    fontsize=9, family='monospace')\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Panel 5: Pupil diameter comparison (bottom left)\n",
    "ax5 = fig.add_subplot(gs[3, 0])\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    ax5.plot(VideoData1['Seconds'], VideoData1['Ellipse.Diameter.Filt'],\n",
    "            linewidth=0.5, c='#FF7F00', alpha=0.6, label='VideoData1 Diameter')\n",
    "    ax5.plot(VideoData2['Seconds'], VideoData2['Ellipse.Diameter.Filt'],\n",
    "            linewidth=0.5, c='#9370DB', alpha=0.6, label='VideoData2 Diameter')\n",
    "elif VideoData1_Has_Sleap:\n",
    "    ax5.plot(VideoData1['Seconds'], VideoData1['Ellipse.Diameter.Filt'],\n",
    "            linewidth=0.5, c='#FF7F00', alpha=0.6, label='VideoData1 Diameter')\n",
    "elif VideoData2_Has_Sleap:\n",
    "    ax5.plot(VideoData2['Seconds'], VideoData2['Ellipse.Diameter.Filt'],\n",
    "            linewidth=0.5, c='#9370DB', alpha=0.6, label='VideoData2 Diameter')\n",
    "\n",
    "ax5.set_xlabel('Time (s)')\n",
    "ax5.set_ylabel('Diameter (pixels)')\n",
    "ax5.set_title('Pupil Diameter Comparison')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics text to Panel 5\n",
    "if pearson_r_display is not None and pearson_p_display is not None and peak_lag_time_display is not None:\n",
    "    stats_text = (f'Pearson r = {pearson_r_display:.4f}\\n'\n",
    "                  f'Pearson p = {pearson_p_display:.4e}\\n'\n",
    "                  f'Peak lag = {peak_lag_time_display:.4f} s')\n",
    "    ax5.text(0.98, 0.98, stats_text, transform=ax5.transAxes,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=10, family='monospace')\n",
    "else:\n",
    "    ax5.text(0.5, 0.5, 'Statistics not available\\n(See Cell 11 for correlation analysis)', \n",
    "            transform=ax5.transAxes, ha='center', va='center', fontsize=10)\n",
    "\n",
    "# Panel 6: Ellipse.Center.X comparison (bottom right) with dual y-axis\n",
    "ax6 = fig.add_subplot(gs[3, 1])\n",
    "ax6_twin = ax6.twinx()  # Create a second y-axis\n",
    "\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    # Plot the individual traces\n",
    "    ax6.plot(VideoData1['Seconds'], VideoData1['Ellipse.Center.X'],\n",
    "            linewidth=0.5, c='#FF7F00', alpha=0.6, label='VideoData1 Ellipse.Center.X')\n",
    "    ax6.plot(VideoData2['Seconds'], VideoData2['Ellipse.Center.X'],\n",
    "            linewidth=0.5, c='#9370DB', alpha=0.6, label='VideoData2 Ellipse.Center.X')\n",
    "    \n",
    "    # Plot the difference on the right axis\n",
    "    # Align the data to the same length and normalize for fair comparison\n",
    "    min_length = min(len(VideoData1), len(VideoData2))\n",
    "    \n",
    "    # Normalize data (z-score) to account for different scales\n",
    "    center_x1_aligned = VideoData1['Ellipse.Center.X'].iloc[:min_length]\n",
    "    center_x2_aligned = VideoData2['Ellipse.Center.X'].iloc[:min_length]\n",
    "    \n",
    "    # Calculate mean and std for normalization\n",
    "    mean1 = center_x1_aligned.mean()\n",
    "    std1 = center_x1_aligned.std()\n",
    "    mean2 = center_x2_aligned.mean()\n",
    "    std2 = center_x2_aligned.std()\n",
    "    \n",
    "    # Normalize both datasets\n",
    "    center_x1_norm = (center_x1_aligned - mean1) / std1\n",
    "    center_x2_norm = (center_x2_aligned - mean2) / std2\n",
    "    \n",
    "    # Calculate difference of normalized data\n",
    "    center_x_diff = center_x1_norm - center_x2_norm\n",
    "    seconds_aligned = VideoData1['Seconds'].iloc[:min_length]\n",
    "    ax6_twin.plot(seconds_aligned, center_x_diff,\n",
    "                  linewidth=0.5, c='green', alpha=0.6, label='Difference (normalized)')\n",
    "    \n",
    "elif VideoData1_Has_Sleap:\n",
    "    ax6.plot(VideoData1['Seconds'], VideoData1['Ellipse.Center.X'],\n",
    "            linewidth=0.5, c='#FF7F00', alpha=0.6, label='VideoData1 Ellipse.Center.X')\n",
    "elif VideoData2_Has_Sleap:\n",
    "    ax6.plot(VideoData2['Seconds'], VideoData2['Ellipse.Center.X'],\n",
    "            linewidth=0.5, c='#9370DB', alpha=0.6, label='VideoData2 Ellipse.Center.X')\n",
    "\n",
    "ax6.set_xlabel('Time (s)')\n",
    "ax6.set_ylabel('Center X (pixels)', color='black')\n",
    "ax6.set_title('Ellipse.Center.X Comparison')\n",
    "ax6.tick_params(axis='y', labelcolor='black')\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    ax6_twin.set_ylabel('Normalized Difference (z-score)', color='green')\n",
    "    ax6_twin.tick_params(axis='y', labelcolor='green')\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines1, labels1 = ax6.get_legend_handles_labels()\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    lines2, labels2 = ax6_twin.get_legend_handles_labels()\n",
    "    ax6.legend(lines1 + lines2, labels1 + labels2, loc='upper left')\n",
    "else:\n",
    "    ax6.legend(loc='upper left')\n",
    "\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics text to Panel 6\n",
    "if pearson_r_center is not None and pearson_p_center is not None and peak_lag_time_center is not None:\n",
    "    stats_text = (f'Pearson r = {pearson_r_center:.4f}\\n'\n",
    "                  f'Pearson p = {pearson_p_center:.4e}\\n'\n",
    "                  f'Peak lag = {peak_lag_time_center:.4f} s')\n",
    "    ax6.text(0.98, 0.98, stats_text, transform=ax6.transAxes,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=10, family='monospace')\n",
    "else:\n",
    "    ax6.text(0.5, 0.5, 'Statistics not available\\n(both eyes required)', \n",
    "            transform=ax6.transAxes, ha='center', va='center', fontsize=10)\n",
    "\n",
    "# Save as PDF (editable vector format)\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "pdf_path = save_path / \"Eye_data_QC.pdf\"\n",
    "plt.savefig(pdf_path, dpi=300, bbox_inches='tight', format='pdf')\n",
    "print(f\"✅ QC figure saved as PDF (editable): {pdf_path}\")\n",
    "\n",
    "# Also save as 600 dpi PNG (high-resolution for printing)\n",
    "png_path = save_path / \"Eye_data_QC.png\"\n",
    "plt.savefig(png_path, dpi=600, bbox_inches='tight', format='png')\n",
    "print(f\"✅ QC figure saved as PNG (600 dpi for printing): {png_path}\")\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d37438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive time series plots using plotly for browser viewing\n",
    "\n",
    "# Create subplots for the time series (3 rows now instead of 2)\n",
    "# Need to enable secondary_y for the third panel\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.08,\n",
    "    subplot_titles=('VideoData1 - center.X Time Series', \n",
    "                    'VideoData2 - center.X Time Series',\n",
    "                    'Ellipse.Center.X Comparison with Difference'),\n",
    "    specs=[[{}], [{}], [{\"secondary_y\": True}]]  # Enable secondary_y for row 3\n",
    ")\n",
    "\n",
    "# Panel 1: VideoData1 center coordinates - Time Series\n",
    "if VideoData1_Has_Sleap:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=VideoData1_centered['Seconds'],\n",
    "        y=VideoData1_centered['center.x'],\n",
    "        mode='lines',\n",
    "        name='center.x original',\n",
    "        line=dict(color='blue', width=0.5),\n",
    "        opacity=0.6\n",
    "    ), row=1, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=VideoData1['Seconds'],\n",
    "        y=VideoData1['Ellipse.Center.X'],\n",
    "        mode='lines',\n",
    "        name='Ellipse Center.X',\n",
    "        line=dict(color='red', width=0.5),\n",
    "        opacity=0.6\n",
    "    ), row=1, col=1)\n",
    "\n",
    "# Panel 2: VideoData2 center coordinates - Time Series\n",
    "if VideoData2_Has_Sleap:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=VideoData2_centered['Seconds'],\n",
    "        y=VideoData2_centered['center.x'],\n",
    "        mode='lines',\n",
    "        name='center.x original',\n",
    "        line=dict(color='blue', width=0.5),\n",
    "        opacity=0.6\n",
    "    ), row=2, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=VideoData2['Seconds'],\n",
    "        y=VideoData2['Ellipse.Center.X'],\n",
    "        mode='lines',\n",
    "        name='Ellipse Center.X',\n",
    "        line=dict(color='red', width=0.5),\n",
    "        opacity=0.6\n",
    "    ), row=2, col=1)\n",
    "\n",
    "# Panel 3: Ellipse.Center.X Comparison with difference\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    # Plot the individual traces\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=VideoData1['Seconds'],\n",
    "        y=VideoData1['Ellipse.Center.X'],\n",
    "        mode='lines',\n",
    "        name='VideoData1 Ellipse.Center.X',\n",
    "        line=dict(color='#FF7F00', width=0.5),  # Orange\n",
    "        opacity=0.6\n",
    "    ), row=3, col=1)\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=VideoData2['Seconds'],\n",
    "        y=VideoData2['Ellipse.Center.X'],\n",
    "        mode='lines',\n",
    "        name='VideoData2 Ellipse.Center.X',\n",
    "        line=dict(color='#9370DB', width=0.5),  # Purple\n",
    "        opacity=0.6\n",
    "    ), row=3, col=1)\n",
    "    \n",
    "    # Plot the difference on secondary y-axis\n",
    "    # Align the data to the same length and normalize for fair comparison\n",
    "    min_length = min(len(VideoData1), len(VideoData2))\n",
    "    \n",
    "    # Normalize data (z-score) to account for different scales\n",
    "    center_x1_aligned = VideoData1['Ellipse.Center.X'].iloc[:min_length]\n",
    "    center_x2_aligned = VideoData2['Ellipse.Center.X'].iloc[:min_length]\n",
    "    \n",
    "    # Calculate mean and std for normalization\n",
    "    mean1 = center_x1_aligned.mean()\n",
    "    std1 = center_x1_aligned.std()\n",
    "    mean2 = center_x2_aligned.mean()\n",
    "    std2 = center_x2_aligned.std()\n",
    "    \n",
    "    # Normalize both datasets\n",
    "    center_x1_norm = (center_x1_aligned - mean1) / std1\n",
    "    center_x2_norm = (center_x2_aligned - mean2) / std2\n",
    "    \n",
    "    # Calculate difference of normalized data\n",
    "    center_x_diff = center_x1_norm - center_x2_norm\n",
    "    seconds_aligned = VideoData1['Seconds'].iloc[:min_length]\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=seconds_aligned,\n",
    "        y=center_x_diff,\n",
    "        mode='lines',\n",
    "        name='Difference (normalized)',\n",
    "        line=dict(color='green', width=0.5),\n",
    "        opacity=0.6\n",
    "    ), row=3, col=1, secondary_y=True)\n",
    "    \n",
    "elif VideoData1_Has_Sleap:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=VideoData1['Seconds'],\n",
    "        y=VideoData1['Ellipse.Center.X'],\n",
    "        mode='lines',\n",
    "        name='VideoData1 Ellipse.Center.X',\n",
    "        line=dict(color='#FF7F00', width=0.5),\n",
    "        opacity=0.6\n",
    "    ), row=3, col=1)\n",
    "elif VideoData2_Has_Sleap:\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=VideoData2['Seconds'],\n",
    "        y=VideoData2['Ellipse.Center.X'],\n",
    "        mode='lines',\n",
    "        name='VideoData2 Ellipse.Center.X',\n",
    "        line=dict(color='#9370DB', width=0.5),\n",
    "        opacity=0.6\n",
    "    ), row=3, col=1)\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    height=1200,  # Increased height for 3 panels\n",
    "    title_text=f'{data_path} - Eye Tracking Time Series QC',\n",
    "    showlegend=True,\n",
    "    hovermode='x unified'\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "fig.update_xaxes(title_text=\"Time (s)\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Position (pixels)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Position (pixels)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"Center X (pixels)\", row=3, col=1)\n",
    "\n",
    "# Update secondary y-axis for difference plot\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    fig.update_yaxes(title_text=\"Normalized Difference (z-score)\", row=3, col=1, secondary_y=True)\n",
    "\n",
    "# Show in browser\n",
    "fig.show(renderer='browser')\n",
    "\n",
    "# Also save as HTML\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "html_path = save_path / \"Eye_data_QC_time_series.html\"\n",
    "fig.write_html(html_path)\n",
    "print(f\"✅ Interactive time series plot saved to: {html_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save as df to csv to be loaded in the photometry/harp/etc. analysis notebook \n",
    "############################################################################################################\n",
    "# reindex to aeon datetime to be done in the other notebook\n",
    " \n",
    "if VideoData1_Has_Sleap:\n",
    "    # Save  DataFrame as CSV to proper path and filename\n",
    "    save_path1 = save_path / \"Video_Sleap_Data1\" / \"Video_Sleap_Data1_1904-01-01T00-00-00.csv\"\n",
    "    save_path1.parent.mkdir(parents=True, exist_ok=True)\n",
    "    #save_path1.parent.mkdir(parents=True, exist_ok=True)\n",
    "    VideoData1.to_csv(save_path1)\n",
    "\n",
    "if VideoData2_Has_Sleap:\n",
    "    # Save  DataFrame as CSV to proper path and filename\n",
    "    save_path2 = save_path / \"Video_Sleap_Data2\" / \"Video_Sleap_Data2_1904-01-01T00-00-00.csv\"\n",
    "    save_path2.parent.mkdir(parents=True, exist_ok=True)\n",
    "    #save_path2.parent.mkdir(parents=True, exist_ok=True)\n",
    "    VideoData2.to_csv(save_path2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "# Saccade detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fefdc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### smooth and plot position X and velocity data \n",
    "\n",
    "# 1. Preprocess:  smooth\n",
    "df = VideoData1[[\"Ellipse.Center.X\", \"Seconds\"]].copy()\n",
    "\n",
    "df['X_smooth'] = (\n",
    "    df['Ellipse.Center.X']\n",
    "      .rolling(window=5, center=True)\n",
    "      .median()\n",
    "      .bfill()\n",
    "      .ffill()\n",
    ")\n",
    "\n",
    "# 2. Compute instantaneous velocity for both original and smoothed data\n",
    "#   dt in seconds\n",
    "df['dt'] = df['Seconds'].diff()\n",
    "#   Original velocity\n",
    "df['vel_x_original'] = df['Ellipse.Center.X'].diff() / df['dt']\n",
    "#   Smoothed velocity\n",
    "df['vel_x_smooth'] = df['X_smooth'].diff() / df['dt']\n",
    "\n",
    "# --- Plot original and smoothed traces with overlay ---\n",
    "# Create subplots with shared x-axis for synchronized zooming\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    shared_xaxes=True,  # This ensures x-axis zoom synchronization\n",
    "    vertical_spacing=0.1,\n",
    "    subplot_titles=('X Position (px)', 'Velocity (px/s)')\n",
    ")\n",
    "\n",
    "# Add original X position to the first subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df['Seconds'],\n",
    "        y=df['Ellipse.Center.X'],\n",
    "        mode='lines',\n",
    "        name='Original X',\n",
    "        line=dict(color='lightblue', width=2),\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add smoothed X to the first subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df['Seconds'],\n",
    "        y=df['X_smooth'],\n",
    "        mode='lines',\n",
    "        name='Smoothed X',\n",
    "        line=dict(color='blue', width=2)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add original velocity to the second subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df['Seconds'],\n",
    "        y=df['vel_x_original'],\n",
    "        mode='lines',\n",
    "        name='Original Velocity',\n",
    "        line=dict(color='lightcoral', width=2),\n",
    "        opacity=0.8\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add smoothed velocity to the second subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df['Seconds'],\n",
    "        y=df['vel_x_smooth'],\n",
    "        mode='lines',\n",
    "        name='Smoothed Velocity',\n",
    "        line=dict(color='red', width=2)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Original vs Smoothed X Position and Velocity (Synchronized Zoom)',\n",
    "    height=600,  # Adjust height for two subplots\n",
    "    showlegend=True,\n",
    "    legend=dict(x=0.01, y=0.99)\n",
    ")\n",
    "\n",
    "# Update x-axes\n",
    "fig.update_xaxes(title_text=\"Time (s)\", row=2, col=1)\n",
    "\n",
    "# Update y-axes\n",
    "fig.update_yaxes(title_text=\"X Position (px)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Velocity (px/s)\", row=2, col=1)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a95447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SACCADE DETECTION (Adaptive Statistical Method)\n",
    "#-------------------------------------------------------------------------------\n",
    "# This approach uses statistical methods to set adaptive thresholds based on the data itself,\n",
    "# which better captures both large and small saccades\n",
    "\n",
    "# 1. Calculate adaptive thresholds using statistical methods\n",
    "abs_vel = df['vel_x_smooth'].abs().dropna()\n",
    "vel_thresh = abs_vel.mean() + k * abs_vel.std()\n",
    "\n",
    "print(f\"Adaptive velocity threshold: {vel_thresh:.2f} px/s\")\n",
    "print(f\"  (mean: {abs_vel.mean():.2f} px/s, std: {abs_vel.std():.2f} px/s, k={k})\")\n",
    "print(f\"Saccade duration parameter: {onset_offset_fraction} (saccade ends when velocity < {vel_thresh * onset_offset_fraction:.2f} px/s)\")\n",
    "\n",
    "# 2. Find peaks using scipy's find_peaks with adaptive height\n",
    "# Find positive peaks (upward saccades)\n",
    "pos_peaks, pos_properties = find_peaks(\n",
    "    df['vel_x_smooth'],\n",
    "    height=vel_thresh,  # Minimum peak height\n",
    "    distance=int(FPS_1 * refractory_period),  # Minimum distance between peaks (~100ms refractory period)\n",
    "    width=1  # Minimum peak width in samples\n",
    ")\n",
    "\n",
    "# Find negative peaks (downward saccades) by inverting the signal\n",
    "neg_peaks, neg_properties = find_peaks(\n",
    "    -df['vel_x_smooth'],  # Invert to find troughs\n",
    "    height=vel_thresh,  # Same threshold\n",
    "    distance=int(FPS_1 * refractory_period),\n",
    "    width=1\n",
    ")\n",
    "\n",
    "# 3. Extract saccade information\n",
    "upward_saccades = []\n",
    "for peak_idx in pos_peaks:\n",
    "    peak_time = df.iloc[peak_idx]['Seconds']\n",
    "    peak_velocity = df.iloc[peak_idx]['vel_x_smooth']\n",
    "    \n",
    "    # Optional: find onset and offset by going backward/forward until velocity drops below threshold\n",
    "    start_idx = peak_idx\n",
    "    end_idx = peak_idx\n",
    "    \n",
    "    # Find onset (go backward)\n",
    "    while start_idx > 0 and abs(df.iloc[start_idx]['vel_x_smooth']) > vel_thresh * onset_offset_fraction:\n",
    "        start_idx -= 1\n",
    "    \n",
    "    # Find offset (go forward)\n",
    "    while end_idx < len(df) - 1 and abs(df.iloc[end_idx]['vel_x_smooth']) > vel_thresh * onset_offset_fraction:\n",
    "        end_idx += 1\n",
    "    \n",
    "    onset_time = df.iloc[start_idx]['Seconds']\n",
    "    offset_time = df.iloc[end_idx]['Seconds']\n",
    "    \n",
    "    # Calculate amplitude (absolute change in X position)\n",
    "    start_x = df.iloc[start_idx]['X_smooth']\n",
    "    end_x = df.iloc[end_idx]['X_smooth']\n",
    "    amplitude = abs(end_x - start_x)\n",
    "    \n",
    "    upward_saccades.append({\n",
    "        'time': peak_time,\n",
    "        'velocity': peak_velocity,\n",
    "        'start_time': onset_time,\n",
    "        'end_time': offset_time,\n",
    "        'duration': offset_time - onset_time,\n",
    "        'start_position': start_x,\n",
    "        'end_position': end_x,\n",
    "        'amplitude': amplitude\n",
    "    })\n",
    "\n",
    "downward_saccades = []\n",
    "for peak_idx in neg_peaks:\n",
    "    peak_time = df.iloc[peak_idx]['Seconds']\n",
    "    peak_velocity = df.iloc[peak_idx]['vel_x_smooth']\n",
    "    \n",
    "    # Find onset and offset\n",
    "    start_idx = peak_idx\n",
    "    end_idx = peak_idx\n",
    "    \n",
    "    # Find onset\n",
    "    while start_idx > 0 and abs(df.iloc[start_idx]['vel_x_smooth']) > vel_thresh * onset_offset_fraction:\n",
    "        start_idx -= 1\n",
    "    \n",
    "    # Find offset\n",
    "    while end_idx < len(df) - 1 and abs(df.iloc[end_idx]['vel_x_smooth']) > vel_thresh * onset_offset_fraction:\n",
    "        end_idx += 1\n",
    "    \n",
    "    onset_time = df.iloc[start_idx]['Seconds']\n",
    "    offset_time = df.iloc[end_idx]['Seconds']\n",
    "    \n",
    "    # Calculate amplitude (absolute change in X position)\n",
    "    start_x = df.iloc[start_idx]['X_smooth']\n",
    "    end_x = df.iloc[end_idx]['X_smooth']\n",
    "    amplitude = abs(end_x - start_x)\n",
    "    \n",
    "    downward_saccades.append({\n",
    "        'time': peak_time,\n",
    "        'velocity': peak_velocity,\n",
    "        'start_time': onset_time,\n",
    "        'end_time': offset_time,\n",
    "        'duration': offset_time - onset_time,\n",
    "        'start_position': start_x,\n",
    "        'end_position': end_x,\n",
    "        'amplitude': amplitude\n",
    "    })\n",
    "\n",
    "# Convert to DataFrames for easier handling\n",
    "upward_saccades_df = pd.DataFrame(upward_saccades)\n",
    "downward_saccades_df = pd.DataFrame(downward_saccades)\n",
    "\n",
    "print(f\"\\n✅ Detected {len(pos_peaks)} upward saccades\")\n",
    "print(f\"✅ Detected {len(neg_peaks)} downward saccades\")\n",
    "\n",
    "# Print summary statistics\n",
    "if len(upward_saccades) > 0:\n",
    "    print(f\"\\nUpward saccades - mean velocity: {upward_saccades_df['velocity'].mean():.2f} px/s\")\n",
    "    print(f\"Upward saccades - mean duration: {upward_saccades_df['duration'].mean():.3f} s\")\n",
    "    print(f\"Upward saccades - mean amplitude: {upward_saccades_df['amplitude'].mean():.2f} px\")\n",
    "    print(f\"Upward saccades - std amplitude: {upward_saccades_df['amplitude'].std():.2f} px\")\n",
    "\n",
    "if len(downward_saccades) > 0:\n",
    "    print(f\"\\nDownward saccades - mean velocity: {downward_saccades_df['velocity'].mean():.2f} px/s\")\n",
    "    print(f\"Downward saccades - mean duration: {downward_saccades_df['duration'].mean():.3f} s\")\n",
    "    print(f\"Downward saccades - mean amplitude: {downward_saccades_df['amplitude'].mean():.2f} px\")\n",
    "    print(f\"Downward saccades - std amplitude: {downward_saccades_df['amplitude'].std():.2f} px\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d823ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT PERI-SACCADE SEGMENTS\n",
    "#-------------------------------------------------------------------------------\n",
    "# Extract each detected saccade with 10 frames before and 20 frames after the threshold crossing (start_time)\n",
    "# This allows us to visualize saccade profiles and do QC on amplitude detection\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# PARAMETERS: Peri-saccade segment extraction window\n",
    "#-------------------------------------------------------------------------------\n",
    "# NOTE: n_before and n_after are defined in Cell 2 (setup cell)\n",
    "# Parameters are being used from Cell 2: n_before={n_before}, n_after={n_after}\n",
    "# If you need to change these, edit Cell 2, not here\n",
    "\n",
    "\n",
    "# Initialize storage for peri-saccade segments\n",
    "peri_saccades = []\n",
    "\n",
    "def extract_saccade_segment(sacc_df, direction='upward'):\n",
    "    \"\"\"Extract peri-saccade segment for a single saccade\n",
    "    Uses start_time (threshold crossing) as center point: n_before points before, n_after points after\n",
    "    Excludes segments with unreasonable time ranges (validation)\"\"\"\n",
    "    segments = []\n",
    "    excluded_segments = []  # Track excluded segments for reporting\n",
    "    \n",
    "    for idx, sacc in sacc_df.iterrows():\n",
    "        start_time = sacc['start_time']\n",
    "        end_time = sacc['end_time']\n",
    "        peak_time = sacc['time']\n",
    "        amplitude = sacc['amplitude']\n",
    "        \n",
    "        # Find threshold crossing index (start_time)\n",
    "        # Find the closest index to start_time\n",
    "        start_idx = df['Seconds'].sub(start_time).abs().idxmin()\n",
    "        \n",
    "        # Calculate pre/post indices centered on threshold crossing\n",
    "        pre_start = max(0, start_idx - n_before)\n",
    "        post_end = min(len(df) - 1, start_idx + n_after)\n",
    "        \n",
    "        # Extract segment\n",
    "        segment = df.iloc[pre_start:post_end + 1].copy()\n",
    "        \n",
    "        # Normalize time relative to threshold crossing (start_time)\n",
    "        segment['Time_rel_threshold'] = segment['Seconds'] - start_time\n",
    "        \n",
    "        # Validate time range\n",
    "        time_range_min = segment['Time_rel_threshold'].min()\n",
    "        time_range_max = segment['Time_rel_threshold'].max()\n",
    "        \n",
    "        # Calculate expected time span based on n_before + n_after points (110% tolerance)\n",
    "        time_span = time_range_max - time_range_min\n",
    "        if len(segment) > 1:\n",
    "            dt_estimate = time_span / (len(segment) - 1)\n",
    "        else:\n",
    "            dt_estimate = 0.0167  # Default to ~60Hz if segment too short\n",
    "        # Expected total points: n_before (before peak) + 1 (peak itself) + n_after (after peak)\n",
    "        expected_total_points = n_before + 1 + n_after\n",
    "        # Expected time span = (n_points - 1) intervals * dt per interval\n",
    "        expected_time_span = (expected_total_points - 1) * dt_estimate\n",
    "        max_allowed_time_span = expected_time_span * 1.1  # 110% of expected\n",
    "        \n",
    "        # Check if time range is reasonable (110% of expected span) or if point count is wrong\n",
    "        # Allow some flexibility for edge cases where we can't extract full window\n",
    "        is_valid = True\n",
    "        if time_span > max_allowed_time_span:\n",
    "            is_valid = False  # Time span too large (likely data gaps)\n",
    "        elif len(segment) < expected_total_points * 0.9:\n",
    "            is_valid = False  # Too few points (likely truncated at edges or data gaps)\n",
    "        \n",
    "        if not is_valid:\n",
    "            excluded_segments.append({\n",
    "                'saccade_id': idx,\n",
    "                'direction': direction,\n",
    "                'time_range': (time_range_min, time_range_max),\n",
    "                'n_points': len(segment),\n",
    "                'threshold_time': start_time,\n",
    "                'peak_time': peak_time,\n",
    "                'amplitude': amplitude\n",
    "            })\n",
    "            continue  # Skip this segment\n",
    "        \n",
    "        segment['Time_rel_saccade_start'] = segment['Seconds'] - start_time\n",
    "        segment['Time_rel_saccade_end'] = segment['Seconds'] - end_time\n",
    "        \n",
    "        # Add metadata\n",
    "        segment['saccade_id'] = idx\n",
    "        segment['saccade_direction'] = direction\n",
    "        segment['saccade_amplitude'] = amplitude\n",
    "        segment['saccade_peak_velocity'] = sacc['velocity']\n",
    "        segment['saccade_duration'] = sacc['duration']\n",
    "        segment['is_saccade_period'] = (segment['Seconds'] >= start_time) & (segment['Seconds'] <= end_time)\n",
    "        \n",
    "        segments.append(segment)\n",
    "    \n",
    "    return segments, excluded_segments\n",
    "\n",
    "# Extract upward saccades\n",
    "all_excluded = []\n",
    "if len(upward_saccades_df) > 0:\n",
    "    upward_segments, upward_excluded = extract_saccade_segment(upward_saccades_df, direction='upward')\n",
    "    peri_saccades.extend(upward_segments)\n",
    "    all_excluded.extend(upward_excluded)\n",
    "    print(f\"✅ Extracted {len(upward_segments)} upward saccade segments\")\n",
    "    if len(upward_excluded) > 0:\n",
    "        print(f\"   ⚠️  Excluded {len(upward_excluded)} upward segment(s) with unreasonable time ranges\")\n",
    "\n",
    "# Extract downward saccades\n",
    "if len(downward_saccades_df) > 0:\n",
    "    downward_segments, downward_excluded = extract_saccade_segment(downward_saccades_df, direction='downward')\n",
    "    peri_saccades.extend(downward_segments)\n",
    "    all_excluded.extend(downward_excluded)\n",
    "    print(f\"✅ Extracted {len(downward_segments)} downward saccade segments\")\n",
    "    if len(downward_excluded) > 0:\n",
    "        print(f\"   ⚠️  Excluded {len(downward_excluded)} downward segment(s) with unreasonable time ranges\")\n",
    "\n",
    "# Report excluded segments\n",
    "if len(all_excluded) > 0:\n",
    "    print(f\"\\n📋 EXCLUSION REPORT:\")\n",
    "    print(f\"   Total excluded: {len(all_excluded)} segments\")\n",
    "    print(f\"   Reason: Time range exceeds 110% of expected span based on n_before + n_after points最开始\")\n",
    "    print(f\"\\n   Excluded segment details (first 10):\")\n",
    "    for i, exc in enumerate(all_excluded[:10]):\n",
    "        tmin, tmax = exc['time_range']\n",
    "        expected_pts = exc.get('expected_points', '?')\n",
    "        print(f\"   {i+1}. ID {exc['saccade_id']} ({exc['direction']}): time range [{tmin:.3f}, {tmax:.3f}]s, \"\n",
    "              f\"{exc['n_points']} points (expected {expected_pts}), amplitude {exc['amplitude']:.2f} px, peak at {exc['peak_time']:.3f}s\")\n",
    "    if len(all_excluded) > 10:\n",
    "        print(f\"   ... and {len(all_excluded) - 10} more excluded segments\")\n",
    "\n",
    "print(f\"\\n📊 Total peri-saccade segments: {len(peri_saccades)}\")\n",
    "\n",
    "# BASELINE CORRECTION\n",
    "#-------------------------------------------------------------------------------\n",
    "# Baseline each saccade using the average value of data points in the baseline window (relative to threshold crossing)\n",
    "# This removes pre-saccade position offsets and centers all saccades at baseline = 0\n",
    "# Baseline window: from baseline_start to baseline_end (default: -n_before to -(n_before - baseline_n_points))\n",
    "\n",
    "# Baseline window: use the last 5 points before threshold crossing\n",
    "baseline_n_points = 5  # Number of points before threshold crossing to use for baseline\n",
    "baseline_start = -n_before  # Relative to threshold crossing (start of extracted window)\n",
    "baseline_end = -(n_before - baseline_n_points)  # Relative to threshold crossing (baseline_n_points before threshold crossing)\n",
    "\n",
    "for segment in peri_saccades:\n",
    "    # Baseline window: We want to use the last baseline_n_points points before threshold crossing\n",
    "    # The segment structure: [points before threshold crossing (n_before points), threshold crossing, points after threshold crossing (n_after points)]\n",
    "    # Index 0 is the earliest pre-threshold point (Time_rel_threshold = -n_before * dt approximately)\n",
    "    # Index n_before is the threshold crossing (Time_rel_threshold = 0)\n",
    "    # We want the last baseline_n_points points before the threshold crossing\n",
    "    # These are at indices: (n_before - baseline_n_points + 1) to n_before (inclusive)\n",
    "    # But we need to handle edge cases where segment might be truncated\n",
    "    \n",
    "    # Find threshold crossing index in segment (where Time_rel_threshold is closest to 0)\n",
    "    threshold_idx_in_seg = segment['Time_rel_threshold'].abs().idxmin()\n",
    "    threshold_pos_in_seg = segment.index.get_loc(threshold_idx_in_seg)\n",
    "    \n",
    "    # Baseline window: last baseline_n_points points before threshold crossing\n",
    "    baseline_start_idx = max(0, threshold_pos_in_seg - baseline_n_points)\n",
    "    baseline_end_idx = threshold_pos_in_seg  # Up to but not including threshold crossing\n",
    "    \n",
    "    if baseline_end_idx > baseline_start_idx:\n",
    "        # Extract baseline window\n",
    "        baseline_indices = range(baseline_start_idx, baseline_end_idx)\n",
    "        baseline_window_size = len(baseline_indices)\n",
    "        \n",
    "        # Calculate baseline as mean X_smooth in this window\n",
    "        baseline_value = segment.iloc[baseline_indices]['X_smooth'].mean()\n",
    "        \n",
    "        # Subtract baseline from all X_smooth values in the segment\n",
    "        segment['X_smooth_baselined'] = segment['X_smooth'] - baseline_value\n",
    "        segment['baseline_value'] = baseline_value\n",
    "    else:\n",
    "        # If segment is too short, use available early points\n",
    "        if len(segment) > 0:\n",
    "            baseline_value = segment.iloc[:min(baseline_window_size, len(segment))]['X_smooth'].mean()\n",
    "            segment['X_smooth_baselined'] = segment['X_smooth'] - baseline_value\n",
    "            segment['baseline_value'] = baseline_value\n",
    "        else:\n",
    "            # If no points found, use zero baseline\n",
    "            segment['X_smooth_baselined'] = segment['X_smooth']\n",
    "            segment['baseline_value'] = 0.0\n",
    "            print(f\"⚠️  Warning: Saccade {segment['saccade_id'].iloc[0]} has no points for baselining\")\n",
    "\n",
    "print(f\"✅ Baselined all {len(peri_saccades)} saccade segments using points {baseline_start} to {baseline_end} relative to peak\")\n",
    "\n",
    "# Store as a list of dataframes for easy iteration and analysis\n",
    "# Each element in peri_saccades is a dataframe containing one saccade's peri-event window\n",
    "\n",
    "# Optional: Create a concatenated version for batch analysis\n",
    "if len(peri_saccades) > 0:\n",
    "    peri_saccades_df = pd.concat(peri_saccades, ignore_index=True)\n",
    "    print(f\"   Combined dataframe shape: {peri_saccades_df.shape}\")\n",
    "    print(f\"\\n   Columns in segment: {list(peri_saccades_df.columns)}\")\n",
    "    print(f\"   Time range per segment: {n_before} points before peak + {n_after} points after peak\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\n📈 Segment Statistics:\")\n",
    "    print(f\"   Mean samples per segment: {peri_saccades_df.groupby('saccade_id').size().mean():.1f}\")\n",
    "    print(f\"   Total samples: {len(peri_saccades_df)}\")\n",
    "\n",
    "# The peri_saccades list contains individual dataframes for each saccade\n",
    "# Access like: peri_saccades[0] for first saccade, peri_saccades[1] for second, etc.\n",
    "# peri_saccades_df is concatenated version for batch analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE ALL SACCADES - SIDE BY SIDE\n",
    "#-------------------------------------------------------------------------------\n",
    "# Plot all upward and downward saccades aligned by time with position and velocity traces\n",
    "\n",
    "# Create figure with 4 columns in a single row: up pos, up vel, down pos, down vel\n",
    "fig_all = make_subplots(\n",
    "    rows=1, cols=4,\n",
    "    shared_yaxes=False,  # Each panel can have different y-axis scale\n",
    "    shared_xaxes=False,\n",
    "    subplot_titles=(\n",
    "        'Position - Upward Saccades',\n",
    "        'Velocity - Upward Saccades',\n",
    "        'Position - Downward Saccades',\n",
    "        'Velocity - Downward Saccades'\n",
    "    ),\n",
    "    vertical_spacing=0.08,\n",
    "    horizontal_spacing=0.05\n",
    ")\n",
    "\n",
    "# Extract segments for each direction\n",
    "upward_segments_all = [seg for seg in peri_saccades if seg['saccade_direction'].iloc[0] == 'upward']\n",
    "downward_segments_all = [seg for seg in peri_saccades if seg['saccade_direction'].iloc[0] == 'downward']\n",
    "\n",
    "# Remove outlier saccades based on amplitude and extreme position/velocity values\n",
    "def filter_outliers(segments, direction_name):\n",
    "    \"\"\"Filter out outlier segments using IQR method on amplitude and extreme values\"\"\"\n",
    "    if len(segments) == 0:\n",
    "        return [], []\n",
    "    \n",
    "    # Calculate statistics on amplitudes\n",
    "    amplitudes = [seg['saccade_amplitude'].iloc[0] for seg in segments]\n",
    "    q1_amp = np.percentile(amplitudes, 25)\n",
    "    q3_amp = np.percentile(amplitudes, 75)\n",
    "    iqr_amp = q3_amp - q1_amp\n",
    "    lower_bound_amp = q1_amp - 3 * iqr_amp  # Using 3*IQR for more lenient filtering\n",
    "    upper_bound_amp = q3_amp + 3 * iqr_amp\n",
    "    \n",
    "    # Calculate statistics on max absolute position values\n",
    "    max_pos_values = []\n",
    "    max_vel_values = []\n",
    "    for seg in segments:\n",
    "        max_pos_values.append(np.abs(seg['X_smooth_baselined']).max())\n",
    "        max_vel_values.append(np.abs(seg['vel_x_smooth']).max())\n",
    "    \n",
    "    q1_pos = np.percentile(max_pos_values, 25)\n",
    "    q3_pos = np.percentile(max_pos_values, 75)\n",
    "    iqr_pos = q3_pos - q1_pos\n",
    "    upper_bound_pos = q3_pos + 3 * iqr_pos\n",
    "    \n",
    "    q1_vel = np.percentile(max_vel_values, 25)\n",
    "    q3_vel = np.percentile(max_vel_values, 75)\n",
    "    iqr_vel = q3_vel - q1_vel\n",
    "    upper_bound_vel = q3_vel + 3 * iqr_vel\n",
    "    \n",
    "    filtered = []\n",
    "    outliers_metadata = []\n",
    "    outlier_segments = []\n",
    "    \n",
    "    for seg in segments:\n",
    "        amp = seg['saccade_amplitude'].iloc[0]\n",
    "        max_pos = np.abs(seg['X_smooth_baselined']).max()\n",
    "        max_vel = np.abs(seg['vel_x_smooth']).max()\n",
    "        seg_id = seg['saccade_id'].iloc[0]\n",
    "        \n",
    "        # Check if outlier\n",
    "        is_outlier = (amp < lower_bound_amp or amp > upper_bound_amp or\n",
    "                     max_pos > upper_bound_pos or\n",
    "                     max_vel > upper_bound_vel)\n",
    "        \n",
    "        if is_outlier:\n",
    "            outliers_metadata.append({\n",
    "                'saccade_id': seg_id,\n",
    "                'amplitude': amp,\n",
    "                'max_abs_position': max_pos,\n",
    "                'max_abs_velocity': max_vel,\n",
    "                'direction': direction_name\n",
    "            })\n",
    "            outlier_segments.append(seg)  # Keep the segment for plotting\n",
    "        else:\n",
    "            filtered.append(seg)\n",
    "    \n",
    "    return filtered, outliers_metadata, outlier_segments\n",
    "\n",
    "# Filter outliers\n",
    "upward_segments, upward_outliers_meta, upward_outlier_segments = filter_outliers(upward_segments_all, 'upward')\n",
    "downward_segments, downward_outliers_meta, downward_outlier_segments = filter_outliers(downward_segments_all, 'downward')\n",
    "\n",
    "print(f\"Plotting {len(upward_segments)} upward and {len(downward_segments)} downward saccades...\")\n",
    "if len(upward_outliers_meta) > 0 or len(downward_outliers_meta) > 0:\n",
    "    print(f\"\\n⚠️  OUTLIER FILTERING:\")\n",
    "    print(f\"   Excluded {len(upward_outliers_meta)} upward outlier(s) and {len(downward_outliers_meta)} downward outlier(s)\")\n",
    "    print(f\"   Criteria: Amplitude or max position/velocity outside 3×IQR range\")\n",
    "    \n",
    "    if len(upward_outliers_meta) > 0:\n",
    "        print(f\"\\n   Upward outliers (first 5):\")\n",
    "        for i, out in enumerate(upward_outliers_meta[:5]):\n",
    "            print(f\"      ID {out['saccade_id']}: amp={out['amplitude']:.2f}px, max_pos={out['max_abs_position']:.2f}px, max_vel={out['max_abs_velocity']:.2f}px/s\")\n",
    "        if len(upward_outliers_meta) > 5:\n",
    "            print(f\"      ... and {len(upward_outliers_meta) - 5} more\")\n",
    "    \n",
    "    if len(downward_outliers_meta) > 0:\n",
    "        print(f\"\\n   Downward outliers (first 5):\")\n",
    "        for i, out in enumerate(downward_outliers_meta[:5]):\n",
    "            print(f\"      ID {out['saccade_id']}: amp={out['amplitude']:.2f}px, max_pos={out['max_abs_position']:.2f}px, max_vel={out['max_abs_velocity']:.2f}px/s\")\n",
    "        if len(downward_outliers_meta) > 5:\n",
    "            print(f\"      ... and {len(downward_outliers_meta) - 5} more\")\n",
    "\n",
    "# Plot upward saccades\n",
    "for i, segment in enumerate(upward_segments):\n",
    "    color_opacity = 0.15 if len(upward_segments) > 20 else 0.3\n",
    "    \n",
    "    # Position trace (using baselined values)\n",
    "    fig_all.add_trace(\n",
    "        go.Scatter(\n",
    "            x=segment['Time_rel_threshold'],\n",
    "            y=segment['X_smooth_baselined'],\n",
    "            mode='lines',\n",
    "            name=f'Up #{i+1}',\n",
    "            line=dict(color='green', width=1),\n",
    "            showlegend=False,\n",
    "            opacity=color_opacity\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Velocity trace\n",
    "    fig_all.add_trace(\n",
    "        go.Scatter(\n",
    "            x=segment['Time_rel_threshold'],\n",
    "            y=segment['vel_x_smooth'],\n",
    "            mode='lines',\n",
    "            name=f'Up #{i+1}',\n",
    "            line=dict(color='green', width=1),\n",
    "                       showlegend=False,\n",
    "            opacity=color_opacity\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "# Plot downward saccades\n",
    "for i, segment in enumerate(downward_segments):\n",
    "    color_opacity = 0.15 if len(downward_segments) > 20 else 0.3\n",
    "    \n",
    "    # Position trace (using baselined values)\n",
    "    fig_all.add_trace(\n",
    "        go.Scatter(\n",
    "            x=segment['Time_rel_threshold'],\n",
    "            y=segment['X_smooth_baselined'],\n",
    "            mode='lines',\n",
    "            name=f'Down #{i+1}',\n",
    "            line=dict(color='purple', width=1),\n",
    "            showlegend=False,\n",
    "            opacity=color_opacity\n",
    "        ),\n",
    "        row=1, col=3\n",
    "    )\n",
    "    \n",
    "    # Velocity trace\n",
    "    fig_all.add_trace(\n",
    "        go.Scatter(\n",
    "            x=segment['Time_rel_threshold'],\n",
    "            y=segment['vel_x_smooth'],\n",
    "            mode='lines',\n",
    "            name=f'Down #{i+1}',\n",
    "            line=dict(color='purple', width=1),\n",
    "            showlegend=False,\n",
    "            opacity=color_opacity\n",
    "        ),\n",
    "        row=1, col=4\n",
    "    )\n",
    "\n",
    "# Add mean traces for reference\n",
    "if len(upward_segments) > 0:\n",
    "    # Calculate mean for upward by aligning segments by Time_rel_threshold (not by array index)\n",
    "    # Find the threshold crossing index (where Time_rel_threshold ≈ 0) for each segment and align based on that\n",
    "    aligned_positions = []\n",
    "    aligned_velocities = []\n",
    "    aligned_times = []\n",
    "    \n",
    "    for seg in upward_segments:\n",
    "        # Find index where Time_rel_threshold is closest to 0 (the threshold crossing)\n",
    "        threshold_idx = np.abs(seg['Time_rel_threshold'].values).argmin()\n",
    "        \n",
    "        # Extract data centered on threshold crossing: n_before points before, threshold crossing, n_after points after\n",
    "        start_idx = max(0, threshold_idx - n_before)\n",
    "        end_idx = min(len(seg), threshold_idx + n_after + 1)\n",
    "        \n",
    "        # Extract aligned segment\n",
    "        aligned_seg = seg.iloc[start_idx:end_idx].copy()\n",
    "        \n",
    "        # Find where the threshold crossing actually is within the extracted segment\n",
    "        threshold_in_seg_idx = threshold_idx - start_idx\n",
    "        \n",
    "        # Ensure threshold crossing is at index n_before by padding at start if needed\n",
    "        if threshold_in_seg_idx < n_before:\n",
    "            # Need to pad at the start to align threshold crossing to index n_before\n",
    "            pad_length = n_before - threshold_in_seg_idx\n",
    "            # Estimate time step from original segment for padding\n",
    "            if len(seg) > 1:\n",
    "                dt_est = np.diff(seg['Time_rel_threshold'].values).mean()\n",
    "            else:\n",
    "                dt_est = 0.0083  # default estimate if we can't calculate\n",
    "            \n",
    "            # Create padding with NaN values\n",
    "            pad_times = aligned_seg['Time_rel_threshold'].iloc[0] - dt_est * np.arange(pad_length, 0, -1)\n",
    "            pad_df = pd.DataFrame({\n",
    "                'X_smooth_baselined': [np.nan] * pad_length,\n",
    "                'vel_x_smooth': [np.nan] * pad_length,\n",
    "                'Time_rel_threshold': pad_times\n",
    "            })\n",
    "            aligned_seg = pd.concat([pad_df, aligned_seg.reset_index(drop=True)], ignore_index=True)\n",
    "        \n",
    "        aligned_positions.append(aligned_seg['X_smooth_baselined'].values)\n",
    "        aligned_velocities.append(aligned_seg['vel_x_smooth'].values)\n",
    "        aligned_times.append(aligned_seg['Time_rel_threshold'].values)\n",
    "    \n",
    "    # Find minimum length after alignment\n",
    "    min_length = min(len(pos) for pos in aligned_positions)\n",
    "    max_length = max(len(pos) for pos in aligned_positions)\n",
    "    \n",
    "    if min_length != max_length:\n",
    "        print(f\"⚠️  Warning: Upward segments have variable lengths after alignment ({min_length} to {max_length} points). Using minimum length {min_length}.\")\n",
    "    \n",
    "    # Truncate all segments to same length and stack\n",
    "    upward_positions = np.array([pos[:min_length] for pos in aligned_positions])\n",
    "    upward_velocities = np.array([vel[:min_length] for vel in aligned_velocities])\n",
    "    upward_times = aligned_times[0][:min_length]  # Use first segment's time values\n",
    "    \n",
    "    # Calculate mean across all segments (axis=0 means across segments, keeping time dimension)\n",
    "    upward_mean_pos = np.mean(upward_positions, axis=0)\n",
    "    upward_mean_vel = np.mean(upward_velocities, axis=0)\n",
    "    \n",
    "    fig_all.add_trace(\n",
    "        go.Scatter(\n",
    "            x=upward_times,\n",
    "            y=upward_mean_pos,\n",
    "            mode='lines',\n",
    "            name='Mean Up',\n",
    "            line=dict(color='darkgreen', width=3),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    fig_all.add_trace(\n",
    "        go.Scatter(\n",
    "            x=upward_times,\n",
    "            y=upward_mean_vel,\n",
    "            mode='lines',\n",
    "            name='Mean Up Vel',\n",
    "            line=dict(color='darkgreen', width=3),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "\n",
    "if len(downward_segments) > 0:\n",
    "    # Calculate mean for downward by taking mean across all segments at each index position\n",
    "    # Find minimum length to handle variable-length segments\n",
    "    min_length_down = min(len(seg) for seg in downward_segments)\n",
    "    max_length_down = max(len(seg) for seg in downward_segments)\n",
    "    \n",
    "    if min_length_down != max_length_down:\n",
    "        print(f\"⚠️  Warning: Downward segments have variable lengths ({min_length_down} to {max_length_down} points). Using minimum length {min_length_down}.\")\n",
    "    \n",
    "    # Stack all segments as arrays (each row is one saccade, columns are time points)\n",
    "    # Use only first min_length points to ensure all arrays have same shape\n",
    "    downward_positions = np.array([seg['X_smooth_baselined'].values[:min_length_down] for seg in downward_segments])\n",
    "    downward_velocities = np.array([seg['vel_x_smooth'].values[:min_length_down] for seg in downward_segments])\n",
    "    downward_times = downward_segments[0]['Time_rel_threshold'].values[:min_length_down]  # Use first segment's time values\n",
    "    \n",
    "    # Calculate mean across all segments (axis=0 means across segments, keeping time dimension)\n",
    "    downward_mean_pos = np.mean(downward_positions, axis=0)\n",
    "    downward_mean_vel = np.mean(downward_velocities, axis=0)\n",
    "    \n",
    "    fig_all.add_trace(\n",
    "        go.Scatter(\n",
    "            x=downward_times,\n",
    "            y=downward_mean_pos,\n",
    "            mode='lines',\n",
    "            name='Mean Down',\n",
    "            line=dict(color='darkviolet', width=3),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=3\n",
    "    )\n",
    "    \n",
    "    fig_all.add_trace(\n",
    "        go.Scatter(\n",
    "            x=downward_times,\n",
    "            y=downward_mean_vel,\n",
    "            mode='lines',\n",
    "            name='Mean Down Vel',\n",
    "            line=dict(color='darkviolet', width=3),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=4\n",
    "    )\n",
    "\n",
    "# Add vertical line at time=0 (saccade onset)\n",
    "for col in [1, 2, 3, 4]:\n",
    "    fig_all.add_shape(\n",
    "        type=\"line\",\n",
    "        x0=0, x1=0,\n",
    "        y0=-999, y1=999,\n",
    "        line=dict(color='black', width=1, dash='dash'),\n",
    "        row=1, col=col\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig_all.update_layout(\n",
    "    title_text=f'All Detected Saccades Overlaid - Position and Velocity Profiles<br><sub>Position traces are baselined (avg of points -{n_before} to -{n_before-5}). All traces in semi-transparent, mean in bold. Time=0 is threshold crossing. {n_before} points before, {n_after} after.</sub>',\n",
    "    height=500,\n",
    "    width=1600,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Calculate x-axis limits based on actual min/max time values from segments (with small padding)\n",
    "# Y-axis will use auto-range (no explicit range setting)\n",
    "\n",
    "# Collect all time values for proper x-axis scaling\n",
    "all_upward_times = []\n",
    "all_downward_times = []\n",
    "\n",
    "for seg in upward_segments:\n",
    "    all_upward_times.extend(seg['Time_rel_threshold'].values)\n",
    "\n",
    "for seg in downward_segments:\n",
    "    all_downward_times.extend(seg['Time_rel_threshold'].values)\n",
    "\n",
    "# Set x-axis ranges using actual min/max from all segment times (with small padding to show all data)\n",
    "padding_factor = 0.02  # 2% padding on each side for readability\n",
    "if len(all_upward_times) > 0:\n",
    "    up_x_range = np.max(all_upward_times) - np.min(all_upward_times)\n",
    "    padding = up_x_range * padding_factor if up_x_range > 0 else 0.01\n",
    "    up_x_min = np.min(all_upward_times) - padding\n",
    "    up_x_max = np.max(all_upward_times) + padding\n",
    "else:\n",
    "    up_x_min, up_x_max = -0.2, 0.4\n",
    "\n",
    "if len(all_downward_times) > 0:\n",
    "    down_x_range = np.max(all_downward_times) - np.min(all_downward_times)\n",
    "    padding = down_x_range * padding_factor if down_x_range > 0 else 0.01\n",
    "    down_x_min = np.min(all_downward_times) - padding\n",
    "    down_x_max = np.max(all_downward_times) + padding\n",
    "else:\n",
    "    down_x_min, down_x_max = -0.2, 0.4\n",
    "\n",
    "# Calculate y-axis ranges separately for position and velocity from filtered data\n",
    "# Collect position and velocity values from filtered segments\n",
    "upward_pos_values = []\n",
    "downward_pos_values = []\n",
    "upward_vel_values = []\n",
    "downward_vel_values = []\n",
    "\n",
    "for seg in upward_segments:\n",
    "    upward_pos_values.extend(seg['X_smooth_baselined'].values)\n",
    "    # Filter out NaN values when collecting velocity data\n",
    "    vel_values = seg['vel_x_smooth'].values\n",
    "    upward_vel_values.extend(vel_values[~np.isnan(vel_values)])\n",
    "\n",
    "for seg in downward_segments:\n",
    "    downward_pos_values.extend(seg['X_smooth_baselined'].values)\n",
    "    # Filter out NaN values when collecting velocity data\n",
    "    vel_values = seg['vel_x_smooth'].values\n",
    "    downward_vel_values.extend(vel_values[~np.isnan(vel_values)])\n",
    "\n",
    "# Position: find min/max for upward and downward, use wider range for both panels in row 1\n",
    "if len(upward_pos_values) > 0 and len(downward_pos_values) > 0:\n",
    "    up_pos_min = np.min(upward_pos_values)\n",
    "    up_pos_max = np.max(upward_pos_values)\n",
    "    down_pos_min = np.min(downward_pos_values)\n",
    "    down_pos_max = np.max(downward_pos_values)\n",
    "    # Use the wider range (smaller min, larger max)\n",
    "    pos_min = min(up_pos_min, down_pos_min)\n",
    "    pos_max = max(up_pos_max, down_pos_max)\n",
    "elif len(upward_pos_values) > 0:\n",
    "    pos_min = np.min(upward_pos_values)\n",
    "    pos_max = np.max(upward_pos_values)\n",
    "elif len(downward_pos_values) > 0:\n",
    "    pos_min = np.min(downward_pos_values)\n",
    "    pos_max = np.max(downward_pos_values)\n",
    "else:\n",
    "    pos_min, pos_max = -50, 50\n",
    "\n",
    "# Velocity: find min/max for upward and downward, use wider range for both panels in row 2\n",
    "# Get min and max directly from all velocity traces being plotted, with padding to prevent clipping\n",
    "if len(upward_vel_values) > 0 and len(downward_vel_values) > 0:\n",
    "    # Get actual min/max from all velocity values\n",
    "    all_vel_min = min(np.min(upward_vel_values), np.min(downward_vel_values))\n",
    "    all_vel_max = max(np.max(upward_vel_values), np.max(downward_vel_values))\n",
    "\n",
    "elif len(upward_vel_values) > 0:\n",
    "    all_vel_min = np.min(upward_vel_values)\n",
    "    all_vel_max = np.max(upward_vel_values)\n",
    "\n",
    "elif len(downward_vel_values) > 0:\n",
    "    all_vel_min = np.min(downward_vel_values)\n",
    "    all_vel_max = np.max(downward_vel_values)\n",
    "\n",
    "else:\n",
    "    all_vel_min, all_vel_max = -1000, 1000\n",
    "    print(f\"   ⚠️  No velocity values found, using default range: [{all_vel_min:.2f}, {all_vel_max:.2f}] px/s\")\n",
    "\n",
    "# Add padding to prevent clipping (20% padding on each side)\n",
    "vel_range = all_vel_max - all_vel_min\n",
    "if vel_range > 0:\n",
    "    padding = vel_range * 0.20  # 20% padding\n",
    "    vel_min = all_vel_min - padding\n",
    "    vel_max = all_vel_max + padding\n",
    "else:\n",
    "    # If range is zero or very small, use default padding\n",
    "    vel_min = all_vel_min - 1.0\n",
    "    vel_max = all_vel_max + 1.0\n",
    "\n",
    "# Update axes - x-axis with ranges, y-axis with explicit ranges based on filtered data\n",
    "fig_all.update_xaxes(title_text=\"Time relative to threshold crossing (s)\", range=[up_x_min, up_x_max], row=1, col=2)\n",
    "fig_all.update_xaxes(title_text=\"Time relative to threshold crossing (s)\", range=[down_x_min, down_x_max], row=1, col=4)\n",
    "fig_all.update_xaxes(title_text=\"\", range=[up_x_min, up_x_max], row=1, col=1)\n",
    "fig_all.update_xaxes(title_text=\"\", range=[down_x_min, down_x_max], row=1, col=3)\n",
    "\n",
    "# Set explicit y-axis ranges - position panels share same range, velocity panels share same range\n",
    "fig_all.update_yaxes(title_text=\"X Position (px)\", range=[pos_min, pos_max], row=1, col=1)\n",
    "fig_all.update_yaxes(title_text=\"X Position (px)\", range=[pos_min, pos_max], row=1, col=3)\n",
    "fig_all.update_yaxes(title_text=\"Velocity (px/s)\", range=[vel_min, vel_max], row=1, col=2)\n",
    "fig_all.update_yaxes(title_text=\"Velocity (px/s)\", range=[vel_min, vel_max], row=1, col=4)\n",
    "\n",
    "\n",
    "fig_all.show()\n",
    "\n",
    "# Print statistics\n",
    "print(f\"\\n=== OVERLAY SUMMARY ===\")\n",
    "if len(upward_segments) > 0:\n",
    "    up_amps = [seg['saccade_amplitude'].iloc[0] for seg in upward_segments]\n",
    "    up_durs = [seg['saccade_duration'].iloc[0] for seg in upward_segments]\n",
    "    print(f\"Upward saccades: {len(upward_segments)}\")\n",
    "    print(f\"  Mean amplitude: {np.mean(up_amps):.2f} px\")\n",
    "    print(f\"  Mean duration: {np.mean(up_durs):.3f} s\")\n",
    "\n",
    "if len(downward_segments) > 0:\n",
    "    down_amps = [seg['saccade_amplitude'].iloc[0] for seg in downward_segments]\n",
    "    down_durs = [seg['saccade_duration'].iloc[0] for seg in downward_segments]\n",
    "    print(f\"Downward saccades: {len(downward_segments)}\")\n",
    "    print(f\"  Mean amplitude: {np.mean(down_amps):.2f} px\")\n",
    "    print(f\"  Mean duration: {np.mean(down_durs):.3f} s\")\n",
    "\n",
    "print(f\"\\n⏱️  Time alignment: All saccades aligned to threshold crossing (Time_rel_threshold=0)\")\n",
    "if len(all_upward_times) > 0 and len(all_downward_times) > 0:\n",
    "    # Use the wider range for reporting\n",
    "    overall_x_min = min(np.min(all_upward_times), np.min(all_downward_times))\n",
    "    overall_x_max = max(np.max(all_upward_times), np.max(all_downward_times))\n",
    "    print(f\"📏 Window: {n_before} points before + {n_after} points after threshold crossing (actual time range: {overall_x_min:.3f} to {overall_x_max:.3f} s)\")\n",
    "elif len(all_upward_times) > 0:\n",
    "    print(f\"📏 Window: {n_before} points before + {n_after} points after threshold crossing (upward actual time range: {np.min(all_upward_times):.3f} to {np.max(all_upward_times):.3f} s)\")\n",
    "elif len(all_downward_times) > 0:\n",
    "    print(f\"📏 Window: {n_before} points before + {n_after} points after threshold crossing (downward actual time range: {np.min(all_downward_times):.3f} to {np.max(all_downward_times):.3f} s)\")\n",
    "else:\n",
    "    print(f\"📏 Window: {n_before} points before + {n_after} points after threshold crossing\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21afe5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SACCADE AMPLITUDE QC VISUALIZATION\n",
    "#-------------------------------------------------------------------------------\n",
    "# 1. Distribution of saccade amplitudes\n",
    "# 2. Correlation between saccade amplitude and duration\n",
    "# 3. Peri-saccade segments colored by amplitude (outlier detection)\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "fig_qc = make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Amplitude Distribution - Upward Saccades', \n",
    "        'Amplitude Distribution - Downward Saccades',\n",
    "        'Amplitude vs Duration - Upward Saccades',\n",
    "        'Amplitude vs Duration - Downward Saccades',\n",
    "        'Peri-Saccade Segments - Upward (colored by amplitude)',\n",
    "        'Peri-Saccade Segments - Downward (colored by amplitude)'\n",
    "    ),\n",
    "    vertical_spacing=0.10,\n",
    "    horizontal_spacing=0.1,\n",
    "    row_heights=[0.25, 0.25, 0.5]  # Make segment plots larger\n",
    ")\n",
    "\n",
    "# 1. Amplitude distributions\n",
    "if len(upward_saccades_df) > 0:\n",
    "    # Histogram for upward saccades\n",
    "    fig_qc.add_trace(\n",
    "        go.Histogram(\n",
    "            x=upward_saccades_df['amplitude'],\n",
    "            nbinsx=30,\n",
    "            name='Upward',\n",
    "            marker_color='green',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=1\n",
    "    )\n",
    "    \n",
    "    # Scatter plot for upward saccades\n",
    "    fig_qc.add_trace(\n",
    "        go.Scatter(\n",
    "            x=upward_saccades_df['duration'],\n",
    "            y=upward_saccades_df['amplitude'],\n",
    "            mode='markers',\n",
    "            name='Upward',\n",
    "            marker=dict(color='green', size=8, opacity=0.6),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "    \n",
    "    # Add correlation line for upward saccades\n",
    "    corr_up = upward_saccades_df[['amplitude', 'duration']].corr().iloc[0, 1]\n",
    "    z_up = np.polyfit(upward_saccades_df['duration'], upward_saccades_df['amplitude'], 1)\n",
    "    p_up = np.poly1d(z_up)\n",
    "    fig_qc.add_trace(\n",
    "        go.Scatter(\n",
    "            x=upward_saccades_df['duration'],\n",
    "            y=p_up(upward_saccades_df['duration']),\n",
    "            mode='lines',\n",
    "            name=f'R={corr_up:.2f}',\n",
    "            line=dict(color='darkgreen', width=2),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "if len(downward_saccades_df) > 0:\n",
    "    # Histogram for downward saccades\n",
    "    fig_qc.add_trace(\n",
    "        go.Histogram(\n",
    "            x=downward_saccades_df['amplitude'],\n",
    "            nbinsx=30,\n",
    "            name='Downward',\n",
    "            marker_color='purple',\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=2\n",
    "    )\n",
    "    \n",
    "    # Scatter plot for downward saccades\n",
    "    fig_qc.add_trace(\n",
    "        go.Scatter(\n",
    "            x=downward_saccades_df['duration'],\n",
    "            y=downward_saccades_df['amplitude'],\n",
    "            mode='markers',\n",
    "            name='Downward',\n",
    "            marker=dict(color='purple', size=8, opacity=0.6),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "    \n",
    "    # Add correlation line for downward saccades\n",
    "    corr_down = downward_saccades_df[['amplitude', 'duration']].corr().iloc[0, 1]\n",
    "    z_down = np.polyfit(downward_saccades_df['duration'], downward_saccades_df['amplitude'], 1)\n",
    "    p_down = np.poly1d(z_down)\n",
    "    fig_qc.add_trace(\n",
    "        go.Scatter(\n",
    "            x=downward_saccades_df['duration'],\n",
    "            y=p_down(downward_saccades_df['duration']),\n",
    "            mode='lines',\n",
    "            name=f'R={corr_down:.2f}',\n",
    "            line=dict(color='darkviolet', width=2),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=2, col=2\n",
    "    )\n",
    "\n",
    "# 3. Plot peri-saccade segments colored by amplitude\n",
    "# Reuse already-extracted and baselined segments from peri_saccades (no re-extraction or re-baselining)\n",
    "\n",
    "# Extract upward and downward segments for QC visualization from already-baselined peri_saccades\n",
    "# (Removed extract_qc_segments function - segments are now baselined only once during initial extraction)\n",
    "if 'peri_saccades' in globals() and len(peri_saccades) > 0:\n",
    "    upward_segments_all = [seg for seg in peri_saccades if seg['saccade_direction'].iloc[0] == 'upward']\n",
    "    downward_segments_all = [seg for seg in peri_saccades if seg['saccade_direction'].iloc[0] == 'downward']\n",
    "else:\n",
    "    upward_segments_all = []\n",
    "    downward_segments_all = []\n",
    "\n",
    "# Function to extract segments for QC visualization based on threshold crossing (REMOVED - no longer needed)\n",
    "def extract_qc_segments_DEPRECATED(sacc_df, direction='upward', n_points_before=10, n_points_after=10):\n",
    "    \"\"\"Extract peri-saccade segments for QC visualization\n",
    "    Uses start_time (threshold crossing) as center point: n_points_before before, n_points_after after\"\"\"\n",
    "    segments = []\n",
    "    \n",
    "    for idx, sacc in sacc_df.iterrows():\n",
    "        start_time = sacc['start_time']  # Threshold crossing time\n",
    "        amplitude = sacc['amplitude']\n",
    "        \n",
    "        # Find threshold crossing index (start_time)\n",
    "        start_idx = df['Seconds'].sub(start_time).abs().idxmin()\n",
    "        \n",
    "        # Extract -10 to +10 points around threshold crossing\n",
    "        segment_start_idx = max(0, start_idx - n_points_before)\n",
    "        segment_end_idx = min(len(df) - 1, start_idx + n_points_after)\n",
    "        \n",
    "        # Extract segment\n",
    "        segment = df.iloc[segment_start_idx:segment_end_idx + 1].copy()\n",
    "        \n",
    "        # Normalize time relative to threshold crossing (start_time)\n",
    "        segment['Time_rel_threshold'] = segment['Seconds'] - start_time\n",
    "        \n",
    "        # Baseline the segment using points before threshold crossing\n",
    "        # Use the last 5 points before threshold crossing (if available) for baseline\n",
    "        baseline_n_points = 5\n",
    "        threshold_idx_in_segment = np.abs(segment['Time_rel_threshold']).idxmin()\n",
    "        threshold_pos_in_segment = segment.index.get_loc(threshold_idx_in_segment)\n",
    "        \n",
    "        baseline_start_idx = max(0, threshold_pos_in_segment - baseline_n_points)\n",
    "        baseline_end_idx = threshold_pos_in_segment\n",
    "        \n",
    "        if baseline_end_idx > baseline_start_idx and 'X_smooth' in segment.columns:\n",
    "            baseline_value = segment.iloc[baseline_start_idx:baseline_end_idx]['X_smooth'].mean()\n",
    "            segment['X_smooth_baselined'] = segment['X_smooth'] - baseline_value\n",
    "        elif 'X_smooth' in segment.columns:\n",
    "            # If not enough points before threshold, use available early points\n",
    "            if len(segment) > 0:\n",
    "                baseline_value = segment.iloc[:min(baseline_n_points, len(segment))]['X_smooth'].mean()\n",
    "                segment['X_smooth_baselined'] = segment['X_smooth'] - baseline_value\n",
    "            else:\n",
    "                segment['X_smooth_baselined'] = segment['X_smooth']\n",
    "        else:\n",
    "            # If X_smooth doesn't exist, create empty column\n",
    "            segment['X_smooth_baselined'] = np.nan\n",
    "        \n",
    "        # Add metadata\n",
    "        segment['saccade_id'] = idx\n",
    "        segment['saccade_direction'] = direction\n",
    "        segment['saccade_amplitude'] = amplitude\n",
    "        segment['saccade_peak_velocity'] = sacc.get('velocity', np.nan)\n",
    "        segment['saccade_duration'] = sacc.get('duration', np.nan)\n",
    "        \n",
    "        segments.append(segment)\n",
    "    \n",
    "    return segments\n",
    "\n",
    "# Old extraction calls removed - now using peri_saccades directly (see above)\n",
    "\n",
    "# Function to create color mapping for outlier detection\n",
    "def get_color_mapping(amplitudes):\n",
    "    \"\"\"Create color mapping from min to max amplitude\"\"\"\n",
    "    amps = np.array(amplitudes)\n",
    "    min_amp = np.min(amps)\n",
    "    max_amp = np.max(amps)\n",
    "    \n",
    "    # Normalize amplitudes to 0-1 range for colormap\n",
    "    if max_amp > min_amp:\n",
    "        normalized_amps = (amps - min_amp) / (max_amp - min_amp)\n",
    "    else:\n",
    "        normalized_amps = np.zeros_like(amps)\n",
    "    \n",
    "    # Use plasma colormap: lower amplitudes get dark purple/blue, higher amplitudes get bright yellow/magenta\n",
    "    colors = cm.plasma(normalized_amps)\n",
    "    return ['rgb({}, {}, {})'.format(int(r*255), int(g*255), int(b*255)) for r, g, b, _ in colors], min_amp, max_amp\n",
    "\n",
    "\n",
    "# Plot upward segments\n",
    "if len(upward_segments_all) > 0:\n",
    "    upward_amplitudes = [seg['saccade_amplitude'].iloc[0] for seg in upward_segments_all]\n",
    "    upward_colors, upward_min_amp, upward_max_amp = get_color_mapping(upward_amplitudes)\n",
    "    \n",
    "    for i, (segment, color) in enumerate(zip(upward_segments_all, upward_colors)):\n",
    "        fig_qc.add_trace(\n",
    "            go.Scatter(\n",
    "                x=segment['Time_rel_threshold'],\n",
    "                y=segment['X_smooth_baselined'],\n",
    "                mode='lines',\n",
    "                name=f'Up #{i+1}',\n",
    "                line=dict(color=color, width=1.5),\n",
    "                showlegend=False,\n",
    "                opacity=0.7,\n",
    "                hovertemplate=f'Amplitude: {segment[\"saccade_amplitude\"].iloc[0]:.2f} px<br>' +\n",
    "                              'Time: %{x:.3f} s<br>' +\n",
    "                              'Position: %{y:.2f} px<extra></extra>'\n",
    "            ),\n",
    "            row=3, col=1\n",
    "        )\n",
    "    \n",
    "    # Add dummy trace for colorbar (hidden but provides colorbar)\n",
    "    fig_qc.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None],  # Hidden trace\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=1,\n",
    "                color=[upward_min_amp, upward_max_amp],\n",
    "                colorscale='Plasma',\n",
    "                cmin=upward_min_amp,\n",
    "                cmax=upward_max_amp,\n",
    "                showscale=True,\n",
    "                colorbar=dict(\n",
    "                    title=dict(text=\"Amplitude (px)\", side=\"right\"),\n",
    "                    x=0.47,  # Position to the right of the left column plot\n",
    "                    xpad=10,\n",
    "                    len=0.45,  # Set colorbar length relative to subplot\n",
    "                    y=0.5,  # Center vertically on the subplot\n",
    "                    yanchor=\"middle\"\n",
    "                )\n",
    "            ),\n",
    "            showlegend=False,\n",
    "            hoverinfo='skip'\n",
    "        ),\n",
    "        row=3, col=1\n",
    "    )\n",
    "\n",
    "# Plot downward segments\n",
    "if len(downward_segments_all) > 0:\n",
    "    downward_amplitudes = [seg['saccade_amplitude'].iloc[0] for seg in downward_segments_all]\n",
    "    downward_colors, downward_min_amp, downward_max_amp = get_color_mapping(downward_amplitudes)\n",
    "    \n",
    "    for i, (segment, color) in enumerate(zip(downward_segments_all, downward_colors)):\n",
    "        fig_qc.add_trace(\n",
    "            go.Scatter(\n",
    "                x=segment['Time_rel_threshold'],\n",
    "                y=segment['X_smooth_baselined'],\n",
    "                mode='lines',\n",
    "                name=f'Down #{i+1}',\n",
    "                line=dict(color=color, width=1.5),\n",
    "                showlegend=False,\n",
    "                opacity=0.7,\n",
    "                hovertemplate=f'Amplitude: {segment[\"saccade_amplitude\"].iloc[0]:.2f} px<br>' +\n",
    "                              'Time: %{x:.3f} s<br>' +\n",
    "                              'Position: %{y:.2f} px<extra></extra>'\n",
    "            ),\n",
    "            row=3, col=2\n",
    "        )\n",
    "    \n",
    "    # Add dummy trace for colorbar (hidden but provides colorbar)\n",
    "    fig_qc.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None],  # Hidden trace\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=1,\n",
    "                color=[downward_min_amp, downward_max_amp],\n",
    "                colorscale='Plasma',\n",
    "                cmin=downward_min_amp,\n",
    "                cmax=downward_max_amp,\n",
    "                showscale=True,\n",
    "                colorbar=dict(\n",
    "                    title=dict(text=\"Amplitude (px)\", side=\"right\"),\n",
    "                    x=0.97,  # Position to the right of the right column plot\n",
    "                    xpad=10,\n",
    "                    len=0.45,  # Set colorbar length relative to subplot\n",
    "                    y=0.5,  # Center vertically on the subplot\n",
    "                    yanchor=\"middle\"\n",
    "                )\n",
    "            ),\n",
    "            showlegend=False,\n",
    "            hoverinfo='skip'\n",
    "        ),\n",
    "        row=3, col=2\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig_qc.update_layout(\n",
    "    title_text='Saccade Amplitude QC: Distributions, Correlations, and Segments (Outlier Detection)',\n",
    "    height=1200,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "# Update axes labels\n",
    "fig_qc.update_xaxes(title_text=\"Amplitude (px)\", row=1, col=1)\n",
    "fig_qc.update_xaxes(title_text=\"Amplitude (px)\", row=1, col=2)\n",
    "fig_qc.update_xaxes(title_text=\"Duration (s)\", row=2, col=1)\n",
    "fig_qc.update_xaxes(title_text=\"Duration (s)\", row=2, col=2)\n",
    "fig_qc.update_xaxes(title_text=\"Time relative to threshold crossing (s)\", row=3, col=1)\n",
    "fig_qc.update_xaxes(title_text=\"Time relative to threshold crossing (s)\", row=3, col=2)\n",
    "fig_qc.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "fig_qc.update_yaxes(title_text=\"Count\", row=1, col=2)\n",
    "fig_qc.update_yaxes(title_text=\"Amplitude (px)\", row=2, col=1)\n",
    "fig_qc.update_yaxes(title_text=\"Amplitude (px)\", row=2, col=2)\n",
    "fig_qc.update_yaxes(title_text=\"Position (baselined, px)\", row=3, col=1)\n",
    "fig_qc.update_yaxes(title_text=\"Position (baselined, px)\", row=3, col=2)\n",
    "\n",
    "fig_qc.show()\n",
    "\n",
    "# Print correlation statistics\n",
    "print(\"\\n=== SACCADE AMPLITUDE-DURATION CORRELATION ===\\n\")\n",
    "if len(upward_saccades) > 0:\n",
    "    print(f\"Upward saccades (n={len(upward_saccades)}):\")\n",
    "    print(f\"  Correlation (amplitude vs duration): {corr_up:.3f}\")\n",
    "    print(f\"  Mean amplitude: {upward_saccades_df['amplitude'].mean():.2f} px\")\n",
    "    print(f\"  Mean duration: {upward_saccades_df['duration'].mean():.3f} s\")\n",
    "    print(f\"  Amp range: {upward_saccades_df['amplitude'].min():.2f} - {upward_saccades_df['amplitude'].max():.2f} px\")\n",
    "\n",
    "if len(downward_saccades) > 0:\n",
    "    print(f\"\\nDownward saccades (n={len(downward_saccades)}):\")\n",
    "    print(f\"  Correlation (amplitude vs duration): {corr_down:.3f}\")\n",
    "    print(f\"  Mean amplitude: {downward_saccades_df['amplitude'].mean():.2f} px\")\n",
    "    print(f\"  Mean duration: {downward_saccades_df['duration'].mean():.3f} s\")\n",
    "    print(f\"  Amp range: {downward_saccades_df['amplitude'].min():.2f} - {downward_saccades_df['amplitude'].max():.2f} px\")\n",
    "\n",
    "print(\"\\n=== PERI-SACCADE SEGMENT COLOR CODING ===\")\n",
    "print(\"Segment plots use 'plasma' colormap: darker colors (purple/blue) = amplitudes near median,\")\n",
    "print(\"  brighter colors (yellow/magenta) = outliers (far from median IQR)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5335e561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD SACCADE INDICATORS TO VideoData1\n",
    "#-------------------------------------------------------------------------------\n",
    "# Add boolean columns and speed columns to VideoData1 at their respective indices\n",
    "\n",
    "# Initialize columns with False and NaN\n",
    "VideoData1['saccade_up'] = False\n",
    "VideoData1['saccade_down'] = False\n",
    "VideoData1['saccade_speed_up'] = np.nan\n",
    "VideoData1['saccade_speed_down'] = np.nan\n",
    "\n",
    "# Mark upward saccades\n",
    "for idx, row in upward_saccades_df.iterrows():\n",
    "    # Find all indices within the saccade duration\n",
    "    start_time = row['start_time']\n",
    "    end_time = row['end_time']\n",
    "    peak_time = row['time']\n",
    "    peak_velocity = row['velocity']\n",
    "    \n",
    "    # Find the peak index\n",
    "    peak_idx = VideoData1[VideoData1['Seconds'] == peak_time].index\n",
    "    if len(peak_idx) > 0:\n",
    "        peak_idx = peak_idx[0]\n",
    "        # Mark the peak with speed\n",
    "        VideoData1.loc[peak_idx, 'saccade_speed_up'] = peak_velocity\n",
    "    \n",
    "    # Mark all points within the saccade duration\n",
    "    mask = (VideoData1['Seconds'] >= start_time) & (VideoData1['Seconds'] <= end_time)\n",
    "    VideoData1.loc[mask, 'saccade_up'] = True\n",
    "\n",
    "# Mark downward saccades\n",
    "for idx, row in downward_saccades_df.iterrows():\n",
    "    start_time = row['start_time']\n",
    "    end_time = row['end_time']\n",
    "    peak_time = row['time']\n",
    "    peak_velocity = row['velocity']\n",
    "    \n",
    "    # Find the peak index\n",
    "    peak_idx = VideoData1[VideoData1['Seconds'] == peak_time].index\n",
    "    if len(peak_idx) > 0:\n",
    "        peak_idx = peak_idx[0]\n",
    "        # Mark the peak with speed\n",
    "        VideoData1.loc[peak_idx, 'saccade_speed_down'] = peak_velocity\n",
    "    \n",
    "    # Mark all points within the saccade duration\n",
    "    mask = (VideoData1['Seconds'] >= start_time) & (VideoData1['Seconds'] <= end_time)\n",
    "    VideoData1.loc[mask, 'saccade_down'] = True\n",
    "\n",
    "print(f\"✅ Added saccade indicators to VideoData1\")\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"   Upward saccades: {upward_saccades_df.shape[0]} events → {VideoData1['saccade_up'].sum()} timepoints marked\")\n",
    "print(f\"   Downward saccades: {downward_saccades_df.shape[0]} events → {VideoData1['saccade_down'].sum()} timepoints marked\")\n",
    "print(f\"   (Each saccade event spans multiple consecutive timepoints)\")\n",
    "print(f\"\\nSpeed values:\")\n",
    "print(f\"   Upward speeds recorded: {VideoData1['saccade_speed_up'].notna().sum()} (peak velocities only)\")\n",
    "print(f\"   Downward speeds recorded: {VideoData1['saccade_speed_down'].notna().sum()} (peak velocities only)\")\n",
    "\n",
    "# If VideoData2 exists, add saccade indicators to it as well\n",
    "# Note: This assumes the same detection logic would apply to VideoData2\n",
    "# You may want to repeat the detection for VideoData2 if it has separate data\n",
    "if 'VideoData2_Has_Sleap' in globals() and VideoData2_Has_Sleap:\n",
    "    VideoData2['saccade_up'] = False\n",
    "    VideoData2['saccade_down'] = False\n",
    "    VideoData2['saccade_speed_up'] = np.nan\n",
    "    VideoData2['saccade_speed_down'] = np.nan\n",
    "    print(f\"\\n⚠️ Note: VideoData2 saccade columns initialized but empty.\")\n",
    "    print(f\"   To add saccades to VideoData2, run the detection code on VideoData2 data separately.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a42926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE DETECTED SACCADES (Adaptive Method)\n",
    "#-------------------------------------------------------------------------------\n",
    "# Create overlay plot showing detected saccades with duration lines and peak arrows\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=1,\n",
    "    shared_xaxes=True,\n",
    "    vertical_spacing=0.1,\n",
    "    subplot_titles=('X Position (px)', 'Velocity (px/s) with Detected Saccades')\n",
    ")\n",
    "\n",
    "# Add smoothed X position to the first subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df['Seconds'],\n",
    "        y=df['X_smooth'],\n",
    "        mode='lines',\n",
    "        name='Smoothed X',\n",
    "        line=dict(color='blue', width=2)\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Add smoothed velocity to the second subplot\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=df['Seconds'],\n",
    "        y=df['vel_x_smooth'],\n",
    "        mode='lines',\n",
    "        name='Smoothed Velocity',\n",
    "        line=dict(color='red', width=2)\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Add adaptive threshold lines for reference\n",
    "fig.add_hline(\n",
    "    y=vel_thresh,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"green\",\n",
    "    opacity=0.5,\n",
    "    annotation_text=f\"Adaptive threshold (±{vel_thresh:.0f} px/s)\",\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "fig.add_hline(\n",
    "    y=-vel_thresh,\n",
    "    line_dash=\"dash\",\n",
    "    line_color=\"green\",\n",
    "    opacity=0.5,\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# Set offset for saccade indicator lines (above the trace for upward, below for downward)\n",
    "vel_max = df['vel_x_smooth'].max()\n",
    "vel_min = df['vel_x_smooth'].min()\n",
    "vel_range = vel_max - vel_min\n",
    "line_offset = vel_range * 0.15  # 15% of velocity range\n",
    "\n",
    "# Plot upward saccades with duration lines and peak arrows\n",
    "if len(upward_saccades_df) > 0:\n",
    "    for idx, row in upward_saccades_df.iterrows():\n",
    "        start_time = row['start_time']\n",
    "        end_time = row['end_time']\n",
    "        peak_time = row['time']\n",
    "        peak_velocity = row['velocity']\n",
    "        \n",
    "        # Draw horizontal line spanning the saccade duration\n",
    "        # Line is positioned above the velocity trace\n",
    "        y_line_pos = vel_max + line_offset\n",
    "        \n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=start_time, y0=y_line_pos,\n",
    "            x1=end_time, y1=y_line_pos,\n",
    "            line=dict(color='green', width=3),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Add arrow annotation at the peak position pointing to the actual peak velocity\n",
    "        # Arrow points from the line to the peak velocity value on the velocity trace\n",
    "        y_arrow_start = y_line_pos\n",
    "        y_arrow_end = peak_velocity\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            x=peak_time,\n",
    "            y=y_arrow_start,\n",
    "            ax=0,\n",
    "            ay=y_arrow_end - y_arrow_start,  # arrow points to peak velocity\n",
    "            arrowhead=2,  # filled arrowhead\n",
    "            arrowsize=2,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor='green',\n",
    "            row=2, col=1,\n",
    "            showarrow=True\n",
    "        )\n",
    "    \n",
    "    # Add legend entry for upward saccades\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            name='Upward Saccades (duration lines)',\n",
    "            marker=dict(symbol='line-ns', size=15, color='green', line=dict(width=3))\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Plot downward saccades with duration lines and peak arrows\n",
    "if len(downward_saccades_df) > 0:\n",
    "    for idx, row in downward_saccades_df.iterrows():\n",
    "        start_time = row['start_time']\n",
    "        end_time = row['end_time']\n",
    "        peak_time = row['time']\n",
    "        peak_velocity = row['velocity']\n",
    "        \n",
    "        # Draw horizontal line spanning the saccade duration\n",
    "        # Line is positioned below the velocity trace\n",
    "        y_line_pos = vel_min - line_offset\n",
    "        \n",
    "        fig.add_shape(\n",
    "            type=\"line\",\n",
    "            x0=start_time, y0=y_line_pos,\n",
    "            x1=end_time, y1=y_line_pos,\n",
    "            line=dict(color='purple', width=3),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Add arrow annotation at the peak position pointing to the actual peak velocity\n",
    "        # Arrow points from the line to the peak velocity value on the velocity trace\n",
    "        y_arrow_start = y_line_pos\n",
    "        y_arrow_end = peak_velocity\n",
    "        \n",
    "        fig.add_annotation(\n",
    "            x=peak_time,\n",
    "            y=y_arrow_start,\n",
    "            ax=0,\n",
    "            ay=y_arrow_end - y_arrow_start,  # arrow points to peak velocity\n",
    "            arrowhead=2,  # filled arrowhead\n",
    "            arrowsize=2,\n",
    "            arrowwidth=2,\n",
    "            arrowcolor='purple',\n",
    "            row=2, col=1,\n",
    "            showarrow=True\n",
    "        )\n",
    "    \n",
    "    # Add legend entry for downward saccades\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[None],\n",
    "            y=[None],\n",
    "            mode='markers',\n",
    "            name='Downward Saccades (duration lines)',\n",
    "            marker=dict(symbol='line-ns', size=15, color='purple', line=dict(width=3))\n",
    "        ),\n",
    "        row=2, col=1\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Detected Saccades: Duration Lines + Peak Arrows (QC Visualization)',\n",
    "    height=600,\n",
    "    showlegend=True,\n",
    "    legend=dict(x=0.01, y=0.99)\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "fig.update_xaxes(title_text=\"Time (s)\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"X Position (px)\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Velocity (px/s)\", row=2, col=1)\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e47802",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
