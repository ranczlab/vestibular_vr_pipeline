{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97a3eb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Safe Jupyter startup on Linux only\n",
    "import os, sys\n",
    "\n",
    "if sys.platform.startswith(\"linux\"):\n",
    "    os.environ.setdefault(\"MPLBACKEND\", \"Agg\")        # avoids Qt/OpenGL issues\n",
    "    os.environ.setdefault(\"QT_QPA_PLATFORM\", \"offscreen\")\n",
    "    #os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")     # tames OpenMP storms\n",
    "    os.environ.setdefault(\"KMP_DUPLICATE_LIB_OK\", \"TRUE\")\n",
    "    #os.environ.setdefault(\"CUDA_VISIBLE_DEVICES\", \"\") # comment out if you WANT GPU\n",
    "else:\n",
    "    # macOS/Windows: leave defaults; optionally keep OMP cap\n",
    "    #os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13d9774",
   "metadata": {},
   "source": [
    "## Setup - NOTEBOOK FROZEN UNTIL POST SfN, only reporen if stricktly necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd99fbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import gc\n",
    "import io\n",
    "\n",
    "from scipy.stats import linregress\n",
    "from scipy.signal import butter, filtfilt\n",
    "from scipy.signal import correlate\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from harp_resources import process\n",
    "import aeon.io.api as api\n",
    "from sleap import load_and_process as lp\n",
    "from sleap import processing_functions as pf\n",
    "from sleap import saccade_processing as sp\n",
    "from sleap.saccade_processing import analyze_eye_video_saccades\n",
    "from sleap.visualization import plot_all_saccades_overlay, plot_saccade_amplitude_qc\n",
    "from sleap.annotation_gui import launch_annotation_gui\n",
    "from sleap.ml_feature_extraction import extract_experiment_id\n",
    "from sleap.annotation_storage import load_annotations, print_annotation_stats\n",
    "from sleap.visualization import visualize_ml_features\n",
    "from sleap.ml_feature_extraction import extract_ml_features\n",
    "\n",
    "# Reload modules to pick up latest changes (useful after code updates)\n",
    "# Set force_reload_modules = True to always reload, or False to use cached\n",
    "# versions\n",
    "# Set to False for faster execution when modules haven't changed\n",
    "force_reload_modules = False\n",
    "if force_reload_modules:\n",
    "    import importlib\n",
    "    import sleap.load_and_process\n",
    "    import sleap.processing_functions\n",
    "    import sleap.saccade_processing\n",
    "    import sleap.visualization\n",
    "    import sleap.annotation_gui\n",
    "    import sleap.ml_feature_extraction\n",
    "    import sleap.annotation_storage\n",
    "\n",
    "    importlib.reload(sleap.load_and_process)\n",
    "    importlib.reload(sleap.processing_functions)\n",
    "    importlib.reload(sleap.saccade_processing)\n",
    "    importlib.reload(sleap.visualization)\n",
    "    importlib.reload(sleap.annotation_gui)\n",
    "    importlib.reload(sleap.ml_feature_extraction)\n",
    "    importlib.reload(sleap.annotation_storage)\n",
    "    # Re-import aliases after reload\n",
    "    lp = sleap.load_and_process\n",
    "    pf = sleap.processing_functions\n",
    "    sp = sleap.saccade_processing\n",
    "    from sleap.saccade_processing import analyze_eye_video_saccades\n",
    "    from sleap.visualization import plot_all_saccades_overlay, plot_saccade_amplitude_qc\n",
    "    from sleap.annotation_gui import launch_annotation_gui\n",
    "    from sleap.ml_feature_extraction import extract_experiment_id\n",
    "    from sleap.annotation_storage import load_annotations, print_annotation_stats\n",
    "\n",
    "\n",
    "def get_eye_label(key):\n",
    "    \"\"\"Return mapped user-viewable eye label for video key.\"\"\"\n",
    "    return VIDEO_LABELS.get(key, key)\n",
    "\n",
    "\n",
    "# Column prefixes that indicate SLEAP-derived eye-tracking data\n",
    "_SLEAP_EYE_PREFIXES = (\n",
    "    \"left\",\n",
    "    \"right\",\n",
    "    \"center\",\n",
    "    \"p1\",\n",
    "    \"p2\",\n",
    "    \"p3\",\n",
    "    \"p4\",\n",
    "    \"p5\",\n",
    "    \"p6\",\n",
    "    \"p7\",\n",
    "    \"p8\",\n",
    "    \"Ellipse\",\n",
    ")\n",
    "\n",
    "RESAMPLED_DROP_COLUMNS = [\n",
    "    \"pre_saccade_mean_velocity\",\n",
    "    \"pre_saccade_position_drift\",\n",
    "    \"post_saccade_position_variance\",\n",
    "    \"post_saccade_position_change\",\n",
    "    \"saccade_start_position\",\n",
    "    \"saccade_end_position\",\n",
    "    \"Ellipse.Angle\",\n",
    "    \"Ellipse.Diameter\",\n",
    "    \"instance.score\",\n",
    "    \"left.x\",\n",
    "    \"left.y\",\n",
    "    \"left.score\",\n",
    "    \"right.x\",\n",
    "    \"right.y\",\n",
    "    \"right.score\",\n",
    "    \"p1.x\",\n",
    "    \"p1.y\",\n",
    "    \"p1.score\",\n",
    "    \"p2.x\",\n",
    "    \"p2.y\",\n",
    "    \"p2.score\",\n",
    "    \"p3.x\",\n",
    "    \"p3.y\",\n",
    "    \"p3.score\",\n",
    "    \"p4.x\",\n",
    "    \"p4.y\",\n",
    "    \"p4.score\",\n",
    "    \"p5.x\",\n",
    "    \"p5.y\",\n",
    "    \"p5.score\",\n",
    "    \"p6.x\",\n",
    "    \"p6.y\",\n",
    "    \"p6.score\",\n",
    "    \"p7.x\",\n",
    "    \"p7.y\",\n",
    "    \"p7.score\",\n",
    "    \"p8.x\",\n",
    "    \"p8.y\",\n",
    "    \"p8.score\",\n",
    "    \"center.x\",\n",
    "    \"center.y\",\n",
    "    \"center.score\",\n",
    "]\n",
    "\n",
    "SACCADE_EXPORT_DROP_COLUMNS = {\n",
    "    \"saccade_id\",\n",
    "    \"video_key\",\n",
    "    \"eye\",\n",
    "    \"direction\",\n",
    "    \"direction_label\",\n",
    "    \"saccade_start_time\",\n",
    "    \"saccade_end_time\",\n",
    "    \"saccade_peak_time\",\n",
    "    \"saccade_start_frame_idx\",\n",
    "    \"saccade_peak_frame_idx\",\n",
    "    \"saccade_end_frame_idx\",\n",
    "    \"saccade_peak_velocity\",\n",
    "    \"saccade_amplitude\",\n",
    "    \"saccade_displacement\",\n",
    "    \"saccade_duration\",\n",
    "    \"saccade_start_position\",\n",
    "    \"saccade_end_position\",\n",
    "    \"saccade_type\",\n",
    "    \"bout_id\",\n",
    "    \"bout_size\",\n",
    "    \"pre_saccade_mean_velocity\",\n",
    "    \"pre_saccade_position_drift\",\n",
    "    \"post_saccade_position_variance\",\n",
    "    \"post_saccade_position_change\",\n",
    "    \"classification_confidence\",\n",
    "    \"rule_based_class\",\n",
    "    \"rule_based_confidence\",\n",
    "    \"merge_frame_idx\",\n",
    "}\n",
    "\n",
    "def _needs_eye_suffix(column: str) -> bool:\n",
    "    \"\"\"Return True if the column should be tagged as eye data during resampling.\"\"\"\n",
    "    return any(column.startswith(prefix) for prefix in _SLEAP_EYE_PREFIXES)\n",
    "\n",
    "\n",
    "def resample_video_dataframe(\n",
    "    video_df: pd.DataFrame,\n",
    "    eye_tag: str,\n",
    "    target_freq_hz: float = None,\n",
    "    optical_filter_hz: float = None,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Resample a SLEAP video dataframe onto the common time grid.\"\"\"\n",
    "    if \"Seconds\" not in video_df.columns:\n",
    "        raise ValueError(\"Video dataframe must contain a 'Seconds' column before resampling.\")\n",
    "\n",
    "    target_freq_hz = target_freq_hz or COMMON_RESAMPLED_RATE\n",
    "    df_for_resample = video_df.copy()\n",
    "\n",
    "    # Rename SLEAP-specific columns so the resampler treats them as eye data\n",
    "    rename_map = {\n",
    "        col: f\"{col}_{eye_tag}\"\n",
    "        for col in df_for_resample.columns\n",
    "        if col not in {\"Seconds\", \"frame_idx\"} and _needs_eye_suffix(col)\n",
    "    }\n",
    "    df_for_resample = df_for_resample.rename(columns=rename_map)\n",
    "\n",
    "    # Convert Seconds to aeon datetime index and drop Seconds before resampling\n",
    "    df_for_resample.index = pd.to_datetime(df_for_resample[\"Seconds\"].apply(api.aeon))\n",
    "    df_for_resample = df_for_resample.drop(columns=[\"Seconds\"])\n",
    "\n",
    "    resampled = process.resample_dataframe(\n",
    "        df_for_resample,\n",
    "        target_freq_Hz=target_freq_hz,\n",
    "        optical_filter_Hz=optical_filter_hz,\n",
    "    )\n",
    "\n",
    "    # Restore original column names\n",
    "    inverse_map = {v: k for k, v in rename_map.items()}\n",
    "    resampled = resampled.rename(columns=inverse_map)\n",
    "\n",
    "    # Convert index back to Seconds\n",
    "    resampled_seconds = (resampled.index - datetime(1904, 1, 1)).total_seconds()\n",
    "    resampled = resampled.reset_index(drop=True)\n",
    "    resampled.insert(0, \"Seconds\", resampled_seconds)\n",
    "\n",
    "    # Frame indices should remain integers if present\n",
    "    if \"frame_idx\" in resampled.columns:\n",
    "        resampled[\"frame_idx\"] = (\n",
    "            pd.to_numeric(resampled[\"frame_idx\"], errors=\"coerce\").round().astype(\"Int64\")\n",
    "        )\n",
    "\n",
    "    return resampled\n",
    "\n",
    "\n",
    "def set_aeon_index(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a copy of the dataframe with a DatetimeIndex derived from Seconds.\"\"\"\n",
    "    df_indexed = df.copy()\n",
    "    df_indexed.index = pd.to_datetime(df_indexed[\"Seconds\"].apply(api.aeon))\n",
    "    df_indexed.index.name = \"aeon_time\"\n",
    "    return df_indexed\n",
    "\n",
    "\n",
    "def append_aeon_time_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Return a copy of the dataframe with an additional aeon_time ISO timestamp column.\"\"\"\n",
    "    df_with_time = df.copy()\n",
    "    if isinstance(df_with_time.index, pd.DatetimeIndex):\n",
    "        df_with_time[\"aeon_time\"] = df_with_time.index.map(lambda ts: ts.isoformat())\n",
    "    else:\n",
    "        df_with_time[\"aeon_time\"] = df_with_time[\"Seconds\"].apply(lambda x: api.aeon(x).isoformat())\n",
    "    return df_with_time\n",
    "\n",
    "\n",
    "# keep as false here, it is to checking if NaNs already removed if the\n",
    "# notebook cell is rerun\n",
    "NaNs_removed = False\n",
    "\n",
    "# symbols to use ✅ ℹ️ ⚠️ ❗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdf72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up variables and load data\n",
    "##########################################################################\n",
    "\n",
    "data_path = Path(\n",
    "    \"/home/ikharitonov/RANCZLAB-NAS/data/ONIX/20241125_Cohort1_rotation/Visual_mismatch_day3/B6J2717-2024-12-10T12-17-03\"\n",
    ")\n",
    "# data_path =\n",
    "# Path('/Users/rancze/Documents/Data/vestVR/Cohort1/No_iso_correction/Visual_mismatch_day3/B6J2717-2024-12-10T12-17-03') only has sleap data 1 for testing purposes\n",
    "\n",
    "### MOST commonly changed params for tuning\n",
    "video1_eye = \"L\" # Options: 'L' or 'R'; which eye does VideoData1 represent? ('L' = Left,'R' = Right)\n",
    "debug = True # Set to True to enable debug output and QC plots across all cells (file loading, processing, etc.)\n",
    "plot_QC_timeseries = True # plots pop up in new windows, code hangs until plot window is closed - issue for batch processing, but shouldn't be used there anyway \n",
    "plot_saccade_detection_QC = False # plots pop up in new windows, code hangs until plot window is closed - issue for batch processing, but shouldn't be used there anyway \n",
    "blink_instance_score_threshold = 3.8 # hard threshold for blink detection - frames with instance.score below this value are considered blinks\n",
    "k1 = 4.5  # adaptive saccade detction threshold (k * SD) for VideoData1 - 3-6 works well\n",
    "k2 = 4.5  # adaptive saccade detction threshold (k * SD) for VideoData1 - 3-6 works well\n",
    "refractory_period = 0.1  # seconds, refractory period for saccade detection\n",
    "bout_window = 1.5  # Time window (seconds) for grouping saccades into bouts\n",
    "\n",
    "### SLEAP raw data filtering \n",
    "score_cutoff = 0.2 # for filtering out inferred points with low confidence, they get interpolated\n",
    "outlier_sd_threshold = 10  # for removing outliers from the data, they get interpolated\n",
    "\n",
    "pupil_filter_cutoff_hz = 10  # Hz, Pupil diameter filter settings (Butterworth low-pass)\n",
    "pupil_filter_order = 6\n",
    "\n",
    "### Parameters for blink detection\n",
    "min_blink_duration_ms = 50  # minimum blink duration in milliseconds\n",
    "blink_merge_window_ms = 100 # NOT CURRENTLY USED: merge window was removed to preserve good data between separate blinks\n",
    "long_blink_warning_ms = 2000 # warn if blinks exceed this duration (in ms) - user should verify these are real blinks\n",
    "\n",
    "### params for for saccade detection and classification \n",
    "onset_offset_fraction = 0.2 # to determine saccade onset and offset, i.e. 0.2 is 20% of the peak velocity\n",
    "\n",
    "# Saccade detection parameters (time-based for FPS independence)\n",
    "\n",
    "pre_saccade_window_time = 0.15 # Time (seconds) before threshold crossing to extract peri-saccade segment\n",
    "post_saccade_window_time = 0.5\n",
    "\n",
    "baseline_window_start_time = -0.06 # Start time (seconds) relative to threshold crossing for baseline window (e.g., -0.1 = 100ms before)\n",
    "baseline_window_end_time = -0.02 # End time (seconds) relative to threshold crossing for baseline window (e.g., -0.02 = 20ms before)\n",
    "smoothing_window_time = 0.08 # Time (seconds) for position smoothing window (rolling median)\n",
    "peak_width_time = 0.005 # Minimum peak width (seconds) for find_peaks - typically 5-20ms for saccades\n",
    "min_saccade_duration = 0.2 # Minimum saccade segment duration (seconds) - segments shorter than this are excluded (typically truncated at recording edges)\n",
    "\n",
    "# Parameters for orienting vs compensatory saccade classification\n",
    "classify_orienting_compensatory = True # this is the rule-based, not ML based, we generally use it \n",
    "pre_saccade_window = 0.3 # Time window (seconds) before saccade onset to analyze\n",
    "max_intersaccade_interval_for_classification = 1.0 # Maximum time (seconds) to extend post-saccade window until next saccade for classification for feature extraction\n",
    "pre_saccade_velocity_threshold = 50.0 # Velocity threshold (px/s) for detecting pre-saccade drift for feature extraction\n",
    "pre_saccade_drift_threshold = 10.0 # Position drift threshold (px) before saccade for compensatory classification for feature extraction\n",
    "post_saccade_variance_threshold = 100.0 # Position variance threshold (px²) after saccade for orienting classification for feature extraction\n",
    "post_saccade_position_change_threshold_percent = 50.0 # Position change threshold (% of saccade amplitude) - if post-saccade change > amplitude * this%, classify as compensatory for feature extraction\n",
    "\n",
    "# Adaptive threshold parameters (percentile-based) for \n",
    "# Set to True to use adaptive thresholds based on feature distributions, False to use fixed thresholds\n",
    "use_adaptive_thresholds = True\n",
    "adaptive_percentile_pre_velocity = 75 # Percentile for pre-saccade velocity threshold (upper percentile for compensatory detection)\n",
    "adaptive_percentile_pre_drift = 75 # Percentile for pre-saccade drift threshold (upper percentile for compensatory detection)\n",
    "adaptive_percentile_post_variance = 25 # Percentile for post-saccade variance threshold (lower percentile for orienting detection - low variance = stable)\n",
    "\n",
    "COMMON_RESAMPLED_RATE = 1000 # Common resampling rate (Hz) used for alignment with other modalities, like photometry, HARP streams, etc. \n",
    "\n",
    "\n",
    "\n",
    "# Automatically assign eye for VideoData2\n",
    "video2_eye = \"R\" if video1_eye == \"L\" else \"L\"\n",
    "eye_fullname = {\"L\": \"Left\", \"R\": \"Right\"} # Map for full names (used in labels)\n",
    "VIDEO_LABELS = { # Update VIDEO_LABELS based on selection\n",
    "    \"VideoData1\": f\"VideoData1 ({video1_eye}: {eye_fullname[video1_eye]})\",\n",
    "    \"VideoData2\": f\"VideoData2 ({video2_eye}: {eye_fullname[video2_eye]})\",\n",
    "}\n",
    "\n",
    "save_path = data_path.parent / f\"{data_path.name}_processedData\"\n",
    "qc_debug_dir = save_path / \"QC_and_debug\"\n",
    "qc_debug_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "VideoData1, VideoData2, VideoData1_Has_Sleap, VideoData2_Has_Sleap = (\n",
    "    lp.load_videography_data(data_path, debug=debug)\n",
    ")\n",
    "\n",
    "# Load manual blink data if available\n",
    "manual_blinks_v1 = pf.load_manual_blinks(data_path, video_number=1)\n",
    "manual_blinks_v2 = pf.load_manual_blinks(data_path, video_number=2)\n",
    "\n",
    "columns_of_interest = [\n",
    "    \"left.x\",\n",
    "    \"left.y\",\n",
    "    \"center.x\",\n",
    "    \"center.y\",\n",
    "    \"right.x\",\n",
    "    \"right.y\",\n",
    "    \"p1.x\",\n",
    "    \"p1.y\",\n",
    "    \"p2.x\",\n",
    "    \"p2.y\",\n",
    "    \"p3.x\",\n",
    "    \"p3.y\",\n",
    "    \"p4.x\",\n",
    "    \"p4.y\",\n",
    "    \"p5.x\",\n",
    "    \"p5.y\",\n",
    "    \"p6.x\",\n",
    "    \"p6.y\",\n",
    "    \"p7.x\",\n",
    "    \"p7.y\",\n",
    "    \"p8.x\",\n",
    "    \"p8.y\",\n",
    "]\n",
    "\n",
    "if VideoData1_Has_Sleap:\n",
    "    # drop the track column as it is empty\n",
    "    if \"track\" in VideoData1.columns:\n",
    "        VideoData1 = VideoData1.drop(columns=[\"track\"])\n",
    "    coordinates_dict1_raw = lp.get_coordinates_dict(VideoData1, columns_of_interest)\n",
    "    # frame rate for VideoData1 TODO where to save it, is it useful?\n",
    "    FPS_1 = 1 / VideoData1[\"Seconds\"].diff().mean()\n",
    "    print()\n",
    "    print(f\"{get_eye_label('VideoData1')}: FPS = {FPS_1}\")\n",
    "\n",
    "if VideoData2_Has_Sleap:\n",
    "    # drop the track column as it is empty\n",
    "    if \"track\" in VideoData2.columns:\n",
    "        VideoData2 = VideoData2.drop(columns=[\"track\"])\n",
    "    coordinates_dict2_raw = lp.get_coordinates_dict(VideoData2, columns_of_interest)\n",
    "    # frame rate for VideoData2\n",
    "    FPS_2 = 1 / VideoData2[\"Seconds\"].diff().mean()\n",
    "    print(f\"{get_eye_label('VideoData2')}: FPS = {FPS_2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a66e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot timeseries of coordinates in browser for both VideoData1 and VideoData2\n",
    "##########################################################################\n",
    "if plot_QC_timeseries:\n",
    "    print(\n",
    "        \"⚠️ Check for long discontinuities and outliers in the data, we will try to deal with them later\"\n",
    "    )\n",
    "    print(\"ℹ️ Figures open in browser window, takes a bit of time.\")\n",
    "\n",
    "    # Helper list variables\n",
    "    subplot_titles = (\n",
    "        \"X coordinates for pupil centre and left-right eye corner\",\n",
    "        \"Y coordinates for pupil centre and left-right eye corner\",\n",
    "        \"X coordinates for iris points\",\n",
    "        \"Y coordinates for iris points\",\n",
    "    )\n",
    "    eye_x = [\"left.x\", \"center.x\", \"right.x\"]\n",
    "    eye_y = [\"left.y\", \"center.y\", \"right.y\"]\n",
    "    iris_x = [\"p1.x\", \"p2.x\", \"p3.x\", \"p4.x\", \"p5.x\", \"p6.x\", \"p7.x\", \"p8.x\"]\n",
    "    iris_y = [\"p1.y\", \"p2.y\", \"p3.y\", \"p4.y\", \"p5.y\", \"p6.y\", \"p7.y\", \"p8.y\"]\n",
    "\n",
    "    # --- VideoData1 ---\n",
    "    if VideoData1_Has_Sleap:\n",
    "        fig1 = make_subplots(\n",
    "            rows=4,\n",
    "            cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=subplot_titles,\n",
    "        )\n",
    "\n",
    "        # Row 1: left.x, center.x, right.x\n",
    "        for col in eye_x:\n",
    "            fig1.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData1[\"Seconds\"], y=VideoData1[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1,\n",
    "            )\n",
    "        # Row 2: left.y, center.y, right.y\n",
    "        for col in eye_y:\n",
    "            fig1.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData1[\"Seconds\"], y=VideoData1[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=2,\n",
    "                col=1,\n",
    "            )\n",
    "        # Row 3: p1.x ... p8.x\n",
    "        for col in iris_x:\n",
    "            fig1.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData1[\"Seconds\"], y=VideoData1[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=3,\n",
    "                col=1,\n",
    "            )\n",
    "        # Row 4: p1.y ... p8.y\n",
    "        for col in iris_y:\n",
    "            fig1.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData1[\"Seconds\"], y=VideoData1[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=4,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        fig1.update_layout(\n",
    "            height=1200,\n",
    "            title_text=f\"Time series subplots for coordinates [{get_eye_label('VideoData1')}]\",\n",
    "            showlegend=True,\n",
    "        )\n",
    "        fig1.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "        fig1.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "        fig1.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "        fig1.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "        fig1.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "        fig1.show(renderer=\"browser\")\n",
    "\n",
    "    # --- VideoData2 ---\n",
    "    if VideoData2_Has_Sleap:\n",
    "        fig2 = make_subplots(\n",
    "            rows=4,\n",
    "            cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=subplot_titles,\n",
    "        )\n",
    "        # Row 1: left.x, center.x, right.x\n",
    "        for col in eye_x:\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData2[\"Seconds\"], y=VideoData2[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1,\n",
    "            )\n",
    "        # Row 2: left.y, center.y, right.y\n",
    "        for col in eye_y:\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData2[\"Seconds\"], y=VideoData2[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=2,\n",
    "                col=1,\n",
    "            )\n",
    "        # Row 3: p1.x ... p8.x\n",
    "        for col in iris_x:\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData2[\"Seconds\"], y=VideoData2[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=3,\n",
    "                col=1,\n",
    "            )\n",
    "        # Row 4: p1.y ... p8.y\n",
    "        for col in iris_y:\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData2[\"Seconds\"], y=VideoData2[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=4,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        fig2.update_layout(\n",
    "            height=1200,\n",
    "            title_text=f\"Time series subplots for coordinates [{get_eye_label('VideoData2')}]\",\n",
    "            showlegend=True,\n",
    "        )\n",
    "        fig2.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "        fig2.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "        fig2.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "        fig2.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "        fig2.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "        fig2.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b774a549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC plot XY coordinate distributions to visualize outliers\n",
    "##########################################################################\n",
    "columns_of_interest = [\n",
    "    \"left\",\n",
    "    \"right\",\n",
    "    \"center\",\n",
    "    \"p1\",\n",
    "    \"p2\",\n",
    "    \"p3\",\n",
    "    \"p4\",\n",
    "    \"p5\",\n",
    "    \"p6\",\n",
    "    \"p7\",\n",
    "    \"p8\",\n",
    "]\n",
    "\n",
    "# Filter out NaN values and calculate the min and max values for X and Y\n",
    "# coordinates for both dict1 and dict2\n",
    "\n",
    "def min_max_dict(coordinates_dict):\n",
    "    x_min = min(\n",
    "        [\n",
    "            coordinates_dict[f\"{col}.x\"][\n",
    "                ~np.isnan(coordinates_dict[f\"{col}.x\"])\n",
    "            ].min()\n",
    "            for col in columns_of_interest\n",
    "        ]\n",
    "    )\n",
    "    x_max = max(\n",
    "        [\n",
    "            coordinates_dict[f\"{col}.x\"][\n",
    "                ~np.isnan(coordinates_dict[f\"{col}.x\"])\n",
    "            ].max()\n",
    "            for col in columns_of_interest\n",
    "        ]\n",
    "    )\n",
    "    y_min = min(\n",
    "        [\n",
    "            coordinates_dict[f\"{col}.y\"][\n",
    "                ~np.isnan(coordinates_dict[f\"{col}.y\"])\n",
    "            ].min()\n",
    "            for col in columns_of_interest\n",
    "        ]\n",
    "    )\n",
    "    y_max = max(\n",
    "        [\n",
    "            coordinates_dict[f\"{col}.y\"][\n",
    "                ~np.isnan(coordinates_dict[f\"{col}.y\"])\n",
    "            ].max()\n",
    "            for col in columns_of_interest\n",
    "        ]\n",
    "    )\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "# PLOT QC plot XY coordinate distributions to visualize outliers\n",
    "##########################################################################\n",
    "if plot_QC_timeseries:\n",
    "    # Compute min/max as before for global axes limits\n",
    "    if VideoData1_Has_Sleap:\n",
    "        x_min1, x_max1, y_min1, y_max1 = pf.min_max_dict(\n",
    "            coordinates_dict1_raw, columns_of_interest\n",
    "        )\n",
    "\n",
    "    if VideoData2_Has_Sleap:\n",
    "        x_min2, x_max2, y_min2, y_max2 = pf.min_max_dict(\n",
    "            coordinates_dict2_raw, columns_of_interest\n",
    "        )\n",
    "\n",
    "    # Use global min and max for consistency only if both VideoData1_Has_Sleap\n",
    "    # and VideoData2_Has_Sleap are True\n",
    "    if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "        x_min = min(x_min1, x_min2)\n",
    "        x_max = max(x_max1, x_max2)\n",
    "        y_min = min(y_min1, y_min2)\n",
    "        y_max = max(y_max1, y_max2)\n",
    "    elif VideoData1_Has_Sleap:\n",
    "        x_min, x_max, y_min, y_max = x_min1, x_max1, y_min1, y_max1\n",
    "    elif VideoData2_Has_Sleap:\n",
    "        x_min, x_max, y_min, y_max = x_min2, x_max2, y_min2, y_max2\n",
    "    else:\n",
    "        raise ValueError(\"Neither VideoData1 nor VideoData2 has Sleap data available.\")\n",
    "\n",
    "    # Create the figure and axes\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"XY coordinate distribution of different points for {get_eye_label('VideoData1')} and {get_eye_label('VideoData2')} before outlier removal and NaN interpolation\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    # Define colormap for p1-p8\n",
    "\n",
    "    colors = [\"blue\", \"green\", \"red\", \"cyan\", \"magenta\", \"yellow\", \"black\", \"orange\"]\n",
    "\n",
    "    # Panel 1: left, right, center (dict1)\n",
    "\n",
    "    if \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "        ax[0, 0].set_title(f\"{get_eye_label('VideoData1')}: left, right, center\")\n",
    "        ax[0, 0].scatter(\n",
    "            coordinates_dict1_raw[\"left.x\"],\n",
    "            coordinates_dict1_raw[\"left.y\"],\n",
    "            color=\"black\",\n",
    "            label=\"left\",\n",
    "            s=10,\n",
    "        )\n",
    "        ax[0, 0].scatter(\n",
    "            coordinates_dict1_raw[\"right.x\"],\n",
    "            coordinates_dict1_raw[\"right.y\"],\n",
    "            color=\"grey\",\n",
    "            label=\"right\",\n",
    "            s=10,\n",
    "        )\n",
    "        ax[0, 0].scatter(\n",
    "            coordinates_dict1_raw[\"center.x\"],\n",
    "            coordinates_dict1_raw[\"center.y\"],\n",
    "            color=\"red\",\n",
    "            label=\"center\",\n",
    "            s=10,\n",
    "        )\n",
    "        ax[0, 0].set_xlim([x_min, x_max])\n",
    "        ax[0, 0].set_ylim([y_min, y_max])\n",
    "        ax[0, 0].set_xlabel(\"x coordinates (pixels)\")\n",
    "        ax[0, 0].set_ylabel(\"y coordinates (pixels)\")\n",
    "        ax[0, 0].legend(loc=\"upper right\")\n",
    "    else:\n",
    "        ax[0, 0].axis(\"off\")\n",
    "\n",
    "    # Panel 2: p1 to p8 (dict1)\n",
    "\n",
    "    if \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "        ax[0, 1].set_title(f\"{get_eye_label('VideoData1')}: p1 to p8\")\n",
    "        for idx, col in enumerate(columns_of_interest[3:]):\n",
    "            ax[0, 1].scatter(\n",
    "                coordinates_dict1_raw[f\"{col}.x\"],\n",
    "                coordinates_dict1_raw[f\"{col}.y\"],\n",
    "                color=colors[idx],\n",
    "                label=col,\n",
    "                s=5,\n",
    "            )\n",
    "\n",
    "        ax[0, 1].set_xlim([x_min, x_max])\n",
    "        ax[0, 1].set_ylim([y_min, y_max])\n",
    "        ax[0, 1].set_xlabel(\"x coordinates (pixels)\")\n",
    "        ax[0, 1].set_ylabel(\"y coordinates (pixels)\")\n",
    "        ax[0, 1].legend(loc=\"upper right\")\n",
    "    else:\n",
    "        ax[0, 1].axis(\"off\")\n",
    "\n",
    "    # Panel 3: left, right, center (dict2)\n",
    "\n",
    "    if \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "        ax[1, 0].set_title(f\"{get_eye_label('VideoData2')}: left, right, center\")\n",
    "        ax[1, 0].scatter(\n",
    "            coordinates_dict2_raw[\"left.x\"],\n",
    "            coordinates_dict2_raw[\"left.y\"],\n",
    "            color=\"black\",\n",
    "            label=\"left\",\n",
    "            s=10,\n",
    "        )\n",
    "        ax[1, 0].scatter(\n",
    "            coordinates_dict2_raw[\"right.x\"],\n",
    "            coordinates_dict2_raw[\"right.y\"],\n",
    "            color=\"grey\",\n",
    "            label=\"right\",\n",
    "            s=10,\n",
    "        )\n",
    "        ax[1, 0].scatter(\n",
    "            coordinates_dict2_raw[\"center.x\"],\n",
    "            coordinates_dict2_raw[\"center.y\"],\n",
    "            color=\"red\",\n",
    "            label=\"center\",\n",
    "            s=10,\n",
    "        )\n",
    "        ax[1, 0].set_xlim([x_min, x_max])\n",
    "        ax[1, 0].set_ylim([y_min, y_max])\n",
    "        ax[1, 0].set_xlabel(\"x coordinates (pixels)\")\n",
    "        ax[1, 0].set_ylabel(\"y coordinates (pixels)\")\n",
    "        ax[1, 0].legend(loc=\"upper right\")\n",
    "    else:\n",
    "        ax[1, 0].axis(\"off\")\n",
    "\n",
    "    # Panel 4: p1 to p8 (dict2)\n",
    "\n",
    "    if \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "        ax[1, 1].set_title(f\"{get_eye_label('VideoData2')}: p1 to p8\")\n",
    "        for idx, col in enumerate(columns_of_interest[3:]):\n",
    "            ax[1, 1].scatter(\n",
    "                coordinates_dict2_raw[f\"{col}.x\"],\n",
    "                coordinates_dict2_raw[f\"{col}.y\"],\n",
    "                color=colors[idx],\n",
    "                label=col,\n",
    "                s=5,\n",
    "            )\n",
    "\n",
    "        ax[1, 1].set_xlim([x_min, x_max])\n",
    "        ax[1, 1].set_ylim([y_min, y_max])\n",
    "        ax[1, 1].set_xlabel(\"x coordinates (pixels)\")\n",
    "        ax[1, 1].set_ylabel(\"y coordinates (pixels)\")\n",
    "        ax[1, 1].legend(loc=\"upper right\")\n",
    "    else:\n",
    "        ax[1, 1].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61646b5b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Center coordinates, filter low-confidence points, remove outliers, and interpolate\n",
    "##########################################################################\n",
    "\n",
    "# Detect and print confidence scores analysis (runs before any filtering)\n",
    "#########\n",
    "\n",
    "if not debug:\n",
    "    print(\n",
    "        \"ℹ️ Debug output suppressed. Set debug=True to see detailed confidence score analysis.\"\n",
    "    )\n",
    "\n",
    "score_columns = [\n",
    "    \"left.score\",\n",
    "    \"center.score\",\n",
    "    \"right.score\",\n",
    "    \"p1.score\",\n",
    "    \"p2.score\",\n",
    "    \"p3.score\",\n",
    "    \"p4.score\",\n",
    "    \"p5.score\",\n",
    "    \"p6.score\",\n",
    "    \"p7.score\",\n",
    "    \"p8.score\",\n",
    "]\n",
    "\n",
    "# VideoData1 confidence score analysis\n",
    "if debug and \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "    pf.analyze_confidence_scores(\n",
    "        VideoData1,\n",
    "        score_columns,\n",
    "        score_cutoff,\n",
    "        get_eye_label(\"VideoData1\"),\n",
    "        debug=debug,\n",
    "    )\n",
    "\n",
    "# VideoData2 confidence score analysis\n",
    "if debug and \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "    pf.analyze_confidence_scores(\n",
    "        VideoData2,\n",
    "        score_columns,\n",
    "        score_cutoff,\n",
    "        get_eye_label(\"VideoData2\"),\n",
    "        debug=debug,\n",
    "    )\n",
    "\n",
    "\n",
    "print()\n",
    "print(\"=== Centering coordinates to the median pupil centre ===\")\n",
    "# Reset columns_of_interest to full coordinate column names (needed after\n",
    "# QC plotting redefined it)\n",
    "columns_of_interest = [\n",
    "    \"left.x\",\n",
    "    \"left.y\",\n",
    "    \"center.x\",\n",
    "    \"center.y\",\n",
    "    \"right.x\",\n",
    "    \"right.y\",\n",
    "    \"p1.x\",\n",
    "    \"p1.y\",\n",
    "    \"p2.x\",\n",
    "    \"p2.y\",\n",
    "    \"p3.x\",\n",
    "    \"p3.y\",\n",
    "    \"p4.x\",\n",
    "    \"p4.y\",\n",
    "    \"p5.x\",\n",
    "    \"p5.y\",\n",
    "    \"p6.x\",\n",
    "    \"p6.y\",\n",
    "    \"p7.x\",\n",
    "    \"p7.y\",\n",
    "    \"p8.x\",\n",
    "    \"p8.y\",\n",
    "]\n",
    "# VideoData1 processing\n",
    "if \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "    VideoData1_centered = pf.center_coordinates_to_median(\n",
    "        VideoData1, columns_of_interest, get_eye_label(\"VideoData1\")\n",
    "    )\n",
    "\n",
    "# VideoData2 processing\n",
    "if \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "    VideoData2_centered = pf.center_coordinates_to_median(\n",
    "        VideoData2, columns_of_interest, get_eye_label(\"VideoData2\")\n",
    "    )\n",
    "\n",
    "# remove low confidence points (score < threshold)\n",
    "##################################################\n",
    "if not NaNs_removed:\n",
    "    if debug:\n",
    "        print(\n",
    "            \"\\n=== Score-based Filtering - point scores below threshold are replaced by interpolation ===\"\n",
    "        )\n",
    "        print(f\"Score threshold: {score_cutoff}\")\n",
    "    # List of point names (without .x, .y, .score)\n",
    "    point_names = [\n",
    "        \"left\",\n",
    "        \"right\",\n",
    "        \"center\",\n",
    "        \"p1\",\n",
    "        \"p2\",\n",
    "        \"p3\",\n",
    "        \"p4\",\n",
    "        \"p5\",\n",
    "        \"p6\",\n",
    "        \"p7\",\n",
    "        \"p8\",\n",
    "    ]\n",
    "\n",
    "    # VideoData1 score-based filtering\n",
    "    if \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "        pf.filter_low_confidence_points(\n",
    "            VideoData1,\n",
    "            point_names,\n",
    "            score_cutoff,\n",
    "            get_eye_label(\"VideoData1\"),\n",
    "            debug=debug,\n",
    "        )\n",
    "\n",
    "    # VideoData2 score-based filtering\n",
    "    if \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "        pf.filter_low_confidence_points(\n",
    "            VideoData2,\n",
    "            point_names,\n",
    "            score_cutoff,\n",
    "            get_eye_label(\"VideoData2\"),\n",
    "            debug=debug,\n",
    "        )\n",
    "\n",
    "    # remove outliers (x times SD)\n",
    "    # then interpolates on all NaN values (skipped frames, low confidence inference points, outliers)\n",
    "    ##########################################################################\n",
    "\n",
    "    if debug:\n",
    "        print(\n",
    "            \"\\n=== Outlier Analysis - outlier points are replaced by interpolation ===\"\n",
    "        )\n",
    "\n",
    "    # Reset columns_of_interest to full coordinate column names (needed after\n",
    "    # QC plotting redefined it)\n",
    "    columns_of_interest = [\n",
    "        \"left.x\",\n",
    "        \"left.y\",\n",
    "        \"center.x\",\n",
    "        \"center.y\",\n",
    "        \"right.x\",\n",
    "        \"right.y\",\n",
    "        \"p1.x\",\n",
    "        \"p1.y\",\n",
    "        \"p2.x\",\n",
    "        \"p2.y\",\n",
    "        \"p3.x\",\n",
    "        \"p3.y\",\n",
    "        \"p4.x\",\n",
    "        \"p4.y\",\n",
    "        \"p5.x\",\n",
    "        \"p5.y\",\n",
    "        \"p6.x\",\n",
    "        \"p6.y\",\n",
    "        \"p7.x\",\n",
    "        \"p7.y\",\n",
    "        \"p8.x\",\n",
    "        \"p8.y\",\n",
    "    ]\n",
    "\n",
    "    # VideoData1 outlier analysis and interpolation\n",
    "    if \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "        outlier_results_v1 = pf.remove_outliers_and_interpolate(\n",
    "            VideoData1,\n",
    "            columns_of_interest,\n",
    "            outlier_sd_threshold,\n",
    "            get_eye_label(\"VideoData1\"),\n",
    "            debug=debug,\n",
    "        )\n",
    "        VideoData1 = outlier_results_v1[\"video_data_interpolated\"]\n",
    "\n",
    "    # VideoData2 outlier analysis and interpolation\n",
    "    if \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "        outlier_results_v2 = pf.remove_outliers_and_interpolate(\n",
    "            VideoData2,\n",
    "            columns_of_interest,\n",
    "            outlier_sd_threshold,\n",
    "            get_eye_label(\"VideoData2\"),\n",
    "            debug=debug,\n",
    "        )\n",
    "        VideoData2 = outlier_results_v2[\"video_data_interpolated\"]\n",
    "\n",
    "    # Set flag after both VideoData1 and VideoData2 processing is complete\n",
    "    NaNs_removed = True\n",
    "else:\n",
    "    print(\"=== Interpolation already done, skipping ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc7517",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Instance.score distribution and hard threshold for blink detection\n",
    "##########################################################################\n",
    "# Plotting the distribution of instance scores and using hard threshold for blink detection.\n",
    "# When instance score is low, that's typically because of a blink or similar occlusion, as there are long sequences of low scores.\n",
    "# Frames with instance.score below the hard threshold are considered\n",
    "# potential blinks.\n",
    "\n",
    "if not debug:\n",
    "    print(\n",
    "        \"ℹ️ Debug output suppressed. Set debug=True to see detailed instance score distribution analysis.\"\n",
    "    )\n",
    "\n",
    "if debug:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"INSTANCE.SCORE DISTRIBUTION AND BLINK DETECTION THRESHOLD\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nHard threshold: instance.score < {blink_instance_score_threshold}\")\n",
    "    print(\n",
    "        \"  Frames with instance.score below this threshold will be considered potential blinks.\"\n",
    "    )\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# Only analyze for dataset(s) that exist\n",
    "has_v1 = \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap\n",
    "has_v2 = \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap\n",
    "\n",
    "# Get FPS for time calculations\n",
    "fps_1_for_threshold = None\n",
    "fps_2_for_threshold = None\n",
    "if has_v1:\n",
    "    fps_1_for_threshold = (\n",
    "        FPS_1\n",
    "        if \"FPS_1\" in globals()\n",
    "        else (1 / VideoData1[\"Seconds\"].diff().mean() if has_v1 else None)\n",
    "    )\n",
    "if has_v2:\n",
    "    fps_2_for_threshold = (\n",
    "        FPS_2\n",
    "        if \"FPS_2\" in globals()\n",
    "        else (1 / VideoData2[\"Seconds\"].diff().mean() if has_v2 else None)\n",
    "    )\n",
    "\n",
    "# Plot combined histograms\n",
    "if debug and (has_v1 or has_v2):\n",
    "    pf.plot_instance_score_distributions_combined(\n",
    "        VideoData1 if has_v1 else None,\n",
    "        VideoData2 if has_v2 else None,\n",
    "        blink_instance_score_threshold,\n",
    "        has_v1=has_v1,\n",
    "        has_v2=has_v2,\n",
    "    )\n",
    "\n",
    "# Report the statistics for available VideoData\n",
    "# Always show key stats: number/percentile below threshold and longest\n",
    "# consecutive segment\n",
    "if has_v1:\n",
    "    pf.analyze_instance_score_distribution(\n",
    "        VideoData1,\n",
    "        blink_instance_score_threshold,\n",
    "        fps_1_for_threshold,\n",
    "        # Already plotted above\n",
    "        get_eye_label(\"VideoData1\"),\n",
    "        debug=debug,\n",
    "        plot=False,\n",
    "    )\n",
    "\n",
    "if has_v2:\n",
    "    pf.analyze_instance_score_distribution(\n",
    "        VideoData2,\n",
    "        blink_instance_score_threshold,\n",
    "        fps_2_for_threshold,\n",
    "        # Already plotted above\n",
    "        get_eye_label(\"VideoData2\"),\n",
    "        debug=debug,\n",
    "        plot=False,\n",
    "    )\n",
    "\n",
    "if debug:\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(\"Note: This threshold will be used for blink detection in the next cell.\")\n",
    "    print(\n",
    "        \"      Frames with instance.score below this threshold are considered potential blinks.\"\n",
    "    )\n",
    "    print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1433bed0",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Blink detection using instance.score - mark blinks and set coordinates to NaN (keep them as NaN, no interpolation)\n",
    "##########################################################################\n",
    "\n",
    "if not debug:\n",
    "    print(\n",
    "        \"ℹ️ Debug output suppressed. Set debug=True to see detailed blink detection information.\"\n",
    "    )\n",
    "\n",
    "# Capture all print output to save to file\n",
    "\n",
    "\n",
    "class TeeOutput:\n",
    "    \"\"\"Output to both stdout and a string buffer\"\"\"\n",
    "\n",
    "    def __init__(self, stdout, buffer):\n",
    "        self.stdout = stdout\n",
    "        self.buffer = buffer\n",
    "\n",
    "    def write(self, s):\n",
    "        self.stdout.write(s)\n",
    "        self.buffer.write(s)\n",
    "\n",
    "    def flush(self):\n",
    "        self.stdout.flush()\n",
    "        self.buffer.flush()\n",
    "\n",
    "\n",
    "output_buffer = io.StringIO()\n",
    "original_stdout = sys.stdout\n",
    "sys.stdout = TeeOutput(original_stdout, output_buffer)\n",
    "\n",
    "# Run blink detection code with output captured\n",
    "if debug:\n",
    "    print(\"\\n=== Blink Detection ===\")\n",
    "\n",
    "# VideoData1 blink detection\n",
    "if \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "    # Get FPS if available, otherwise will be calculated in function\n",
    "    fps_1 = FPS_1 if \"FPS_1\" in globals() else None\n",
    "\n",
    "    # Get manual blinks if available\n",
    "    manual_blinks_for_v1 = (\n",
    "        manual_blinks_v1\n",
    "        if \"manual_blinks_v1\" in globals() and manual_blinks_v1 is not None\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Run blink detection\n",
    "    blink_results_v1 = pf.detect_blinks_for_video(\n",
    "        video_data=VideoData1,\n",
    "        columns_of_interest=columns_of_interest,\n",
    "        blink_instance_score_threshold=blink_instance_score_threshold,\n",
    "        long_blink_warning_ms=long_blink_warning_ms,\n",
    "        min_frames_threshold=4,\n",
    "        merge_window_frames=10,\n",
    "        fps=fps_1,\n",
    "        video_label=get_eye_label(\"VideoData1\"),\n",
    "        manual_blinks=manual_blinks_for_v1,\n",
    "        debug=debug,\n",
    "    )\n",
    "\n",
    "    # Extract results to maintain compatibility with existing variable names\n",
    "    blink_segments_v1 = blink_results_v1[\"blink_segments\"]\n",
    "    short_blink_segments_v1 = blink_results_v1[\"short_blink_segments\"]\n",
    "    blink_bouts_v1 = blink_results_v1[\"blink_bouts\"]\n",
    "    all_blink_segments_v1 = blink_results_v1[\"all_blink_segments\"]\n",
    "    fps_1 = blink_results_v1[\"fps\"]  # Update fps_1 with calculated value\n",
    "    FPS_1 = fps_1  # Also update global FPS_1 for use elsewhere\n",
    "    long_blinks_warnings_v1 = blink_results_v1[\"long_blinks_warnings\"]\n",
    "\n",
    "# VideoData2 blink detection\n",
    "if \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "    # Get FPS if available, otherwise will be calculated in function\n",
    "    fps_2 = FPS_2 if \"FPS_2\" in globals() else None\n",
    "\n",
    "    # Get manual blinks if available\n",
    "    manual_blinks_for_v2 = (\n",
    "        manual_blinks_v2\n",
    "        if \"manual_blinks_v2\" in globals() and manual_blinks_v2 is not None\n",
    "        else None\n",
    "    )\n",
    "\n",
    "    # Run blink detection\n",
    "    blink_results_v2 = pf.detect_blinks_for_video(\n",
    "        video_data=VideoData2,\n",
    "        columns_of_interest=columns_of_interest,\n",
    "        blink_instance_score_threshold=blink_instance_score_threshold,\n",
    "        long_blink_warning_ms=long_blink_warning_ms,\n",
    "        min_frames_threshold=4,\n",
    "        merge_window_frames=10,\n",
    "        fps=fps_2,\n",
    "        video_label=get_eye_label(\"VideoData2\"),\n",
    "        manual_blinks=manual_blinks_for_v2,\n",
    "        debug=debug,\n",
    "    )\n",
    "\n",
    "    # Extract results to maintain compatibility with existing variable names\n",
    "    blink_segments_v2 = blink_results_v2[\"blink_segments\"]\n",
    "    short_blink_segments_v2 = blink_results_v2[\"short_blink_segments\"]\n",
    "    blink_bouts_v2 = blink_results_v2[\"blink_bouts\"]\n",
    "    all_blink_segments_v2 = blink_results_v2[\"all_blink_segments\"]\n",
    "    fps_2 = blink_results_v2[\"fps\"]  # Update fps_2 with calculated value\n",
    "    FPS_2 = fps_2  # Also update global FPS_2 for use elsewhere\n",
    "    long_blinks_warnings_v2 = blink_results_v2[\"long_blinks_warnings\"]\n",
    "\n",
    "print(\"\\n✅ Blink detection complete. Blink periods remain as NaN (not interpolated).\")\n",
    "\n",
    "# Compare blink bout timing between VideoData1 and VideoData2 (between eyes)\n",
    "if (\n",
    "    \"VideoData1_Has_Sleap\" in globals()\n",
    "    and VideoData1_Has_Sleap\n",
    "    and \"VideoData2_Has_Sleap\" in globals()\n",
    "    and VideoData2_Has_Sleap\n",
    "):\n",
    "    if debug:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"BLINK BOUT TIMING COMPARISON: VideoData1 vs VideoData2 (Between Eyes)\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "    # Get blink bout frame ranges for both videos (if they exist)\n",
    "    # Check if blink_bouts variables exist (they are created during blink\n",
    "    # detection)\n",
    "    try:\n",
    "        has_bouts_v1 = \"blink_bouts_v1\" in globals() and len(blink_bouts_v1) > 0\n",
    "    except BaseException:\n",
    "        has_bouts_v1 = False\n",
    "\n",
    "    try:\n",
    "        has_bouts_v2 = \"blink_bouts_v2\" in globals() and len(blink_bouts_v2) > 0\n",
    "    except BaseException:\n",
    "        has_bouts_v2 = False\n",
    "\n",
    "    if has_bouts_v1 and has_bouts_v2:\n",
    "        # Convert bout indices to frame numbers\n",
    "        bouts_v1 = []\n",
    "        for i, bout in enumerate(blink_bouts_v1, 1):\n",
    "            start_idx = bout[\"start_idx\"]\n",
    "            end_idx = bout[\"end_idx\"]\n",
    "            # CRITICAL FIX: Use stored frame_idx values if available (from merge_nearby_blinks)\n",
    "            if \"start_frame_idx\" in bout and \"end_frame_idx\" in bout:\n",
    "                start_frame = int(bout[\"start_frame_idx\"]) if pd.notna(bout[\"start_frame_idx\"]) else start_idx\n",
    "                end_frame = int(bout[\"end_frame_idx\"]) if pd.notna(bout[\"end_frame_idx\"]) else end_idx\n",
    "            elif \"frame_idx\" in VideoData1.columns:\n",
    "                # Fallback: look up from DataFrame (may be wrong if DataFrame was modified)\n",
    "                start_frame = int(VideoData1[\"frame_idx\"].iloc[start_idx])\n",
    "                end_frame = int(VideoData1[\"frame_idx\"].iloc[end_idx])\n",
    "            else:\n",
    "                start_frame = start_idx\n",
    "                end_frame = end_idx\n",
    "            bouts_v1.append(\n",
    "                {\n",
    "                    \"num\": i,\n",
    "                    \"start_frame\": start_frame,\n",
    "                    \"end_frame\": end_frame,\n",
    "                    \"start_idx\": start_idx,\n",
    "                    \"end_idx\": end_idx,\n",
    "                    \"length\": bout[\"length\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        bouts_v2 = []\n",
    "        for i, bout in enumerate(blink_bouts_v2, 1):\n",
    "            start_idx = bout[\"start_idx\"]\n",
    "            end_idx = bout[\"end_idx\"]\n",
    "            # CRITICAL FIX: Use stored frame_idx values if available (from merge_nearby_blinks)\n",
    "            if \"start_frame_idx\" in bout and \"end_frame_idx\" in bout:\n",
    "                start_frame = int(bout[\"start_frame_idx\"]) if pd.notna(bout[\"start_frame_idx\"]) else start_idx\n",
    "                end_frame = int(bout[\"end_frame_idx\"]) if pd.notna(bout[\"end_frame_idx\"]) else end_idx\n",
    "            elif \"frame_idx\" in VideoData2.columns:\n",
    "                # Fallback: look up from DataFrame (may be wrong if DataFrame was modified)\n",
    "                start_frame = int(VideoData2[\"frame_idx\"].iloc[start_idx])\n",
    "                end_frame = int(VideoData2[\"frame_idx\"].iloc[end_idx])\n",
    "            else:\n",
    "                start_frame = start_idx\n",
    "                end_frame = end_idx\n",
    "            bouts_v2.append(\n",
    "                {\n",
    "                    \"num\": i,\n",
    "                    \"start_frame\": start_frame,\n",
    "                    \"end_frame\": end_frame,\n",
    "                    \"start_idx\": start_idx,\n",
    "                    \"end_idx\": end_idx,\n",
    "                    \"length\": bout[\"length\"],\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Find concurrent bouts (overlapping in time, synchronized by Seconds)\n",
    "        concurrent_bouts = []\n",
    "        v1_independent = []\n",
    "        v2_independent = []\n",
    "\n",
    "        v2_matched = set()  # Track which VideoData2 bouts have been matched\n",
    "\n",
    "        for bout1 in bouts_v1:\n",
    "            # Get time range for bout1\n",
    "            v1_start_time = VideoData1[\"Seconds\"].iloc[bout1[\"start_idx\"]]\n",
    "            v1_end_time = VideoData1[\"Seconds\"].iloc[bout1[\"end_idx\"]]\n",
    "\n",
    "            found_match = False\n",
    "            for bout2 in bouts_v2:\n",
    "                # Get time range for bout2\n",
    "                v2_start_time = VideoData2[\"Seconds\"].iloc[bout2[\"start_idx\"]]\n",
    "                v2_end_time = VideoData2[\"Seconds\"].iloc[bout2[\"end_idx\"]]\n",
    "\n",
    "                # Check if bouts overlap in time (any overlapping time period)\n",
    "                overlap_start_time = max(v1_start_time, v2_start_time)\n",
    "                overlap_end_time = min(v1_end_time, v2_end_time)\n",
    "\n",
    "                if overlap_start_time <= overlap_end_time:\n",
    "                    # Concurrent - they overlap in time\n",
    "                    # Calculate overlap duration\n",
    "                    overlap_duration = overlap_end_time - overlap_start_time\n",
    "\n",
    "                    concurrent_bouts.append(\n",
    "                        {\n",
    "                            \"v1_num\": bout1[\"num\"],\n",
    "                            \"v1_start_frame\": bout1[\"start_frame\"],\n",
    "                            \"v1_end_frame\": bout1[\"end_frame\"],\n",
    "                            \"v1_start_time\": v1_start_time,\n",
    "                            \"v1_end_time\": v1_end_time,\n",
    "                            \"v2_num\": bout2[\"num\"],\n",
    "                            \"v2_start_frame\": bout2[\"start_frame\"],\n",
    "                            \"v2_end_frame\": bout2[\"end_frame\"],\n",
    "                            \"v2_start_time\": v2_start_time,\n",
    "                            \"v2_end_time\": v2_end_time,\n",
    "                            \"overlap_start_time\": overlap_start_time,\n",
    "                            \"overlap_end_time\": overlap_end_time,\n",
    "                            \"overlap_duration\": overlap_duration,\n",
    "                        }\n",
    "                    )\n",
    "                    v2_matched.add(bout2[\"num\"])\n",
    "                    found_match = True\n",
    "                    break\n",
    "\n",
    "            if not found_match:\n",
    "                v1_independent.append(bout1)\n",
    "\n",
    "        # Find VideoData2 bouts that don't have matches\n",
    "        for bout2 in bouts_v2:\n",
    "            if bout2[\"num\"] not in v2_matched:\n",
    "                v2_independent.append(bout2)\n",
    "\n",
    "        # Calculate statistics\n",
    "        total_v1_bouts = len(bouts_v1)\n",
    "        total_v2_bouts = len(bouts_v2)\n",
    "        total_concurrent = len(concurrent_bouts)\n",
    "        total_v1_independent = len(v1_independent)\n",
    "        total_v2_independent = len(v2_independent)\n",
    "\n",
    "        if debug:\n",
    "            print(\"\\nBlink bout counts:\")\n",
    "            print(f\"  VideoData1: {total_v1_bouts} blink bout(s)\")\n",
    "            print(f\"  VideoData2: {total_v2_bouts} blink bout(s)\")\n",
    "            print(f\"  Concurrent: {total_concurrent} bout(s) (overlapping frames)\")\n",
    "            print(f\"  VideoData1 only: {total_v1_independent} bout(s)\")\n",
    "            print(f\"  VideoData2 only: {total_v2_independent} bout(s)\")\n",
    "\n",
    "            if total_v1_bouts > 0 and total_v2_bouts > 0:\n",
    "                concurrent_pct_v1 = (total_concurrent / total_v1_bouts) * 100\n",
    "                concurrent_pct_v2 = (total_concurrent / total_v2_bouts) * 100\n",
    "                print(\"\\nConcurrency percentage:\")\n",
    "                print(\n",
    "                    f\"  {concurrent_pct_v1:.1f}% of VideoData1 bouts are concurrent with VideoData2\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"  {concurrent_pct_v2:.1f}% of VideoData2 bouts are concurrent with VideoData1\"\n",
    "                )\n",
    "\n",
    "                # Calculate timing offsets for concurrent bouts\n",
    "                if len(concurrent_bouts) > 0:\n",
    "                    time_offsets_ms = []\n",
    "                    for cb in concurrent_bouts:\n",
    "                        # Calculate offset from start times (already in\n",
    "                        # Seconds)\n",
    "                        offset_ms = (cb[\"v1_start_time\"] - cb[\"v2_start_time\"]) * 1000\n",
    "                        time_offsets_ms.append(offset_ms)\n",
    "                        cb[\"time_offset_ms\"] = offset_ms\n",
    "\n",
    "                    mean_offset = np.mean(time_offsets_ms)\n",
    "                    std_offset = np.std(time_offsets_ms)\n",
    "                    print(\"\\nTiming offset for concurrent bouts:\")\n",
    "                    print(\n",
    "                        f\"  Mean offset (VideoData1 - VideoData2): {mean_offset:.2f} ms\"\n",
    "                    )\n",
    "                    print(f\"  Std offset: {std_offset:.2f} ms\")\n",
    "                    print(\n",
    "                        f\"  Range: {min(time_offsets_ms):.2f} to {max(time_offsets_ms):.2f} ms\"\n",
    "                    )\n",
    "\n",
    "            # Visualization removed per request\n",
    "            print(\"=\" * 80)\n",
    "    elif has_bouts_v1 or has_bouts_v2:\n",
    "        print(\n",
    "            \"\\n⚠️ Cannot compare blink bouts - only one eye has blink bouts detected:\"\n",
    "        )\n",
    "        if has_bouts_v1:\n",
    "            print(f\"  VideoData1: {len(blink_bouts_v1)} blink bout(s)\")\n",
    "        else:\n",
    "            print(\"  VideoData1: 0 blink bout(s)\")\n",
    "        if has_bouts_v2:\n",
    "            print(f\"  VideoData2: {len(blink_bouts_v2)} blink bout(s)\")\n",
    "        else:\n",
    "            print(\"  VideoData2: 0 blink bout(s)\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ Cannot compare blink bouts - neither video has blink bouts detected\")\n",
    "\n",
    "# Save blink detection results to CSV files\n",
    "if \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "    if len(blink_segments_v1) > 0:\n",
    "        # Collect blink information\n",
    "        blink_data_v1 = []\n",
    "        manual_blinks_for_csv = None\n",
    "        if \"manual_blinks_v1\" in globals() and manual_blinks_v1 is not None:\n",
    "            manual_blinks_for_csv = manual_blinks_v1\n",
    "\n",
    "        for i, blink in enumerate(blink_segments_v1, 1):\n",
    "            # CRITICAL FIX: Use stored frame_idx values from blink detection\n",
    "            # These were captured before any DataFrame modifications (e.g., merge operations)\n",
    "            if \"start_frame_idx\" in blink and \"end_frame_idx\" in blink:\n",
    "                first_frame = int(blink[\"start_frame_idx\"]) if pd.notna(blink[\"start_frame_idx\"]) else blink[\"start_idx\"]\n",
    "                last_frame = int(blink[\"end_frame_idx\"]) if pd.notna(blink[\"end_frame_idx\"]) else blink[\"end_idx\"]\n",
    "            else:\n",
    "                # Fallback to old method if frame_idx not stored (for backward compatibility)\n",
    "                start_idx = blink[\"start_idx\"]\n",
    "                end_idx = blink[\"end_idx\"]\n",
    "                if \"frame_idx\" in VideoData1.columns:\n",
    "                    first_frame = int(VideoData1[\"frame_idx\"].iloc[start_idx])\n",
    "                    last_frame = int(VideoData1[\"frame_idx\"].iloc[end_idx])\n",
    "                else:\n",
    "                    first_frame = start_idx\n",
    "                    last_frame = end_idx\n",
    "\n",
    "            # Check if this blink matches a manual one (using function from\n",
    "            # processing_functions)\n",
    "            matches_manual = pf.check_manual_match(\n",
    "                first_frame, last_frame, manual_blinks_for_csv\n",
    "            )\n",
    "\n",
    "            blink_data_v1.append(\n",
    "                {\n",
    "                    \"blink_number\": i,\n",
    "                    \"first_frame\": first_frame,\n",
    "                    \"last_frame\": last_frame,\n",
    "                    \"matches_manual\": matches_manual,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Create DataFrame and save to CSV\n",
    "        blink_df_v1 = pd.DataFrame(blink_data_v1)\n",
    "        blink_csv_path_v1 = qc_debug_dir / \"blink_detection_VideoData1.csv\"\n",
    "        blink_df_v1.to_csv(blink_csv_path_v1, index=False)\n",
    "        print(\n",
    "            f\"\\n✅ Blink detection results (VideoData1) saved to: {blink_csv_path_v1}\"\n",
    "        )\n",
    "        print(f\"   Saved {len(blink_data_v1)} blinks\")\n",
    "\n",
    "if \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "    if len(blink_segments_v2) > 0:\n",
    "        # Collect blink information\n",
    "        blink_data_v2 = []\n",
    "        manual_blinks_for_csv = None\n",
    "        if \"manual_blinks_v2\" in globals() and manual_blinks_v2 is not None:\n",
    "            manual_blinks_for_csv = manual_blinks_v2\n",
    "\n",
    "        for i, blink in enumerate(blink_segments_v2, 1):\n",
    "            # CRITICAL FIX: Use stored frame_idx values from blink detection\n",
    "            # These were captured before any DataFrame modifications (e.g., merge operations)\n",
    "            if \"start_frame_idx\" in blink and \"end_frame_idx\" in blink:\n",
    "                first_frame = int(blink[\"start_frame_idx\"]) if pd.notna(blink[\"start_frame_idx\"]) else blink[\"start_idx\"]\n",
    "                last_frame = int(blink[\"end_frame_idx\"]) if pd.notna(blink[\"end_frame_idx\"]) else blink[\"end_idx\"]\n",
    "            else:\n",
    "                # Fallback to old method if frame_idx not stored (for backward compatibility)\n",
    "                start_idx = blink[\"start_idx\"]\n",
    "                end_idx = blink[\"end_idx\"]\n",
    "                if \"frame_idx\" in VideoData2.columns:\n",
    "                    first_frame = int(VideoData2[\"frame_idx\"].iloc[start_idx])\n",
    "                    last_frame = int(VideoData2[\"frame_idx\"].iloc[end_idx])\n",
    "                else:\n",
    "                    first_frame = start_idx\n",
    "                    last_frame = end_idx\n",
    "\n",
    "            # Check if this blink matches a manual one (using function from\n",
    "            # processing_functions)\n",
    "            matches_manual = pf.check_manual_match(\n",
    "                first_frame, last_frame, manual_blinks_for_csv\n",
    "            )\n",
    "\n",
    "            blink_data_v2.append(\n",
    "                {\n",
    "                    \"blink_number\": i,\n",
    "                    \"first_frame\": first_frame,\n",
    "                    \"last_frame\": last_frame,\n",
    "                    \"matches_manual\": matches_manual,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # Create DataFrame and save to CSV\n",
    "        blink_df_v2 = pd.DataFrame(blink_data_v2)\n",
    "        blink_csv_path_v2 = qc_debug_dir / \"blink_detection_VideoData2.csv\"\n",
    "        blink_df_v2.to_csv(blink_csv_path_v2, index=False)\n",
    "        print(\n",
    "            f\"\\n✅ Blink detection results (VideoData2) saved to: {blink_csv_path_v2}\"\n",
    "        )\n",
    "        print(f\"   Saved {len(blink_data_v2)} blinks\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📹 MANUAL QC CHECK:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"For instructions on how to prepare videos for manual blink detection QC,\")\n",
    "print(\"see: https://github.com/ranczlab/vestibular_vr_pipeline/issues/86\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Restore original stdout and save captured output to file\n",
    "sys.stdout = original_stdout\n",
    "\n",
    "# Get the captured output\n",
    "captured_output = output_buffer.getvalue()\n",
    "\n",
    "# Save to file in data_path folder\n",
    "output_file = qc_debug_dir / \"blink_detection_QC.txt\"\n",
    "output_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(captured_output)\n",
    "\n",
    "print(f\"\\n✅ Blink detection output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe92c4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# QC plot timeseries of interpolation corrected NaN in browser\n",
    "##########################################################################\n",
    "\n",
    "if plot_QC_timeseries:\n",
    "    print(\"ℹ️ Figure opens in browser window, takes a bit of time.\")\n",
    "\n",
    "    # VideoData1 QC Plot\n",
    "    if \"VideoData1_Has_Sleap\" in globals() and VideoData1_Has_Sleap:\n",
    "        fig1 = make_subplots(\n",
    "            rows=4,\n",
    "            cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=(\n",
    "                \"VideoData1 - X coordinates for pupil centre and left-right eye corner\",\n",
    "                \"VideoData1 - Y coordinates for pupil centre and left-right eye corner\",\n",
    "                \"VideoData1 - X coordinates for iris points\",\n",
    "                \"VideoData1 - Y coordinates for iris points\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Row 1: Plot left.x, center.x, right.x\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"left.x\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"left.x\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"center.x\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"center.x\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"right.x\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"right.x\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Row 2: Plot left.y, center.y, right.y\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"left.y\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"left.y\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"center.y\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"center.y\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        fig1.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"right.y\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"right.y\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Row 3: Plot p.x coordinates for p1 to p8\n",
    "        for col in [\"p1.x\", \"p2.x\", \"p3.x\", \"p4.x\", \"p5.x\", \"p6.x\", \"p7.x\", \"p8.x\"]:\n",
    "            fig1.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData1[\"Seconds\"], y=VideoData1[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=3,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        # Row 4: Plot p.y coordinates for p1 to p8\n",
    "        for col in [\"p1.y\", \"p2.y\", \"p3.y\", \"p4.y\", \"p5.y\", \"p6.y\", \"p7.y\", \"p8.y\"]:\n",
    "            fig1.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData1[\"Seconds\"], y=VideoData1[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=4,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        fig1.update_layout(\n",
    "            height=1200,\n",
    "            title_text=\"VideoData1 - Time series subplots for coordinates (QC after interpolation)\",\n",
    "            showlegend=True,\n",
    "        )\n",
    "        fig1.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "        fig1.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "        fig1.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "        fig1.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "        fig1.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "        fig1.show(renderer=\"browser\")\n",
    "\n",
    "    # VideoData2 QC Plot\n",
    "    if \"VideoData2_Has_Sleap\" in globals() and VideoData2_Has_Sleap:\n",
    "        fig2 = make_subplots(\n",
    "            rows=4,\n",
    "            cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.05,\n",
    "            subplot_titles=(\n",
    "                \"VideoData2 - X coordinates for pupil centre and left-right eye corner\",\n",
    "                \"VideoData2 - Y coordinates for pupil centre and left-right eye corner\",\n",
    "                \"VideoData2 - X coordinates for iris points\",\n",
    "                \"VideoData2 - Y coordinates for iris points\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Row 1: Plot left.x, center.x, right.x\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"left.x\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"left.x\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"center.x\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"center.x\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"right.x\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"right.x\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Row 2: Plot left.y, center.y, right.y\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"left.y\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"left.y\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"center.y\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"center.y\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        fig2.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"right.y\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"right.y\",\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Row 3: Plot p.x coordinates for p1 to p8\n",
    "\n",
    "        for col in [\"p1.x\", \"p2.x\", \"p3.x\", \"p4.x\", \"p5.x\", \"p6.x\", \"p7.x\", \"p8.x\"]:\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData2[\"Seconds\"], y=VideoData2[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=3,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        # Row 4: Plot p.y coordinates for p1 to p8\n",
    "\n",
    "        for col in [\"p1.y\", \"p2.y\", \"p3.y\", \"p4.y\", \"p5.y\", \"p6.y\", \"p7.y\", \"p8.y\"]:\n",
    "            fig2.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=VideoData2[\"Seconds\"], y=VideoData2[col], mode=\"lines\", name=col\n",
    "                ),\n",
    "                row=4,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        fig2.update_layout(\n",
    "            height=1200,\n",
    "            title_text=\"VideoData2 - Time series subplots for coordinates (QC after interpolation)\",\n",
    "            showlegend=True,\n",
    "        )\n",
    "        fig2.update_xaxes(title_text=\"Seconds\", row=4, col=1)\n",
    "        fig2.update_yaxes(title_text=\"X Position\", row=1, col=1)\n",
    "        fig2.update_yaxes(title_text=\"Y Position\", row=2, col=1)\n",
    "        fig2.update_yaxes(title_text=\"X Position\", row=3, col=1)\n",
    "        fig2.update_yaxes(title_text=\"Y Position\", row=4, col=1)\n",
    "\n",
    "        fig2.show(renderer=\"browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fac291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC plot XY coordinate distributions after NaN are interpolated\n",
    "################################################################\n",
    "\n",
    "columns_of_interest = [\n",
    "    \"left.x\",\n",
    "    \"left.y\",\n",
    "    \"center.x\",\n",
    "    \"center.y\",\n",
    "    \"right.x\",\n",
    "    \"right.y\",\n",
    "    \"p1.x\",\n",
    "    \"p1.y\",\n",
    "    \"p2.x\",\n",
    "    \"p2.y\",\n",
    "    \"p3.x\",\n",
    "    \"p3.y\",\n",
    "    \"p4.x\",\n",
    "    \"p4.y\",\n",
    "    \"p5.x\",\n",
    "    \"p5.y\",\n",
    "    \"p6.x\",\n",
    "    \"p6.y\",\n",
    "    \"p7.x\",\n",
    "    \"p7.y\",\n",
    "    \"p8.x\",\n",
    "    \"p8.y\",\n",
    "]\n",
    "\n",
    "# Create coordinates_dict for both datasets\n",
    "if VideoData1_Has_Sleap:\n",
    "    coordinates_dict1_processed = lp.get_coordinates_dict(\n",
    "        VideoData1, columns_of_interest\n",
    "    )\n",
    "\n",
    "if VideoData2_Has_Sleap:\n",
    "    coordinates_dict2_processed = lp.get_coordinates_dict(\n",
    "        VideoData2, columns_of_interest\n",
    "    )\n",
    "\n",
    "\n",
    "columns_of_interest = [\n",
    "    \"left\",\n",
    "    \"right\",\n",
    "    \"center\",\n",
    "    \"p1\",\n",
    "    \"p2\",\n",
    "    \"p3\",\n",
    "    \"p4\",\n",
    "    \"p5\",\n",
    "    \"p6\",\n",
    "    \"p7\",\n",
    "    \"p8\",\n",
    "]\n",
    "\n",
    "# Filter out NaN values and calculate the min and max values for X and Y\n",
    "# coordinates for both dict1 and dict2\n",
    "\n",
    "def min_max_dict(coordinates_dict):\n",
    "    x_min = min(\n",
    "        [\n",
    "            coordinates_dict[f\"{col}.x\"][~np.isnan(coordinates_dict[f\"{col}.x\"])].min()\n",
    "            for col in columns_of_interest\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    x_max = max(\n",
    "        [\n",
    "            coordinates_dict[f\"{col}.x\"][~np.isnan(coordinates_dict[f\"{col}.x\"])].max()\n",
    "            for col in columns_of_interest\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y_min = min(\n",
    "        [\n",
    "            coordinates_dict[f\"{col}.y\"][~np.isnan(coordinates_dict[f\"{col}.y\"])].min()\n",
    "            for col in columns_of_interest\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y_max = max(\n",
    "        [\n",
    "            coordinates_dict[f\"{col}.y\"][~np.isnan(coordinates_dict[f\"{col}.y\"])].max()\n",
    "            for col in columns_of_interest\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return x_min, x_max, y_min, y_max\n",
    "\n",
    "\n",
    "if plot_QC_timeseries:\n",
    "    if VideoData1_Has_Sleap:\n",
    "        x_min1, x_max1, y_min1, y_max1 = min_max_dict(coordinates_dict1_processed)\n",
    "    if VideoData2_Has_Sleap:\n",
    "        x_min2, x_max2, y_min2, y_max2 = min_max_dict(coordinates_dict2_processed)\n",
    "\n",
    "    # Use global min and max for consistency across subplots\n",
    "    if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "        x_min = min(x_min1, x_min2)\n",
    "        x_max = max(x_max1, x_max2)\n",
    "        y_min = min(y_min1, y_min2)\n",
    "        y_max = max(y_max1, y_max2)\n",
    "    elif VideoData1_Has_Sleap:\n",
    "        x_min, x_max, y_min, y_max = x_min1, x_max1, y_min1, y_max1\n",
    "    elif VideoData2_Has_Sleap:\n",
    "        x_min, x_max, y_min, y_max = x_min2, x_max2, y_min2, y_max2\n",
    "\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(18, 12))\n",
    "    fig.suptitle(\n",
    "        f\"XY coordinate distribution of different points for {get_eye_label('VideoData1')} and {get_eye_label('VideoData2')} post outlier removal and NaN interpolation\",\n",
    "        fontsize=14,\n",
    "    )\n",
    "\n",
    "    # Define colormap for p1-p8\n",
    "    colors = [\"blue\", \"green\", \"red\", \"cyan\", \"magenta\", \"yellow\", \"black\", \"orange\"]\n",
    "\n",
    "    # Panel 1: left, right, center (VideoData1)\n",
    "    if VideoData1_Has_Sleap:\n",
    "        ax[0, 0].set_title(f\"{get_eye_label('VideoData1')}: left, right, center\")\n",
    "\n",
    "        ax[0, 0].scatter(\n",
    "            coordinates_dict1_processed[\"left.x\"],\n",
    "            coordinates_dict1_processed[\"left.y\"],\n",
    "            color=\"black\",\n",
    "            label=\"left\",\n",
    "            s=10,\n",
    "        )\n",
    "\n",
    "        ax[0, 0].scatter(\n",
    "            coordinates_dict1_processed[\"right.x\"],\n",
    "            coordinates_dict1_processed[\"right.y\"],\n",
    "            color=\"grey\",\n",
    "            label=\"right\",\n",
    "            s=10,\n",
    "        )\n",
    "\n",
    "        ax[0, 0].scatter(\n",
    "            coordinates_dict1_processed[\"center.x\"],\n",
    "            coordinates_dict1_processed[\"center.y\"],\n",
    "            color=\"red\",\n",
    "            label=\"center\",\n",
    "            s=10,\n",
    "        )\n",
    "\n",
    "        ax[0, 0].set_xlim([x_min, x_max])\n",
    "\n",
    "        ax[0, 0].set_ylim([y_min, y_max])\n",
    "\n",
    "        ax[0, 0].set_xlabel(\"x coordinates (pixels)\")\n",
    "\n",
    "        ax[0, 0].set_ylabel(\"y coordinates (pixels)\")\n",
    "\n",
    "        ax[0, 0].legend(loc=\"upper right\")\n",
    "\n",
    "        # Panel 2: p1 to p8 (VideoData1)\n",
    "\n",
    "        ax[0, 1].set_title(f\"{get_eye_label('VideoData1')}: p1 to p8\")\n",
    "\n",
    "        for idx, col in enumerate(columns_of_interest[3:]):\n",
    "            ax[0, 1].scatter(\n",
    "                coordinates_dict1_processed[f\"{col}.x\"],\n",
    "                coordinates_dict1_processed[f\"{col}.y\"],\n",
    "                color=colors[idx],\n",
    "                label=col,\n",
    "                s=5,\n",
    "            )\n",
    "\n",
    "        ax[0, 1].set_xlim([x_min, x_max])\n",
    "\n",
    "        ax[0, 1].set_ylim([y_min, y_max])\n",
    "\n",
    "        ax[0, 1].set_xlabel(\"x coordinates (pixels)\")\n",
    "\n",
    "        ax[0, 1].set_ylabel(\"y coordinates (pixels)\")\n",
    "\n",
    "        ax[0, 1].legend(loc=\"upper right\")\n",
    "\n",
    "    # Panel 3: left, right, center (VideoData2)\n",
    "    if VideoData2_Has_Sleap:\n",
    "        ax[1, 0].set_title(f\"{get_eye_label('VideoData2')}: left, right, center\")\n",
    "\n",
    "        ax[1, 0].scatter(\n",
    "            coordinates_dict2_processed[\"left.x\"],\n",
    "            coordinates_dict2_processed[\"left.y\"],\n",
    "            color=\"black\",\n",
    "            label=\"left\",\n",
    "            s=10,\n",
    "        )\n",
    "\n",
    "        ax[1, 0].scatter(\n",
    "            coordinates_dict2_processed[\"right.x\"],\n",
    "            coordinates_dict2_processed[\"right.y\"],\n",
    "            color=\"grey\",\n",
    "            label=\"right\",\n",
    "            s=10,\n",
    "        )\n",
    "\n",
    "        ax[1, 0].scatter(\n",
    "            coordinates_dict2_processed[\"center.x\"],\n",
    "            coordinates_dict2_processed[\"center.y\"],\n",
    "            color=\"red\",\n",
    "            label=\"center\",\n",
    "            s=10,\n",
    "        )\n",
    "\n",
    "        ax[1, 0].set_xlim([x_min, x_max])\n",
    "\n",
    "        ax[1, 0].set_ylim([y_min, y_max])\n",
    "\n",
    "        ax[1, 0].set_xlabel(\"x coordinates (pixels)\")\n",
    "\n",
    "        ax[1, 0].set_ylabel(\"y coordinates (pixels)\")\n",
    "\n",
    "        ax[1, 0].legend(loc=\"upper right\")\n",
    "\n",
    "        # Panel 4: p1 to p8 (VideoData2)\n",
    "\n",
    "        ax[1, 1].set_title(f\"{get_eye_label('VideoData2')}: p1 to p8\")\n",
    "\n",
    "        for idx, col in enumerate(columns_of_interest[3:]):\n",
    "            ax[1, 1].scatter(\n",
    "                coordinates_dict2_processed[f\"{col}.x\"],\n",
    "                coordinates_dict2_processed[f\"{col}.y\"],\n",
    "                color=colors[idx],\n",
    "                label=col,\n",
    "                s=5,\n",
    "            )\n",
    "\n",
    "        ax[1, 1].set_xlim([x_min, x_max])\n",
    "\n",
    "        ax[1, 1].set_ylim([y_min, y_max])\n",
    "\n",
    "        ax[1, 1].set_xlabel(\"x coordinates (pixels)\")\n",
    "\n",
    "        ax[1, 1].set_ylabel(\"y coordinates (pixels)\")\n",
    "\n",
    "        ax[1, 1].legend(loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.96])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feeeff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit ellipses on the 8 points to determine pupil centre and diameter\n",
    "##########################################################################\n",
    "\n",
    "columns_of_interest = [\n",
    "    \"left.x\",\n",
    "    \"left.y\",\n",
    "    \"center.x\",\n",
    "    \"center.y\",\n",
    "    \"right.x\",\n",
    "    \"right.y\",\n",
    "    \"p1.x\",\n",
    "    \"p1.y\",\n",
    "    \"p2.x\",\n",
    "    \"p2.y\",\n",
    "    \"p3.x\",\n",
    "    \"p3.y\",\n",
    "    \"p4.x\",\n",
    "    \"p4.y\",\n",
    "    \"p5.x\",\n",
    "    \"p5.y\",\n",
    "    \"p6.x\",\n",
    "    \"p6.y\",\n",
    "    \"p7.x\",\n",
    "    \"p7.y\",\n",
    "    \"p8.x\",\n",
    "    \"p8.y\",\n",
    "]\n",
    "\n",
    "# VideoData1 processing\n",
    "if VideoData1_Has_Sleap:\n",
    "    print(\"=== VideoData1 Ellipse Fitting for Pupil Diameter ===\")\n",
    "    coordinates_dict1_processed = lp.get_coordinates_dict(\n",
    "        VideoData1, columns_of_interest\n",
    "    )\n",
    "\n",
    "    theta1 = lp.find_horizontal_axis_angle(VideoData1, \"left\", \"center\")\n",
    "    center_point1 = lp.get_left_right_center_point(coordinates_dict1_processed)\n",
    "\n",
    "    columns_of_interest_reformatted = [\n",
    "        \"left\",\n",
    "        \"right\",\n",
    "        \"center\",\n",
    "        \"p1\",\n",
    "        \"p2\",\n",
    "        \"p3\",\n",
    "        \"p4\",\n",
    "        \"p5\",\n",
    "        \"p6\",\n",
    "        \"p7\",\n",
    "        \"p8\",\n",
    "    ]\n",
    "    remformatted_coordinates_dict1 = lp.get_reformatted_coordinates_dict(\n",
    "        coordinates_dict1_processed, columns_of_interest_reformatted\n",
    "    )\n",
    "    centered_coordinates_dict1 = lp.get_centered_coordinates_dict(\n",
    "        remformatted_coordinates_dict1, center_point1\n",
    "    )\n",
    "    rotated_coordinates_dict1 = lp.get_rotated_coordinates_dict(\n",
    "        centered_coordinates_dict1, theta1\n",
    "    )\n",
    "\n",
    "    columns_of_interest_ellipse = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\", \"p8\"]\n",
    "    ellipse_parameters_data1, ellipse_center_points_data1 = (\n",
    "        lp.get_fitted_ellipse_parameters(\n",
    "            rotated_coordinates_dict1, columns_of_interest_ellipse\n",
    "        )\n",
    "    )\n",
    "\n",
    "    average_diameter1 = np.mean(\n",
    "        [ellipse_parameters_data1[:, 0], ellipse_parameters_data1[:, 1]], axis=0\n",
    "    )\n",
    "\n",
    "    SleapVideoData1 = process.convert_arrays_to_dataframe(\n",
    "        [\n",
    "            \"Seconds\",\n",
    "            \"Ellipse.Diameter\",\n",
    "            \"Ellipse.Angle\",\n",
    "            \"Ellipse.Center.X\",\n",
    "            \"Ellipse.Center.Y\",\n",
    "        ],\n",
    "        [\n",
    "            VideoData1[\"Seconds\"].values,\n",
    "            average_diameter1,\n",
    "            ellipse_parameters_data1[:, 2],\n",
    "            ellipse_center_points_data1[:, 0],\n",
    "            ellipse_center_points_data1[:, 1],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "# VideoData2 processing\n",
    "if VideoData2_Has_Sleap:\n",
    "    print(\"=== VideoData2 Ellipse Fitting for Pupil Diameter ===\")\n",
    "    coordinates_dict2_processed = lp.get_coordinates_dict(\n",
    "        VideoData2, columns_of_interest\n",
    "    )\n",
    "\n",
    "    theta2 = lp.find_horizontal_axis_angle(VideoData2, \"left\", \"center\")\n",
    "    center_point2 = lp.get_left_right_center_point(coordinates_dict2_processed)\n",
    "\n",
    "    columns_of_interest_reformatted = [\n",
    "        \"left\",\n",
    "        \"right\",\n",
    "        \"center\",\n",
    "        \"p1\",\n",
    "        \"p2\",\n",
    "        \"p3\",\n",
    "        \"p4\",\n",
    "        \"p5\",\n",
    "        \"p6\",\n",
    "        \"p7\",\n",
    "        \"p8\",\n",
    "    ]\n",
    "    remformatted_coordinates_dict2 = lp.get_reformatted_coordinates_dict(\n",
    "        coordinates_dict2_processed, columns_of_interest_reformatted\n",
    "    )\n",
    "    centered_coordinates_dict2 = lp.get_centered_coordinates_dict(\n",
    "        remformatted_coordinates_dict2, center_point2\n",
    "    )\n",
    "    rotated_coordinates_dict2 = lp.get_rotated_coordinates_dict(\n",
    "        centered_coordinates_dict2, theta2\n",
    "    )\n",
    "\n",
    "    columns_of_interest_ellipse = [\"p1\", \"p2\", \"p3\", \"p4\", \"p5\", \"p6\", \"p7\", \"p8\"]\n",
    "    ellipse_parameters_data2, ellipse_center_points_data2 = (\n",
    "        lp.get_fitted_ellipse_parameters(\n",
    "            rotated_coordinates_dict2, columns_of_interest_ellipse\n",
    "        )\n",
    "    )\n",
    "\n",
    "    average_diameter2 = np.mean(\n",
    "        [ellipse_parameters_data2[:, 0], ellipse_parameters_data2[:, 1]], axis=0\n",
    "    )\n",
    "\n",
    "    SleapVideoData2 = process.convert_arrays_to_dataframe(\n",
    "        [\n",
    "            \"Seconds\",\n",
    "            \"Ellipse.Diameter\",\n",
    "            \"Ellipse.Angle\",\n",
    "            \"Ellipse.Center.X\",\n",
    "            \"Ellipse.Center.Y\",\n",
    "        ],\n",
    "        [\n",
    "            VideoData2[\"Seconds\"].values,\n",
    "            average_diameter2,\n",
    "            ellipse_parameters_data2[:, 2],\n",
    "            ellipse_center_points_data2[:, 0],\n",
    "            ellipse_center_points_data2[:, 1],\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "# Filter pupil diameter using a user set (default 10) Hz Butterworth low-pass filter\n",
    "##########################################################################\n",
    "\n",
    "# VideoData1 filtering\n",
    "if VideoData1_Has_Sleap:\n",
    "    print(\"\\n=== Filtering pupil diameter for VideoData1  ===\")\n",
    "    # Butterworth filter parameters - pupil_filter_cutoff_hz low-pass filter\n",
    "    # Sampling frequency (Hz)\n",
    "    fs1 = 1 / np.median(np.diff(SleapVideoData1[\"Seconds\"]))\n",
    "    order = pupil_filter_order\n",
    "\n",
    "    b1, a1 = butter(order, pupil_filter_cutoff_hz / (0.5 * fs1), btype=\"low\")\n",
    "\n",
    "    # Handle NaN values before filtering (from blink detection)\n",
    "    # Replace NaN with forward-fill for filtering purposes only (to avoid\n",
    "    # filtfilt issues)\n",
    "    diameter_data = SleapVideoData1[\"Ellipse.Diameter\"].copy()\n",
    "    # Use ffill() and bfill() instead of deprecated fillna(method='ffill')\n",
    "    diameter_data_filled = diameter_data.ffill().bfill()\n",
    "\n",
    "    # Apply Butterworth filter\n",
    "    if not diameter_data_filled.isna().all():\n",
    "        filtered = filtfilt(b1, a1, diameter_data_filled)\n",
    "        # Restore NaN values at original NaN positions (from blinks)\n",
    "        filtered = pd.Series(filtered, index=diameter_data.index)\n",
    "        filtered[diameter_data.isna()] = np.nan\n",
    "        SleapVideoData1[\"Ellipse.Diameter.Filt\"] = filtered\n",
    "    else:\n",
    "        # If all values are NaN, just copy\n",
    "        SleapVideoData1[\"Ellipse.Diameter.Filt\"] = diameter_data\n",
    "\n",
    "# VideoData2 filtering\n",
    "if VideoData2_Has_Sleap:\n",
    "    print(\"=== Filtering pupil diameter for VideoData1 ===\")\n",
    "    # Butterworth filter parameters - pupil_filter_cutoff_hz low-pass filter\n",
    "    # Sampling frequency (Hz)\n",
    "    fs2 = 1 / np.median(np.diff(SleapVideoData2[\"Seconds\"]))\n",
    "    order = pupil_filter_order\n",
    "\n",
    "    b2, a2 = butter(order, pupil_filter_cutoff_hz / (0.5 * fs2), btype=\"low\")\n",
    "\n",
    "    # Handle NaN values before filtering (from blink detection)\n",
    "    # Replace NaN with forward-fill for filtering purposes only (to avoid\n",
    "    # filtfilt issues)\n",
    "    diameter_data = SleapVideoData2[\"Ellipse.Diameter\"].copy()\n",
    "    # Use ffill() and bfill() instead of deprecated fillna(method='ffill')\n",
    "    diameter_data_filled = diameter_data.ffill().bfill()\n",
    "\n",
    "    # Apply Butterworth filter\n",
    "    if not diameter_data_filled.isna().all():\n",
    "        filtered = filtfilt(b2, a2, diameter_data_filled)\n",
    "        # Restore NaN values at original NaN positions (from blinks)\n",
    "        filtered = pd.Series(filtered, index=diameter_data.index)\n",
    "        filtered[diameter_data.isna()] = np.nan\n",
    "        SleapVideoData2[\"Ellipse.Diameter.Filt\"] = filtered\n",
    "    else:\n",
    "        # If all values are NaN, just copy\n",
    "        SleapVideoData2[\"Ellipse.Diameter.Filt\"] = diameter_data\n",
    "\n",
    "print(\"✅ Done calculating pupil diameter and angle for both VideoData1 and VideoData2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f420118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross-correlate pupil diameter for left and right eye\n",
    "##########################################################################\n",
    "\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    # Cross-correlation analysis\n",
    "    print(\"=== Cross-Correlation Analysis ===\")\n",
    "\n",
    "    # Get pupil diameter data\n",
    "    # Use filtered diameter data (with NaN restored at blink positions)\n",
    "    pupil1 = SleapVideoData1[\"Ellipse.Diameter.Filt\"].values\n",
    "    pupil2 = SleapVideoData2[\"Ellipse.Diameter.Filt\"].values\n",
    "\n",
    "    # Handle different lengths by using the shorter dataset length\n",
    "    min_length = min(len(pupil1), len(pupil2))\n",
    "\n",
    "    # Truncate both datasets to the same length (preserving time alignment)\n",
    "    pupil1_truncated = pupil1[:min_length]\n",
    "    pupil2_truncated = pupil2[:min_length]\n",
    "\n",
    "    # Remove NaN values for correlation - preserve time alignment by only keeping pairs where BOTH are valid\n",
    "    # This ensures cross-correlation is computed on temporally aligned data\n",
    "    valid_mask1 = ~np.isnan(pupil1_truncated)\n",
    "    valid_mask2 = ~np.isnan(pupil2_truncated)\n",
    "    # Only use indices where both arrays have valid data\n",
    "    valid_mask = valid_mask1 & valid_mask2\n",
    "\n",
    "    # Extract aligned pairs (preserves temporal alignment)\n",
    "    pupil1_clean = pupil1_truncated[valid_mask]\n",
    "    pupil2_clean = pupil2_truncated[valid_mask]\n",
    "\n",
    "    # Check if we have enough data\n",
    "    if len(pupil1_clean) < 2 or len(pupil2_clean) < 2:\n",
    "        print(\"❌ Error: Not enough valid data points for correlation analysis\")\n",
    "    else:\n",
    "        # Z-score normalize both signals before cross-correlation\n",
    "        # This accounts for different camera magnifications/orientations by comparing relative changes\n",
    "        # Formula: z = (x - mean) / std\n",
    "        pupil1_mean = np.mean(pupil1_clean)\n",
    "        pupil1_std = np.std(pupil1_clean)\n",
    "        pupil2_mean = np.mean(pupil2_clean)\n",
    "        pupil2_std = np.std(pupil2_clean)\n",
    "\n",
    "        if pupil1_std > 0 and pupil2_std > 0:\n",
    "            pupil1_z = (pupil1_clean - pupil1_mean) / pupil1_std\n",
    "            pupil2_z = (pupil2_clean - pupil2_mean) / pupil2_std\n",
    "            print(\n",
    "                \"Applied z-score normalization to pupil diameter signals (accounts for different camera magnifications)\"\n",
    "            )\n",
    "            print(f\"  VideoData1: mean={pupil1_mean:.2f}, std={pupil1_std:.2f}\")\n",
    "            print(f\"  VideoData2: mean={pupil2_mean:.2f}, std={pupil2_std:.2f}\")\n",
    "        else:\n",
    "            print(\n",
    "                \"⚠️ Warning: Zero variance detected, using raw signals (no normalization)\"\n",
    "            )\n",
    "            pupil1_z = pupil1_clean\n",
    "            pupil2_z = pupil2_clean\n",
    "\n",
    "        # Calculate cross-correlation using z-scored signals\n",
    "        try:\n",
    "            correlation = correlate(pupil1_z, pupil2_z, mode=\"full\")\n",
    "\n",
    "            # Calculate lags (in samples)\n",
    "            lags = np.arange(-len(pupil2_z) + 1, len(pupil1_z))\n",
    "\n",
    "            # Convert lags to time (assuming same sampling rate)\n",
    "            dt = np.median(np.diff(SleapVideoData1[\"Seconds\"]))\n",
    "            lag_times = lags * dt\n",
    "\n",
    "            # Find peak correlation and corresponding lag\n",
    "            peak_idx = np.argmax(correlation)\n",
    "            peak_correlation = correlation[peak_idx]\n",
    "            peak_lag_samples = lags[peak_idx]\n",
    "            peak_lag_time = lag_times[peak_idx]\n",
    "            peak_lag_time_display = peak_lag_time  # for final QC figure\n",
    "\n",
    "            print(f\"Peak lag (time): {peak_lag_time:.4f} seconds\")\n",
    "\n",
    "            # Normalize correlation to [-1, 1] range (for z-scored signals,\n",
    "            # this is standard normalization)\n",
    "            norm_factor = np.sqrt(np.sum(pupil1_z**2) * np.sum(pupil2_z**2))\n",
    "            if norm_factor > 0:\n",
    "                correlation_normalized = correlation / norm_factor\n",
    "                peak_correlation_normalized = correlation_normalized[peak_idx]\n",
    "                print(f\"Peak normalized correlation: {peak_correlation_normalized:.4f}\")\n",
    "            else:\n",
    "                print(\"❌ Error: Cannot normalize correlation (zero variance)\")\n",
    "                correlation_normalized = correlation\n",
    "                peak_correlation_normalized = 0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in cross-correlation calculation: {e}\")\n",
    "\n",
    "    # Additional correlation statistics\n",
    "    if len(pupil1_clean) >= 2 and len(pupil2_clean) >= 2:\n",
    "        try:\n",
    "            # Calculate Pearson correlation coefficient on z-scored signals\n",
    "            # Note: For z-scored signals, Pearson correlation is equivalent to\n",
    "            # the normalized cross-correlation at zero lag\n",
    "            pearson_r, pearson_p = pearsonr(pupil1_z, pupil2_z)\n",
    "            pearson_r_display = pearson_r\n",
    "            pearson_p_display = pearson_p\n",
    "\n",
    "            print(\"\\n=== Additional Statistics ===\")\n",
    "            print(f\"Pearson correlation coefficient: {pearson_r:.2f}\")\n",
    "\n",
    "            # Handle extremely small p-values\n",
    "            if pearson_p < 1e-300:\n",
    "                print(\"Pearson p-value: < 1e-300 (extremely significant)\")\n",
    "            else:\n",
    "                print(f\"Pearson p-value: {pearson_p:.5e}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error in additional statistics: {e}\")\n",
    "            pearson_r_display = None\n",
    "            pearson_p_display = None\n",
    "    else:\n",
    "        print(\"❌ Cannot calculate additional statistics - insufficient data\")\n",
    "else:\n",
    "    print(\"Only one eye is present, no pupil diameter cross-correlation can be done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47406885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if Second values match 1:1 between VideoData and SleapVideoData then merge them into VideoData\n",
    "##########################################################################\n",
    "\n",
    "if VideoData1_Has_Sleap is True:\n",
    "    if VideoData1[\"Seconds\"].equals(SleapVideoData1[\"Seconds\"]) is False:\n",
    "        print(\n",
    "            f\"❗ {get_eye_label('VideoData1')}: The 'Seconds' columns DO NOT correspond 1:1 between the two DataFrames. This should not happen\"\n",
    "        )\n",
    "    else:\n",
    "        VideoData1 = VideoData1.merge(SleapVideoData1, on=\"Seconds\", how=\"outer\")\n",
    "        del SleapVideoData1\n",
    "        # CRITICAL FIX: Validate frame_idx after merge\n",
    "        if \"frame_idx\" in VideoData1.columns:\n",
    "            if VideoData1['frame_idx'].duplicated().any():\n",
    "                dup_count = VideoData1['frame_idx'].duplicated().sum()\n",
    "                print(f\"   ⚠️ WARNING: VideoData1 has {dup_count} duplicate frame_idx values after merge with SleapVideoData1!\")\n",
    "                print(f\"      This should not happen. Frame_idx should be unique.\")\n",
    "            if not VideoData1['frame_idx'].is_monotonic_increasing:\n",
    "                print(f\"   ⚠️ WARNING: VideoData1 frame_idx is not monotonic after merge with SleapVideoData1!\")\n",
    "                print(f\"      This should not happen. Frame_idx should be strictly increasing.\")\n",
    "\n",
    "if VideoData2_Has_Sleap is True:\n",
    "    if VideoData2[\"Seconds\"].equals(SleapVideoData2[\"Seconds\"]) is False:\n",
    "        print(\n",
    "            f\"❗ {get_eye_label('VideoData2')}: The 'Seconds' columns DO NOT correspond 1:1 between the two DataFrames. This should not happen\"\n",
    "        )\n",
    "    else:\n",
    "        VideoData2 = VideoData2.merge(SleapVideoData2, on=\"Seconds\", how=\"outer\")\n",
    "        del SleapVideoData2\n",
    "        # CRITICAL FIX: Validate frame_idx after merge\n",
    "        if \"frame_idx\" in VideoData2.columns:\n",
    "            if VideoData2['frame_idx'].duplicated().any():\n",
    "                dup_count = VideoData2['frame_idx'].duplicated().sum()\n",
    "                print(f\"   ⚠️ WARNING: VideoData2 has {dup_count} duplicate frame_idx values after merge with SleapVideoData2!\")\n",
    "                print(f\"      This should not happen. Frame_idx should be unique.\")\n",
    "            if not VideoData2['frame_idx'].is_monotonic_increasing:\n",
    "                print(f\"   ⚠️ WARNING: VideoData2 frame_idx is not monotonic after merge with SleapVideoData2!\")\n",
    "                print(f\"      This should not happen. Frame_idx should be strictly increasing.\")\n",
    "gc.collect()\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf39696",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Compare SLEAP center.x and .y with fitted ellipse centre distributions for both VideoData1 and VideoData2\n",
    "##########################################################################\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1) Compute correlations for VideoData1\n",
    "# ------------------------------------------------------------------\n",
    "if VideoData1_Has_Sleap is True:\n",
    "    print(\"=== VideoData1 Analysis ===\")\n",
    "    slope_x1, intercept_x1, r_value_x1, p_value_x1, std_err_x1 = linregress(\n",
    "        VideoData1[\"Ellipse.Center.X\"], VideoData1[\"center.x\"]\n",
    "    )\n",
    "    r_squared_x1 = r_value_x1**2\n",
    "    print(\n",
    "        f\"{get_eye_label('VideoData1')} - R^2 between center point and ellipse center X data: {r_squared_x1:.4f}\"\n",
    "    )\n",
    "\n",
    "    slope_y1, intercept_y1, r_value_y1, p_value_y1, std_err_y1 = linregress(\n",
    "        VideoData1[\"Ellipse.Center.Y\"], VideoData1[\"center.y\"]\n",
    "    )\n",
    "    r_squared_y1 = r_value_y1**2\n",
    "    print(\n",
    "        f\"{get_eye_label('VideoData1')} - R^2 between center point and ellipse center Y data: {r_squared_y1:.4f}\"\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2) Compute correlations for VideoData2\n",
    "# ------------------------------------------------------------------\n",
    "if VideoData2_Has_Sleap is True:\n",
    "    print(\"\\n=== VideoData2 Analysis ===\")\n",
    "    slope_x2, intercept_x2, r_value_x2, p_value_x2, std_err_x2 = linregress(\n",
    "        VideoData2[\"Ellipse.Center.X\"], VideoData2[\"center.x\"]\n",
    "    )\n",
    "    r_squared_x2 = r_value_x2**2\n",
    "    print(\n",
    "        f\"{get_eye_label('VideoData2')} - R^2 between center point and ellipse center X data: {r_squared_x2:.4f}\"\n",
    "    )\n",
    "\n",
    "    slope_y2, intercept_y2, r_value_y2, p_value_y2, std_err_y2 = linregress(\n",
    "        VideoData2[\"Ellipse.Center.Y\"], VideoData2[\"center.y\"]\n",
    "    )\n",
    "    r_squared_y2 = r_value_y2**2\n",
    "    print(\n",
    "        f\"{get_eye_label('VideoData2')} - R^2 between center point and ellipse center Y data: {r_squared_y2:.4f}\"\n",
    "    )\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3) Center of Mass Analysis (if both VideoData1 and VideoData2 are available)\n",
    "# ------------------------------------------------------------------\n",
    "if VideoData1_Has_Sleap is True and VideoData2_Has_Sleap is True:\n",
    "    print(\"\\n=== Center of Mass Distance Analysis ===\")\n",
    "\n",
    "    # Calculate center of mass (mean) for VideoData1\n",
    "    com_center_x1 = VideoData1[\"center.x\"].mean()\n",
    "    com_center_y1 = VideoData1[\"center.y\"].mean()\n",
    "    com_ellipse_x1 = VideoData1[\"Ellipse.Center.X\"].mean()\n",
    "    com_ellipse_y1 = VideoData1[\"Ellipse.Center.Y\"].mean()\n",
    "\n",
    "    # Calculate absolute distances for VideoData1\n",
    "\n",
    "    dist_x1 = abs(com_center_x1 - com_ellipse_x1)\n",
    "\n",
    "    dist_y1 = abs(com_center_y1 - com_ellipse_y1)\n",
    "\n",
    "    print(f\"\\n{get_eye_label('VideoData1')}:\")\n",
    "\n",
    "    print(\n",
    "        f\"  Center of mass for center.x/y: ({com_center_x1:.4f}, {com_center_y1:.4f})\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"  Center of mass for Ellipse.Center.X/Y: ({com_ellipse_x1:.4f}, {com_ellipse_y1:.4f})\"\n",
    "    )\n",
    "\n",
    "    print(f\"  Absolute distance in X: {dist_x1:.4f} pixels\")\n",
    "\n",
    "    print(f\"  Absolute distance in Y: {dist_y1:.4f} pixels\")\n",
    "\n",
    "    # Calculate center of mass (mean) for VideoData2\n",
    "\n",
    "    com_center_x2 = VideoData2[\"center.x\"].mean()\n",
    "\n",
    "    com_center_y2 = VideoData2[\"center.y\"].mean()\n",
    "\n",
    "    com_ellipse_x2 = VideoData2[\"Ellipse.Center.X\"].mean()\n",
    "\n",
    "    com_ellipse_y2 = VideoData2[\"Ellipse.Center.Y\"].mean()\n",
    "\n",
    "    # Calculate absolute distances for VideoData2\n",
    "\n",
    "    dist_x2 = abs(com_center_x2 - com_ellipse_x2)\n",
    "\n",
    "    dist_y2 = abs(com_center_y2 - com_ellipse_y2)\n",
    "\n",
    "    print(f\"\\n{get_eye_label('VideoData2')}:\")\n",
    "\n",
    "    print(\n",
    "        f\"  Center of mass for center.x/y: ({com_center_x2:.4f}, {com_center_y2:.4f})\"\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        f\"  Center of mass for Ellipse.Center.X/Y: ({com_ellipse_x2:.4f}, {com_ellipse_y2:.4f})\"\n",
    "    )\n",
    "\n",
    "    print(f\"  Absolute distance in X: {dist_x2:.4f} pixels\")\n",
    "\n",
    "    print(f\"  Absolute distance in Y: {dist_y2:.4f} pixels\")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4) Re-center Ellipse.Center.X and Ellipse.Center.Y using median\n",
    "# ------------------------------------------------------------------\n",
    "print(\"\\n=== Re-centering Ellipse.Center coordinates ===\")\n",
    "\n",
    "\n",
    "# Re-center VideoData1 Ellipse.Center coordinates\n",
    "\n",
    "if VideoData1_Has_Sleap is True:\n",
    "    # Calculate median\n",
    "    median_ellipse_x1 = VideoData1[\"Ellipse.Center.X\"].median()\n",
    "    median_ellipse_y1 = VideoData1[\"Ellipse.Center.Y\"].median()\n",
    "\n",
    "    # Center the coordinates\n",
    "    VideoData1[\"Ellipse.Center.X\"] = VideoData1[\"Ellipse.Center.X\"] - median_ellipse_x1\n",
    "    VideoData1[\"Ellipse.Center.Y\"] = VideoData1[\"Ellipse.Center.Y\"] - median_ellipse_y1\n",
    "\n",
    "    print(\n",
    "        f\"{get_eye_label('VideoData1')} - Re-centered Ellipse.Center using median: ({median_ellipse_x1:.4f}, {median_ellipse_y1:.4f})\"\n",
    "    )\n",
    "\n",
    "# Re-center VideoData2 Ellipse.Center coordinates\n",
    "if VideoData2_Has_Sleap is True:\n",
    "    # Calculate median\n",
    "    median_ellipse_x2 = VideoData2[\"Ellipse.Center.X\"].median()\n",
    "    median_ellipse_y2 = VideoData2[\"Ellipse.Center.Y\"].median()\n",
    "\n",
    "    # Center the coordinates\n",
    "    VideoData2[\"Ellipse.Center.X\"] = VideoData2[\"Ellipse.Center.X\"] - median_ellipse_x2\n",
    "    VideoData2[\"Ellipse.Center.Y\"] = VideoData2[\"Ellipse.Center.Y\"] - median_ellipse_y2\n",
    "\n",
    "    print(\n",
    "        f\"{get_eye_label('VideoData2')} - Re-centered Ellipse.Center using median: ({median_ellipse_x2:.4f}, {median_ellipse_y2:.4f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb2c2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make and save summary QC plot using matplotlib with scatter plots for 2D\n",
    "# distributions\n",
    "\n",
    "# Initialize the statistics variables (these are calculated in Cell 11)\n",
    "try:\n",
    "    pearson_r_display\n",
    "except NameError:\n",
    "    pearson_r_display = None\n",
    "    pearson_p_display = None\n",
    "    peak_lag_time_display = None\n",
    "    print(\"⚠️ Note: Statistics not found. They should be calculated in Cell 11.\")\n",
    "\n",
    "# Visualization and statistics calculation (only if plot_QC_timeseries is True)\n",
    "if plot_QC_timeseries:\n",
    "    # Calculate correlation for Ellipse.Center.X between VideoData1 and\n",
    "    # VideoData2 (if both exist)\n",
    "    pearson_r_center = None\n",
    "    pearson_p_center = None\n",
    "    peak_lag_time_center = None\n",
    "else:\n",
    "    pearson_r_center = None\n",
    "    pearson_p_center = None\n",
    "    peak_lag_time_center = None\n",
    "\n",
    "\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    # Get the Center.X data\n",
    "    center_x1 = VideoData1[\"Ellipse.Center.X\"].values\n",
    "    center_x2 = VideoData2[\"Ellipse.Center.X\"].values\n",
    "    min_length = min(len(center_x1), len(center_x2))\n",
    "    center_x1_truncated = center_x1[:min_length]\n",
    "    center_x2_truncated = center_x2[:min_length]\n",
    "    valid_mask1 = ~np.isnan(center_x1_truncated)\n",
    "    valid_mask2 = ~np.isnan(center_x2_truncated)\n",
    "    valid_mask = valid_mask1 & valid_mask2\n",
    "    center_x1_clean = center_x1_truncated[valid_mask]\n",
    "    center_x2_clean = center_x2_truncated[valid_mask]\n",
    "\n",
    "    if len(center_x1_clean) >= 2 and len(center_x2_clean) >= 2:\n",
    "        try:\n",
    "            # Calculate Pearson correlation\n",
    "            pearson_r_center, pearson_p_center = pearsonr(\n",
    "                center_x1_clean, center_x2_clean\n",
    "            )\n",
    "            # Calculate cross-correlation for peak lag\n",
    "            correlation = correlate(center_x1_clean, center_x2_clean, mode=\"full\")\n",
    "            lags = np.arange(-len(center_x2_clean) + 1, len(center_x1_clean))\n",
    "            dt = np.median(np.diff(VideoData1[\"Seconds\"]))\n",
    "            lag_times = lags * dt\n",
    "            peak_idx = np.argmax(correlation)\n",
    "            peak_lag_time_center = lag_times[peak_idx]\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error calculating Ellipse.Center.X correlation stats: {e}\")\n",
    "\n",
    "\n",
    "# Create the QC summary figure using matplotlib with custom grid layout\n",
    "fig = plt.figure(figsize=(20, 18))\n",
    "fig.suptitle(str(data_path), fontsize=16, y=0.995)\n",
    "\n",
    "# Create a grid layout:\n",
    "# - Top row (full width): VideoData1 Time Series\n",
    "# - Second row (full width): VideoData2 Time Series\n",
    "# - Third row (two columns): 2D scatter plots (VideoData1 left, VideoData2 right)\n",
    "# - Fourth row (two columns): Pupil diameter (left), Ellipse.Center.X correlation (right)\n",
    "\n",
    "gs = fig.add_gridspec(4, 2, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Panel 1: VideoData1 center coordinates - Time Series (full width)\n",
    "if VideoData1_Has_Sleap:\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(\n",
    "        VideoData1_centered[\"Seconds\"],\n",
    "        VideoData1_centered[\"center.x\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"blue\",\n",
    "        alpha=0.6,\n",
    "        label=\"center.x original\",\n",
    "    )\n",
    "    ax1.plot(\n",
    "        VideoData1[\"Seconds\"],\n",
    "        VideoData1[\"Ellipse.Center.X\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"red\",\n",
    "        alpha=0.6,\n",
    "        label=\"Ellipse Center.X\",\n",
    "    )\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "    ax1.set_ylabel(\"Position (pixels)\")\n",
    "    ax1.set_title(f\"{get_eye_label('VideoData1')} - center.X Time Series\")\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 2: VideoData2 center coordinates - Time Series (full width)\n",
    "if VideoData2_Has_Sleap:\n",
    "    ax2 = fig.add_subplot(gs[1, :])\n",
    "    ax2.plot(\n",
    "        VideoData2_centered[\"Seconds\"],\n",
    "        VideoData2_centered[\"center.x\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"blue\",\n",
    "        alpha=0.6,\n",
    "        label=\"center.x original\",\n",
    "    )\n",
    "    ax2.plot(\n",
    "        VideoData2[\"Seconds\"],\n",
    "        VideoData2[\"Ellipse.Center.X\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"red\",\n",
    "        alpha=0.6,\n",
    "        label=\"Ellipse Center.X\",\n",
    "    )\n",
    "    ax2.set_xlabel(\"Time (s)\")\n",
    "    ax2.set_ylabel(\"Position (pixels)\")\n",
    "    ax2.set_title(f\"{get_eye_label('VideoData2')} - center.X Time Series\")\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Panel 3: VideoData1 center coordinates - Scatter plot (left half)\n",
    "if VideoData1_Has_Sleap:\n",
    "    ax3 = fig.add_subplot(gs[2, 0])\n",
    "\n",
    "    # Ellipse.Center (blue)\n",
    "    x_ellipse1 = VideoData1[\"Ellipse.Center.X\"].to_numpy()\n",
    "    y_ellipse1 = VideoData1[\"Ellipse.Center.Y\"].to_numpy()\n",
    "    mask1 = ~(np.isnan(x_ellipse1) | np.isnan(y_ellipse1))\n",
    "\n",
    "    ax3.scatter(\n",
    "        x_ellipse1[mask1],\n",
    "        y_ellipse1[mask1],\n",
    "        s=1,\n",
    "        alpha=0.3,\n",
    "        c=\"blue\",\n",
    "        label=\"Ellipse.Center\",\n",
    "    )\n",
    "\n",
    "    # Center (red) - from centered data\n",
    "    x_center1 = VideoData1_centered[\"center.x\"].to_numpy()\n",
    "    y_center1 = VideoData1_centered[\"center.y\"].to_numpy()\n",
    "    mask2 = ~(np.isnan(x_center1) | np.isnan(y_center1))\n",
    "\n",
    "    ax3.scatter(\n",
    "        x_center1[mask2],\n",
    "        y_center1[mask2],\n",
    "        s=1,\n",
    "        alpha=0.3,\n",
    "        c=\"red\",\n",
    "        label=\"center.x original\",\n",
    "    )\n",
    "\n",
    "    ax3.set_xlabel(\"Center X (pixels)\")\n",
    "    ax3.set_ylabel(\"Center Y (pixels)\")\n",
    "    ax3.set_title(\n",
    "        f\"{get_eye_label('VideoData1')} - Center X-Y Distribution (center.X vs Ellipse)\"\n",
    "    )\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add R² statistics for VideoData1 (bottom left)\n",
    "    try:\n",
    "        if \"r_squared_x1\" in globals() and \"r_squared_y1\" in globals():\n",
    "            stats_text = f\"R² X: {r_squared_x1:.2g}\\nR² Y: {r_squared_y1:.2g}\"\n",
    "            ax3.text(\n",
    "                0.02,\n",
    "                0.02,\n",
    "                stats_text,\n",
    "                transform=ax3.transAxes,\n",
    "                verticalalignment=\"bottom\",\n",
    "                horizontalalignment=\"left\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    "                fontsize=9,\n",
    "                family=\"monospace\",\n",
    "            )\n",
    "    except BaseException:\n",
    "        pass\n",
    "\n",
    "    # Add center of mass distance for VideoData1 (bottom right)\n",
    "    try:\n",
    "        if \"dist_x1\" in globals() and \"dist_y1\" in globals():\n",
    "            distance_text = f\"COM Dist X: {dist_x1:.3g}\\nCOM Dist Y: {dist_y1:.3g}\"\n",
    "            ax3.text(\n",
    "                0.98,\n",
    "                0.02,\n",
    "                distance_text,\n",
    "                transform=ax3.transAxes,\n",
    "                verticalalignment=\"bottom\",\n",
    "                horizontalalignment=\"right\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.8),\n",
    "                fontsize=9,\n",
    "                family=\"monospace\",\n",
    "            )\n",
    "    except BaseException:\n",
    "        pass\n",
    "\n",
    "# Panel 4: VideoData2 center coordinates - Scatter plot (right half)\n",
    "if VideoData2_Has_Sleap:\n",
    "    ax4 = fig.add_subplot(gs[2, 1])\n",
    "\n",
    "    # Ellipse.Center (blue)\n",
    "    x_ellipse2 = VideoData2[\"Ellipse.Center.X\"].to_numpy()\n",
    "    y_ellipse2 = VideoData2[\"Ellipse.Center.Y\"].to_numpy()\n",
    "    mask3 = ~(np.isnan(x_ellipse2) | np.isnan(y_ellipse2))\n",
    "\n",
    "    ax4.scatter(\n",
    "        x_ellipse2[mask3],\n",
    "        y_ellipse2[mask3],\n",
    "        s=1,\n",
    "        alpha=0.3,\n",
    "        c=\"blue\",\n",
    "        label=\"Ellipse.Center\",\n",
    "    )\n",
    "\n",
    "    # Center (red) - from centered data\n",
    "    x_center2 = VideoData2_centered[\"center.x\"].to_numpy()\n",
    "    y_center2 = VideoData2_centered[\"center.y\"].to_numpy()\n",
    "    mask4 = ~(np.isnan(x_center2) | np.isnan(y_center2))\n",
    "\n",
    "    ax4.scatter(\n",
    "        x_center2[mask4],\n",
    "        y_center2[mask4],\n",
    "        s=1,\n",
    "        alpha=0.3,\n",
    "        c=\"red\",\n",
    "        label=\"center.X Center\",\n",
    "    )\n",
    "\n",
    "    ax4.set_xlabel(\"Center X (pixels)\")\n",
    "    ax4.set_ylabel(\"Center Y (pixels)\")\n",
    "    ax4.set_title(\n",
    "        f\"{get_eye_label('VideoData2')} - Center X-Y Distribution (center.X vs Ellipse)\"\n",
    "    )\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "\n",
    "    # Add R² statistics for VideoData2 (bottom left)\n",
    "    try:\n",
    "        if \"r_squared_x2\" in globals() and \"r_squared_y2\" in globals():\n",
    "            stats_text = f\"R² X: {r_squared_x2:.2g}\\nR² Y: {r_squared_y2:.2g}\"\n",
    "            ax4.text(\n",
    "                0.02,\n",
    "                0.02,\n",
    "                stats_text,\n",
    "                transform=ax4.transAxes,\n",
    "                verticalalignment=\"bottom\",\n",
    "                horizontalalignment=\"left\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    "                fontsize=9,\n",
    "                family=\"monospace\",\n",
    "            )\n",
    "    except BaseException:\n",
    "        pass\n",
    "\n",
    "    # Add center of mass distance for VideoData2 (bottom right)\n",
    "    try:\n",
    "        if \"dist_x2\" in globals() and \"dist_y2\" in globals():\n",
    "            distance_text = f\"COM Dist X: {dist_x2:.3g}\\nCOM Dist Y: {dist_y2:.3g}\"\n",
    "            ax4.text(\n",
    "                0.98,\n",
    "                0.02,\n",
    "                distance_text,\n",
    "                transform=ax4.transAxes,\n",
    "                verticalalignment=\"bottom\",\n",
    "                horizontalalignment=\"right\",\n",
    "                bbox=dict(boxstyle=\"round\", facecolor=\"lightblue\", alpha=0.8),\n",
    "                fontsize=9,\n",
    "                family=\"monospace\",\n",
    "            )\n",
    "    except BaseException:\n",
    "        pass\n",
    "\n",
    "# Panel 5: Pupil diameter comparison (bottom left)\n",
    "ax5 = fig.add_subplot(gs[3, 0])\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    ax5.plot(\n",
    "        VideoData1[\"Seconds\"],\n",
    "        VideoData1[\"Ellipse.Diameter.Filt\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"#FF7F00\",\n",
    "        alpha=0.6,\n",
    "        label=\"VideoData1 Diameter\",\n",
    "    )\n",
    "    ax5.plot(\n",
    "        VideoData2[\"Seconds\"],\n",
    "        VideoData2[\"Ellipse.Diameter.Filt\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"#9370DB\",\n",
    "        alpha=0.6,\n",
    "        label=\"VideoData2 Diameter\",\n",
    "    )\n",
    "elif VideoData1_Has_Sleap:\n",
    "    ax5.plot(\n",
    "        VideoData1[\"Seconds\"],\n",
    "        VideoData1[\"Ellipse.Diameter.Filt\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"#FF7F00\",\n",
    "        alpha=0.6,\n",
    "        label=\"VideoData1 Diameter\",\n",
    "    )\n",
    "elif VideoData2_Has_Sleap:\n",
    "    ax5.plot(\n",
    "        VideoData2[\"Seconds\"],\n",
    "        VideoData2[\"Ellipse.Diameter.Filt\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"#9370DB\",\n",
    "        alpha=0.6,\n",
    "        label=\"VideoData2 Diameter\",\n",
    "    )\n",
    "\n",
    "ax5.set_xlabel(\"Time (s)\")\n",
    "ax5.set_ylabel(\"Diameter (pixels)\")\n",
    "ax5.set_title(\"Pupil Diameter Comparison\")\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics text to Panel 5\n",
    "if (\n",
    "    pearson_r_display is not None\n",
    "    and pearson_p_display is not None\n",
    "    and peak_lag_time_display is not None\n",
    "):\n",
    "    stats_text = (\n",
    "        f\"Pearson r = {pearson_r_display:.4f}\\n\"\n",
    "        f\"Pearson p = {pearson_p_display:.4e}\\n\"\n",
    "        f\"Peak lag = {peak_lag_time_display:.4f} s\"\n",
    "    )\n",
    "    ax5.text(\n",
    "        0.98,\n",
    "        0.98,\n",
    "        stats_text,\n",
    "        transform=ax5.transAxes,\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"right\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    "        fontsize=10,\n",
    "        family=\"monospace\",\n",
    "    )\n",
    "else:\n",
    "    ax5.text(\n",
    "        0.5,\n",
    "        0.5,\n",
    "        \"Statistics not available\\n(See Cell 11 for correlation analysis)\",\n",
    "        transform=ax5.transAxes,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Panel 6: Ellipse.Center.X comparison (bottom right) with dual y-axis\n",
    "ax6 = fig.add_subplot(gs[3, 1])\n",
    "ax6_twin = ax6.twinx()  # Create a second y-axis\n",
    "\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    # Plot the individual traces\n",
    "    ax6.plot(\n",
    "        VideoData1[\"Seconds\"],\n",
    "        VideoData1[\"Ellipse.Center.X\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"#FF7F00\",\n",
    "        alpha=0.6,\n",
    "        label=\"VideoData1 Ellipse.Center.X\",\n",
    "    )\n",
    "    ax6.plot(\n",
    "        VideoData2[\"Seconds\"],\n",
    "        VideoData2[\"Ellipse.Center.X\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"#9370DB\",\n",
    "        alpha=0.6,\n",
    "        label=\"VideoData2 Ellipse.Center.X\",\n",
    "    )\n",
    "\n",
    "    # Plot the difference on the right axis\n",
    "    # Align the data to the same length and normalize for fair comparison\n",
    "    min_length = min(len(VideoData1), len(VideoData2))\n",
    "\n",
    "    # Normalize data (z-score) to account for different scales\n",
    "    center_x1_aligned = VideoData1[\"Ellipse.Center.X\"].iloc[:min_length]\n",
    "    center_x2_aligned = VideoData2[\"Ellipse.Center.X\"].iloc[:min_length]\n",
    "\n",
    "    # Calculate mean and std for normalization\n",
    "    mean1 = center_x1_aligned.mean()\n",
    "    std1 = center_x1_aligned.std()\n",
    "    mean2 = center_x2_aligned.mean()\n",
    "    std2 = center_x2_aligned.std()\n",
    "\n",
    "    # Normalize both datasets\n",
    "    center_x1_norm = (center_x1_aligned - mean1) / std1\n",
    "    center_x2_norm = (center_x2_aligned - mean2) / std2\n",
    "\n",
    "    # Calculate difference of normalized data\n",
    "    center_x_diff = center_x1_norm - center_x2_norm\n",
    "    seconds_aligned = VideoData1[\"Seconds\"].iloc[:min_length]\n",
    "    ax6_twin.plot(\n",
    "        seconds_aligned,\n",
    "        center_x_diff,\n",
    "        linewidth=0.5,\n",
    "        c=\"green\",\n",
    "        alpha=0.6,\n",
    "        label=\"Difference (normalized)\",\n",
    "    )\n",
    "\n",
    "elif VideoData1_Has_Sleap:\n",
    "    ax6.plot(\n",
    "        VideoData1[\"Seconds\"],\n",
    "        VideoData1[\"Ellipse.Center.X\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"#FF7F00\",\n",
    "        alpha=0.6,\n",
    "        label=\"VideoData1 Ellipse.Center.X\",\n",
    "    )\n",
    "elif VideoData2_Has_Sleap:\n",
    "    ax6.plot(\n",
    "        VideoData2[\"Seconds\"],\n",
    "        VideoData2[\"Ellipse.Center.X\"],\n",
    "        linewidth=0.5,\n",
    "        c=\"#9370DB\",\n",
    "        alpha=0.6,\n",
    "        label=\"VideoData2 Ellipse.Center.X\",\n",
    "    )\n",
    "\n",
    "ax6.set_xlabel(\"Time (s)\")\n",
    "ax6.set_ylabel(\"Center X (pixels)\", color=\"black\")\n",
    "ax6.set_title(\"Ellipse.Center.X Comparison\")\n",
    "ax6.tick_params(axis=\"y\", labelcolor=\"black\")\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    ax6_twin.set_ylabel(\"Normalized Difference (z-score)\", color=\"green\")\n",
    "    ax6_twin.tick_params(axis=\"y\", labelcolor=\"green\")\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines1, labels1 = ax6.get_legend_handles_labels()\n",
    "if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "    lines2, labels2 = ax6_twin.get_legend_handles_labels()\n",
    "    ax6.legend(lines1 + lines2, labels1 + labels2, loc=\"upper left\")\n",
    "else:\n",
    "    ax6.legend(loc=\"upper left\")\n",
    "\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistics text to Panel 6\n",
    "if (\n",
    "    pearson_r_center is not None\n",
    "    and pearson_p_center is not None\n",
    "    and peak_lag_time_center is not None\n",
    "):\n",
    "    stats_text = (\n",
    "        f\"Pearson r = {pearson_r_center:.4f}\\n\"\n",
    "        f\"Pearson p = {pearson_p_center:.4e}\\n\"\n",
    "        f\"Peak lag = {peak_lag_time_center:.4f} s\"\n",
    "    )\n",
    "    ax6.text(\n",
    "        0.98,\n",
    "        0.98,\n",
    "        stats_text,\n",
    "        transform=ax6.transAxes,\n",
    "        verticalalignment=\"top\",\n",
    "        horizontalalignment=\"right\",\n",
    "        bbox=dict(boxstyle=\"round\", facecolor=\"wheat\", alpha=0.8),\n",
    "        fontsize=10,\n",
    "        family=\"monospace\",\n",
    "    )\n",
    "else:\n",
    "    ax6.text(\n",
    "        0.5,\n",
    "        0.5,\n",
    "        \"Statistics not available\\n(both eyes required)\",\n",
    "        transform=ax6.transAxes,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=10,\n",
    "    )\n",
    "\n",
    "# Save as PDF (editable vector format)\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "pdf_path = qc_debug_dir / \"Eye_data_QC.pdf\"\n",
    "plt.savefig(pdf_path, dpi=300, bbox_inches=\"tight\", format=\"pdf\")\n",
    "print(f\"✅ QC figure saved as PDF (editable): {pdf_path}\")\n",
    "\n",
    "# Also save as 600 dpi PNG (high-resolution for printing)\n",
    "png_path = qc_debug_dir / \"Eye_data_QC.png\"\n",
    "plt.savefig(png_path, dpi=600, bbox_inches=\"tight\", format=\"png\")\n",
    "print(f\"✅ QC figure saved as PNG (600 dpi for printing): {png_path}\")\n",
    "\n",
    "if plot_QC_timeseries:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916d17d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive time series plots using plotly for browser viewing\n",
    "if plot_QC_timeseries:\n",
    "    # Create subplots for the time series (3 rows now instead of 2)\n",
    "    # Need to enable secondary_y for the third panel\n",
    "    fig = make_subplots(\n",
    "        rows=3,\n",
    "        cols=1,\n",
    "        shared_xaxes=True,\n",
    "        vertical_spacing=0.08,\n",
    "        subplot_titles=(\n",
    "            f\"{get_eye_label('VideoData1')} - center.X Time Series\",\n",
    "            f\"{get_eye_label('VideoData2')} - center.X Time Series\",\n",
    "            \"Ellipse.Center.X Comparison with Difference\",\n",
    "        ),\n",
    "        # Enable secondary_y for row 3\n",
    "        specs=[[{}], [{}], [{\"secondary_y\": True}]],\n",
    "    )\n",
    "\n",
    "    # Panel 1: VideoData1 center coordinates - Time Series\n",
    "    if VideoData1_Has_Sleap:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1_centered[\"Seconds\"],\n",
    "                y=VideoData1_centered[\"center.x\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"center.x original\",\n",
    "                line=dict(color=\"blue\", width=0.5),\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"Ellipse.Center.X\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Ellipse Center.X\",\n",
    "                line=dict(color=\"red\", width=0.5),\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    # Panel 2: VideoData2 center coordinates - Time Series\n",
    "    if VideoData2_Has_Sleap:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2_centered[\"Seconds\"],\n",
    "                y=VideoData2_centered[\"center.x\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"center.x original\",\n",
    "                line=dict(color=\"blue\", width=0.5),\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"Ellipse.Center.X\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Ellipse Center.X\",\n",
    "                line=dict(color=\"red\", width=0.5),\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    # Panel 3: Ellipse.Center.X Comparison with difference\n",
    "    if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "        # Plot the individual traces\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"Ellipse.Center.X\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"VideoData1 Ellipse.Center.X\",\n",
    "                line=dict(color=\"#FF7F00\", width=0.5),  # Orange\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=3,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"Ellipse.Center.X\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"VideoData2 Ellipse.Center.X\",\n",
    "                line=dict(color=\"#9370DB\", width=0.5),  # Purple\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=3,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Plot the difference on secondary y-axis\n",
    "        # Align the data to the same length and normalize for fair comparison\n",
    "        min_length = min(len(VideoData1), len(VideoData2))\n",
    "\n",
    "        # Normalize data (z-score) to account for different scales\n",
    "        center_x1_aligned = VideoData1[\"Ellipse.Center.X\"].iloc[:min_length]\n",
    "        center_x2_aligned = VideoData2[\"Ellipse.Center.X\"].iloc[:min_length]\n",
    "\n",
    "        # Calculate mean and std for normalization\n",
    "        mean1 = center_x1_aligned.mean()\n",
    "        std1 = center_x1_aligned.std()\n",
    "        mean2 = center_x2_aligned.mean()\n",
    "        std2 = center_x2_aligned.std()\n",
    "\n",
    "        # Normalize both datasets\n",
    "        center_x1_norm = (center_x1_aligned - mean1) / std1\n",
    "        center_x2_norm = (center_x2_aligned - mean2) / std2\n",
    "\n",
    "        # Calculate difference of normalized data\n",
    "        center_x_diff = center_x1_norm - center_x2_norm\n",
    "        seconds_aligned = VideoData1[\"Seconds\"].iloc[:min_length]\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=seconds_aligned,\n",
    "                y=center_x_diff,\n",
    "                mode=\"lines\",\n",
    "                name=\"Difference (normalized)\",\n",
    "                line=dict(color=\"green\", width=0.5),\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=3,\n",
    "            col=1,\n",
    "            secondary_y=True,\n",
    "        )\n",
    "\n",
    "    elif VideoData1_Has_Sleap:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData1[\"Seconds\"],\n",
    "                y=VideoData1[\"Ellipse.Center.X\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"VideoData1 Ellipse.Center.X\",\n",
    "                line=dict(color=\"#FF7F00\", width=0.5),\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=3,\n",
    "            col=1,\n",
    "        )\n",
    "    elif VideoData2_Has_Sleap:\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=VideoData2[\"Seconds\"],\n",
    "                y=VideoData2[\"Ellipse.Center.X\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"VideoData2 Ellipse.Center.X\",\n",
    "                line=dict(color=\"#9370DB\", width=0.5),\n",
    "                opacity=0.6,\n",
    "            ),\n",
    "            row=3,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        height=1200,  # Increased height for 3 panels\n",
    "        title_text=f\"{data_path} - Eye Tracking Time Series QC\",\n",
    "        showlegend=True,\n",
    "        hovermode=\"x unified\",\n",
    "    )\n",
    "\n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text=\"Time (s)\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Position (pixels)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Position (pixels)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Center X (pixels)\", row=3, col=1)\n",
    "\n",
    "    # Update secondary y-axis for difference plot\n",
    "    if VideoData1_Has_Sleap and VideoData2_Has_Sleap:\n",
    "        fig.update_yaxes(\n",
    "            title_text=\"Normalized Difference (z-score)\", row=3, col=1, secondary_y=True\n",
    "        )\n",
    "\n",
    "    # Show in browser\n",
    "    fig.show(renderer=\"browser\")\n",
    "\n",
    "    # Also save as HTML\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    html_path = qc_debug_dir / \"Eye_data_QC_time_series.html\"\n",
    "    fig.write_html(html_path)\n",
    "    print(f\"✅ Interactive time series plot saved to: {html_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00048661",
   "metadata": {},
   "source": [
    "# Saccade detection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3265ec25",
   "metadata": {},
   "outputs": [],
   "source": [
    "saccade_results = {}\n",
    "\n",
    "# Helper: map detected directions (upward/downward) to NT/TN based on eye assignment\n",
    "# Left eye: upward→NT, downward→TN; Right eye: upward→TN, downward→NT\n",
    "\n",
    "\n",
    "def get_direction_map_for_video(video_key):\n",
    "    eye = video1_eye if video_key == \"VideoData1\" else video2_eye\n",
    "    if eye == \"L\":\n",
    "        return {\"upward\": \"NT\", \"downward\": \"TN\"}\n",
    "    else:\n",
    "        return {\"upward\": \"TN\", \"downward\": \"NT\"}\n",
    "\n",
    "\n",
    "def get_eye_code_for_video(video_key):\n",
    "    \"\"\"Return 'L' or 'R' for the specified video.\"\"\"\n",
    "    return video1_eye if video_key == \"VideoData1\" else video2_eye\n",
    "\n",
    "\n",
    "if VideoData1_Has_Sleap:\n",
    "    df1 = VideoData1[[\"Ellipse.Center.X\", \"Seconds\", \"frame_idx\"]].copy()\n",
    "    dir_map_v1 = get_direction_map_for_video(\"VideoData1\")\n",
    "    saccade_results[\"VideoData1\"] = analyze_eye_video_saccades(\n",
    "        df1,\n",
    "        FPS_1,\n",
    "        get_eye_label(\"VideoData1\"),\n",
    "        k=k1,\n",
    "        refractory_period=refractory_period,\n",
    "        onset_offset_fraction=onset_offset_fraction,\n",
    "        pre_saccade_window_time=pre_saccade_window_time,\n",
    "        post_saccade_window_time=post_saccade_window_time,\n",
    "        baseline_window_start_time=baseline_window_start_time,\n",
    "        baseline_window_end_time=baseline_window_end_time,\n",
    "        smoothing_window_time=smoothing_window_time,\n",
    "        peak_width_time=peak_width_time,\n",
    "        min_saccade_duration=min_saccade_duration,\n",
    "        upward_label=dir_map_v1[\"upward\"],\n",
    "        downward_label=dir_map_v1[\"downward\"],\n",
    "        classify_orienting_compensatory=classify_orienting_compensatory,\n",
    "        bout_window=bout_window,\n",
    "        pre_saccade_window=pre_saccade_window,\n",
    "        max_intersaccade_interval_for_classification=max_intersaccade_interval_for_classification,\n",
    "        pre_saccade_velocity_threshold=pre_saccade_velocity_threshold,\n",
    "        pre_saccade_drift_threshold=pre_saccade_drift_threshold,\n",
    "        post_saccade_variance_threshold=post_saccade_variance_threshold,\n",
    "        post_saccade_position_change_threshold_percent=post_saccade_position_change_threshold_percent,\n",
    "        use_adaptive_thresholds=use_adaptive_thresholds,\n",
    "        adaptive_percentile_pre_velocity=adaptive_percentile_pre_velocity,\n",
    "        adaptive_percentile_pre_drift=adaptive_percentile_pre_drift,\n",
    "        adaptive_percentile_post_variance=adaptive_percentile_post_variance,\n",
    "        debug=debug,\n",
    "    )\n",
    "\n",
    "\n",
    "if VideoData2_Has_Sleap:\n",
    "    df2 = VideoData2[[\"Ellipse.Center.X\", \"Seconds\", \"frame_idx\"]].copy()\n",
    "    dir_map_v2 = get_direction_map_for_video(\"VideoData2\")\n",
    "    saccade_results[\"VideoData2\"] = analyze_eye_video_saccades(\n",
    "        df2,\n",
    "        FPS_2,\n",
    "        get_eye_label(\"VideoData2\"),\n",
    "        k=k2,\n",
    "        refractory_period=refractory_period,\n",
    "        onset_offset_fraction=onset_offset_fraction,\n",
    "        pre_saccade_window_time=pre_saccade_window_time,\n",
    "        post_saccade_window_time=post_saccade_window_time,\n",
    "        baseline_window_start_time=baseline_window_start_time,\n",
    "        baseline_window_end_time=baseline_window_end_time,\n",
    "        smoothing_window_time=smoothing_window_time,\n",
    "        peak_width_time=peak_width_time,\n",
    "        min_saccade_duration=min_saccade_duration,\n",
    "        upward_label=dir_map_v2[\"upward\"],\n",
    "        downward_label=dir_map_v2[\"downward\"],\n",
    "        classify_orienting_compensatory=classify_orienting_compensatory,\n",
    "        bout_window=bout_window,\n",
    "        pre_saccade_window=pre_saccade_window,\n",
    "        max_intersaccade_interval_for_classification=max_intersaccade_interval_for_classification,\n",
    "        pre_saccade_velocity_threshold=pre_saccade_velocity_threshold,\n",
    "        pre_saccade_drift_threshold=pre_saccade_drift_threshold,\n",
    "        post_saccade_variance_threshold=post_saccade_variance_threshold,\n",
    "        post_saccade_position_change_threshold_percent=post_saccade_position_change_threshold_percent,\n",
    "        use_adaptive_thresholds=use_adaptive_thresholds,\n",
    "        adaptive_percentile_pre_velocity=adaptive_percentile_pre_velocity,\n",
    "        adaptive_percentile_pre_drift=adaptive_percentile_pre_drift,\n",
    "        adaptive_percentile_post_variance=adaptive_percentile_post_variance,\n",
    "        debug=debug,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac4790",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# SAVE SACCADE RESULTS TO FILES\n",
    "##########################################################################\n",
    "# Build tidy per-saccade summary tables, merge saccade metadata into VideoData,\n",
    "# then save enriched DataFrames (parquet) and QC summaries (CSV).\n",
    "\n",
    "\n",
    "def build_saccade_summary(video_key):\n",
    "    \"\"\"Create a tidy per-saccade summary table for the specified video.\"\"\"\n",
    "    results = saccade_results.get(video_key)\n",
    "    if results is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    direction_map = get_direction_map_for_video(video_key)\n",
    "    summary_parts = []\n",
    "    for direction, df in (\n",
    "        (\"upward\", results.get(\"upward_saccades_df\")),\n",
    "        (\"downward\", results.get(\"downward_saccades_df\")),\n",
    "    ):\n",
    "        if df is None or df.empty:\n",
    "            continue\n",
    "        temp = df.copy()\n",
    "        temp[\"direction\"] = direction\n",
    "        temp[\"direction_label\"] = direction_map.get(direction, direction)\n",
    "        summary_parts.append(temp)\n",
    "\n",
    "    if not summary_parts:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    summary = pd.concat(summary_parts, ignore_index=True)\n",
    "    summary = summary.sort_values([\"start_time\", \"time\"]).reset_index(drop=True)\n",
    "    summary.insert(0, \"saccade_id\", np.arange(1, len(summary) + 1, dtype=int))\n",
    "    summary[\"video_key\"] = video_key\n",
    "    summary[\"eye\"] = get_eye_code_for_video(video_key)\n",
    "\n",
    "    # Normalise frame/index columns\n",
    "    summary[\"merge_frame_idx\"] = pd.to_numeric(\n",
    "        summary.get(\"start_frame_idx\"), errors=\"coerce\"\n",
    "    ).astype(\"Int64\")\n",
    "    for col_name in [\n",
    "        \"start_frame_idx\",\n",
    "        \"peak_frame_idx\",\n",
    "        \"end_frame_idx\",\n",
    "    ]:\n",
    "        if col_name in summary.columns:\n",
    "            summary[col_name] = pd.to_numeric(\n",
    "                summary[col_name], errors=\"coerce\"\n",
    "            ).astype(\"Int64\")\n",
    "\n",
    "    rename_map = {\n",
    "        \"time\": \"saccade_peak_time\",\n",
    "        \"velocity\": \"saccade_peak_velocity\",\n",
    "        \"start_time\": \"saccade_start_time\",\n",
    "        \"end_time\": \"saccade_end_time\",\n",
    "        \"duration\": \"saccade_duration\",\n",
    "        \"start_position\": \"saccade_start_position\",\n",
    "        \"end_position\": \"saccade_end_position\",\n",
    "        \"amplitude\": \"saccade_amplitude\",\n",
    "        \"displacement\": \"saccade_displacement\",\n",
    "        \"start_frame_idx\": \"saccade_start_frame_idx\",\n",
    "        \"peak_frame_idx\": \"saccade_peak_frame_idx\",\n",
    "        \"end_frame_idx\": \"saccade_end_frame_idx\",\n",
    "    }\n",
    "    summary = summary.rename(\n",
    "        columns={k: v for k, v in rename_map.items() if k in summary.columns}\n",
    "    )\n",
    "\n",
    "    preferred_order = [\n",
    "        \"saccade_id\",\n",
    "        \"video_key\",\n",
    "        \"eye\",\n",
    "        \"direction\",\n",
    "        \"direction_label\",\n",
    "        \"saccade_start_time\",\n",
    "        \"saccade_end_time\",\n",
    "        \"saccade_peak_time\",\n",
    "        \"saccade_start_frame_idx\",\n",
    "        \"saccade_peak_frame_idx\",\n",
    "        \"saccade_end_frame_idx\",\n",
    "        \"saccade_peak_velocity\",\n",
    "        \"saccade_amplitude\",\n",
    "        \"saccade_displacement\",\n",
    "        \"saccade_duration\",\n",
    "        \"saccade_start_position\",\n",
    "        \"saccade_end_position\",\n",
    "        \"saccade_type\",\n",
    "        \"bout_id\",\n",
    "        \"bout_size\",\n",
    "        \"pre_saccade_mean_velocity\",\n",
    "        \"pre_saccade_position_drift\",\n",
    "        \"post_saccade_position_variance\",\n",
    "        \"post_saccade_position_change\",\n",
    "        \"merge_frame_idx\",\n",
    "    ]\n",
    "    remaining_cols = [col for col in summary.columns if col not in preferred_order]\n",
    "    summary = summary[preferred_order + remaining_cols]\n",
    "    return summary\n",
    "\n",
    "\n",
    "summary_tables = {}\n",
    "\n",
    "\n",
    "def merge_summary_into_video(video_df, summary_df):\n",
    "    \"\"\"Merge tidy saccade summary columns into the per-frame VideoData DataFrame.\"\"\"\n",
    "    if summary_df is None or summary_df.empty:\n",
    "        return video_df\n",
    "\n",
    "    summary_columns = [col for col in summary_df.columns if col != \"merge_frame_idx\"]\n",
    "    columns_to_drop = [col for col in summary_columns if col in video_df.columns]\n",
    "    if columns_to_drop:\n",
    "        video_df = video_df.drop(columns=columns_to_drop)\n",
    "\n",
    "    summary_for_join = summary_df.set_index(\"merge_frame_idx\")\n",
    "    summary_for_join = summary_for_join.drop(columns=[\"merge_frame_idx\"], errors=\"ignore\")\n",
    "\n",
    "    merged = (\n",
    "        video_df.set_index(\"frame_idx\")\n",
    "        .join(summary_for_join, how=\"left\")\n",
    "        .reset_index()\n",
    "        .rename(columns={\"index\": \"frame_idx\"})\n",
    "    )\n",
    "    return merged\n",
    "\n",
    "\n",
    "if \"VideoData1\" in globals() and \"VideoData1\" in saccade_results:\n",
    "\n",
    "    summary_v1 = build_saccade_summary(\"VideoData1\")\n",
    "    if not summary_v1.empty:\n",
    "        VideoData1 = merge_summary_into_video(VideoData1, summary_v1)\n",
    "        summary_tables[\"VideoData1\"] = summary_v1.drop(columns=[\"merge_frame_idx\"])\n",
    "    else:\n",
    "        summary_tables[\"VideoData1\"] = summary_v1\n",
    "\n",
    "if \"VideoData2\" in globals() and \"VideoData2\" in saccade_results:\n",
    "    summary_v2 = build_saccade_summary(\"VideoData2\")\n",
    "    if not summary_v2.empty:\n",
    "        VideoData2 = merge_summary_into_video(VideoData2, summary_v2)\n",
    "        summary_tables[\"VideoData2\"] = summary_v2.drop(columns=[\"merge_frame_idx\"])\n",
    "    else:\n",
    "        summary_tables[\"VideoData2\"] = summary_v2\n",
    "\n",
    "# Save enriched VideoData tables as parquet and tidy summaries as CSV for QC\n",
    "downsampled_output_dir = save_path / \"downsampled_data\"\n",
    "downsampled_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if \"VideoData1\" in globals():\n",
    "    video_dir1 = qc_debug_dir / \"Video_Sleap_Data1\"\n",
    "    if debug:\n",
    "        video_dir1.mkdir(parents=True, exist_ok=True)\n",
    "    summary_output_path1 = downsampled_output_dir / \"VideoData1_saccade_summary.csv\"\n",
    "\n",
    "    drop_for_export = [col for col in SACCADE_EXPORT_DROP_COLUMNS if col in VideoData1.columns]\n",
    "    VideoData1_export = VideoData1.drop(columns=drop_for_export)\n",
    "\n",
    "    VideoData1_export_renamed = (\n",
    "        VideoData1_export.rename(columns={\"Ellipse.Diameter.Filt\": \"Pupil.Diameter\"})\n",
    "        if \"Ellipse.Diameter.Filt\" in VideoData1_export.columns\n",
    "        else VideoData1_export\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        VideoData1_full_indexed = set_aeon_index(VideoData1_export_renamed)\n",
    "        append_aeon_time_column(VideoData1_full_indexed).to_csv(\n",
    "            video_dir1 / \"Video_Sleap_Data1_1904-01-01T00-00-00.csv\", index=False\n",
    "        )\n",
    "\n",
    "    drop_for_resample = [col for col in RESAMPLED_DROP_COLUMNS if col in VideoData1_export.columns]\n",
    "    VideoData1_resampled_input = VideoData1_export.drop(columns=drop_for_resample)\n",
    "    VideoData1_resampled = resample_video_dataframe(VideoData1_resampled_input, \"eye1\")\n",
    "    if \"Ellipse.Diameter.Filt\" in VideoData1_resampled.columns:\n",
    "        VideoData1_resampled = VideoData1_resampled.rename(columns={\"Ellipse.Diameter.Filt\": \"Pupil.Diameter\"})\n",
    "    VideoData1_resampled_indexed = set_aeon_index(VideoData1_resampled)\n",
    "    if debug:\n",
    "        append_aeon_time_column(VideoData1_resampled_indexed).to_csv(\n",
    "            video_dir1 / \"Video_Sleap_Data1_1904-01-01T00-00-00_resampled.csv\", index=False\n",
    "        )\n",
    "    downsampled_video1_path = downsampled_output_dir / \"VideoData1_resampled.parquet\"\n",
    "    VideoData1_resampled_indexed.to_parquet(\n",
    "        downsampled_video1_path, engine=\"pyarrow\", compression=\"snappy\"\n",
    "    )\n",
    "    print(f\"✅ Saved VideoData1 resampled parquet to {downsampled_video1_path}\")\n",
    "\n",
    "    summary_table = summary_tables.get(\"VideoData1\")\n",
    "    if summary_table is not None and not summary_table.empty:\n",
    "        summary_export = summary_table.copy()\n",
    "        summary_export[\"aeon_time\"] = summary_export[\"saccade_peak_time\"].apply(api.aeon)\n",
    "        summary_export.to_csv(summary_output_path1, index=False)\n",
    "\n",
    "if \"VideoData2\" in globals():\n",
    "    video_dir2 = qc_debug_dir / \"Video_Sleap_Data2\"\n",
    "    if debug:\n",
    "        video_dir2.mkdir(parents=True, exist_ok=True)\n",
    "    summary_output_path2 = downsampled_output_dir / \"VideoData2_saccade_summary.csv\"\n",
    "\n",
    "    drop_for_export = [col for col in SACCADE_EXPORT_DROP_COLUMNS if col in VideoData2.columns]\n",
    "    VideoData2_export = VideoData2.drop(columns=drop_for_export)\n",
    "\n",
    "    VideoData2_export_renamed = (\n",
    "        VideoData2_export.rename(columns={\"Ellipse.Diameter.Filt\": \"Pupil.Diameter\"})\n",
    "        if \"Ellipse.Diameter.Filt\" in VideoData2_export.columns\n",
    "        else VideoData2_export\n",
    "    )\n",
    "\n",
    "    if debug:\n",
    "        VideoData2_full_indexed = set_aeon_index(VideoData2_export_renamed)\n",
    "        append_aeon_time_column(VideoData2_full_indexed).to_csv(\n",
    "            video_dir2 / \"Video_Sleap_Data2_1904-01-01T00-00-00.csv\", index=False\n",
    "        )\n",
    "\n",
    "    drop_for_resample = [col for col in RESAMPLED_DROP_COLUMNS if col in VideoData2_export.columns]\n",
    "    VideoData2_resampled_input = VideoData2_export.drop(columns=drop_for_resample)\n",
    "    VideoData2_resampled = resample_video_dataframe(VideoData2_resampled_input, \"eye2\")\n",
    "    if \"Ellipse.Diameter.Filt\" in VideoData2_resampled.columns:\n",
    "        VideoData2_resampled = VideoData2_resampled.rename(columns={\"Ellipse.Diameter.Filt\": \"Pupil.Diameter\"})\n",
    "    VideoData2_resampled_indexed = set_aeon_index(VideoData2_resampled)\n",
    "    if debug:\n",
    "        append_aeon_time_column(VideoData2_resampled_indexed).to_csv(\n",
    "            video_dir2 / \"Video_Sleap_Data2_1904-01-01T00-00-00_resampled.csv\", index=False\n",
    "        )\n",
    "    downsampled_video2_path = downsampled_output_dir / \"VideoData2_resampled.parquet\"\n",
    "    VideoData2_resampled_indexed.to_parquet(\n",
    "        downsampled_video2_path, engine=\"pyarrow\", compression=\"snappy\"\n",
    "    )\n",
    "    print(f\"✅ Saved VideoData2 resampled parquet to {downsampled_video2_path}\")\n",
    "\n",
    "    summary_table = summary_tables.get(\"VideoData2\")\n",
    "    if summary_table is not None and not summary_table.empty:\n",
    "        summary_export = summary_table.copy()\n",
    "        summary_export[\"aeon_time\"] = summary_export[\"saccade_peak_time\"].apply(api.aeon)\n",
    "        summary_export.to_csv(summary_output_path2, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288336e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# VISUALIZE ALL SACCADES - SIDE BY SIDE\n",
    "# -------------------------------------------------------------------------------\n",
    "# Plot all upward and downward saccades aligned by time with position and velocity traces\n",
    "# Using extracted visualization function from sleap.visualization\n",
    "\n",
    "if plot_saccade_detection_QC:\n",
    "    plot_all_saccades_overlay(\n",
    "        saccade_results=saccade_results,\n",
    "        video_labels=VIDEO_LABELS,\n",
    "        video1_eye=video1_eye,\n",
    "        video2_eye=video2_eye,\n",
    "        pre_saccade_window_time=pre_saccade_window_time,\n",
    "        post_saccade_window_time=post_saccade_window_time,\n",
    "        debug=debug,\n",
    "        show_plot=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54708796",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# SACCADE AMPLITUDE QC VISUALIZATION\n",
    "# -------------------------------------------------------------------------------\n",
    "# 1. Distribution of saccade amplitudes\n",
    "# 2. Correlation between saccade amplitude and duration\n",
    "# 3. Peri-saccade segments colored by amplitude (outlier detection)\n",
    "# Using extracted visualization function from sleap.visualization\n",
    "\n",
    "if plot_saccade_detection_QC:\n",
    "    plot_saccade_amplitude_qc(\n",
    "        saccade_results=saccade_results,\n",
    "        video_labels=VIDEO_LABELS,\n",
    "        video1_eye=video1_eye,\n",
    "        video2_eye=video2_eye,\n",
    "        debug=debug,\n",
    "        show_plot=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0599f4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# DEBUG: BASELINING DIAGNOSTICS\n",
    "# -------------------------------------------------------------------------------\n",
    "# Plot distribution of baseline window values before and after baselining\n",
    "# This helps diagnose why some segments might not be baselined correctly\n",
    "\n",
    "if debug:\n",
    "    for video_key, res in saccade_results.items():\n",
    "        dir_map = get_direction_map_for_video(video_key)\n",
    "        label_up = dir_map[\"upward\"]\n",
    "        label_down = dir_map[\"downward\"]\n",
    "\n",
    "        peri_saccades = res[\"peri_saccades\"]\n",
    "\n",
    "        if len(peri_saccades) == 0:\n",
    "            print(\n",
    "                f\"\\n⚠️  No saccades found for {get_eye_label(video_key)}, skipping baselining diagnostics\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Extract baseline window statistics for each segment\n",
    "        baseline_values = []  # What was subtracted\n",
    "        # Mean position in baseline window BEFORE baselining\n",
    "        baseline_window_means_before = []\n",
    "        # Mean position in baseline window AFTER baselining\n",
    "        baseline_window_means_after = []\n",
    "        baseline_window_counts = []  # Number of points in baseline window\n",
    "        segment_directions = []\n",
    "        segment_ids = []\n",
    "\n",
    "        # Get baseline window parameters from the function call (use defaults\n",
    "        # if not available)\n",
    "        baseline_window_start_time = (\n",
    "            -0.1\n",
    "            if \"baseline_window_start_time\" not in globals()\n",
    "            else baseline_window_start_time\n",
    "        )\n",
    "        baseline_window_end_time = (\n",
    "            -0.02\n",
    "            if \"baseline_window_end_time\" not in globals()\n",
    "            else baseline_window_end_time\n",
    "        )\n",
    "\n",
    "        for seg in peri_saccades:\n",
    "            seg_id = (\n",
    "                seg[\"saccade_id\"].iloc[0]\n",
    "                if \"saccade_id\" in seg.columns\n",
    "                else len(baseline_values)\n",
    "            )\n",
    "            direction = (\n",
    "                seg[\"saccade_direction\"].iloc[0]\n",
    "                if \"saccade_direction\" in seg.columns\n",
    "                else \"unknown\"\n",
    "            )\n",
    "\n",
    "            # Get baseline value that was used\n",
    "            if \"baseline_value\" in seg.columns:\n",
    "                baseline_val = seg[\"baseline_value\"].iloc[0]\n",
    "            else:\n",
    "                baseline_val = np.nan\n",
    "\n",
    "            # Find baseline window points (before threshold crossing)\n",
    "            baseline_mask = (\n",
    "                (seg[\"Time_rel_threshold\"] >= baseline_window_start_time)\n",
    "                & (seg[\"Time_rel_threshold\"] <= baseline_window_end_time)\n",
    "                & (seg[\"Time_rel_threshold\"] < 0)  # Pre-threshold only\n",
    "            )\n",
    "\n",
    "            # Get original position values (reconstruct if needed)\n",
    "            if \"X_raw\" in seg.columns:\n",
    "                original_pos_col = \"X_raw\"\n",
    "            elif \"X_smooth\" in seg.columns:\n",
    "                original_pos_col = \"X_smooth\"\n",
    "            else:\n",
    "                original_pos_col = None\n",
    "\n",
    "            # Calculate mean in baseline window BEFORE baselining\n",
    "            if original_pos_col is not None:\n",
    "                baseline_window_original = seg.loc[\n",
    "                    baseline_mask, original_pos_col\n",
    "                ].dropna()\n",
    "                if len(baseline_window_original) > 0:\n",
    "                    mean_before = baseline_window_original.mean()\n",
    "                else:\n",
    "                    mean_before = np.nan\n",
    "            else:\n",
    "                # Reconstruct: original = baselined + baseline_value\n",
    "                if \"X_smooth_baselined\" in seg.columns and not pd.isna(baseline_val):\n",
    "                    baseline_window_baselined = seg.loc[\n",
    "                        baseline_mask, \"X_smooth_baselined\"\n",
    "                    ].dropna()\n",
    "                    if len(baseline_window_baselined) > 0:\n",
    "                        mean_before = baseline_window_baselined.mean() + baseline_val\n",
    "                    else:\n",
    "                        mean_before = np.nan\n",
    "                else:\n",
    "                    mean_before = np.nan\n",
    "\n",
    "            # Calculate mean in baseline window AFTER baselining\n",
    "            if \"X_smooth_baselined\" in seg.columns:\n",
    "                baseline_window_baselined = seg.loc[\n",
    "                    baseline_mask, \"X_smooth_baselined\"\n",
    "                ].dropna()\n",
    "                if len(baseline_window_baselined) > 0:\n",
    "                    mean_after = baseline_window_baselined.mean()\n",
    "                    n_points = len(baseline_window_baselined)\n",
    "                else:\n",
    "                    mean_after = np.nan\n",
    "                    n_points = 0\n",
    "            else:\n",
    "                mean_after = np.nan\n",
    "                n_points = 0\n",
    "\n",
    "            baseline_values.append(baseline_val)\n",
    "            baseline_window_means_before.append(mean_before)\n",
    "            baseline_window_means_after.append(mean_after)\n",
    "            baseline_window_counts.append(n_points)\n",
    "            segment_directions.append(direction)\n",
    "            segment_ids.append(seg_id)\n",
    "\n",
    "        # Convert to arrays for easier manipulation\n",
    "        baseline_values = np.array(baseline_values)\n",
    "        baseline_window_means_before = np.array(baseline_window_means_before)\n",
    "        baseline_window_means_after = np.array(baseline_window_means_after)\n",
    "        baseline_window_counts = np.array(baseline_window_counts)\n",
    "        segment_directions = np.array(segment_directions)\n",
    "\n",
    "        # Create diagnostic figure\n",
    "        fig_baseline = make_subplots(\n",
    "            rows=2,\n",
    "            cols=2,\n",
    "            subplot_titles=(\n",
    "                \"Baseline Values (What Was Subtracted)\",\n",
    "                \"Baseline Window Mean - BEFORE Baselining\",\n",
    "                \"Baseline Window Mean - AFTER Baselining\",\n",
    "                \"Baseline Window Point Counts\",\n",
    "            ),\n",
    "            vertical_spacing=0.15,\n",
    "            horizontal_spacing=0.12,\n",
    "        )\n",
    "\n",
    "        # Plot 1: Baseline values distribution\n",
    "        for direction in [\"upward\", \"downward\"]:\n",
    "            mask = segment_directions == direction\n",
    "            if mask.sum() > 0:\n",
    "                label = label_up if direction == \"upward\" else label_down\n",
    "                color = \"green\" if direction == \"upward\" else \"purple\"\n",
    "                fig_baseline.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=baseline_values[mask],\n",
    "                        nbinsx=50,\n",
    "                        name=f\"{label}\",\n",
    "                        marker_color=color,\n",
    "                        opacity=0.6,\n",
    "                    ),\n",
    "                    row=1,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "        # Plot 2: Baseline window mean BEFORE baselining\n",
    "        for direction in [\"upward\", \"downward\"]:\n",
    "            mask = segment_directions == direction\n",
    "            if mask.sum() > 0:\n",
    "                label = label_up if direction == \"upward\" else label_down\n",
    "                color = \"green\" if direction == \"upward\" else \"purple\"\n",
    "                valid_mask = mask & ~np.isnan(baseline_window_means_before)\n",
    "                if valid_mask.sum() > 0:\n",
    "                    fig_baseline.add_trace(\n",
    "                        go.Histogram(\n",
    "                            x=baseline_window_means_before[valid_mask],\n",
    "                            nbinsx=50,\n",
    "                            name=f\"{label}\",\n",
    "                            marker_color=color,\n",
    "                            opacity=0.6,\n",
    "                            showlegend=False,\n",
    "                        ),\n",
    "                        row=1,\n",
    "                        col=2,\n",
    "                    )\n",
    "\n",
    "        # Plot 3: Baseline window mean AFTER baselining (should be ~0)\n",
    "        for direction in [\"upward\", \"downward\"]:\n",
    "            mask = segment_directions == direction\n",
    "            if mask.sum() > 0:\n",
    "                label = label_up if direction == \"upward\" else label_down\n",
    "                color = \"green\" if direction == \"upward\" else \"purple\"\n",
    "                valid_mask = mask & ~np.isnan(baseline_window_means_after)\n",
    "                if valid_mask.sum() > 0:\n",
    "                    fig_baseline.add_trace(\n",
    "                        go.Histogram(\n",
    "                            x=baseline_window_means_after[valid_mask],\n",
    "                            nbinsx=50,\n",
    "                            name=f\"{label}\",\n",
    "                            marker_color=color,\n",
    "                            opacity=0.6,\n",
    "                            showlegend=False,\n",
    "                        ),\n",
    "                        row=2,\n",
    "                        col=1,\n",
    "                    )\n",
    "\n",
    "        # Plot 4: Baseline window point counts\n",
    "        for direction in [\"upward\", \"downward\"]:\n",
    "            mask = segment_directions == direction\n",
    "            if mask.sum() > 0:\n",
    "                label = label_up if direction == \"upward\" else label_down\n",
    "                color = \"green\" if direction == \"upward\" else \"purple\"\n",
    "                fig_baseline.add_trace(\n",
    "                    go.Histogram(\n",
    "                        x=baseline_window_counts[mask],\n",
    "                        nbinsx=20,\n",
    "                        name=f\"{label}\",\n",
    "                        marker_color=color,\n",
    "                        opacity=0.6,\n",
    "                        showlegend=False,\n",
    "                    ),\n",
    "                    row=2,\n",
    "                    col=2,\n",
    "                )\n",
    "\n",
    "        # Add vertical line at 0 for \"AFTER baselining\" plot\n",
    "        fig_baseline.add_vline(\n",
    "            x=0,\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"red\",\n",
    "            line_width=2,\n",
    "            opacity=0.7,\n",
    "            annotation_text=\"Expected: 0\",\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Update layout\n",
    "        fig_baseline.update_layout(\n",
    "            title_text=f\"Baselining Diagnostics: {get_eye_label(video_key)}<br><sub>After baselining, baseline window mean should be ~0</sub>\",\n",
    "            height=800,\n",
    "            showlegend=True,\n",
    "            legend=dict(x=0.02, y=0.98),\n",
    "        )\n",
    "\n",
    "        # Update axes labels\n",
    "        fig_baseline.update_xaxes(title_text=\"Baseline Value (px)\", row=1, col=1)\n",
    "        fig_baseline.update_xaxes(\n",
    "            title_text=\"Mean Position in Baseline Window (px)\", row=1, col=2\n",
    "        )\n",
    "        fig_baseline.update_xaxes(\n",
    "            title_text=\"Mean Position in Baseline Window (px)\", row=2, col=1\n",
    "        )\n",
    "        fig_baseline.update_xaxes(title_text=\"Number of Points\", row=2, col=2)\n",
    "        fig_baseline.update_yaxes(title_text=\"Count\", row=1, col=1)\n",
    "        fig_baseline.update_yaxes(title_text=\"Count\", row=1, col=2)\n",
    "        fig_baseline.update_yaxes(title_text=\"Count\", row=2, col=1)\n",
    "        fig_baseline.update_yaxes(title_text=\"Count\", row=2, col=2)\n",
    "\n",
    "        fig_baseline.show()\n",
    "\n",
    "        # Print statistics\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(f\"BASELINING DIAGNOSTICS: {get_eye_label(video_key)}\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        for direction in [\"upward\", \"downward\"]:\n",
    "            mask = segment_directions == direction\n",
    "            label = label_up if direction == \"upward\" else label_down\n",
    "\n",
    "            if mask.sum() > 0:\n",
    "                print(f\"\\n{label} saccades (n={mask.sum()}):\")\n",
    "\n",
    "                # Baseline values\n",
    "                valid_baseline = baseline_values[mask & ~np.isnan(baseline_values)]\n",
    "                if len(valid_baseline) > 0:\n",
    "                    print(\"  Baseline values (subtracted):\")\n",
    "                    print(f\"    Mean: {valid_baseline.mean():.2f} px\")\n",
    "                    print(f\"    Std: {valid_baseline.std():.2f} px\")\n",
    "                    print(\n",
    "                        f\"    Range: [{valid_baseline.min():.2f}, {valid_baseline.max():.2f}] px\"\n",
    "                    )\n",
    "                    print(f\"    NaN count: {np.isnan(baseline_values[mask]).sum()}\")\n",
    "\n",
    "                # Baseline window means BEFORE\n",
    "                valid_before = baseline_window_means_before[\n",
    "                    mask & ~np.isnan(baseline_window_means_before)\n",
    "                ]\n",
    "                if len(valid_before) > 0:\n",
    "                    print(\"\\n  Baseline window mean BEFORE baselining:\")\n",
    "                    print(f\"    Mean: {valid_before.mean():.2f} px\")\n",
    "                    print(f\"    Std: {valid_before.std():.2f} px\")\n",
    "                    print(\n",
    "                        f\"    Range: [{valid_before.min():.2f}, {valid_before.max():.2f}] px\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    NaN count: {np.isnan(baseline_window_means_before[mask]).sum()}\"\n",
    "                    )\n",
    "\n",
    "                # Baseline window means AFTER (should be ~0)\n",
    "                valid_after = baseline_window_means_after[\n",
    "                    mask & ~np.isnan(baseline_window_means_after)\n",
    "                ]\n",
    "                if len(valid_after) > 0:\n",
    "                    print(\"\\n  Baseline window mean AFTER baselining (should be ~0):\")\n",
    "                    print(f\"    Mean: {valid_after.mean():.2f} px\")\n",
    "                    print(f\"    Std: {valid_after.std():.2f} px\")\n",
    "                    print(\n",
    "                        f\"    Range: [{valid_after.min():.2f}, {valid_after.max():.2f}] px\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    NaN count: {np.isnan(baseline_window_means_after[mask]).sum()}\"\n",
    "                    )\n",
    "\n",
    "                    # Count segments that are NOT properly baselined (mean >\n",
    "                    # 1px away from 0)\n",
    "                    not_baselined = np.abs(valid_after) > 1.0\n",
    "                    if not_baselined.sum() > 0:\n",
    "                        print(\n",
    "                            f\"\\n  ⚠️  WARNING: {not_baselined.sum()} segments NOT properly baselined (|mean| > 1px)\"\n",
    "                        )\n",
    "                        print(\n",
    "                            f\"    Mean values for non-baselined segments: {valid_after[not_baselined]}\"\n",
    "                        )\n",
    "\n",
    "                    # Show distribution of baseline window means (should all be\n",
    "                    # ~0)\n",
    "                    print(\n",
    "                        \"\\n  Distribution of baseline window means AFTER baselining:\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    Segments with |mean| < 0.1 px: {(np.abs(valid_after) < 0.1).sum()}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    Segments with 0.1 <= |mean| < 0.5 px: {((np.abs(valid_after) >= 0.1) & (np.abs(valid_after) < 0.5)).sum()}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    Segments with 0.5 <= |mean| < 1.0 px: {((np.abs(valid_after) >= 0.5) & (np.abs(valid_after) < 1.0)).sum()}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    Segments with |mean| >= 1.0 px: {(np.abs(valid_after) >= 1.0).sum()}\"\n",
    "                    )\n",
    "\n",
    "                    # Show worst offenders\n",
    "                    worst_indices = np.argsort(np.abs(valid_after))[\n",
    "                        -10:\n",
    "                    ]  # Top 10 worst\n",
    "                    if len(worst_indices) > 0:\n",
    "                        print(\n",
    "                            \"\\n  Top 10 segments with largest |baseline window mean|:\"\n",
    "                        )\n",
    "                        for i, idx in enumerate(\n",
    "                            worst_indices[::-1]\n",
    "                        ):  # Reverse to show worst first\n",
    "                            seg_idx = np.where(mask)[0][idx]\n",
    "                            seg_id = segment_ids[seg_idx]\n",
    "                            mean_val = valid_after[idx]\n",
    "                            baseline_val = baseline_values[mask][idx]\n",
    "                            print(\n",
    "                                f\"    Segment {seg_id}: baseline_window_mean={mean_val:.3f} px, baseline_value={baseline_val:.3f} px\"\n",
    "                            )\n",
    "\n",
    "                    # CRITICAL CHECK: Verify that baseline_value actually equals baseline_window_mean_before\n",
    "                    # This checks if baselining logic is correct\n",
    "                    valid_before_check = baseline_window_means_before[\n",
    "                        mask & ~np.isnan(baseline_window_means_before)\n",
    "                    ]\n",
    "                    if len(valid_before_check) > 0 and len(valid_baseline) > 0:\n",
    "                        # Check if baseline_value matches\n",
    "                        # baseline_window_mean_before (should be identical)\n",
    "                        # Allow small floating point differences\n",
    "                        mismatches = np.abs(valid_baseline - valid_before_check) > 0.01\n",
    "                        if mismatches.sum() > 0:\n",
    "                            print(\n",
    "                                f\"\\n  ⚠️  CRITICAL: {mismatches.sum()} segments where baseline_value != baseline_window_mean_before\"\n",
    "                            )\n",
    "                            print(\"    This indicates a bug in baselining logic!\")\n",
    "                            for i in np.where(mismatches)[0][:5]:  # Show first 5\n",
    "                                print(\n",
    "                                    f\"      Segment {i}: baseline_value={valid_baseline[i]:.3f}, baseline_window_mean_before={valid_before_check[i]:.3f}\"\n",
    "                                )\n",
    "                        else:\n",
    "                            print(\n",
    "                                \"\\n  ✅ Baselining logic check: baseline_value matches baseline_window_mean_before for all segments\"\n",
    "                            )\n",
    "\n",
    "                # Baseline window point counts\n",
    "                valid_counts = baseline_window_counts[\n",
    "                    mask & (baseline_window_counts > 0)\n",
    "                ]\n",
    "                if len(valid_counts) > 0:\n",
    "                    print(\"\\n  Baseline window point counts:\")\n",
    "                    print(f\"    Mean: {valid_counts.mean():.1f} points\")\n",
    "                    print(\n",
    "                        f\"    Range: [{valid_counts.min()}, {valid_counts.max()}] points\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    Segments with 0 points in baseline window: {(baseline_window_counts[mask] == 0).sum()}\"\n",
    "                    )\n",
    "\n",
    "        print(f\"\\n{'=' * 80}\\n\")\n",
    "\n",
    "        # Additional diagnostic: Check if baselining is actually applied to segments\n",
    "        # Compare original vs baselined values at the start of segments (before\n",
    "        # threshold)\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "        print(\"ADDITIONAL BASELINING CHECK: Comparing segment start positions\")\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        for direction in [\"upward\", \"downward\"]:\n",
    "            mask = segment_directions == direction\n",
    "            label = label_up if direction == \"upward\" else label_down\n",
    "\n",
    "            if mask.sum() > 0:\n",
    "                print(f\"\\n{label} saccades:\")\n",
    "\n",
    "                # Check first few points of each segment (should be ~0 after\n",
    "                # baselining)\n",
    "                segment_start_means_original = []\n",
    "                segment_start_means_baselined = []\n",
    "\n",
    "                for i, seg in enumerate(peri_saccades):\n",
    "                    if segment_directions[i] != direction:\n",
    "                        continue\n",
    "\n",
    "                    # Get first 5 points before threshold (if available)\n",
    "                    pre_threshold_mask = seg[\"Time_rel_threshold\"] < 0\n",
    "                    pre_threshold_seg = seg.loc[pre_threshold_mask].head(5)\n",
    "\n",
    "                    if len(pre_threshold_seg) > 0:\n",
    "                        # Get original position\n",
    "                        if \"X_raw\" in seg.columns:\n",
    "                            orig_col = \"X_raw\"\n",
    "                        elif \"X_smooth\" in seg.columns:\n",
    "                            orig_col = \"X_smooth\"\n",
    "                        else:\n",
    "                            orig_col = None\n",
    "\n",
    "                        if orig_col is not None:\n",
    "                            orig_mean = pre_threshold_seg[orig_col].mean()\n",
    "                            segment_start_means_original.append(orig_mean)\n",
    "\n",
    "                        # Get baselined position\n",
    "                        if \"X_smooth_baselined\" in seg.columns:\n",
    "                            baselined_mean = pre_threshold_seg[\n",
    "                                \"X_smooth_baselined\"\n",
    "                            ].mean()\n",
    "                            segment_start_means_baselined.append(baselined_mean)\n",
    "\n",
    "                if len(segment_start_means_baselined) > 0:\n",
    "                    segment_start_means_baselined = np.array(\n",
    "                        segment_start_means_baselined\n",
    "                    )\n",
    "                    print(\n",
    "                        \"  Mean position at segment start (first 5 pre-threshold points) AFTER baselining:\"\n",
    "                    )\n",
    "                    print(f\"    Mean: {segment_start_means_baselined.mean():.3f} px\")\n",
    "                    print(f\"    Std: {segment_start_means_baselined.std():.3f} px\")\n",
    "                    print(\n",
    "                        f\"    Range: [{segment_start_means_baselined.min():.3f}, {segment_start_means_baselined.max():.3f}] px\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    Segments with |mean| > 1 px: {(np.abs(segment_start_means_baselined) > 1.0).sum()}\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"    Segments with |mean| > 5 px: {(np.abs(segment_start_means_baselined) > 5.0).sum()}\"\n",
    "                    )\n",
    "\n",
    "                    # Show worst offenders\n",
    "                    worst_indices = np.argsort(np.abs(segment_start_means_baselined))[\n",
    "                        -10:\n",
    "                    ]\n",
    "                    if len(worst_indices) > 0:\n",
    "                        print(\n",
    "                            \"\\n  Top 10 segments with largest |start position mean| AFTER baselining:\"\n",
    "                        )\n",
    "                        for idx in worst_indices[::-1]:\n",
    "                            print(\n",
    "                                f\"    Segment {idx}: start_mean={segment_start_means_baselined[idx]:.3f} px\"\n",
    "                            )\n",
    "\n",
    "        print(f\"\\n{'=' * 80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3972c2e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# VISUALIZE DETECTED SACCADES (Adaptive Method)\n",
    "# -------------------------------------------------------------------------------\n",
    "# Create overlay plot showing detected saccades with duration lines and\n",
    "# peak arrows\n",
    "if plot_saccade_detection_QC:\n",
    "    for video_key, res in saccade_results.items():\n",
    "        dir_map = get_direction_map_for_video(video_key)\n",
    "        label_up = dir_map[\"upward\"]\n",
    "        label_down = dir_map[\"downward\"]\n",
    "\n",
    "        upward_saccades_df = res[\"upward_saccades_df\"]\n",
    "        downward_saccades_df = res[\"downward_saccades_df\"]\n",
    "        peri_saccades = res[\"peri_saccades\"]\n",
    "        upward_segments = res[\"upward_segments\"]\n",
    "        downward_segments = res[\"downward_segments\"]\n",
    "        # Any other variables you need...\n",
    "\n",
    "        # Optional: Find 5-minute window with highest saccade density\n",
    "        plot_5min_window = (\n",
    "            True  # Set to True to plot only highest density 5-minute window\n",
    "        )\n",
    "        window_duration = 300  # 5 minutes in seconds\n",
    "\n",
    "        # Initialize variables for windowing\n",
    "        best_window_start = None\n",
    "        best_window_end = None\n",
    "        best_window_count = 0\n",
    "\n",
    "        if plot_5min_window and (\n",
    "            len(upward_saccades_df) > 0 or len(downward_saccades_df) > 0\n",
    "        ):\n",
    "            # Combine all saccades and find time window with highest density\n",
    "            all_saccade_times = []\n",
    "            if len(upward_saccades_df) > 0:\n",
    "                all_saccade_times.extend(upward_saccades_df[\"time\"].values)\n",
    "            if len(downward_saccades_df) > 0:\n",
    "                all_saccade_times.extend(downward_saccades_df[\"time\"].values)\n",
    "\n",
    "            if len(all_saccade_times) > 0:\n",
    "                all_saccade_times = np.array(all_saccade_times)\n",
    "                time_min = all_saccade_times.min()\n",
    "                time_max = all_saccade_times.max()\n",
    "\n",
    "                # Slide window and count saccades in each window\n",
    "                best_window_start = time_min\n",
    "                best_window_count = 0\n",
    "                step_size = 10  # Check every 10 seconds\n",
    "\n",
    "                for window_start in np.arange(\n",
    "                    time_min, time_max - window_duration + step_size, step_size\n",
    "                ):\n",
    "                    window_end = window_start + window_duration\n",
    "                    count = np.sum(\n",
    "                        (all_saccade_times >= window_start)\n",
    "                        & (all_saccade_times <= window_end)\n",
    "                    )\n",
    "                    if count > best_window_count:\n",
    "                        best_window_count = count\n",
    "                        best_window_start = window_start\n",
    "\n",
    "                best_window_end = best_window_start + window_duration\n",
    "\n",
    "                # Filter data to this window\n",
    "                df_window = res[\"df\"][\n",
    "                    (res[\"df\"][\"Seconds\"] >= best_window_start)\n",
    "                    & (res[\"df\"][\"Seconds\"] <= best_window_end)\n",
    "                ].copy()\n",
    "                upward_saccades_df_window = upward_saccades_df[\n",
    "                    (upward_saccades_df[\"time\"] >= best_window_start)\n",
    "                    & (upward_saccades_df[\"time\"] <= best_window_end)\n",
    "                ].copy()\n",
    "                downward_saccades_df_window = downward_saccades_df[\n",
    "                    (downward_saccades_df[\"time\"] >= best_window_start)\n",
    "                    & (downward_saccades_df[\"time\"] <= best_window_end)\n",
    "                ].copy()\n",
    "\n",
    "                if debug:\n",
    "                    print(\n",
    "                        f\"\\n📊 Highest saccade density window: {best_window_start:.1f}s to {best_window_end:.1f}s\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"   ({best_window_count} saccades in {window_duration / 60:.1f} minutes)\"\n",
    "                    )\n",
    "                    print(\n",
    "                        f\"   Density: {best_window_count / (window_duration / 60):.1f} saccades/min\"\n",
    "                    )\n",
    "            else:\n",
    "                plot_5min_window = False\n",
    "        else:\n",
    "            plot_5min_window = False\n",
    "\n",
    "        # Use windowed data if requested, otherwise use full data\n",
    "        if plot_5min_window:\n",
    "            df_plot = df_window\n",
    "            upward_saccades_df_plot = upward_saccades_df_window\n",
    "            downward_saccades_df_plot = downward_saccades_df_window\n",
    "            time_range_text = f\" (5-min window: {best_window_start:.1f}-{best_window_end:.1f}s, {best_window_count} saccades)\"\n",
    "        else:\n",
    "            df_plot = res[\"df\"]\n",
    "            upward_saccades_df_plot = upward_saccades_df\n",
    "            downward_saccades_df_plot = downward_saccades_df\n",
    "            time_range_text = \"\"\n",
    "\n",
    "        fig = make_subplots(\n",
    "            rows=2,\n",
    "            cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.1,\n",
    "            subplot_titles=(\n",
    "                \"X Position (px)\",\n",
    "                \"Velocity (px/s) with Detected Saccades\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Add smoothed X position to the first subplot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_plot[\"Seconds\"],\n",
    "                y=df_plot[\"X_smooth\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Smoothed X\",\n",
    "                line=dict(color=\"blue\", width=2),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Add smoothed velocity to the second subplot\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_plot[\"Seconds\"],\n",
    "                y=df_plot[\"vel_x_smooth\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Smoothed Velocity\",\n",
    "                line=dict(color=\"red\", width=2),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Add adaptive threshold lines for reference\n",
    "        fig.add_hline(\n",
    "            y=res[\"vel_thresh\"],\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"green\",\n",
    "            opacity=0.5,\n",
    "            annotation_text=f\"Adaptive threshold (±{res['vel_thresh']:.0f} px/s)\",\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        fig.add_hline(\n",
    "            y=-res[\"vel_thresh\"],\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"green\",\n",
    "            opacity=0.5,\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Calculate position y-axis range for vertical lines\n",
    "        pos_max = df_plot[\"X_smooth\"].max()\n",
    "        pos_min = df_plot[\"X_smooth\"].min()\n",
    "        pos_range = pos_max - pos_min\n",
    "        # Add small padding to ensure lines span full visible range\n",
    "        pos_padding = pos_range * 0.05\n",
    "        pos_y_min = pos_min - pos_padding\n",
    "        pos_y_max = pos_max + pos_padding\n",
    "\n",
    "        # Plot upward saccades (TN) as vertical lines on position trace\n",
    "        if len(upward_saccades_df_plot) > 0:\n",
    "            for idx, row in upward_saccades_df_plot.iterrows():\n",
    "                start_time = row[\"start_time\"]\n",
    "                end_time = row[\"end_time\"]\n",
    "\n",
    "                # Use rectangle with thin border to show duration span more efficiently\n",
    "                # Opacity must be set at shape level or via rgba color, not in\n",
    "                # line dict\n",
    "                fig.add_shape(\n",
    "                    type=\"rect\",\n",
    "                    x0=start_time,\n",
    "                    y0=pos_y_min,\n",
    "                    x1=end_time,\n",
    "                    y1=pos_y_max,\n",
    "                    # Light green fill with opacity\n",
    "                    fillcolor=\"rgba(0,128,0,0.1)\",\n",
    "                    # Green border with opacity via rgba\n",
    "                    line=dict(color=\"rgba(0,128,0,0.3)\", width=2),\n",
    "                    row=1,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "            # Add legend entry for upward saccades\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[None],\n",
    "                    y=[None],\n",
    "                    mode=\"lines\",\n",
    "                    name=f\"{label_up} Saccades\",\n",
    "                    line=dict(\n",
    "                        color=\"rgba(0,128,0,0.3)\", width=3\n",
    "                    ),  # Green with opacity via rgba\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        # Plot downward saccades (NT) as vertical lines on position trace\n",
    "        if len(downward_saccades_df_plot) > 0:\n",
    "            for idx, row in downward_saccades_df_plot.iterrows():\n",
    "                start_time = row[\"start_time\"]\n",
    "                end_time = row[\"end_time\"]\n",
    "\n",
    "                # Use rectangle with thin border to show duration span more efficiently\n",
    "                # Opacity must be set at shape level or via rgba color, not in\n",
    "                # line dict\n",
    "                fig.add_shape(\n",
    "                    type=\"rect\",\n",
    "                    x0=start_time,\n",
    "                    y0=pos_y_min,\n",
    "                    x1=end_time,\n",
    "                    y1=pos_y_max,\n",
    "                    # Light purple fill with opacity\n",
    "                    fillcolor=\"rgba(128,0,128,0.1)\",\n",
    "                    # Purple border with opacity via rgba\n",
    "                    line=dict(color=\"rgba(128,0,128,0.3)\", width=2),\n",
    "                    row=1,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "            # Add legend entry for downward saccades\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=[None],\n",
    "                    y=[None],\n",
    "                    mode=\"lines\",\n",
    "                    name=f\"{label_down} Saccades\",\n",
    "                    line=dict(\n",
    "                        color=\"rgba(128,0,128,0.3)\", width=3\n",
    "                    ),  # Purple with opacity via rgba\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            title=f\"Detected Saccades ({get_eye_label(video_key)}): Vertical Lines on Position Trace (QC Visualization){time_range_text}\",\n",
    "            height=600,\n",
    "            showlegend=True,\n",
    "            legend=dict(x=0.01, y=0.99),\n",
    "        )\n",
    "\n",
    "        # Update axes\n",
    "        fig.update_xaxes(title_text=\"Time (s)\", row=2, col=1)\n",
    "        fig.update_yaxes(title_text=\"X Position (px)\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"Velocity (px/s)\", row=2, col=1)\n",
    "\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6eebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADAPTIVE THRESHOLD DIAGNOSTIC PLOTS (only if debug=True)\n",
    "# -------------------------------------------------------------------------------\n",
    "# Plot distributions of classification features to help determine\n",
    "# meaningful adaptive thresholds\n",
    "if debug and len(saccade_results) > 0:\n",
    "    print(\"\\n📊 Generating adaptive threshold diagnostic plots...\")\n",
    "\n",
    "    for video_key, res in saccade_results.items():\n",
    "        all_saccades_df = res.get(\"all_saccades_df\", pd.DataFrame())\n",
    "\n",
    "        if len(all_saccades_df) == 0:\n",
    "            print(\n",
    "                f\"⚠️  No saccades found for {get_eye_label(video_key)}, skipping diagnostic plots\"\n",
    "            )\n",
    "            continue\n",
    "\n",
    "        # Filter out NaN values for plotting\n",
    "        pre_vel = all_saccades_df[\"pre_saccade_mean_velocity\"].dropna()\n",
    "        pre_drift = all_saccades_df[\"pre_saccade_position_drift\"].dropna()\n",
    "        post_var = all_saccades_df[\"post_saccade_position_variance\"].dropna()\n",
    "        post_change = all_saccades_df[\"post_saccade_position_change\"].dropna()\n",
    "        amplitude = all_saccades_df[\"amplitude\"].dropna()\n",
    "\n",
    "        # Calculate post_change / amplitude ratio (for percentage threshold visualization)\n",
    "        # Align by index to ensure matching\n",
    "        aligned_indices = post_change.index.intersection(amplitude.index)\n",
    "        post_change_aligned = post_change.loc[aligned_indices]\n",
    "        amplitude_aligned = amplitude.loc[aligned_indices]\n",
    "        # Convert to percentage\n",
    "        post_change_ratio = (post_change_aligned / amplitude_aligned) * 100\n",
    "\n",
    "        # Calculate current thresholds for visualization\n",
    "        if use_adaptive_thresholds:\n",
    "            # Calculate adaptive thresholds from current data\n",
    "            if len(pre_vel) >= 3:\n",
    "                current_pre_vel_threshold = np.percentile(\n",
    "                    pre_vel, adaptive_percentile_pre_velocity\n",
    "                )\n",
    "            else:\n",
    "                current_pre_vel_threshold = pre_saccade_velocity_threshold\n",
    "\n",
    "            if len(pre_drift) >= 3:\n",
    "                current_pre_drift_threshold = np.percentile(\n",
    "                    pre_drift, adaptive_percentile_pre_drift\n",
    "                )\n",
    "            else:\n",
    "                current_pre_drift_threshold = pre_saccade_drift_threshold\n",
    "\n",
    "            if len(post_var) >= 3:\n",
    "                current_post_var_threshold = np.percentile(\n",
    "                    post_var, adaptive_percentile_post_variance\n",
    "                )\n",
    "            else:\n",
    "                current_post_var_threshold = post_saccade_variance_threshold\n",
    "        else:\n",
    "            # Use fixed thresholds\n",
    "            current_pre_vel_threshold = pre_saccade_velocity_threshold\n",
    "            current_pre_drift_threshold = pre_saccade_drift_threshold\n",
    "            current_post_var_threshold = post_saccade_variance_threshold\n",
    "\n",
    "        # Create figure with 2x2 subplots\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "        fig.suptitle(\n",
    "            f\"Adaptive Threshold Diagnostic Plots: {get_eye_label(video_key)}\\n\"\n",
    "            f\"(n={len(all_saccades_df)} saccades)\",\n",
    "            fontsize=14,\n",
    "            fontweight=\"bold\",\n",
    "        )\n",
    "\n",
    "        # Plot 1: Pre-saccade mean velocity\n",
    "        ax = axes[0, 0]\n",
    "        if len(pre_vel) > 0:\n",
    "            ax.hist(pre_vel, bins=50, alpha=0.7, color=\"skyblue\", edgecolor=\"black\")\n",
    "            ax.axvline(\n",
    "                current_pre_vel_threshold,\n",
    "                color=\"red\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=2,\n",
    "                label=f\"Threshold: {current_pre_vel_threshold:.2f} px/s\",\n",
    "            )\n",
    "            if use_adaptive_thresholds:\n",
    "                ax.axvline(\n",
    "                    np.percentile(pre_vel, 50),\n",
    "                    color=\"gray\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=1,\n",
    "                    label=f\"Median: {np.percentile(pre_vel, 50):.2f} px/s\",\n",
    "                )\n",
    "                ax.axvline(\n",
    "                    np.percentile(pre_vel, 75),\n",
    "                    color=\"orange\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=1,\n",
    "                    label=f\"75th: {np.percentile(pre_vel, 75):.2f} px/s\",\n",
    "                )\n",
    "            ax.set_xlabel(\"Pre-saccade Mean Velocity (px/s)\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "            ax.set_title(\n",
    "                f\"Pre-saccade Velocity Distribution\\n\"\n",
    "                f\"{'Adaptive' if use_adaptive_thresholds else 'Fixed'} threshold at \"\n",
    "                f\"{adaptive_percentile_pre_velocity if use_adaptive_thresholds else 'fixed'}th percentile\"\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 2: Pre-saccade position drift\n",
    "        ax = axes[0, 1]\n",
    "        if len(pre_drift) > 0:\n",
    "            ax.hist(\n",
    "                pre_drift, bins=50, alpha=0.7, color=\"lightgreen\", edgecolor=\"black\"\n",
    "            )\n",
    "            ax.axvline(\n",
    "                current_pre_drift_threshold,\n",
    "                color=\"red\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=2,\n",
    "                label=f\"Threshold: {current_pre_drift_threshold:.2f} px\",\n",
    "            )\n",
    "            if use_adaptive_thresholds:\n",
    "                ax.axvline(\n",
    "                    np.percentile(pre_drift, 50),\n",
    "                    color=\"gray\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=1,\n",
    "                    label=f\"Median: {np.percentile(pre_drift, 50):.2f} px\",\n",
    "                )\n",
    "                ax.axvline(\n",
    "                    np.percentile(pre_drift, 75),\n",
    "                    color=\"orange\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=1,\n",
    "                    label=f\"75th: {np.percentile(pre_drift, 75):.2f} px\",\n",
    "                )\n",
    "            ax.set_xlabel(\"Pre-saccade Position Drift (px)\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "            ax.set_title(\n",
    "                f\"Pre-saccade Drift Distribution\\n\"\n",
    "                f\"{'Adaptive' if use_adaptive_thresholds else 'Fixed'} threshold at \"\n",
    "                f\"{adaptive_percentile_pre_drift if use_adaptive_thresholds else 'fixed'}th percentile\"\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 3: Post-saccade position variance\n",
    "        ax = axes[1, 0]\n",
    "        if len(post_var) > 0:\n",
    "            ax.hist(post_var, bins=50, alpha=0.7, color=\"plum\", edgecolor=\"black\")\n",
    "            ax.axvline(\n",
    "                current_post_var_threshold,\n",
    "                color=\"red\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=2,\n",
    "                label=f\"Threshold: {current_post_var_threshold:.2f} px²\",\n",
    "            )\n",
    "            if use_adaptive_thresholds:\n",
    "                ax.axvline(\n",
    "                    np.percentile(post_var, 25),\n",
    "                    color=\"orange\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=1,\n",
    "                    label=f\"25th: {np.percentile(post_var, 25):.2f} px²\",\n",
    "                )\n",
    "                ax.axvline(\n",
    "                    np.percentile(post_var, 50),\n",
    "                    color=\"gray\",\n",
    "                    linestyle=\":\",\n",
    "                    linewidth=1,\n",
    "                    label=f\"Median: {np.percentile(post_var, 50):.2f} px²\",\n",
    "                )\n",
    "            ax.set_xlabel(\"Post-saccade Position Variance (px²)\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "            ax.set_title(\n",
    "                f\"Post-saccade Variance Distribution\\n\"\n",
    "                f\"{'Adaptive' if use_adaptive_thresholds else 'Fixed'} threshold at \"\n",
    "                f\"{adaptive_percentile_post_variance if use_adaptive_thresholds else 'fixed'}th percentile\"\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        # Plot 4: Post-saccade position change (as percentage of amplitude)\n",
    "        ax = axes[1, 1]\n",
    "        if len(post_change_ratio) > 0:\n",
    "            ax.hist(\n",
    "                post_change_ratio, bins=50, alpha=0.7, color=\"salmon\", edgecolor=\"black\"\n",
    "            )\n",
    "            ax.axvline(\n",
    "                post_saccade_position_change_threshold_percent,\n",
    "                color=\"red\",\n",
    "                linestyle=\"--\",\n",
    "                linewidth=2,\n",
    "                label=f\"Threshold: {post_saccade_position_change_threshold_percent:.1f}%\",\n",
    "            )\n",
    "            ax.axvline(\n",
    "                np.percentile(post_change_ratio, 50),\n",
    "                color=\"gray\",\n",
    "                linestyle=\":\",\n",
    "                linewidth=1,\n",
    "                label=f\"Median: {np.percentile(post_change_ratio, 50):.1f}%\",\n",
    "            )\n",
    "            ax.axvline(\n",
    "                np.percentile(post_change_ratio, 75),\n",
    "                color=\"orange\",\n",
    "                linestyle=\":\",\n",
    "                linewidth=1,\n",
    "                label=f\"75th: {np.percentile(post_change_ratio, 75):.1f}%\",\n",
    "            )\n",
    "            ax.set_xlabel(\"Post-saccade Position Change / Amplitude (%)\")\n",
    "            ax.set_ylabel(\"Count\")\n",
    "            ax.set_title(\n",
    "                f\"Post-saccade Position Change Ratio\\n\"\n",
    "                f\"Fixed threshold: {post_saccade_position_change_threshold_percent:.1f}% of amplitude\"\n",
    "            )\n",
    "            ax.legend()\n",
    "            ax.grid(True, alpha=0.3)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        # Print summary statistics\n",
    "        print(f\"\\n📈 Summary Statistics for {get_eye_label(video_key)}:\")\n",
    "        if len(pre_vel) > 0:\n",
    "            print(\n",
    "                f\"  Pre-saccade velocity: mean={pre_vel.mean():.2f}, median={pre_vel.median():.2f}, \"\n",
    "                f\"std={pre_vel.std():.2f} px/s\"\n",
    "            )\n",
    "        if len(pre_drift) > 0:\n",
    "            print(\n",
    "                f\"  Pre-saccade drift: mean={pre_drift.mean():.2f}, median={pre_drift.median():.2f}, \"\n",
    "                f\"std={pre_drift.std():.2f} px\"\n",
    "            )\n",
    "        if len(post_var) > 0:\n",
    "            print(\n",
    "                f\"  Post-saccade variance: mean={post_var.mean():.2f}, median={post_var.median():.2f}, \"\n",
    "                f\"std={post_var.std():.2f} px²\"\n",
    "            )\n",
    "        if len(post_change_ratio) > 0:\n",
    "            print(\n",
    "                f\"  Post-saccade change ratio: mean={post_change_ratio.mean():.1f}%, \"\n",
    "                f\"median={post_change_ratio.median():.1f}%, std={post_change_ratio.std():.1f}%\"\n",
    "            )\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5d3dfc",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# VISUALIZE AND ANALYZE SACCADE CLASSIFICATION (Orienting vs Compensatory)\n",
    "# -------------------------------------------------------------------------------\n",
    "# Create validation plots and statistical comparisons for saccade\n",
    "# classification\n",
    "\n",
    "if plot_saccade_detection_QC:\n",
    "    for video_key, res in saccade_results.items():\n",
    "        dir_map = get_direction_map_for_video(video_key)\n",
    "        label_up = dir_map[\"upward\"]\n",
    "        label_down = dir_map[\"downward\"]\n",
    "\n",
    "        all_saccades_df = res.get(\"all_saccades_df\", pd.DataFrame())\n",
    "\n",
    "        if len(all_saccades_df) == 0:\n",
    "            print(f\"\\n⚠️ No saccades found for {get_eye_label(video_key)}\")\n",
    "            continue\n",
    "\n",
    "        # Check if classification was performed\n",
    "\n",
    "        if \"saccade_type\" not in all_saccades_df.columns:\n",
    "            print(f\"\\n⚠️ Classification not performed for {get_eye_label(video_key)}\")\n",
    "            continue\n",
    "\n",
    "        orienting_saccades = all_saccades_df[\n",
    "            all_saccades_df[\"saccade_type\"] == \"orienting\"\n",
    "        ]\n",
    "\n",
    "        compensatory_saccades = all_saccades_df[\n",
    "            all_saccades_df[\"saccade_type\"] == \"compensatory\"\n",
    "        ]\n",
    "\n",
    "        print(f\"\\n{'=' * 80}\")\n",
    "\n",
    "        print(f\"CLASSIFICATION ANALYSIS: {get_eye_label(video_key)}\")\n",
    "\n",
    "        print(f\"{'=' * 80}\")\n",
    "\n",
    "        # Statistical comparisons\n",
    "\n",
    "        from scipy import stats\n",
    "\n",
    "        print(\"\\n📊 Statistical Comparisons:\")\n",
    "\n",
    "        print(f\"  Orienting saccades: {len(orienting_saccades)}\")\n",
    "\n",
    "        print(f\"  Compensatory saccades: {len(compensatory_saccades)}\")\n",
    "\n",
    "        if len(orienting_saccades) > 0 and len(compensatory_saccades) > 0:\n",
    "            # Amplitude comparison\n",
    "\n",
    "            orienting_amps = orienting_saccades[\"amplitude\"].values\n",
    "\n",
    "            compensatory_amps = compensatory_saccades[\"amplitude\"].values\n",
    "\n",
    "            amp_stat, amp_p = stats.mannwhitneyu(\n",
    "                orienting_amps, compensatory_amps, alternative=\"two-sided\"\n",
    "            )\n",
    "\n",
    "            print(\"\\n  Amplitude (px):\")\n",
    "\n",
    "            print(\n",
    "                f\"    Orienting: {orienting_amps.mean():.2f} ± {orienting_amps.std():.2f} (median: {np.median(orienting_amps):.2f})\"\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"    Compensatory: {compensatory_amps.mean():.2f} ± {compensatory_amps.std():.2f} (median: {np.median(compensatory_amps):.2f})\"\n",
    "            )\n",
    "\n",
    "            print(f\"    Mann-Whitney U test: U={amp_stat:.1f}, p={amp_p:.4f}\")\n",
    "\n",
    "            # Duration comparison\n",
    "\n",
    "            orienting_durs = orienting_saccades[\"duration\"].values\n",
    "\n",
    "            compensatory_durs = compensatory_saccades[\"duration\"].values\n",
    "\n",
    "            dur_stat, dur_p = stats.mannwhitneyu(\n",
    "                orienting_durs, compensatory_durs, alternative=\"two-sided\"\n",
    "            )\n",
    "\n",
    "            print(\"\\n  Duration (s):\")\n",
    "\n",
    "            print(\n",
    "                f\"    Orienting: {orienting_durs.mean():.3f} ± {orienting_durs.std():.3f} (median: {np.median(orienting_durs):.3f})\"\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"    Compensatory: {compensatory_durs.mean():.3f} ± {compensatory_durs.std():.3f} (median: {np.median(compensatory_durs):.3f})\"\n",
    "            )\n",
    "\n",
    "            print(f\"    Mann-Whitney U test: U={dur_stat:.1f}, p={dur_p:.4f}\")\n",
    "\n",
    "            # Pre-saccade velocity comparison\n",
    "\n",
    "            orienting_pre_vel = orienting_saccades[\"pre_saccade_mean_velocity\"].values\n",
    "\n",
    "            compensatory_pre_vel = compensatory_saccades[\n",
    "                \"pre_saccade_mean_velocity\"\n",
    "            ].values\n",
    "\n",
    "            pre_vel_stat, pre_vel_p = stats.mannwhitneyu(\n",
    "                orienting_pre_vel, compensatory_pre_vel, alternative=\"two-sided\"\n",
    "            )\n",
    "\n",
    "            print(\"\\n  Pre-saccade velocity (px/s):\")\n",
    "\n",
    "            print(\n",
    "                f\"    Orienting: {orienting_pre_vel.mean():.2f} ± {orienting_pre_vel.std():.2f} (median: {np.median(orienting_pre_vel):.2f})\"\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"    Compensatory: {compensatory_pre_vel.mean():.2f} ± {compensatory_pre_vel.std():.2f} (median: {np.median(compensatory_pre_vel):.2f})\"\n",
    "            )\n",
    "\n",
    "            print(f\"    Mann-Whitney U test: U={pre_vel_stat:.1f}, p={pre_vel_p:.4f}\")\n",
    "\n",
    "            # Pre-saccade drift comparison\n",
    "\n",
    "            orienting_pre_drift = orienting_saccades[\n",
    "                \"pre_saccade_position_drift\"\n",
    "            ].values\n",
    "\n",
    "            compensatory_pre_drift = compensatory_saccades[\n",
    "                \"pre_saccade_position_drift\"\n",
    "            ].values\n",
    "\n",
    "            pre_drift_stat, pre_drift_p = stats.mannwhitneyu(\n",
    "                orienting_pre_drift, compensatory_pre_drift, alternative=\"two-sided\"\n",
    "            )\n",
    "\n",
    "            print(\"\\n  Pre-saccade position drift (px):\")\n",
    "\n",
    "            print(\n",
    "                f\"    Orienting: {orienting_pre_drift.mean():.2f} ± {orienting_pre_drift.std():.2f} (median: {np.median(orienting_pre_drift):.2f})\"\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"    Compensatory: {compensatory_pre_drift.mean():.2f} ± {compensatory_pre_drift.std():.2f} (median: {np.median(compensatory_pre_drift):.2f})\"\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"    Mann-Whitney U test: U={pre_drift_stat:.1f}, p={pre_drift_p:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Post-saccade variance comparison\n",
    "\n",
    "            orienting_post_var = orienting_saccades[\n",
    "                \"post_saccade_position_variance\"\n",
    "            ].values\n",
    "\n",
    "            compensatory_post_var = compensatory_saccades[\n",
    "                \"post_saccade_position_variance\"\n",
    "            ].values\n",
    "\n",
    "            post_var_stat, post_var_p = stats.mannwhitneyu(\n",
    "                orienting_post_var, compensatory_post_var, alternative=\"two-sided\"\n",
    "            )\n",
    "\n",
    "            print(\"\\n  Post-saccade position variance (px²):\")\n",
    "\n",
    "            print(\n",
    "                f\"    Orienting: {orienting_post_var.mean():.2f} ± {orienting_post_var.std():.2f} (median: {np.median(orienting_post_var):.2f})\"\n",
    "            )\n",
    "\n",
    "            print(\n",
    "                f\"    Compensatory: {compensatory_post_var.mean():.2f} ± {compensatory_post_var.std():.2f} (median: {np.median(compensatory_post_var):.2f})\"\n",
    "            )\n",
    "\n",
    "            print(f\"    Mann-Whitney U test: U={post_var_stat:.1f}, p={post_var_p:.4f}\")\n",
    "\n",
    "            # Bout size for compensatory saccades\n",
    "\n",
    "            if len(compensatory_saccades) > 0:\n",
    "                bout_sizes = compensatory_saccades[\"bout_size\"].values\n",
    "                print(\"\\n  Bout size (compensatory saccades only):\")\n",
    "                print(\n",
    "                    f\"    Mean: {bout_sizes.mean():.2f} ± {bout_sizes.std():.2f} saccades\"\n",
    "                )\n",
    "                print(\n",
    "                    f\"    Range: {bout_sizes.min():.0f} - {bout_sizes.max():.0f} saccades\"\n",
    "                )\n",
    "                print(f\"    Median: {np.median(bout_sizes):.0f} saccades\")\n",
    "\n",
    "            # Classification confidence comparison\n",
    "            if \"classification_confidence\" in all_saccades_df.columns:\n",
    "                orienting_conf = orienting_saccades[\"classification_confidence\"].values\n",
    "\n",
    "                compensatory_conf = compensatory_saccades[\n",
    "                    \"classification_confidence\"\n",
    "                ].values\n",
    "\n",
    "                conf_stat, conf_p = stats.mannwhitneyu(\n",
    "                    orienting_conf, compensatory_conf, alternative=\"two-sided\"\n",
    "                )\n",
    "\n",
    "                print(\"\\n  Classification Confidence:\")\n",
    "\n",
    "                print(\n",
    "                    f\"    Orienting: {orienting_conf.mean():.3f} ± {orienting_conf.std():.3f} (median: {np.median(orienting_conf):.3f})\"\n",
    "                )\n",
    "\n",
    "                print(\n",
    "                    f\"    Compensatory: {compensatory_conf.mean():.3f} ± {compensatory_conf.std():.3f} (median: {np.median(compensatory_conf):.3f})\"\n",
    "                )\n",
    "\n",
    "                print(f\"    Mann-Whitney U test: U={conf_stat:.1f}, p={conf_p:.4f}\")\n",
    "\n",
    "        else:\n",
    "            print(\n",
    "                \"  ⚠️ Cannot perform statistical comparisons - need both types present\"\n",
    "            )\n",
    "\n",
    "        # Visualization\n",
    "\n",
    "        # Create visualization figure\n",
    "\n",
    "        fig_class = make_subplots(\n",
    "            rows=2,\n",
    "            cols=3,\n",
    "            subplot_titles=(\n",
    "                \"Amplitude Distribution\",\n",
    "                \"Duration Distribution\",\n",
    "                \"Pre-saccade Velocity Distribution\",\n",
    "                \"Pre-saccade Position Drift\",\n",
    "                \"Post-saccade Position Variance\",\n",
    "                \"Bout Size Distribution (Compensatory)\",\n",
    "            ),\n",
    "            vertical_spacing=0.12,\n",
    "            horizontal_spacing=0.1,\n",
    "        )\n",
    "\n",
    "        # Row 1, Col 1: Amplitude distributions\n",
    "\n",
    "        if len(orienting_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=orienting_saccades[\"amplitude\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Orienting\",\n",
    "                    marker_color=\"blue\",\n",
    "                    opacity=0.6,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        if len(compensatory_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=compensatory_saccades[\"amplitude\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Compensatory\",\n",
    "                    marker_color=\"orange\",\n",
    "                    opacity=0.6,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=1,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        # Row 1, Col 2: Duration distributions\n",
    "\n",
    "        if len(orienting_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=orienting_saccades[\"duration\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Orienting\",\n",
    "                    marker_color=\"blue\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=1,\n",
    "                col=2,\n",
    "            )\n",
    "        if len(compensatory_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=compensatory_saccades[\"duration\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Compensatory\",\n",
    "                    marker_color=\"orange\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=1,\n",
    "                col=2,\n",
    "            )\n",
    "\n",
    "        # Row 1, Col 3: Pre-saccade velocity distributions\n",
    "\n",
    "        if len(orienting_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=orienting_saccades[\"pre_saccade_mean_velocity\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Orienting\",\n",
    "                    marker_color=\"blue\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=1,\n",
    "                col=3,\n",
    "            )\n",
    "\n",
    "        if len(compensatory_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=compensatory_saccades[\"pre_saccade_mean_velocity\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Compensatory\",\n",
    "                    marker_color=\"orange\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=1,\n",
    "                col=3,\n",
    "            )\n",
    "\n",
    "        # Row 2, Col 1: Pre-saccade drift distributions\n",
    "\n",
    "        if len(orienting_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=orienting_saccades[\"pre_saccade_position_drift\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Orienting\",\n",
    "                    marker_color=\"blue\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=2,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        if len(compensatory_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=compensatory_saccades[\"pre_saccade_position_drift\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Compensatory\",\n",
    "                    marker_color=\"orange\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=2,\n",
    "                col=1,\n",
    "            )\n",
    "\n",
    "        # Row 2, Col 2: Post-saccade variance distributions\n",
    "\n",
    "        if len(orienting_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=orienting_saccades[\"post_saccade_position_variance\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Orienting\",\n",
    "                    marker_color=\"blue\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=2,\n",
    "                col=2,\n",
    "            )\n",
    "\n",
    "        if len(compensatory_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=compensatory_saccades[\"post_saccade_position_variance\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Compensatory\",\n",
    "                    marker_color=\"orange\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=2,\n",
    "                col=2,\n",
    "            )\n",
    "\n",
    "        # Row 2, Col 3: Bout size distribution (compensatory only)\n",
    "\n",
    "        if len(compensatory_saccades) > 0:\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=compensatory_saccades[\"bout_size\"],\n",
    "                    nbinsx=20,\n",
    "                    name=\"Compensatory Bout Size\",\n",
    "                    marker_color=\"orange\",\n",
    "                    opacity=0.6,\n",
    "                    showlegend=False,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=2,\n",
    "                col=3,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # Add empty trace to maintain layout\n",
    "            fig_class.add_trace(\n",
    "                go.Histogram(x=[], name=\"No compensatory saccades\"), row=2, col=3\n",
    "            )\n",
    "\n",
    "        # Update layout\n",
    "\n",
    "        fig_class.update_layout(\n",
    "            title_text=f\"Saccade Classification Analysis: Orienting vs Compensatory ({get_eye_label(video_key)})\",\n",
    "            height=800,\n",
    "            showlegend=True,\n",
    "            legend=dict(x=0.02, y=0.98),\n",
    "        )\n",
    "\n",
    "        # Update axes labels\n",
    "        fig_class.update_xaxes(title_text=\"Amplitude (px)\", row=1, col=1)\n",
    "        fig_class.update_xaxes(title_text=\"Duration (s)\", row=1, col=2)\n",
    "        fig_class.update_xaxes(title_text=\"Velocity (px/s)\", row=1, col=3)\n",
    "        fig_class.update_xaxes(title_text=\"Drift (px)\", row=2, col=1)\n",
    "        fig_class.update_xaxes(title_text=\"Variance (px²)\", row=2, col=2)\n",
    "        fig_class.update_xaxes(title_text=\"Bout Size (saccades)\", row=2, col=3)\n",
    "\n",
    "        fig_class.update_yaxes(title_text=\"Probability\", row=1, col=1)\n",
    "        fig_class.update_yaxes(title_text=\"Probability\", row=1, col=2)\n",
    "        fig_class.update_yaxes(title_text=\"Probability\", row=1, col=3)\n",
    "        fig_class.update_yaxes(title_text=\"Probability\", row=2, col=1)\n",
    "        fig_class.update_yaxes(title_text=\"Probability\", row=2, col=2)\n",
    "        fig_class.update_yaxes(title_text=\"Probability\", row=2, col=3)\n",
    "\n",
    "        fig_class.show()\n",
    "\n",
    "        # Confidence distribution visualization\n",
    "\n",
    "        if \"classification_confidence\" in all_saccades_df.columns:\n",
    "            fig_conf = make_subplots(\n",
    "                rows=1,\n",
    "                cols=2,\n",
    "                subplot_titles=(\n",
    "                    \"Classification Confidence Distribution\",\n",
    "                    \"Confidence by Saccade Type\",\n",
    "                ),\n",
    "                horizontal_spacing=0.15,\n",
    "            )\n",
    "\n",
    "        # Overall confidence distribution\n",
    "\n",
    "        fig_conf.add_trace(\n",
    "            go.Histogram(\n",
    "                x=all_saccades_df[\"classification_confidence\"],\n",
    "                nbinsx=30,\n",
    "                name=\"All Saccades\",\n",
    "                marker_color=\"gray\",\n",
    "                opacity=0.7,\n",
    "                histnorm=\"probability\",\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Add vertical lines for confidence thresholds\n",
    "        fig_conf.add_vline(\n",
    "            x=0.7,\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"green\",\n",
    "            annotation_text=\"High (≥0.7)\",\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "        fig_conf.add_vline(\n",
    "            x=0.4,\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"orange\",\n",
    "            annotation_text=\"Medium (0.4-0.7)\",\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Confidence by type\n",
    "        if len(orienting_saccades) > 0:\n",
    "            fig_conf.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=orienting_saccades[\"classification_confidence\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Orienting\",\n",
    "                    marker_color=\"blue\",\n",
    "                    opacity=0.6,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=1,\n",
    "                col=2,\n",
    "            )\n",
    "        if len(compensatory_saccades) > 0:\n",
    "            fig_conf.add_trace(\n",
    "                go.Histogram(\n",
    "                    x=compensatory_saccades[\"classification_confidence\"],\n",
    "                    nbinsx=30,\n",
    "                    name=\"Compensatory\",\n",
    "                    marker_color=\"orange\",\n",
    "                    opacity=0.6,\n",
    "                    histnorm=\"probability\",\n",
    "                ),\n",
    "                row=1,\n",
    "                col=2,\n",
    "            )\n",
    "\n",
    "        fig_conf.update_layout(\n",
    "            title_text=f\"Classification Confidence Analysis ({get_eye_label(video_key)})\",\n",
    "            height=400,\n",
    "            showlegend=True,\n",
    "            legend=dict(x=0.02, y=0.98),\n",
    "        )\n",
    "\n",
    "        fig_conf.update_xaxes(title_text=\"Confidence Score\", row=1, col=1)\n",
    "\n",
    "        fig_conf.update_xaxes(title_text=\"Confidence Score\", row=1, col=2)\n",
    "\n",
    "        fig_conf.update_yaxes(title_text=\"Probability\", row=1, col=1)\n",
    "\n",
    "        fig_conf.update_yaxes(title_text=\"Probability\", row=1, col=2)\n",
    "\n",
    "        fig_conf.show()\n",
    "\n",
    "        # Time series visualization with classification\n",
    "\n",
    "        fig_ts = make_subplots(\n",
    "            rows=2,\n",
    "            cols=1,\n",
    "            shared_xaxes=True,\n",
    "            vertical_spacing=0.1,\n",
    "            subplot_titles=(\n",
    "                \"X Position (px)\",\n",
    "                \"Velocity (px/s) with Classified Saccades\",\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # Add position trace\n",
    "\n",
    "        fig_ts.add_trace(\n",
    "            go.Scatter(\n",
    "                x=res[\"df\"][\"Seconds\"],\n",
    "                y=res[\"df\"][\"X_smooth\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Smoothed X\",\n",
    "                line=dict(color=\"blue\", width=2),\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Add velocity trace\n",
    "\n",
    "        fig_ts.add_trace(\n",
    "            go.Scatter(\n",
    "                x=res[\"df\"][\"Seconds\"],\n",
    "                y=res[\"df\"][\"vel_x_smooth\"],\n",
    "                mode=\"lines\",\n",
    "                name=\"Smoothed Velocity\",\n",
    "                line=dict(color=\"red\", width=2),\n",
    "            ),\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Add adaptive threshold lines\n",
    "        fig_ts.add_hline(\n",
    "            y=res[\"vel_thresh\"],\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"green\",\n",
    "            opacity=0.5,\n",
    "            annotation_text=f\"Adaptive threshold (±{res['vel_thresh']:.0f} px/s)\",\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "        fig_ts.add_hline(\n",
    "            y=-res[\"vel_thresh\"],\n",
    "            line_dash=\"dash\",\n",
    "            line_color=\"green\",\n",
    "            opacity=0.5,\n",
    "            row=2,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Calculate position y-axis range for vertical lines\n",
    "        pos_max = res[\"df\"][\"X_smooth\"].max()\n",
    "        pos_min = res[\"df\"][\"X_smooth\"].min()\n",
    "        pos_range = pos_max - pos_min\n",
    "        # Add small padding to ensure lines span full visible range\n",
    "        pos_padding = pos_range * 0.05\n",
    "        pos_y_min = pos_min - pos_padding\n",
    "        pos_y_max = pos_max + pos_padding\n",
    "\n",
    "        # Plot orienting saccades (blue) as rectangles on position trace\n",
    "        orienting_in_df = all_saccades_df[\n",
    "            all_saccades_df[\"saccade_type\"] == \"orienting\"\n",
    "        ]\n",
    "        if len(orienting_in_df) > 0:\n",
    "            for idx, row in orienting_in_df.iterrows():\n",
    "                start_time = row[\"start_time\"]\n",
    "\n",
    "                end_time = row[\"end_time\"]\n",
    "\n",
    "                # Use rectangle with thin border to show duration span more\n",
    "                # efficiently\n",
    "\n",
    "                # Opacity must be set via rgba color, not in line dict\n",
    "\n",
    "                fig_ts.add_shape(\n",
    "                    type=\"rect\",\n",
    "                    x0=start_time,\n",
    "                    y0=pos_y_min,\n",
    "                    x1=end_time,\n",
    "                    y1=pos_y_max,\n",
    "                    fillcolor=\"rgba(0,0,255,0.1)\",  # Light blue fill with opacity\n",
    "                    # Blue border with opacity via rgba\n",
    "                    line=dict(color=\"rgba(0,0,255,0.3)\", width=2),\n",
    "                    row=1,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "        # Legend entry\n",
    "\n",
    "        fig_ts.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"lines\",\n",
    "                name=\"Orienting Saccades\",\n",
    "                line=dict(\n",
    "                    color=\"rgba(0,0,255,0.3)\", width=3\n",
    "                ),  # Blue with opacity via rgba\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Plot compensatory saccades (orange) as rectangles on position trace\n",
    "\n",
    "        compensatory_in_df = all_saccades_df[\n",
    "            all_saccades_df[\"saccade_type\"] == \"compensatory\"\n",
    "        ]\n",
    "\n",
    "        if len(compensatory_in_df) > 0:\n",
    "            for idx, row in compensatory_in_df.iterrows():\n",
    "                start_time = row[\"start_time\"]\n",
    "                end_time = row[\"end_time\"]\n",
    "\n",
    "                # Use rectangle with thin border to show duration span more\n",
    "                # efficiently\n",
    "\n",
    "                # Opacity must be set via rgba color, not in line dict\n",
    "\n",
    "                fig_ts.add_shape(\n",
    "                    type=\"rect\",\n",
    "                    x0=start_time,\n",
    "                    y0=pos_y_min,\n",
    "                    x1=end_time,\n",
    "                    y1=pos_y_max,\n",
    "                    # Light orange fill with opacity\n",
    "                    fillcolor=\"rgba(255,165,0,0.1)\",\n",
    "                    # Orange border with opacity via rgba\n",
    "                    line=dict(color=\"rgba(255,165,0,0.3)\", width=2),\n",
    "                    row=1,\n",
    "                    col=1,\n",
    "                )\n",
    "\n",
    "        # Legend entry\n",
    "\n",
    "        fig_ts.add_trace(\n",
    "            go.Scatter(\n",
    "                x=[None],\n",
    "                y=[None],\n",
    "                mode=\"lines\",\n",
    "                name=\"Compensatory Saccades\",\n",
    "                line=dict(\n",
    "                    color=\"rgba(255,165,0,0.3)\", width=3\n",
    "                ),  # Orange with opacity via rgba\n",
    "            ),\n",
    "            row=1,\n",
    "            col=1,\n",
    "        )\n",
    "\n",
    "        # Update layout\n",
    "        fig_ts.update_layout(\n",
    "            title=f\"Time Series with Saccade Classification ({get_eye_label(video_key)})<br><sub>Blue: Orienting, Orange: Compensatory</sub>\",\n",
    "            height=600,\n",
    "            showlegend=True,\n",
    "            legend=dict(x=0.01, y=0.99),\n",
    "        )\n",
    "\n",
    "        # Update axes\n",
    "        fig_ts.update_xaxes(title_text=\"Time (s)\", row=2, col=1)\n",
    "        fig_ts.update_yaxes(title_text=\"X Position (px)\", row=1, col=1)\n",
    "        fig_ts.update_yaxes(title_text=\"Velocity (px/s)\", row=2, col=1)\n",
    "\n",
    "        fig_ts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885e8421",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# ML Feature Extraction and Visualization\n",
    "# Extract features for ML classification and visualize distributions\n",
    "##########################################################################\n",
    "\n",
    "\n",
    "# Extract features for VideoData1 (if available)\n",
    "features_v1 = None\n",
    "if VideoData1_Has_Sleap and \"VideoData1\" in saccade_results:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Extracting ML features for VideoData1...\")\n",
    "    print(\"=\" * 80)\n",
    "    # Use the processed df from saccade_results (has X_smooth, vel_x_smooth\n",
    "    # columns)\n",
    "    df1_processed = saccade_results[\"VideoData1\"][\"df\"]\n",
    "    features_v1 = extract_ml_features(\n",
    "        saccade_results=saccade_results[\"VideoData1\"],\n",
    "        df=df1_processed,  # Use processed df with X_smooth, vel_x_smooth\n",
    "        fps=FPS_1,\n",
    "        data_path=data_path,\n",
    "        verbose=True,\n",
    "    )\n",
    "    if len(features_v1) > 0:\n",
    "        features_v1[\"eye\"] = \"Left\" if video1_eye == \"L\" else \"Right\"\n",
    "        print(\n",
    "            f\"✅ Extracted {len(features_v1)} saccades with {len(features_v1.columns)} features\"\n",
    "        )\n",
    "\n",
    "# Extract features for VideoData2 (if available)\n",
    "features_v2 = None\n",
    "if VideoData2_Has_Sleap and \"VideoData2\" in saccade_results:\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Extracting ML features for VideoData2...\")\n",
    "    print(\"=\" * 80)\n",
    "    # Use the processed df from saccade_results (has X_smooth, vel_x_smooth\n",
    "    # columns)\n",
    "    df2_processed = saccade_results[\"VideoData2\"][\"df\"]\n",
    "    features_v2 = extract_ml_features(\n",
    "        saccade_results=saccade_results[\"VideoData2\"],\n",
    "        df=df2_processed,  # Use processed df with X_smooth, vel_x_smooth\n",
    "        fps=FPS_2,\n",
    "        data_path=data_path,\n",
    "        verbose=True,\n",
    "    )\n",
    "    if len(features_v2) > 0:\n",
    "        features_v2[\"eye\"] = \"Right\" if video1_eye == \"L\" else \"Left\"\n",
    "        print(\n",
    "            f\"✅ Extracted {len(features_v2)} saccades with {len(features_v2.columns)} features\"\n",
    "        )\n",
    "\n",
    "# Combine features from both eyes\n",
    "if features_v1 is not None and features_v2 is not None:\n",
    "    features_combined = pd.concat([features_v1, features_v2], ignore_index=True)\n",
    "    print(\n",
    "        f\"\\n✅ Combined features: {len(features_combined)} total saccades ({len(features_v1)} left, {len(features_v2)} right)\"\n",
    "    )\n",
    "elif features_v1 is not None:\n",
    "    features_combined = features_v1.copy()\n",
    "    print(f\"\\n✅ Using VideoData1 only: {len(features_combined)} saccades\")\n",
    "elif features_v2 is not None:\n",
    "    features_combined = features_v2.copy()\n",
    "    print(f\"\\n✅ Using VideoData2 only: {len(features_combined)} saccades\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No features extracted - check if saccades were detected\")\n",
    "    features_combined = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65e3463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Feature Distributions: Panel 1 (Violin Plots by Category) + Panel 2 (Key Features by Class)\n",
    "##########################################################################\n",
    "\n",
    "if features_combined is not None and len(features_combined) > 0:\n",
    "    # Define feature categories\n",
    "    feature_categories = {\n",
    "        \"Category A: Basic Properties\": [\n",
    "            \"amplitude\",\n",
    "            \"duration\",\n",
    "            \"peak_velocity\",\n",
    "            \"direction\",\n",
    "            \"start_time\",\n",
    "            \"end_time\",\n",
    "            \"time\",\n",
    "        ],\n",
    "        \"Category B: Pre-Saccade\": [\n",
    "            \"pre_saccade_mean_velocity\",\n",
    "            \"pre_saccade_position_drift\",\n",
    "            \"pre_saccade_position_variance\",\n",
    "            \"pre_saccade_drift_rate\",\n",
    "            \"pre_saccade_window_duration\",\n",
    "        ],\n",
    "        \"Category C: Post-Saccade\": [\n",
    "            \"post_saccade_position_variance\",\n",
    "            \"post_saccade_position_change\",\n",
    "            \"post_saccade_position_change_pct\",\n",
    "            \"post_saccade_mean_velocity\",\n",
    "            \"post_saccade_drift_rate\",\n",
    "            \"post_saccade_window_duration\",\n",
    "        ],\n",
    "        \"Category D: Temporal Context\": [\n",
    "            \"time_since_previous_saccade\",\n",
    "            \"time_until_next_saccade\",\n",
    "            \"bout_size\",\n",
    "            \"position_in_bout\",\n",
    "            \"is_first_in_bout\",\n",
    "            \"is_last_in_bout\",\n",
    "            \"is_isolated\",\n",
    "            \"bout_duration\",\n",
    "            \"inter_saccade_interval_mean\",\n",
    "            \"inter_saccade_interval_std\",\n",
    "        ],\n",
    "        \"Category G: Amplitude/Direction Consistency\": [\n",
    "            \"amplitude_relative_to_bout_mean\",\n",
    "            \"amplitude_consistency_in_bout\",\n",
    "            \"direction_relative_to_previous\",\n",
    "        ],\n",
    "        \"Category H: Rule-Based Classification\": [\n",
    "            \"rule_based_class\",\n",
    "            \"rule_based_confidence\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    # Use the visualization function\n",
    "    visualize_ml_features(\n",
    "        features_combined=features_combined,\n",
    "        feature_categories=feature_categories,\n",
    "        video_labels=VIDEO_LABELS,\n",
    "        show_plots=True,\n",
    "        verbose=True,\n",
    "    )\n",
    "else:\n",
    "    print(\"⚠️ No features available for visualization. Run feature extraction first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAUNCH GUI ANNOTATION TOOL\n",
    "##########################################################################\n",
    "# Use this cell to launch the GUI for manual annotation of saccades\n",
    "# The GUI starts with rule-based classifications and allows you to correct\n",
    "# them to 4 classes\n",
    "\n",
    "# Get experiment ID\n",
    "experiment_id = extract_experiment_id(data_path)\n",
    "print(f\"Experiment ID: {experiment_id}\")\n",
    "\n",
    "# Launch GUI with BOTH eyes combined (VideoData1 and VideoData2)\n",
    "# The GUI will automatically combine saccades from both eyes and display\n",
    "# them together\n",
    "\n",
    "# Get features for BOTH eyes (since we're combining both eyes' saccades)\n",
    "# features_combined already contains features from both VideoData1 and\n",
    "# VideoData2\n",
    "video_features = (\n",
    "    features_combined\n",
    "    if features_combined is not None and len(features_combined) > 0\n",
    "    else None\n",
    ")\n",
    "\n",
    "# Set annotations file path (save in data_path parent directory)\n",
    "annotations_file = data_path.parent / \"saccade_annotations_master.csv\"\n",
    "# Or use a project-wide location:\n",
    "# annotations_file = Path('/Users/rancze/Documents/Data/vestVR/saccade_annotations_master.csv')\n",
    "\n",
    "# Count saccades from both eyes for display\n",
    "total_saccades = 0\n",
    "eye_breakdown = {}\n",
    "if isinstance(saccade_results, dict):\n",
    "    for key in [\"VideoData1\", \"VideoData2\"]:\n",
    "        if key in saccade_results:\n",
    "            eye_data = saccade_results[key]\n",
    "            if \"all_saccades_df\" in eye_data:\n",
    "                count = len(eye_data[\"all_saccades_df\"])\n",
    "                total_saccades += count\n",
    "                eye_label = VIDEO_LABELS.get(key, key)\n",
    "                eye_breakdown[eye_label] = count\n",
    "\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"Launching GUI Annotation Tool (BOTH EYES)\")\n",
    "print(f\"{'=' * 80}\")\n",
    "print(f\"Experiment ID: {experiment_id}\")\n",
    "print(f\"Eyes: {', '.join(eye_breakdown.keys()) if eye_breakdown else 'Unknown'}\")\n",
    "print(f\"Total saccades: {total_saccades}\")\n",
    "if eye_breakdown:\n",
    "    for eye, count in eye_breakdown.items():\n",
    "        print(f\"  - {eye}: {count} saccades\")\n",
    "print(f\"Features: {len(video_features) if video_features is not None else 0}\")\n",
    "print(f\"Annotations file: {annotations_file}\")\n",
    "print(f\"{'=' * 80}\\n\")\n",
    "print(\"ℹ️ Instructions:\")\n",
    "print(\n",
    "    \"  - Use keyboard shortcuts: 1=Compensatory, 2=Orienting, 3=Saccade-and-Fixate, 4=Non-Saccade\"\n",
    ")\n",
    "print(\"  - Navigation: . = Next, , = Previous, S = Save\")\n",
    "print(\"  - Click on saccades in the table to select them\")\n",
    "print(\"  - The table shows saccades from both eyes (L and R) combined\")\n",
    "print(\"  - Close the GUI window when done annotating\")\n",
    "print(f\"{'=' * 80}\\n\")\n",
    "\n",
    "# Launch GUI (this will block until GUI is closed)\n",
    "# Pass the FULL saccade_results dict so both eyes are combined\n",
    "launch_annotation_gui(\n",
    "    # Pass full dict with VideoData1 and VideoData2 keys\n",
    "    saccade_results=saccade_results,\n",
    "    features_df=video_features,  # Pass all features (both eyes)\n",
    "    experiment_id=experiment_id,\n",
    "    annotations_file_path=annotations_file,\n",
    ")\n",
    "\n",
    "# After GUI closes, show statistics\n",
    "print(f\"\\n{'=' * 80}\")\n",
    "print(\"Annotation session complete!\")\n",
    "print(f\"{'=' * 80}\")\n",
    "\n",
    "# Load and display annotations\n",
    "annotations = load_annotations(annotations_file, experiment_id=experiment_id)\n",
    "if len(annotations) > 0:\n",
    "    print(f\"\\n✅ Annotated {len(annotations)} saccades for this experiment\")\n",
    "    print_annotation_stats(annotations_file, experiment_id=experiment_id)\n",
    "else:\n",
    "    print(\"\\n⚠️ No annotations saved for this experiment\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "aeon2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
