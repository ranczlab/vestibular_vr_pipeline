{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import Dict, Iterable, List, Optional, Tuple\n",
    "\n",
    "import math\n",
    "import os\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "try:\n",
    "    from scipy import stats\n",
    "except Exception:  # pragma: no cover - SciPy is optional\n",
    "    stats = None\n",
    "    warnings.warn(\n",
    "        \"SciPy is not available; paired t-test p-values will be reported as NaN.\",\n",
    "        RuntimeWarning,\n",
    "    )\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    \"figure.dpi\": 120,\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 11,\n",
    "})\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "# ----------------------------------------------------------------------\n",
    "#HERE: COMMENT OUT PATHS YOU DON'T WANT TO RUN. For example, run analysis only for experimental day types. \n",
    "# Will automatically separate halt and no halt\n",
    "# Root directories containing cohort-level folders with aligned data.\n",
    "DATA_DIRS: List[Path] = [\n",
    "    Path(\"/Volumes/RanczLab2/Cohort1_rotation/Visual_mismatch_day4/\").expanduser(),\n",
    "    Path(\"/Volumes/RanczLab2/Cohort3_rotation/Visual_mismatch_day4/\").expanduser(),\n",
    "    # Path(\"/Volumes/RanczLab2/Cohort1_rotation/Visual_mismatch_day3\").expanduser(),\n",
    "    # Path(\"/Volumes/RanczLab2/Cohort3_rotation/Visual_mismatch_day3/\").expanduser(),\n",
    "]\n",
    "\n",
    "OUTPUT_SUBDIR_NAME = \"turning_analysis\"\n",
    "\n",
    "# Diagnostic settings\n",
    "ENABLE_DECAY_DIAGNOSTICS = False  # Set True to run detailed diagnostics on decay fit failures\n",
    "MAX_DIAGNOSTIC_EXAMPLES = 3       # Maximum number of failed fits to diagnose in detail\n",
    "\n",
    "# Event file suffixes that encode turn direction in their names.\n",
    "EVENT_SUFFIXES: List[str] = [\n",
    "    \"_Apply halt_2s_right_turns_baselined_data.csv\",\n",
    "    \"_Apply halt_2s_left_turns_baselined_data.csv\",\n",
    "    \"_No halt_right_turns_baselined_data.csv\",\n",
    "    \"_No halt_left_turns_baselined_data.csv\",\n",
    "]\n",
    "\n",
    "# Optional subset of mice to analyse (use [] to include every mouse found).\n",
    "SELECTED_MICE: List[str] = []\n",
    "\n",
    "# Data columns\n",
    "TIME_COLUMN = \"Time (s)\"\n",
    "VELOCITY_COLUMN = \"Motor_Velocity\"  # Motor turning velocity (deg/s)\n",
    "RUNNING_COLUMN = \"Velocity_0X\"      # Forward running velocity (m/s)\n",
    "\n",
    "# ==================================================================================\n",
    "# TIME WINDOW CONFIGURATION\n",
    "# ==================================================================================\n",
    "# All windows are (start, end) tuples in seconds, relative to turn onset (t=0)\n",
    "# \n",
    "# USAGE GUIDE:\n",
    "# - BASELINE_WINDOW: Pre-halt baseline for direction change detection & normalization\n",
    "# - ANALYSIS_WINDOW_MEAN_PEAK: ⚙️ PRIMARY CONFIGURABLE WINDOW ⚙️\n",
    "#   Controls the analysis window for:\n",
    "#   • Post-halt mean velocity (turning & running)\n",
    "#   • Peak velocity (turning & running)\n",
    "#   • AUC calculation\n",
    "#   Default: (0.0, 1.0) = analyze the first 1 second after halt onset\n",
    "# - EXTENDED_RESPONSE_WINDOW: For mean absolute velocity (combines left/right turns)\n",
    "# - FULL_RESPONSE_WINDOW: For exponential decay fitting (longer window needed)\n",
    "# - TEMPORAL_DYNAMICS_WINDOWS: Fine-grained windows for temporal pattern analysis\n",
    "# ==================================================================================\n",
    "\n",
    "# Baseline (pre-halt) window\n",
    "BASELINE_WINDOW = (-1.0, 0.0)  # Used for: direction detection, baseline normalization\n",
    "\n",
    "# Post-halt response windows (used for primary metrics)\n",
    "# ⚙️ USER CONFIGURABLE: Change this window to control mean and peak velocity analysis\n",
    "ANALYSIS_WINDOW_MEAN_PEAK = (0.0, 2.0)  # Window for post-halt mean & peak velocity analysis\n",
    "\n",
    "EARLY_RESPONSE_WINDOW = ANALYSIS_WINDOW_MEAN_PEAK  # Used for: peak velocity, AUC, post-halt mean\n",
    "FULL_RESPONSE_WINDOW = (0.0, 3.0)       # Used for: exponential decay fitting\n",
    "\n",
    "# Fine-grained temporal dynamics windows (used for alternative metrics)\n",
    "TEMPORAL_EARLY_WINDOW = (0.0, 0.5)   # Immediate response phase\n",
    "TEMPORAL_MID_WINDOW = (0.5, 1.0)     # Mid response phase\n",
    "TEMPORAL_LATE_WINDOW = (1.0, 2.0)    # Sustained response phase\n",
    "TEMPORAL_FULL_WINDOW = (0.0, 2.0)    # Full temporal analysis window\n",
    "\n",
    "# Legacy compatibility (kept for function signatures, but values derived from above)\n",
    "EXTENDED_RESPONSE_WINDOW = ANALYSIS_WINDOW_MEAN_PEAK   # Used for: mean absolute velocity (combines left/right)\n",
    "PRE_WINDOW = BASELINE_WINDOW           # Alias for backward compatibility\n",
    "POST_WINDOW = EARLY_RESPONSE_WINDOW   # Alias for backward compatibility\n",
    "PEAK_WINDOW = EARLY_RESPONSE_WINDOW   # Peak finding window (same as early response)\n",
    "AUC_WINDOW = EARLY_RESPONSE_WINDOW    # Primary AUC window (same as early response)\n",
    "DECAY_FIT_WINDOW = FULL_RESPONSE_WINDOW  # Decay fitting window\n",
    "\n",
    "# Other thresholds\n",
    "ZERO_THRESHOLD = 1e-2      # Threshold (deg/s) to treat near-zero values as zero\n",
    "LATENCY_FRACTION = 0.5     # [DEPRECATED] Fraction of peak for latency calculation\n",
    "\n",
    "# Mapping from inferred turn direction to expected velocity sign after time 0.\n",
    "# Here we expect the actual turn to be opposite the label in the filename.\n",
    "EXPECTED_DIRECTION_SIGN = {\n",
    "    \"right\": -1,  # filenames tagged \"right\" should result in negative velocity\n",
    "    \"left\": 1,    # filenames tagged \"left\" should result in positive velocity\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def _iter_raw_mouse_dirs(data_dirs: Iterable[Path]) -> Iterable[Tuple[str, Path]]:\n",
    "    \"\"\"Yield (mouse_id, raw_dir) pairs for each mouse found in the data dirs.\"\"\"\n",
    "    for data_dir in data_dirs:\n",
    "        base = Path(data_dir)\n",
    "        if not base.exists():\n",
    "            print(f\"⚠️ Data directory not found: {base}\")\n",
    "            continue\n",
    "\n",
    "        if base.is_dir() and base.name.endswith(\"_processedData\"):\n",
    "            raw_dir = base.with_name(base.name.replace(\"_processedData\", \"\"))\n",
    "            if raw_dir.exists():\n",
    "                mouse_id = raw_dir.name.split(\"-\")[0]\n",
    "                yield mouse_id, raw_dir\n",
    "            else:\n",
    "                print(f\"⚠️ Raw directory for processed data not found: {base}\")\n",
    "            continue\n",
    "\n",
    "        if not base.is_dir():\n",
    "            continue\n",
    "\n",
    "        candidate_mouse_dirs = [\n",
    "            subdir\n",
    "            for subdir in base.iterdir()\n",
    "            if subdir.is_dir() and \"-\" in subdir.name and not subdir.name.endswith(\"_processedData\")\n",
    "        ]\n",
    "        if candidate_mouse_dirs:\n",
    "            for subdir in candidate_mouse_dirs:\n",
    "                mouse_id = subdir.name.split(\"-\")[0]\n",
    "                yield mouse_id, subdir\n",
    "            continue\n",
    "\n",
    "        mouse_id = base.name.split(\"-\")[0]\n",
    "        yield mouse_id, base\n",
    "\n",
    "\n",
    "def find_turn_event_files(\n",
    "    data_dirs: Iterable[Path],\n",
    "    event_suffixes: Iterable[str],\n",
    "    selected_mice: Optional[Iterable[str]] = None,\n",
    ") -> List[Dict[str, object]]:\n",
    "    \"\"\"Locate aligned CSV files whose names encode turn direction.\"\"\"\n",
    "    selected = set(selected_mice or [])\n",
    "    matches: List[Dict[str, object]] = []\n",
    "\n",
    "    for mouse_id, raw_dir in _iter_raw_mouse_dirs(data_dirs):\n",
    "        if selected and mouse_id not in selected:\n",
    "            continue\n",
    "\n",
    "        aligned_dir = raw_dir.parent / f\"{raw_dir.name}_processedData\" / \"aligned_data\"\n",
    "        if not aligned_dir.exists():\n",
    "            continue\n",
    "\n",
    "        for suffix in event_suffixes:\n",
    "            csv_path = aligned_dir / f\"{mouse_id}{suffix}\"\n",
    "            if not csv_path.exists():\n",
    "                continue\n",
    "            direction = infer_direction_from_name(csv_path.name)\n",
    "            group = infer_event_group(suffix)\n",
    "            matches.append(\n",
    "                {\n",
    "                    \"mouse\": mouse_id,\n",
    "                    \"direction\": direction,\n",
    "                    \"group\": group,\n",
    "                    \"event_suffix\": suffix,\n",
    "                    \"csv_path\": csv_path,\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return matches\n",
    "\n",
    "\n",
    "def infer_direction_from_name(filename: str) -> str:\n",
    "    name = filename.lower()\n",
    "    if \"right\" in name:\n",
    "        return \"right\"\n",
    "    if \"left\" in name:\n",
    "        return \"left\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "def infer_event_group(name: str) -> str:\n",
    "    lower = name.lower()\n",
    "    if \"no_halt\" in lower or \"no halt\" in lower:\n",
    "        return \"No halt\"\n",
    "    if \"apply\" in lower:\n",
    "        return \"Apply halt\"\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def load_time_series(\n",
    "    csv_path: Path,\n",
    "    time_column: str,\n",
    "    value_column: str,\n",
    "    value_alias: str = \"velocity\",\n",
    ") -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if time_column not in df.columns:\n",
    "        raise ValueError(f\"Time column '{time_column}' not found in {csv_path}\")\n",
    "    if value_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{value_column}' not found in {csv_path}\")\n",
    "    subset = df[[time_column, value_column]].copy()\n",
    "    subset = subset.dropna()\n",
    "    subset = subset.rename(columns={time_column: \"time\", value_column: value_alias})\n",
    "    subset[\"time\"] = pd.to_numeric(subset[\"time\"], errors=\"coerce\")\n",
    "    subset[value_alias] = pd.to_numeric(subset[value_alias], errors=\"coerce\")\n",
    "    subset = subset.dropna()\n",
    "    subset = subset.sort_values(\"time\")\n",
    "    return subset\n",
    "\n",
    "\n",
    "def load_motor_velocity(\n",
    "    csv_path: Path,\n",
    "    time_column: str,\n",
    "    velocity_column: str,\n",
    ") -> pd.DataFrame:\n",
    "    return load_time_series(csv_path, time_column, velocity_column, value_alias=\"velocity\")\n",
    "\n",
    "\n",
    "def compute_window_mean(df: pd.DataFrame, window: Tuple[float, float]) -> float:\n",
    "    start, end = window\n",
    "    mask = (df[\"time\"] >= start) & (df[\"time\"] < end if start < end else df[\"time\"] <= end)\n",
    "    if not mask.any():\n",
    "        return float(\"nan\")\n",
    "    return float(df.loc[mask, \"velocity\"].mean())\n",
    "\n",
    "\n",
    "def sign_with_threshold(value: float, threshold: float) -> int:\n",
    "    if not math.isfinite(value) or abs(value) <= threshold:\n",
    "        return 0\n",
    "    return 1 if value > 0 else -1\n",
    "\n",
    "\n",
    "def sem(values) -> float:\n",
    "    arr = np.asarray(values, dtype=float)\n",
    "    arr = arr[np.isfinite(arr)]\n",
    "    n = arr.size\n",
    "    if n <= 1:\n",
    "        return 0.0 if n == 1 else float(\"nan\")\n",
    "    return float(arr.std(ddof=1) / np.sqrt(n))\n",
    "\n",
    "\n",
    "def fit_exponential_decay(time_values: Iterable[float], amplitude_values: Iterable[float], verbose: bool = False) -> float:\n",
    "    \"\"\"\n",
    "    Fit exponential decay: y = A * exp(-t/tau)\n",
    "    \n",
    "    NOTE: This often fails because motor velocity doesn't always show clean exponential decay.\n",
    "    The velocity may:\n",
    "    - Stay elevated (sustained turning)\n",
    "    - Show complex multi-phase dynamics\n",
    "    - Have noise that breaks the exponential assumption\n",
    "    \n",
    "    Consider using alternative metrics like AUC in different time windows instead.\n",
    "    \"\"\"\n",
    "    time_arr = np.asarray(time_values, dtype=float)\n",
    "    amp_arr = np.asarray(amplitude_values, dtype=float)\n",
    "    mask = np.isfinite(time_arr) & np.isfinite(amp_arr)\n",
    "    if mask.sum() < 3:\n",
    "        if verbose:\n",
    "            print(f\"Decay fit failed: Only {mask.sum()} finite points\")\n",
    "        return float(\"nan\")\n",
    "    time_arr = time_arr[mask]\n",
    "    amp_arr = amp_arr[mask]\n",
    "    amp_arr = np.abs(amp_arr)\n",
    "    positive_mask = amp_arr > 0\n",
    "    if positive_mask.sum() < 3:\n",
    "        if verbose:\n",
    "            print(f\"Decay fit failed: Only {positive_mask.sum()} positive amplitude points\")\n",
    "        return float(\"nan\")\n",
    "    time_arr = time_arr[positive_mask]\n",
    "    amp_arr = amp_arr[positive_mask]\n",
    "    time_arr = time_arr - time_arr.min()\n",
    "    if time_arr.ptp() <= 0:\n",
    "        if verbose:\n",
    "            print(\"Decay fit failed: No time variation\")\n",
    "        return float(\"nan\")\n",
    "    log_amp = np.log(amp_arr)\n",
    "    slope, intercept = np.polyfit(time_arr, log_amp, 1)\n",
    "    if slope >= 0:\n",
    "        if verbose:\n",
    "            print(f\"Decay fit failed: Non-decaying (slope={slope:.6f})\")\n",
    "            print(f\"  → Signal is increasing or flat, not exponentially decaying\")\n",
    "            print(f\"  → Consider using AUC or sustained response metrics instead\")\n",
    "        return float(\"nan\")\n",
    "    tau = -1.0 / slope\n",
    "    return float(tau)\n",
    "\n",
    "\n",
    "def assign_mouse_colors_consistent(mouse_ids: Iterable[str]) -> Dict[str, tuple]:\n",
    "    normalized = [str(mouse) for mouse in mouse_ids]\n",
    "    unique_mice = sorted(dict.fromkeys(normalized))\n",
    "    if not unique_mice:\n",
    "        return OrderedDict()\n",
    "    palette = sns.color_palette(\"gnuplot2\", len(unique_mice))\n",
    "    return OrderedDict((mouse, palette[idx]) for idx, mouse in enumerate(unique_mice))\n",
    "\n",
    "\n",
    "def compute_windowed_auc(\n",
    "    df: pd.DataFrame,\n",
    "    windows: List[Tuple[float, float]],\n",
    "    time_col: str = \"time\",\n",
    "    value_col: str = \"velocity\",\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute area under curve for multiple time windows.\n",
    "    \n",
    "    This is often more robust than decay fitting for characterizing response dynamics.\n",
    "    Different windows capture different phases of the response:\n",
    "    - Early (0-0.5s): Initial response magnitude\n",
    "    - Mid (0.5-1s): Sustained response\n",
    "    - Late (1-2s): Extended dynamics\n",
    "    \"\"\"\n",
    "    auc_results = {}\n",
    "    for start, end in windows:\n",
    "        window_df = df[(df[time_col] >= start) & (df[time_col] <= end)]\n",
    "        if not window_df.empty and len(window_df) > 1:\n",
    "            auc = float(np.trapz(\n",
    "                np.abs(window_df[value_col].to_numpy()),\n",
    "                window_df[time_col].to_numpy()\n",
    "            ))\n",
    "            auc_results[f\"auc_{start}_{end}s\"] = auc\n",
    "        else:\n",
    "            auc_results[f\"auc_{start}_{end}s\"] = float(\"nan\")\n",
    "    return auc_results\n",
    "\n",
    "\n",
    "def compute_sustained_response_ratio(\n",
    "    df: pd.DataFrame,\n",
    "    early_window: Tuple[float, float] = (0.0, 0.5),\n",
    "    late_window: Tuple[float, float] = (1.0, 2.0),\n",
    "    time_col: str = \"time\",\n",
    "    value_col: str = \"velocity\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute ratio of late to early response magnitude.\n",
    "    \n",
    "    Ratio < 1: Response decays\n",
    "    Ratio ~ 1: Response is sustained\n",
    "    Ratio > 1: Response increases over time\n",
    "    \n",
    "    This can distinguish between transient vs sustained turning responses.\n",
    "    \"\"\"\n",
    "    early_auc = compute_window_mean(df.rename(columns={time_col: \"time\", value_col: \"velocity\"}), early_window)\n",
    "    late_auc = compute_window_mean(df.rename(columns={time_col: \"time\", value_col: \"velocity\"}), late_window)\n",
    "    \n",
    "    if math.isfinite(early_auc) and math.isfinite(late_auc) and abs(early_auc) > 1e-6:\n",
    "        return float(abs(late_auc) / abs(early_auc))\n",
    "    return float(\"nan\")\n",
    "\n",
    "\n",
    "def compute_time_to_baseline(\n",
    "    df: pd.DataFrame,\n",
    "    baseline_window: Tuple[float, float] = (-1.0, 0.0),\n",
    "    post_start: float = 0.0,\n",
    "    n_std: float = 2.0,\n",
    "    time_col: str = \"time\",\n",
    "    value_col: str = \"velocity\",\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute time for response to return to baseline level (mean + n_std).\n",
    "    \n",
    "    Returns NaN if response never returns to baseline in the available data.\n",
    "    This is more interpretable than tau for non-exponential dynamics.\n",
    "    \"\"\"\n",
    "    baseline_df = df[(df[time_col] >= baseline_window[0]) & (df[time_col] < baseline_window[1])]\n",
    "    if baseline_df.empty:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    baseline_mean = float(baseline_df[value_col].abs().mean())\n",
    "    baseline_std = float(baseline_df[value_col].abs().std())\n",
    "    threshold = baseline_mean + n_std * baseline_std\n",
    "    \n",
    "    post_df = df[df[time_col] >= post_start].sort_values(time_col)\n",
    "    if post_df.empty:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    post_abs = post_df[value_col].abs()\n",
    "    below_threshold = post_abs < threshold\n",
    "    \n",
    "    if not below_threshold.any():\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    # Find first sustained return (at least 3 consecutive points below threshold)\n",
    "    below_indices = post_df.index[below_threshold].tolist()\n",
    "    if len(below_indices) < 3:\n",
    "        return float(\"nan\")\n",
    "    \n",
    "    for i in range(len(below_indices) - 2):\n",
    "        if (below_indices[i+1] == below_indices[i] + 1 and \n",
    "            below_indices[i+2] == below_indices[i] + 2):\n",
    "            return float(post_df.loc[below_indices[i], time_col])\n",
    "    \n",
    "    return float(\"nan\")\n",
    "\n",
    "\n",
    "def diagnostic_exponential_fit(\n",
    "    time_values: Iterable[float],\n",
    "    amplitude_values: Iterable[float],\n",
    "    title: str = \"Decay Fit Diagnostic\",\n",
    "    show_plots: bool = True,\n",
    ") -> Tuple[float, Dict[str, object]]:\n",
    "    \"\"\"\n",
    "    Detailed diagnostic of exponential decay fitting.\n",
    "    \n",
    "    Returns:\n",
    "        tau: The decay time constant (NaN if fit fails)\n",
    "        diagnostics: Dictionary with diagnostic information\n",
    "    \"\"\"\n",
    "    time_arr = np.asarray(time_values, dtype=float)\n",
    "    amp_arr = np.asarray(amplitude_values, dtype=float)\n",
    "    \n",
    "    diagnostics = {\n",
    "        \"title\": title,\n",
    "        \"n_points_initial\": len(time_arr),\n",
    "        \"time_range\": (float(time_arr.min()), float(time_arr.max())) if len(time_arr) > 0 else (np.nan, np.nan),\n",
    "        \"amp_range\": (float(amp_arr.min()), float(amp_arr.max())) if len(amp_arr) > 0 else (np.nan, np.nan),\n",
    "        \"failure_reason\": None,\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{title}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Initial data points: {len(time_arr)}\")\n",
    "    if len(time_arr) > 0:\n",
    "        print(f\"Time range: {time_arr.min():.3f} to {time_arr.max():.3f}\")\n",
    "        print(f\"Amplitude range: {amp_arr.min():.3f} to {amp_arr.max():.3f}\")\n",
    "    \n",
    "    # Check 1: Finite values\n",
    "    mask = np.isfinite(time_arr) & np.isfinite(amp_arr)\n",
    "    if mask.sum() < 3:\n",
    "        diagnostics[\"failure_reason\"] = f\"Only {mask.sum()} finite points (need ≥3)\"\n",
    "        print(f\"❌ FAIL: {diagnostics['failure_reason']}\")\n",
    "        return float(\"nan\"), diagnostics\n",
    "    \n",
    "    time_arr = time_arr[mask]\n",
    "    amp_arr = amp_arr[mask]\n",
    "    diagnostics[\"n_points_finite\"] = int(mask.sum())\n",
    "    print(f\"After finite check: {len(time_arr)} points\")\n",
    "    \n",
    "    # Check 2: Absolute values\n",
    "    amp_arr = np.abs(amp_arr)\n",
    "    positive_mask = amp_arr > 0\n",
    "    if positive_mask.sum() < 3:\n",
    "        diagnostics[\"failure_reason\"] = f\"Only {positive_mask.sum()} positive amplitude points\"\n",
    "        print(f\"❌ FAIL: {diagnostics['failure_reason']}\")\n",
    "        return float(\"nan\"), diagnostics\n",
    "    \n",
    "    time_arr = time_arr[positive_mask]\n",
    "    amp_arr = amp_arr[positive_mask]\n",
    "    diagnostics[\"n_points_positive\"] = int(positive_mask.sum())\n",
    "    print(f\"After positive check: {len(time_arr)} points\")\n",
    "    \n",
    "    # Check 3: Time normalization\n",
    "    time_arr = time_arr - time_arr.min()\n",
    "    if time_arr.ptp() <= 0:\n",
    "        diagnostics[\"failure_reason\"] = f\"No time variation (ptp={time_arr.ptp()})\"\n",
    "        print(f\"❌ FAIL: {diagnostics['failure_reason']}\")\n",
    "        return float(\"nan\"), diagnostics\n",
    "    \n",
    "    diagnostics[\"time_ptp\"] = float(time_arr.ptp())\n",
    "    print(f\"Time variation (ptp): {time_arr.ptp():.3f}\")\n",
    "    \n",
    "    # Check 4: Log transform and linear fit\n",
    "    log_amp = np.log(amp_arr)\n",
    "    slope, intercept = np.polyfit(time_arr, log_amp, 1)\n",
    "    diagnostics[\"slope\"] = float(slope)\n",
    "    diagnostics[\"intercept\"] = float(intercept)\n",
    "    print(f\"Log-linear fit: slope={slope:.6f}, intercept={intercept:.3f}\")\n",
    "    \n",
    "    if slope >= 0:\n",
    "        diagnostics[\"failure_reason\"] = f\"Non-decaying (slope={slope:.6f})\"\n",
    "        diagnostics[\"amp_start\"] = float(amp_arr[0])\n",
    "        diagnostics[\"amp_end\"] = float(amp_arr[-1])\n",
    "        diagnostics[\"amp_mean\"] = float(amp_arr.mean())\n",
    "        diagnostics[\"trend\"] = \"increasing\" if amp_arr[-1] > amp_arr[0] else \"decreasing\"\n",
    "        \n",
    "        print(f\"❌ FAIL: Positive or zero slope ({slope:.6f}) - not decaying!\")\n",
    "        print(f\"   This means the signal is INCREASING or flat, not decaying.\")\n",
    "        print(f\"\\n   Amplitude at start: {amp_arr[0]:.3f}\")\n",
    "        print(f\"   Amplitude at end: {amp_arr[-1]:.3f}\")\n",
    "        print(f\"   Mean amplitude: {amp_arr.mean():.3f}\")\n",
    "        print(f\"   Amplitude trend: {diagnostics['trend']}\")\n",
    "        \n",
    "        if show_plots:\n",
    "            # Create diagnostic plot\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "            \n",
    "            # Plot 1: Actual data\n",
    "            axes[0].plot(time_arr, amp_arr, 'o-', label='Data', color='#1f77b4')\n",
    "            axes[0].set_xlabel('Time (s)')\n",
    "            axes[0].set_ylabel('|Velocity| (deg/s)')\n",
    "            axes[0].set_title('Absolute Velocity vs Time')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 2: Log scale\n",
    "            axes[1].plot(time_arr, log_amp, 'o-', label='Log(amplitude)', color='#1f77b4')\n",
    "            axes[1].plot(time_arr, slope * time_arr + intercept, 'r--', \n",
    "                        label=f'Fit: slope={slope:.4f}', linewidth=2)\n",
    "            axes[1].set_xlabel('Time (s)')\n",
    "            axes[1].set_ylabel('Log(|Velocity|)')\n",
    "            axes[1].set_title('Log Scale (should be linear for exponential decay)')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.suptitle(f\"{title} - Decay Fit Failed\", fontsize=12)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return float(\"nan\"), diagnostics\n",
    "    \n",
    "    tau = -1.0 / slope\n",
    "    diagnostics[\"tau\"] = float(tau)\n",
    "    diagnostics[\"failure_reason\"] = None\n",
    "    print(f\"✅ SUCCESS: τ = {tau:.3f} s\")\n",
    "    \n",
    "    if show_plots:\n",
    "        # Create diagnostic plot for successful fit\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        # Plot 1: Actual data with exponential fit\n",
    "        fitted_curve = np.exp(intercept) * np.exp(slope * time_arr)\n",
    "        axes[0].plot(time_arr, amp_arr, 'o', label='Data', alpha=0.6, color='#1f77b4')\n",
    "        axes[0].plot(time_arr, fitted_curve, 'r-', label=f'Fit: τ={tau:.3f}s', linewidth=2)\n",
    "        axes[0].set_xlabel('Time (s)')\n",
    "        axes[0].set_ylabel('|Velocity| (deg/s)')\n",
    "        axes[0].set_title('Exponential Decay Fit')\n",
    "        axes[0].legend()\n",
    "        axes[0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 2: Log scale\n",
    "        axes[1].plot(time_arr, log_amp, 'o', label='Log(amplitude)', color='#1f77b4')\n",
    "        axes[1].plot(time_arr, slope * time_arr + intercept, 'r--', \n",
    "                    label=f'Fit: slope={slope:.4f}', linewidth=2)\n",
    "        axes[1].set_xlabel('Time (s)')\n",
    "        axes[1].set_ylabel('Log(|Velocity|)')\n",
    "        axes[1].set_title('Log Scale')\n",
    "        axes[1].legend()\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Plot 3: Residuals\n",
    "        residuals = log_amp - (slope * time_arr + intercept)\n",
    "        axes[2].plot(time_arr, residuals, 'o', color='#1f77b4')\n",
    "        axes[2].axhline(0, color='r', linestyle='--', linewidth=2)\n",
    "        axes[2].set_xlabel('Time (s)')\n",
    "        axes[2].set_ylabel('Residuals')\n",
    "        axes[2].set_title('Fit Residuals')\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.suptitle(f\"{title} - Decay Fit Successful\", fontsize=12)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return float(tau), diagnostics\n",
    "\n",
    "\n",
    "def _sanitize_label(value: str) -> str:\n",
    "    cleaned = re.sub(r\"[^\\w\\-]+\", \"_\", value)\n",
    "    cleaned = re.sub(r\"_+\", \"_\", cleaned)\n",
    "    return cleaned.strip(\"_\")\n",
    "\n",
    "\n",
    "def build_output_folder_name(base_name: str, data_dirs: Iterable[Path]) -> str:\n",
    "    labels: List[str] = []\n",
    "    for directory in data_dirs:\n",
    "        try:\n",
    "            path = Path(directory).expanduser()\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not path.exists():\n",
    "            continue\n",
    "        cohort = path.parent.name if path.parent != path else \"\"\n",
    "        day = path.name\n",
    "        parts = [part for part in (cohort, day) if part]\n",
    "        if not parts:\n",
    "            continue\n",
    "        label = _sanitize_label(\"_\".join(parts))\n",
    "        if not label:\n",
    "            continue\n",
    "        if label not in labels:\n",
    "            labels.append(label)\n",
    "    if not labels:\n",
    "        return base_name\n",
    "    suffix = \"__\".join(labels)\n",
    "    return f\"{base_name}__{suffix}\"\n",
    "\n",
    "\n",
    "def determine_output_directory(data_dirs: Iterable[Path], folder_name: str) -> Optional[Path]:\n",
    "    existing_dirs = []\n",
    "    for directory in data_dirs:\n",
    "        candidate = Path(directory).expanduser()\n",
    "        if candidate.exists():\n",
    "            existing_dirs.append(candidate)\n",
    "    if not existing_dirs:\n",
    "        print(\"⚠️ No existing data directories found; results will not be saved.\")\n",
    "        return None\n",
    "\n",
    "    folder_name = build_output_folder_name(folder_name, existing_dirs)\n",
    "    try:\n",
    "        common_path = Path(os.path.commonpath([str(path) for path in existing_dirs]))\n",
    "    except ValueError:\n",
    "        common_path = existing_dirs[0]\n",
    "\n",
    "    candidate_bases: List[Path] = []\n",
    "    candidate_bases.append(common_path)\n",
    "    for path in existing_dirs:\n",
    "        if path not in candidate_bases:\n",
    "            candidate_bases.append(path)\n",
    "        parent = path.parent\n",
    "        if parent not in candidate_bases:\n",
    "            candidate_bases.append(parent)\n",
    "    cwd_base = Path.cwd()\n",
    "    if cwd_base not in candidate_bases:\n",
    "        candidate_bases.append(cwd_base)\n",
    "\n",
    "    for base in candidate_bases:\n",
    "        target_dir = Path(base) / folder_name\n",
    "        try:\n",
    "            target_dir.mkdir(parents=True, exist_ok=True)\n",
    "            return target_dir\n",
    "        except Exception as exc:  # noqa: BLE001\n",
    "            print(f\"⚠️ Could not create output directory {target_dir}: {exc}\")\n",
    "\n",
    "    print(\"⚠️ Exhausted all fallback locations; results will not be saved.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def compute_paired_t_test(\n",
    "    pivot_df: pd.DataFrame,\n",
    "    group_a: str,\n",
    "    group_b: str,\n",
    ") -> Dict[str, float]:\n",
    "    result = {\n",
    "        \"n_pairs\": 0,\n",
    "        \"mean_difference\": float(\"nan\"),\n",
    "        \"t_statistic\": float(\"nan\"),\n",
    "        \"p_value\": float(\"nan\"),\n",
    "    }\n",
    "    if group_a not in pivot_df.columns or group_b not in pivot_df.columns:\n",
    "        return result\n",
    "    paired = pivot_df[[group_a, group_b]].dropna()\n",
    "    n_pairs = int(len(paired))\n",
    "    result[\"n_pairs\"] = n_pairs\n",
    "    if n_pairs == 0:\n",
    "        return result\n",
    "\n",
    "    diff = paired[group_b] - paired[group_a]\n",
    "    mean_diff = float(diff.mean())\n",
    "    result[\"mean_difference\"] = mean_diff\n",
    "\n",
    "    if n_pairs < 2:\n",
    "        return result\n",
    "\n",
    "    if stats is not None:\n",
    "        t_stat, p_value = stats.ttest_rel(\n",
    "            paired[group_b].to_numpy(dtype=float),\n",
    "            paired[group_a].to_numpy(dtype=float),\n",
    "            nan_policy=\"omit\",\n",
    "        )\n",
    "        result[\"t_statistic\"] = float(t_stat)\n",
    "        result[\"p_value\"] = float(p_value)\n",
    "    else:\n",
    "        std_diff = diff.std(ddof=1)\n",
    "        if math.isfinite(std_diff) and std_diff > 0:\n",
    "            t_statistic = mean_diff / (std_diff / math.sqrt(n_pairs))\n",
    "            result[\"t_statistic\"] = float(t_statistic)\n",
    "    return result\n",
    "\n",
    "\n",
    "OUTPUT_DIR = determine_output_directory(DATA_DIRS, OUTPUT_SUBDIR_NAME)\n",
    "if OUTPUT_DIR is not None:\n",
    "    print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "\n",
    "def analyse_turn_direction(\n",
    "    df: pd.DataFrame,\n",
    "    pre_window: Tuple[float, float],\n",
    "    post_window: Tuple[float, float],\n",
    "    zero_threshold: float,\n",
    ") -> Dict[str, float]:\n",
    "    pre_mean = compute_window_mean(df, pre_window)\n",
    "    post_mean = compute_window_mean(df, post_window)\n",
    "    pre_sign = sign_with_threshold(pre_mean, zero_threshold)\n",
    "    post_sign = sign_with_threshold(post_mean, zero_threshold)\n",
    "    direction_changed = (pre_sign != 0 and post_sign != 0 and pre_sign != post_sign)\n",
    "    return {\n",
    "        \"pre_mean\": pre_mean,\n",
    "        \"post_mean\": post_mean,\n",
    "        \"pre_sign\": pre_sign,\n",
    "        \"post_sign\": post_sign,\n",
    "        \"direction_changed\": direction_changed,\n",
    "    }\n",
    "\n",
    "\n",
    "def summarise_results(results: pd.DataFrame) -> pd.DataFrame:\n",
    "    if results.empty:\n",
    "        return results\n",
    "    group_cols = [\"group\", \"direction\", \"expected_sign\"]\n",
    "    grouped = (\n",
    "        results.groupby(group_cols, dropna=False)\n",
    "        .agg(\n",
    "            n_files=(\"mouse\", \"count\"),\n",
    "            n_mice=(\"mouse\", \"nunique\"),\n",
    "            mean_post_velocity=(\"post_mean\", \"mean\"),\n",
    "            fraction_direction_change=(\"direction_changed\", \"mean\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    grouped[\"fraction_direction_change\"] = grouped[\"fraction_direction_change\"].round(3)\n",
    "    return grouped\n",
    "\n",
    "\n",
    "def compute_turn_timing_metrics(\n",
    "    df: pd.DataFrame,\n",
    "    expected_sign: float,\n",
    "    zero_threshold: float,\n",
    "    peak_window: Tuple[float, float],\n",
    "    auc_window: Tuple[float, float],\n",
    "    pre_window: Tuple[float, float],\n",
    "    latency_fraction: float,\n",
    "    decay_fit_window: Tuple[float, float],\n",
    ") -> Dict[str, float]:\n",
    "    sign_used = expected_sign\n",
    "    if not math.isfinite(sign_used) or sign_used == 0:\n",
    "        post_mean = compute_window_mean(df, (0.0, 1.0))\n",
    "        fallback_sign = sign_with_threshold(post_mean, zero_threshold)\n",
    "        sign_used = fallback_sign if fallback_sign != 0 else 1\n",
    "\n",
    "    start_peak, end_peak = peak_window\n",
    "    peak_subset = df[(df[\"time\"] >= start_peak) & (df[\"time\"] <= end_peak)]\n",
    "    timing_metrics = {\n",
    "        \"sign_used\": float(sign_used),\n",
    "        \"time_to_peak\": float(\"nan\"),\n",
    "        \"peak_velocity_signed\": float(\"nan\"),\n",
    "        \"peak_velocity_magnitude\": float(\"nan\"),\n",
    "        \"peak_velocity_abs_1s\": float(\"nan\"),\n",
    "        \"latency_to_fraction_peak\": float(\"nan\"),\n",
    "        \"auc_abs\": float(\"nan\"),\n",
    "        \"decay_tau\": float(\"nan\"),\n",
    "    }\n",
    "    if peak_subset.empty:\n",
    "        return timing_metrics\n",
    "\n",
    "    abs_velocity = peak_subset[\"velocity\"].abs()\n",
    "    if abs_velocity.isna().all():\n",
    "        return timing_metrics\n",
    "\n",
    "    peak_idx = abs_velocity.idxmax()\n",
    "    peak_value_abs = abs_velocity.loc[peak_idx]\n",
    "    if not math.isfinite(peak_value_abs) or peak_value_abs <= 0:\n",
    "        return timing_metrics\n",
    "\n",
    "    peak_time = float(peak_subset.loc[peak_idx, \"time\"])\n",
    "    raw_peak_value = float(peak_subset.loc[peak_idx, \"velocity\"])\n",
    "    timing_metrics[\"time_to_peak\"] = peak_time\n",
    "    timing_metrics[\"peak_velocity_signed\"] = raw_peak_value\n",
    "    timing_metrics[\"peak_velocity_magnitude\"] = float(peak_value_abs)\n",
    "    timing_metrics[\"peak_velocity_abs_1s\"] = float(peak_value_abs)\n",
    "\n",
    "    baseline_mask = (df[\"time\"] >= pre_window[0]) & (df[\"time\"] <= pre_window[1])\n",
    "    baseline_abs = df.loc[baseline_mask, \"velocity\"].abs().mean()\n",
    "    baseline_abs = float(baseline_abs) if math.isfinite(baseline_abs) else 0.0\n",
    "\n",
    "    if 0 < latency_fraction < 1 and peak_value_abs > baseline_abs:\n",
    "        target_value = baseline_abs + (peak_value_abs - baseline_abs) * latency_fraction\n",
    "        time_values = peak_subset[\"time\"].to_numpy(dtype=float)\n",
    "        abs_values = abs_velocity.to_numpy(dtype=float)\n",
    "        above_threshold_idx = np.where(abs_values >= target_value)[0]\n",
    "        if above_threshold_idx.size:\n",
    "            idx = int(above_threshold_idx[0])\n",
    "            if idx == 0:\n",
    "                latency_time = float(time_values[0])\n",
    "            else:\n",
    "                prev_idx = idx - 1\n",
    "                y0 = abs_values[prev_idx]\n",
    "                y1 = abs_values[idx]\n",
    "                t0 = time_values[prev_idx]\n",
    "                t1 = time_values[idx]\n",
    "                if not math.isfinite(y0):\n",
    "                    y0 = 0.0\n",
    "                if not math.isfinite(y1) or math.isclose(y1, y0):\n",
    "                    latency_time = float(t1)\n",
    "                else:\n",
    "                    fraction = (target_value - y0) / (y1 - y0)\n",
    "                    fraction = min(max(fraction, 0.0), 1.0)\n",
    "                    latency_time = float(t0 + fraction * (t1 - t0))\n",
    "            timing_metrics[\"latency_to_fraction_peak\"] = latency_time\n",
    "\n",
    "    start_auc, end_auc = auc_window\n",
    "    auc_subset = df[(df[\"time\"] >= start_auc) & (df[\"time\"] <= end_auc)]\n",
    "    if not auc_subset.empty:\n",
    "        auc_abs = auc_subset[\"velocity\"].abs()\n",
    "        auc_value = float(np.trapz(auc_abs.to_numpy(), auc_subset[\"time\"].to_numpy()))\n",
    "        timing_metrics[\"auc_abs\"] = auc_value\n",
    "\n",
    "    start_decay, end_decay = decay_fit_window\n",
    "    if math.isfinite(peak_time):\n",
    "        start_decay = max(start_decay, peak_time)\n",
    "    decay_mask = (df[\"time\"] >= start_decay) & (df[\"time\"] <= end_decay)\n",
    "    decay_subset = df.loc[decay_mask].copy()\n",
    "    if not decay_subset.empty:\n",
    "        decay_subset[\"abs_velocity\"] = decay_subset[\"velocity\"].abs()\n",
    "        per_time = (\n",
    "            decay_subset.groupby(\"time\", dropna=False)[\"abs_velocity\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "            .sort_values(\"time\")\n",
    "        )\n",
    "        tau = fit_exponential_decay(per_time[\"time\"], per_time[\"abs_velocity\"])\n",
    "        if math.isfinite(tau):\n",
    "            timing_metrics[\"decay_tau\"] = float(tau)\n",
    "\n",
    "    return timing_metrics\n",
    "\n",
    "\n",
    "def plot_motor_velocity(df: pd.DataFrame, title: str, pre_window, post_window) -> None:\n",
    "    fig, ax = plt.subplots(figsize=(6, 3.5))\n",
    "    ax.plot(df[\"time\"], df[\"velocity\"], color=\"#1f77b4\", linewidth=0.9)\n",
    "    ax.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "    ax.axvspan(pre_window[0], pre_window[1], color=\"#2ca02c\", alpha=0.15, label=\"Pre window\")\n",
    "    ax.axvspan(post_window[0], post_window[1], color=\"#d62728\", alpha=0.15, label=\"Post window\")\n",
    "    ax.set_xlabel(\"Time (s)\")\n",
    "    ax.set_ylabel(\"Motor velocity (deg/s)\")\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load data and compute direction metrics\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "turn_event_files = find_turn_event_files(DATA_DIRS, EVENT_SUFFIXES, SELECTED_MICE)\n",
    "print(f\"Found {len(turn_event_files)} turn-specific files\")\n",
    "\n",
    "records: List[Dict[str, object]] = []\n",
    "trace_records: List[pd.DataFrame] = []\n",
    "errors: List[str] = []\n",
    "\n",
    "for entry in turn_event_files:\n",
    "    csv_path = entry[\"csv_path\"]\n",
    "    try:\n",
    "        df = load_motor_velocity(csv_path, TIME_COLUMN, VELOCITY_COLUMN)\n",
    "    except Exception as exc:  # noqa: BLE001\n",
    "        errors.append(f\"{csv_path}: {exc}\")\n",
    "        continue\n",
    "\n",
    "    metrics = analyse_turn_direction(df, PRE_WINDOW, POST_WINDOW, ZERO_THRESHOLD)\n",
    "    expected_sign = EXPECTED_DIRECTION_SIGN.get(entry[\"direction\"], np.nan)\n",
    "    timing_metrics = compute_turn_timing_metrics(\n",
    "        df,\n",
    "        expected_sign,\n",
    "        ZERO_THRESHOLD,\n",
    "        PEAK_WINDOW,\n",
    "        AUC_WINDOW,\n",
    "        PRE_WINDOW,\n",
    "        LATENCY_FRACTION,\n",
    "        DECAY_FIT_WINDOW,\n",
    "    )\n",
    "\n",
    "    enriched_trace = df.copy()\n",
    "    enriched_trace[\"group\"] = entry[\"group\"]\n",
    "    enriched_trace[\"mouse\"] = entry[\"mouse\"]\n",
    "    enriched_trace[\"direction\"] = entry[\"direction\"]\n",
    "    enriched_trace[\"csv_path\"] = str(csv_path)\n",
    "    enriched_trace[\"sign_used\"] = timing_metrics.get(\"sign_used\", expected_sign)\n",
    "    trace_records.append(enriched_trace)\n",
    "\n",
    "    records.append(\n",
    "        {\n",
    "            **entry,\n",
    "            **metrics,\n",
    "            **timing_metrics,\n",
    "            \"expected_sign\": expected_sign,\n",
    "            \"csv_path\": str(csv_path),\n",
    "        }\n",
    "    )\n",
    "\n",
    "results_df = pd.DataFrame(records)\n",
    "trace_samples_df = pd.concat(trace_records, ignore_index=True) if trace_records else pd.DataFrame()\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Inspect any files that could not be processed\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59fdb99",
   "metadata": {},
   "source": [
    "### Decay fit diagnostics (optional)\n",
    "If enabled, diagnose why exponential decay fitting fails for specific examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc63b3c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Run detailed diagnostics on failed decay fits\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if ENABLE_DECAY_DIAGNOSTICS and not results_df.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"DECAY FIT DIAGNOSTICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Find files where decay fit failed (tau is NaN)\n",
    "    failed_fits = results_df[results_df[\"decay_tau\"].isna()].copy()\n",
    "    \n",
    "    if failed_fits.empty:\n",
    "        print(\"✅ All decay fits succeeded (no NaN values)\")\n",
    "    else:\n",
    "        n_failed = len(failed_fits)\n",
    "        print(f\"⚠️ Found {n_failed} failed decay fits out of {len(results_df)} total\")\n",
    "        print(f\"   ({100 * n_failed / len(results_df):.1f}% failure rate)\\n\")\n",
    "        \n",
    "        # Analyze distribution of failures\n",
    "        print(\"Failure distribution:\")\n",
    "        for group_name, group_df in failed_fits.groupby(\"group\", dropna=False):\n",
    "            n_group = len(group_df)\n",
    "            n_group_total = len(results_df[results_df[\"group\"] == group_name])\n",
    "            print(f\"  {group_name}: {n_group}/{n_group_total} failed ({100*n_group/n_group_total:.1f}%)\")\n",
    "        \n",
    "        # Run detailed diagnostics on a few examples\n",
    "        n_to_diagnose = min(MAX_DIAGNOSTIC_EXAMPLES, len(failed_fits))\n",
    "        print(f\"\\nRunning detailed diagnostics on {n_to_diagnose} examples...\")\n",
    "        \n",
    "        diagnostic_results = []\n",
    "        \n",
    "        for idx, row in failed_fits.head(n_to_diagnose).iterrows():\n",
    "            csv_path = Path(row[\"csv_path\"])\n",
    "            try:\n",
    "                df = load_motor_velocity(csv_path, TIME_COLUMN, VELOCITY_COLUMN)\n",
    "            except Exception as exc:\n",
    "                print(f\"⚠️ Could not load {csv_path}: {exc}\")\n",
    "                continue\n",
    "            \n",
    "            # Extract decay window data\n",
    "            decay_mask = (df[\"time\"] >= DECAY_FIT_WINDOW[0]) & (df[\"time\"] <= DECAY_FIT_WINDOW[1])\n",
    "            decay_data = df.loc[decay_mask].copy()\n",
    "            \n",
    "            if decay_data.empty:\n",
    "                print(f\"⚠️ No data in decay window for {row['mouse']} - {row['group']}\")\n",
    "                continue\n",
    "            \n",
    "            # Group by time and average (same as original analysis)\n",
    "            decay_data[\"abs_velocity\"] = decay_data[\"velocity\"].abs()\n",
    "            per_time = (\n",
    "                decay_data.groupby(\"time\", dropna=False)[\"abs_velocity\"]\n",
    "                .mean()\n",
    "                .reset_index()\n",
    "                .sort_values(\"time\")\n",
    "            )\n",
    "            \n",
    "            # Run diagnostic\n",
    "            title = f\"{row['mouse']} | {row['group']} | {row['direction']} turn\"\n",
    "            tau, diag_info = diagnostic_exponential_fit(\n",
    "                per_time[\"time\"].values,\n",
    "                per_time[\"abs_velocity\"].values,\n",
    "                title=title,\n",
    "                show_plots=True,\n",
    "            )\n",
    "            \n",
    "            diagnostic_results.append({\n",
    "                \"mouse\": row[\"mouse\"],\n",
    "                \"group\": row[\"group\"],\n",
    "                \"direction\": row[\"direction\"],\n",
    "                \"csv_path\": str(csv_path),\n",
    "                **diag_info,\n",
    "            })\n",
    "        \n",
    "        # Save diagnostic results\n",
    "        if diagnostic_results:\n",
    "            diagnostic_df = pd.DataFrame(diagnostic_results)\n",
    "            if OUTPUT_DIR is not None:\n",
    "                diagnostic_df.to_csv(OUTPUT_DIR / \"decay_fit_diagnostics.csv\", index=False)\n",
    "                print(f\"\\n✅ Saved diagnostic results to: {OUTPUT_DIR / 'decay_fit_diagnostics.csv'}\")\n",
    "            \n",
    "            # Summary of failure reasons\n",
    "            print(\"\\n\" + \"-\"*60)\n",
    "            print(\"Summary of failure reasons:\")\n",
    "            if \"failure_reason\" in diagnostic_df.columns:\n",
    "                for reason, count_df in diagnostic_df.groupby(\"failure_reason\"):\n",
    "                    if pd.notna(reason):\n",
    "                        print(f\"  {reason}: {len(count_df)} cases\")\n",
    "elif ENABLE_DECAY_DIAGNOSTICS:\n",
    "    print(\"⚠️ Decay diagnostics enabled but no results available to diagnose\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running velocity summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Running velocity (Velocity_0X_Baseline) analysis\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "running_records: List[Dict[str, object]] = []\n",
    "running_trace_records: List[pd.DataFrame] = []\n",
    "running_errors: List[str] = []\n",
    "running_peak_diagnostics: List[Dict[str, object]] = []\n",
    "\n",
    "if not results_df.empty:\n",
    "    for _, row in results_df.iterrows():\n",
    "        csv_path = Path(row[\"csv_path\"])\n",
    "        try:\n",
    "            running_df = load_time_series(csv_path, TIME_COLUMN, RUNNING_COLUMN, value_alias=\"velocity\")\n",
    "        except Exception as exc:  # noqa: BLE001\n",
    "            running_errors.append(f\"{csv_path}: {exc}\")\n",
    "            continue\n",
    "\n",
    "        peak_window_mask = (running_df[\"time\"] >= 0.0) & (running_df[\"time\"] <= 1.0)\n",
    "        if peak_window_mask.any():\n",
    "            raw_peak_abs_mps = float(running_df.loc[peak_window_mask, \"velocity\"].abs().max())\n",
    "        else:\n",
    "            raw_peak_abs_mps = float(\"nan\")\n",
    "\n",
    "        running_df[\"velocity\"] = running_df[\"velocity\"] * 100.0\n",
    "\n",
    "        running_metrics = analyse_turn_direction(running_df, PRE_WINDOW, POST_WINDOW, ZERO_THRESHOLD)\n",
    "        expected_sign = EXPECTED_DIRECTION_SIGN.get(row[\"direction\"], np.nan)\n",
    "\n",
    "        running_trace = running_df.copy()\n",
    "        running_trace[\"group\"] = row[\"group\"]\n",
    "        running_trace[\"mouse\"] = row[\"mouse\"]\n",
    "        running_trace[\"turn_label\"] = row[\"direction\"]\n",
    "        running_trace[\"csv_path\"] = row[\"csv_path\"]\n",
    "        running_trace_records.append(running_trace)\n",
    "\n",
    "        running_records.append(\n",
    "            {\n",
    "                \"mouse\": row[\"mouse\"],\n",
    "                \"turn_label\": row[\"direction\"],\n",
    "                \"group\": row[\"group\"],\n",
    "                \"event_suffix\": row[\"event_suffix\"],\n",
    "                \"csv_path\": row[\"csv_path\"],\n",
    "                **running_metrics,\n",
    "                \"expected_sign\": expected_sign,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        running_peak_diagnostics.append(\n",
    "            {\n",
    "                \"mouse\": row[\"mouse\"],\n",
    "                \"group\": row[\"group\"],\n",
    "                \"turn_label\": row[\"direction\"],\n",
    "                \"csv_path\": row[\"csv_path\"],\n",
    "                \"peak_abs_velocity_mps\": raw_peak_abs_mps,\n",
    "                \"peak_abs_velocity_cmps\": raw_peak_abs_mps * 100.0 if math.isfinite(raw_peak_abs_mps) else float(\"nan\"),\n",
    "            }\n",
    "        )\n",
    "\n",
    "running_results_df = pd.DataFrame(running_records)\n",
    "if not running_results_df.empty:\n",
    "    running_results_df[\"direction\"] = \"All turns\"\n",
    "running_trace_samples_df = pd.concat(running_trace_records, ignore_index=True) if running_trace_records else pd.DataFrame()\n",
    "if not running_trace_samples_df.empty:\n",
    "    running_trace_samples_df[\"direction\"] = \"All turns\"\n",
    "\n",
    "running_peak_diag_df = pd.DataFrame(running_peak_diagnostics)\n",
    "\n",
    "running_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545f36c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if running_peak_diag_df.empty:\n",
    "    print(\"⚠️ No running peak diagnostics available\")\n",
    "else:\n",
    "    display(Markdown(\"#### Running peak velocity diagnostics (per file)\"))\n",
    "    display(\n",
    "        running_peak_diag_df.sort_values(\"peak_abs_velocity_cmps\", ascending=False)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    if OUTPUT_DIR is not None:\n",
    "        running_peak_diag_df.to_csv(OUTPUT_DIR / \"running_peak_velocity_diagnostic.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "running_summary_df = summarise_results(running_results_df)\n",
    "if running_summary_df.empty:\n",
    "    print(\"⚠️ No running velocity statistics available\")\n",
    "else:\n",
    "    for group_name, subdf in running_summary_df.groupby(\"group\", dropna=False):\n",
    "        title = group_name if isinstance(group_name, str) else \"Unknown\"\n",
    "        display(Markdown(f\"#### {title}\"))\n",
    "        display(subdf.drop(columns=[\"group\"], errors=\"ignore\").reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if running_results_df.empty:\n",
    "    running_mouse_means = pd.DataFrame()\n",
    "else:\n",
    "    running_mouse_means = (\n",
    "        running_results_df.groupby([\"group\", \"mouse\"], dropna=False)\n",
    "        .agg(\n",
    "            post_mean=(\"post_mean\", \"mean\"),\n",
    "            pre_mean=(\"pre_mean\", \"mean\"),\n",
    "            n_files=(\"csv_path\", \"count\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    running_mouse_means[\"expected_sign\"] = np.nan\n",
    "    running_mouse_means[\"post_sign\"] = running_mouse_means[\"post_mean\"].apply(lambda v: sign_with_threshold(v, ZERO_THRESHOLD))\n",
    "    running_mouse_means[\"direction\"] = \"All turns\"\n",
    "\n",
    "running_mouse_means\n",
    "\n",
    "if running_trace_samples_df.empty:\n",
    "    running_peak_abs_df = pd.DataFrame()\n",
    "else:\n",
    "    running_peak_mask = (running_trace_samples_df[\"time\"] >= 0.0) & (running_trace_samples_df[\"time\"] <= 1.0)\n",
    "    running_peak_subset = running_trace_samples_df.loc[running_peak_mask].copy()\n",
    "    if running_peak_subset.empty:\n",
    "        running_peak_abs_df = pd.DataFrame()\n",
    "    else:\n",
    "        running_peak_subset[\"abs_velocity\"] = running_peak_subset[\"velocity\"].abs()\n",
    "        running_per_record_peak = (\n",
    "            running_peak_subset.groupby([\"mouse\", \"group\", \"csv_path\"], dropna=False)[\"abs_velocity\"]\n",
    "            .max()\n",
    "            .reset_index(name=\"peak_velocity_abs_1s\")\n",
    "        )\n",
    "        running_peak_abs_df = (\n",
    "            running_per_record_peak.groupby([\"mouse\", \"group\"], dropna=False)[\"peak_velocity_abs_1s\"]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "if running_mouse_means.empty and running_peak_abs_df.empty:\n",
    "    running_metrics_combined = pd.DataFrame()\n",
    "else:\n",
    "    if running_mouse_means.empty:\n",
    "        running_metrics_combined = running_peak_abs_df.copy()\n",
    "    else:\n",
    "        running_metrics_combined = running_mouse_means[[\"group\", \"mouse\", \"post_mean\"]].copy()\n",
    "        if \"direction\" in running_mouse_means.columns and \"direction\" not in running_metrics_combined.columns:\n",
    "            running_metrics_combined[\"direction\"] = running_mouse_means[\"direction\"]\n",
    "        if \"n_files\" in running_mouse_means.columns and \"n_files\" not in running_metrics_combined.columns:\n",
    "            running_metrics_combined[\"n_files\"] = running_mouse_means[\"n_files\"]\n",
    "        if \"pre_mean\" in running_mouse_means.columns and \"pre_mean\" not in running_metrics_combined.columns:\n",
    "            running_metrics_combined[\"pre_mean\"] = running_mouse_means[\"pre_mean\"]\n",
    "        if \"expected_sign\" in running_mouse_means.columns and \"expected_sign\" not in running_metrics_combined.columns:\n",
    "            running_metrics_combined[\"expected_sign\"] = running_mouse_means[\"expected_sign\"]\n",
    "        if \"post_sign\" in running_mouse_means.columns and \"post_sign\" not in running_metrics_combined.columns:\n",
    "            running_metrics_combined[\"post_sign\"] = running_mouse_means[\"post_sign\"]\n",
    "        if running_peak_abs_df.empty:\n",
    "            pass\n",
    "        else:\n",
    "            running_metrics_combined = pd.merge(\n",
    "                running_metrics_combined,\n",
    "                running_peak_abs_df,\n",
    "                on=[\"mouse\", \"group\"],\n",
    "                how=\"outer\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if running_trace_samples_df.empty:\n",
    "    running_per_mouse_traces = pd.DataFrame()\n",
    "    running_avg_traces = pd.DataFrame()\n",
    "    print(\"⚠️ No running traces available. Ensure the running velocity analysis cell completed successfully.\")\n",
    "else:\n",
    "    running_per_mouse_traces = (\n",
    "        running_trace_samples_df\n",
    "        .groupby([\"group\", \"mouse\", \"time\"], dropna=False)[\"velocity\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    running_per_mouse_traces[\"direction\"] = \"All turns\"\n",
    "    running_avg_traces = (\n",
    "        running_per_mouse_traces\n",
    "        .groupby([\"group\", \"direction\", \"time\"], dropna=False)\n",
    "        .agg(\n",
    "            mean_velocity=(\"velocity\", \"mean\"),\n",
    "            sem_velocity=(\"velocity\", lambda x: sem(x) if len(x.dropna()) > 1 else 0.0),\n",
    "            n_mice=(\"mouse\", \"nunique\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    n_traces = running_trace_samples_df[\"csv_path\"].nunique()\n",
    "    n_mice_traces = running_trace_samples_df[\"mouse\"].nunique()\n",
    "    print(f\"✅ Running traces aggregated: {n_traces} files across {n_mice_traces} mice.\")\n",
    "\n",
    "running_avg_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "if running_avg_traces.empty:\n",
    "    print(\"⚠️ Skipping running trace plots because no averaged traces are available.\")\n",
    "else:\n",
    "    plot_groups = [\"Apply halt\", \"No halt\"]\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=True)\n",
    "\n",
    "    for ax, group_name in zip(axes, plot_groups):\n",
    "        subset = running_avg_traces[running_avg_traces[\"group\"] == group_name]\n",
    "        if subset.empty:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\")\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        ax.plot(subset[\"time\"], subset[\"mean_velocity\"], color=\"#ff7f0e\", linewidth=1.5)\n",
    "        if \"sem_velocity\" in subset.columns:\n",
    "            upper = subset[\"mean_velocity\"] + subset[\"sem_velocity\"].fillna(0)\n",
    "            lower = subset[\"mean_velocity\"] - subset[\"sem_velocity\"].fillna(0)\n",
    "            ax.fill_between(subset[\"time\"], lower, upper, color=\"#ff7f0e\", alpha=0.2)\n",
    "\n",
    "        ax.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "        ax.axhline(0, color=\"grey\", linestyle=\":\", linewidth=1)\n",
    "        ax.set_title(f\"Running | {group_name}\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Running velocity (cm/s)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db1d544",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Running velocity comparisons (Apply halt vs No halt)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "running_metric_specs = [\n",
    "    (\"post_mean\", f\"Post-halt mean velocity {ANALYSIS_WINDOW_MEAN_PEAK[0]}-{ANALYSIS_WINDOW_MEAN_PEAK[1]}s (cm/s)\"),\n",
    "    (\"peak_velocity_abs_1s\", f\"Peak running velocity {ANALYSIS_WINDOW_MEAN_PEAK[0]}-{ANALYSIS_WINDOW_MEAN_PEAK[1]}s (cm/s)\"),\n",
    "]\n",
    "running_plot_groups = [\"No halt\", \"Apply halt\"]\n",
    "running_stats_df = pd.DataFrame()\n",
    "\n",
    "if running_metrics_combined.empty:\n",
    "    print(\"⚠️ No per-mouse running velocity metrics available for comparison\")\n",
    "else:\n",
    "    running_mouse_colors = assign_mouse_colors_consistent(running_metrics_combined[\"mouse\"].dropna().unique())\n",
    "    available_running_specs = [\n",
    "        (metric, label)\n",
    "        for metric, label in running_metric_specs\n",
    "        if metric in running_metrics_combined.columns\n",
    "    ]\n",
    "\n",
    "    if not available_running_specs:\n",
    "        print(\"⚠️ Running metrics not found in aggregated data\")\n",
    "    else:\n",
    "        subplot_width_cm = 7.5\n",
    "        subplot_height_cm = 7\n",
    "        fig_width = len(available_running_specs) * subplot_width_cm / 2.54\n",
    "        fig_height = subplot_height_cm / 2.54\n",
    "        fig, axes = plt.subplots(\n",
    "            1,\n",
    "            len(available_running_specs),\n",
    "            figsize=(fig_width, fig_height),\n",
    "            sharey=False,\n",
    "        )\n",
    "        if len(available_running_specs) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        mean_handles = []\n",
    "        running_mouse_handles: Dict[str, object] = {}\n",
    "        running_stats_records: List[Dict[str, object]] = []\n",
    "\n",
    "        for ax, (metric, label) in zip(axes, available_running_specs):\n",
    "            pivot = running_metrics_combined.pivot(index=\"mouse\", columns=\"group\", values=metric)\n",
    "            groups_present = [group for group in running_plot_groups if group in pivot.columns]\n",
    "            if len(groups_present) < 2:\n",
    "                ax.text(0.5, 0.5, \"Insufficient data\", ha=\"center\", va=\"center\")\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            group_a, group_b = groups_present[0], groups_present[1]\n",
    "            stats_result = compute_paired_t_test(pivot, group_a, group_b)\n",
    "            stats_result.update(\n",
    "                {\n",
    "                    \"metric\": metric,\n",
    "                    \"metric_label\": label,\n",
    "                    \"group_a\": group_a,\n",
    "                    \"group_b\": group_b,\n",
    "                }\n",
    "            )\n",
    "            running_stats_records.append(stats_result)\n",
    "\n",
    "            x_positions = np.arange(len(groups_present), dtype=float)\n",
    "\n",
    "            for mouse in pivot.index:\n",
    "                values = pivot.loc[mouse, groups_present]\n",
    "                if values.isna().all():\n",
    "                    continue\n",
    "                line, = ax.plot(\n",
    "                    x_positions,\n",
    "                    values.to_numpy(dtype=float),\n",
    "                    marker=\"o\",\n",
    "                    linewidth=1.1,\n",
    "                    alpha=0.65,\n",
    "                    color=running_mouse_colors.get(mouse, \"#1f77b4\"),\n",
    "                    zorder=2,\n",
    "                )\n",
    "                running_mouse_handles.setdefault(mouse, line)\n",
    "\n",
    "            group_means = pivot[groups_present].mean(axis=0)\n",
    "            group_sems = pivot[groups_present].apply(lambda col: sem(col.dropna()), axis=0)\n",
    "            mean_values = group_means.to_numpy(dtype=float)\n",
    "            sem_values = group_sems.to_numpy(dtype=float)\n",
    "            valid_mask = np.isfinite(mean_values) & np.isfinite(sem_values)\n",
    "            if valid_mask.any():\n",
    "                x_valid = x_positions[valid_mask]\n",
    "                mean_valid = mean_values[valid_mask]\n",
    "                sem_valid = sem_values[valid_mask]\n",
    "                ax.fill_between(\n",
    "                    x_valid,\n",
    "                    mean_valid - sem_valid,\n",
    "                    mean_valid + sem_valid,\n",
    "                    color=\"#b3b3b3\",\n",
    "                    alpha=0.3,\n",
    "                    zorder=1,\n",
    "                    linewidth=0,\n",
    "                )\n",
    "\n",
    "            error_container = ax.errorbar(\n",
    "                x_positions,\n",
    "                mean_values,\n",
    "                yerr=sem_values,\n",
    "                fmt=\"o-\",\n",
    "                color=\"#333333\",\n",
    "                linewidth=2.1,\n",
    "                capsize=4,\n",
    "                label=\"Mean ± SEM\",\n",
    "                zorder=3,\n",
    "            )\n",
    "            mean_handles.append(error_container)\n",
    "\n",
    "            ax.set_xticks(x_positions)\n",
    "            ax.set_xticklabels(groups_present)\n",
    "            ax.set_xlim(-0.3, len(groups_present) - 1 + 0.31)\n",
    "            ax.set_title(label)\n",
    "            ax.set_ylabel(label)\n",
    "            ax.grid(True, which=\"both\", axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
    "\n",
    "        legend_handles = list(running_mouse_handles.values())\n",
    "        legend_labels = list(running_mouse_handles.keys())\n",
    "        if mean_handles:\n",
    "            legend_handles.append(mean_handles[0].lines[0])\n",
    "            legend_labels.append(\"Mean ± SEM\")\n",
    "        if legend_handles:\n",
    "            fig.legend(\n",
    "                legend_handles,\n",
    "                legend_labels,\n",
    "                loc=\"center left\",\n",
    "                bbox_to_anchor=(0.85, 0.5),\n",
    "                borderaxespad=0.0,\n",
    "                frameon=True,\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "        fig.subplots_adjust(left=0, right=0.84, bottom=0.18, top=0.92, wspace=0.4)\n",
    "        if OUTPUT_DIR is not None:\n",
    "            fig.savefig(OUTPUT_DIR / \"running_metric_comparisons.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "        if running_stats_records:\n",
    "            running_stats_df = pd.DataFrame(running_stats_records)\n",
    "            display(Markdown(\"#### Running metrics paired t-tests\"))\n",
    "            display(running_stats_df)\n",
    "            if OUTPUT_DIR is not None:\n",
    "                running_stats_df.to_csv(OUTPUT_DIR / \"running_metrics_ttests.csv\", index=False)\n",
    "        else:\n",
    "            running_stats_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning velocity summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# TURNING Summary statistics\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "summary_df = summarise_results(results_df)\n",
    "if summary_df.empty:\n",
    "    print(\"⚠️ No summary statistics available\")\n",
    "else:\n",
    "    for group_name, subdf in summary_df.groupby(\"group\", dropna=False):\n",
    "        title = group_name if isinstance(group_name, str) else \"Unknown\"\n",
    "        display(Markdown(f\"### {title}\"))\n",
    "        display(subdf.drop(columns=[\"group\"], errors=\"ignore\").reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn timing and magnitude metrics\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if results_df.empty:\n",
    "    timing_summary_df = pd.DataFrame()\n",
    "    timing_mouse_df = pd.DataFrame()\n",
    "else:\n",
    "    timing_columns = [\n",
    "        \"time_to_peak\",\n",
    "        \"latency_to_fraction_peak\",\n",
    "        \"peak_velocity_magnitude\",\n",
    "        \"peak_velocity_abs_1s\",\n",
    "        \"auc_abs\",\n",
    "        \"decay_tau\",\n",
    "    ]\n",
    "    timing_columns = [column for column in timing_columns if column in results_df.columns]\n",
    "    if timing_columns:\n",
    "        timing_summary_df = (\n",
    "            results_df.groupby([\"group\", \"direction\"], dropna=False)[timing_columns]\n",
    "            .agg([\"mean\", \"sem\"])\n",
    "        )\n",
    "        timing_summary_df.columns = [f\"{metric}_{stat}\" for metric, stat in timing_summary_df.columns]\n",
    "        timing_summary_df = timing_summary_df.reset_index()\n",
    "\n",
    "        timing_mouse_df = (\n",
    "            results_df.groupby([\"group\", \"mouse\", \"direction\"], dropna=False)[timing_columns]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "    else:\n",
    "        timing_summary_df = pd.DataFrame()\n",
    "        timing_mouse_df = pd.DataFrame()\n",
    "\n",
    "timing_summary_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if timing_summary_df.empty:\n",
    "    print(\"⚠️ No timing metrics available\")\n",
    "else:\n",
    "    for group_name, subset in timing_summary_df.groupby(\"group\", dropna=False):\n",
    "        title = group_name if isinstance(group_name, str) else \"Unknown\"\n",
    "        display(Markdown(f\"### Turn timing | {title}\"))\n",
    "        display(subset.drop(columns=[\"group\"], errors=\"ignore\").reset_index(drop=True))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Compute mean absolute velocity 0-2s (for combining left and right turns)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if trace_samples_df.empty:\n",
    "    mean_abs_velocity_by_mouse = pd.DataFrame()\n",
    "else:\n",
    "    mean_abs_records = []\n",
    "    \n",
    "    for (group, mouse), group_df in trace_samples_df.groupby([\"group\", \"mouse\"]):\n",
    "        window_mask = (group_df[\"time\"] >= EXTENDED_RESPONSE_WINDOW[0]) & (group_df[\"time\"] <= EXTENDED_RESPONSE_WINDOW[1])\n",
    "        window_df = group_df.loc[window_mask].copy()\n",
    "        \n",
    "        if not window_df.empty:\n",
    "            mean_abs_vel = float(window_df[\"velocity\"].abs().mean())\n",
    "            mean_abs_records.append({\n",
    "                \"group\": group,\n",
    "                \"mouse\": mouse,\n",
    "                \"mean_abs_velocity_0_2s\": mean_abs_vel,\n",
    "            })\n",
    "    \n",
    "    mean_abs_velocity_by_mouse = pd.DataFrame(mean_abs_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6eda4a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Turning metric comparisons in a single figure (Apply halt vs No halt)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "metric_specs = [\n",
    "    (\"peak_velocity_abs_1s\", f\"Peak velocity {ANALYSIS_WINDOW_MEAN_PEAK[0]}-{ANALYSIS_WINDOW_MEAN_PEAK[1]}s (deg/s)\"),\n",
    "    (\"mean_abs_velocity_0_2s\", f\"Mean |velocity| {EXTENDED_RESPONSE_WINDOW[0]}-{EXTENDED_RESPONSE_WINDOW[1]}s (deg/s)\"),\n",
    "    (\"auc_abs\", f\"AUC {ANALYSIS_WINDOW_MEAN_PEAK[0]}-{ANALYSIS_WINDOW_MEAN_PEAK[1]}s (deg·s)\"),\n",
    "    (\"decay_tau\", \"Decay time constant τ (s)\"),\n",
    "]\n",
    "plot_groups = [\"No halt\", \"Apply halt\"]\n",
    "turning_stats_df = pd.DataFrame()\n",
    "\n",
    "# Aggregate timing metrics directly from results_df\n",
    "if results_df.empty:\n",
    "    combined = pd.DataFrame()\n",
    "else:\n",
    "    metric_columns = [metric for metric, _ in metric_specs if metric in results_df.columns]\n",
    "    if metric_columns:\n",
    "        combined = (\n",
    "            results_df.groupby([\"mouse\", \"group\"], dropna=False)[metric_columns]\n",
    "            .mean()\n",
    "            .reset_index()\n",
    "        )\n",
    "    else:\n",
    "        combined = pd.DataFrame()\n",
    "    \n",
    "    # Merge in mean absolute velocity 0-2s\n",
    "    if not mean_abs_velocity_by_mouse.empty and not combined.empty:\n",
    "        combined = pd.merge(\n",
    "            combined,\n",
    "            mean_abs_velocity_by_mouse,\n",
    "            on=[\"mouse\", \"group\"],\n",
    "            how=\"outer\",\n",
    "        )\n",
    "    elif not mean_abs_velocity_by_mouse.empty:\n",
    "        combined = mean_abs_velocity_by_mouse.copy()\n",
    "\n",
    "if combined.empty:\n",
    "    print(\"⚠️ No turning metrics available for comparison\")\n",
    "else:\n",
    "    available_specs = [(metric, label) for metric, label in metric_specs if metric in combined.columns]\n",
    "    if not available_specs:\n",
    "        print(\"⚠️ Metrics not found in aggregated data\")\n",
    "    else:\n",
    "        subplot_width_cm = 6.5\n",
    "        subplot_height_cm = 7\n",
    "        fig_width = len(available_specs) * subplot_width_cm / 2.54\n",
    "        fig_height = subplot_height_cm / 2.54\n",
    "        fig, axes = plt.subplots(1, len(available_specs), figsize=(fig_width, fig_height), sharey=False)\n",
    "        if len(available_specs) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        mouse_colors = assign_mouse_colors_consistent(combined[\"mouse\"].dropna().unique())\n",
    "        mean_handles = []\n",
    "        mouse_handles: Dict[str, object] = {}\n",
    "        turning_stats_records: List[Dict[str, object]] = []\n",
    "\n",
    "        for ax, (metric, label) in zip(axes, available_specs):\n",
    "            pivot = combined.pivot(index=\"mouse\", columns=\"group\", values=metric)\n",
    "            groups_present = [group for group in plot_groups if group in pivot.columns]\n",
    "            if len(groups_present) < 2:\n",
    "                ax.text(0.5, 0.5, \"Insufficient data\", ha=\"center\", va=\"center\")\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            group_a, group_b = groups_present[0], groups_present[1]\n",
    "            stats_result = compute_paired_t_test(pivot, group_a, group_b)\n",
    "            stats_result.update(\n",
    "                {\n",
    "                    \"metric\": metric,\n",
    "                    \"metric_label\": label,\n",
    "                    \"group_a\": group_a,\n",
    "                    \"group_b\": group_b,\n",
    "                }\n",
    "            )\n",
    "            turning_stats_records.append(stats_result)\n",
    "\n",
    "            x_positions = np.arange(len(groups_present))\n",
    "\n",
    "            for mouse in pivot.index:\n",
    "                values = pivot.loc[mouse, groups_present]\n",
    "                if values.isna().all():\n",
    "                    continue\n",
    "                valid_mask = values.notna()\n",
    "                if not valid_mask.any():\n",
    "                    continue\n",
    "                x_mouse = x_positions[valid_mask.to_numpy(dtype=bool)]\n",
    "                y_mouse = values[valid_mask].to_numpy(dtype=float)\n",
    "                color = mouse_colors.get(mouse, \"#1f77b4\")\n",
    "                if x_mouse.size == 1:\n",
    "                    line, = ax.plot(\n",
    "                        x_mouse,\n",
    "                        y_mouse,\n",
    "                        marker=\"o\",\n",
    "                        linestyle=\"none\",\n",
    "                        markersize=5,\n",
    "                        alpha=0.8,\n",
    "                        color=color,\n",
    "                        zorder=2,\n",
    "                    )\n",
    "                else:\n",
    "                    line, = ax.plot(\n",
    "                        x_mouse,\n",
    "                        y_mouse,\n",
    "                        marker=\"o\",\n",
    "                        linewidth=1.1,\n",
    "                        alpha=0.65,\n",
    "                        color=color,\n",
    "                        zorder=2,\n",
    "                    )\n",
    "                mouse_handles.setdefault(mouse, line)\n",
    "\n",
    "            group_means = pivot[groups_present].mean(axis=0)\n",
    "            group_sems = pivot[groups_present].apply(lambda col: sem(col.dropna()), axis=0)\n",
    "            mean_values = group_means.to_numpy(dtype=float)\n",
    "            sem_values = group_sems.to_numpy(dtype=float)\n",
    "            valid_mask = np.isfinite(mean_values) & np.isfinite(sem_values)\n",
    "            if valid_mask.any():\n",
    "                x_valid = x_positions[valid_mask]\n",
    "                mean_valid = mean_values[valid_mask]\n",
    "                sem_valid = sem_values[valid_mask]\n",
    "                ax.fill_between(\n",
    "                    x_valid,\n",
    "                    mean_valid - sem_valid,\n",
    "                    mean_valid + sem_valid,\n",
    "                    color=\"#b3b3b3\",\n",
    "                    alpha=0.3,\n",
    "                    zorder=1,\n",
    "                    linewidth=0,\n",
    "                )\n",
    "\n",
    "            error_container = ax.errorbar(\n",
    "                x_positions,\n",
    "                mean_values,\n",
    "                yerr=sem_values,\n",
    "                fmt=\"o-\",\n",
    "                color=\"#333333\",\n",
    "                linewidth=2.1,\n",
    "                capsize=4,\n",
    "                label=\"Mean ± SEM\",\n",
    "                zorder=3,\n",
    "            )\n",
    "            mean_handles.append(error_container)\n",
    "\n",
    "            ax.set_xticks(x_positions)\n",
    "            ax.set_xticklabels(groups_present)\n",
    "            ax.set_xlim(-0.3, len(groups_present) - 1 + 0.31)\n",
    "            ax.set_title(label)\n",
    "            ax.set_ylabel(label)\n",
    "            ax.grid(True, which=\"both\", axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
    "\n",
    "        legend_handles = list(mouse_handles.values())\n",
    "        legend_labels = list(mouse_handles.keys())\n",
    "        if mean_handles:\n",
    "            legend_handles.append(mean_handles[0].lines[0])\n",
    "            legend_labels.append(\"Mean ± SEM\")\n",
    "        if legend_handles:\n",
    "            fig.legend(\n",
    "                legend_handles,\n",
    "                legend_labels,\n",
    "                loc=\"center left\",\n",
    "                bbox_to_anchor=(0.85, 0.5),\n",
    "                borderaxespad=0.0,\n",
    "                frameon=True,\n",
    "                fontsize=8,\n",
    "            )\n",
    "\n",
    "        fig.subplots_adjust(left=0, right=0.84, bottom=0.18, top=0.92, wspace=0.4)\n",
    "        if OUTPUT_DIR is not None:\n",
    "            fig.savefig(OUTPUT_DIR / \"turning_metric_comparisons.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "        plt.show()\n",
    "        plt.close(fig)\n",
    "\n",
    "        if turning_stats_records:\n",
    "            turning_stats_df = pd.DataFrame(turning_stats_records)\n",
    "            display(Markdown(\"#### Turning metrics paired t-tests\"))\n",
    "            display(turning_stats_df)\n",
    "            if OUTPUT_DIR is not None:\n",
    "                turning_stats_df.to_csv(OUTPUT_DIR / \"turning_metrics_ttests.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Average motor velocity traces by condition and turn direction\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if trace_samples_df.empty:\n",
    "    per_mouse_traces = pd.DataFrame()\n",
    "    avg_traces = pd.DataFrame()\n",
    "else:\n",
    "    per_mouse_traces = (\n",
    "        trace_samples_df\n",
    "        .groupby([\"group\", \"direction\", \"mouse\", \"time\"], dropna=False)[\"velocity\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    avg_traces = (\n",
    "        per_mouse_traces\n",
    "        .groupby([\"group\", \"direction\", \"time\"], dropna=False)\n",
    "        .agg(\n",
    "            mean_velocity=(\"velocity\", \"mean\"),\n",
    "            sem_velocity=(\"velocity\", lambda x: sem(x) if len(x.dropna()) > 1 else 0.0),\n",
    "            n_mice=(\"mouse\", \"nunique\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "avg_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# 2x2 average motor velocity figure (Apply halt / No halt x Left / Right)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if avg_traces.empty:\n",
    "    print(\"⚠️ No averaged traces available for plotting\")\n",
    "else:\n",
    "    plot_order = [\n",
    "        (\"Apply halt\", \"left\"),\n",
    "        (\"Apply halt\", \"right\"),\n",
    "        (\"No halt\", \"left\"),\n",
    "        (\"No halt\", \"right\"),\n",
    "    ]\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for ax, (group_name, direction) in zip(axes, plot_order):\n",
    "        subset = avg_traces[\n",
    "            (avg_traces[\"group\"] == group_name)\n",
    "            & (avg_traces[\"direction\"] == direction)\n",
    "        ]\n",
    "        if subset.empty:\n",
    "            ax.text(0.5, 0.5, \"No data\", ha=\"center\", va=\"center\")\n",
    "            ax.axis(\"off\")\n",
    "            continue\n",
    "\n",
    "        ax.plot(subset[\"time\"], subset[\"mean_velocity\"], color=\"#1f77b4\", linewidth=1.5)\n",
    "        if \"sem_velocity\" in subset.columns:\n",
    "            upper = subset[\"mean_velocity\"] + subset[\"sem_velocity\"].fillna(0)\n",
    "            lower = subset[\"mean_velocity\"] - subset[\"sem_velocity\"].fillna(0)\n",
    "            ax.fill_between(subset[\"time\"], lower, upper, color=\"#1f77b4\", alpha=0.2)\n",
    "\n",
    "        ax.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "        ax.axhline(0, color=\"grey\", linestyle=\":\", linewidth=1)\n",
    "        ax.set_title(f\"{group_name} | {direction.capitalize()} turns\")\n",
    "        ax.set_xlabel(\"Time (s)\")\n",
    "        ax.set_ylabel(\"Motor velocity (deg/s)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a34a22",
   "metadata": {},
   "source": [
    "### Alternative temporal dynamics analysis (better than decay fitting)\n",
    "\n",
    "The exponential decay fit often fails because motor velocity shows complex, \n",
    "non-exponential dynamics. Better approaches:\n",
    "1. **Windowed AUC**: Quantify response in different time phases\n",
    "2. **Sustained response ratio**: Compare early vs late response magnitude  \n",
    "3. **Time to baseline**: When does response return to pre-turn levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e6625c",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Compute alternative temporal metrics for each mouse\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if not trace_samples_df.empty:\n",
    "    print(\"Computing alternative temporal dynamics metrics...\")\n",
    "    \n",
    "    # Define time windows for AUC analysis\n",
    "    AUC_WINDOWS = [\n",
    "        (0.0, 0.5),   # Early response\n",
    "        (0.5, 1.0),   # Mid response  \n",
    "        (1.0, 2.0),   # Late response\n",
    "        (0.0, 2.0),   # Total response\n",
    "    ]\n",
    "    \n",
    "    alternative_metrics_records = []\n",
    "    \n",
    "    for (group, mouse, direction), group_df in trace_samples_df.groupby([\"group\", \"mouse\", \"direction\"]):\n",
    "        # Compute windowed AUC\n",
    "        auc_metrics = compute_windowed_auc(group_df, AUC_WINDOWS)\n",
    "        \n",
    "        # Compute sustained response ratio\n",
    "        sustained_ratio = compute_sustained_response_ratio(group_df)\n",
    "        \n",
    "        # Compute time to baseline\n",
    "        time_to_baseline = compute_time_to_baseline(group_df)\n",
    "        \n",
    "        # Compile all metrics\n",
    "        alternative_metrics_records.append({\n",
    "            \"group\": group,\n",
    "            \"mouse\": mouse,\n",
    "            \"direction\": direction,\n",
    "            **auc_metrics,\n",
    "            \"sustained_ratio\": sustained_ratio,\n",
    "            \"time_to_baseline\": time_to_baseline,\n",
    "        })\n",
    "    \n",
    "    alternative_metrics_df = pd.DataFrame(alternative_metrics_records)\n",
    "    \n",
    "    # Average across turn directions per mouse\n",
    "    alt_metrics_by_mouse = (\n",
    "        alternative_metrics_df.groupby([\"group\", \"mouse\"], dropna=False)\n",
    "        .mean(numeric_only=True)\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Computed alternative metrics for {len(alt_metrics_by_mouse)} mouse-group combinations\")\n",
    "    display(Markdown(\"#### Alternative temporal dynamics metrics (per mouse)\"))\n",
    "    display(alt_metrics_by_mouse)\n",
    "    \n",
    "    if OUTPUT_DIR is not None:\n",
    "        alt_metrics_by_mouse.to_csv(OUTPUT_DIR / \"alternative_temporal_metrics.csv\", index=False)\n",
    "else:\n",
    "    alternative_metrics_df = pd.DataFrame()\n",
    "    alt_metrics_by_mouse = pd.DataFrame()\n",
    "    print(\"⚠️ No trace data available for alternative metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fadaf3f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Statistical comparison of alternative metrics: Apply halt vs No halt\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if not alt_metrics_by_mouse.empty:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"STATISTICAL COMPARISON: Apply halt vs No halt\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Define metrics to compare\n",
    "    alt_metrics_to_compare = [\n",
    "        (\"auc_0.0_0.5s\", \"Early AUC 0-0.5s (deg)\"),\n",
    "        (\"auc_0.5_1.0s\", \"Mid AUC 0.5-1s (deg)\"),\n",
    "        (\"auc_1.0_2.0s\", \"Late AUC 1-2s (deg)\"),\n",
    "        (\"auc_0.0_2.0s\", \"Total AUC 0-2s (deg)\"),\n",
    "        (\"sustained_ratio\", \"Sustained response ratio (late/early)\"),\n",
    "        (\"time_to_baseline\", \"Time to baseline (s)\"),\n",
    "    ]\n",
    "    \n",
    "    alt_stats_records = []\n",
    "    \n",
    "    for metric, label in alt_metrics_to_compare:\n",
    "        if metric not in alt_metrics_by_mouse.columns:\n",
    "            continue\n",
    "        \n",
    "        # Create pivot table\n",
    "        pivot = alt_metrics_by_mouse.pivot(index=\"mouse\", columns=\"group\", values=metric)\n",
    "        \n",
    "        if \"No halt\" in pivot.columns and \"Apply halt\" in pivot.columns:\n",
    "            stats_result = compute_paired_t_test(pivot, \"No halt\", \"Apply halt\")\n",
    "            \n",
    "            # Add descriptive statistics\n",
    "            no_halt_vals = pivot[\"No halt\"].dropna()\n",
    "            apply_halt_vals = pivot[\"Apply halt\"].dropna()\n",
    "            \n",
    "            stats_result.update({\n",
    "                \"metric\": metric,\n",
    "                \"metric_label\": label,\n",
    "                \"no_halt_mean\": float(no_halt_vals.mean()) if len(no_halt_vals) > 0 else float(\"nan\"),\n",
    "                \"no_halt_sem\": float(sem(no_halt_vals)) if len(no_halt_vals) > 1 else float(\"nan\"),\n",
    "                \"apply_halt_mean\": float(apply_halt_vals.mean()) if len(apply_halt_vals) > 0 else float(\"nan\"),\n",
    "                \"apply_halt_sem\": float(sem(apply_halt_vals)) if len(apply_halt_vals) > 1 else float(\"nan\"),\n",
    "            })\n",
    "            \n",
    "            alt_stats_records.append(stats_result)\n",
    "    \n",
    "    if alt_stats_records:\n",
    "        alt_stats_df = pd.DataFrame(alt_stats_records)\n",
    "        \n",
    "        # Reorder columns for clarity\n",
    "        col_order = [\n",
    "            \"metric_label\", \n",
    "            \"no_halt_mean\", \"no_halt_sem\",\n",
    "            \"apply_halt_mean\", \"apply_halt_sem\",\n",
    "            \"mean_difference\", \"t_statistic\", \"p_value\", \"n_pairs\"\n",
    "        ]\n",
    "        alt_stats_df = alt_stats_df[[col for col in col_order if col in alt_stats_df.columns]]\n",
    "        \n",
    "        display(Markdown(\"#### Paired t-tests for alternative temporal metrics\"))\n",
    "        display(alt_stats_df)\n",
    "        \n",
    "        if OUTPUT_DIR is not None:\n",
    "            alt_stats_df.to_csv(OUTPUT_DIR / \"alternative_metrics_ttests.csv\", index=False)\n",
    "        \n",
    "        # Highlight significant results\n",
    "        if \"p_value\" in alt_stats_df.columns:\n",
    "            sig_results = alt_stats_df[alt_stats_df[\"p_value\"] < 0.05]\n",
    "            if not sig_results.empty:\n",
    "                display(Markdown(\"#### Significant differences (p < 0.05)\"))\n",
    "                display(sig_results)\n",
    "    else:\n",
    "        alt_stats_df = pd.DataFrame()\n",
    "        print(\"⚠️ Could not perform statistical comparisons\")\n",
    "else:\n",
    "    alt_stats_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142d1c9",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Visualization: Alternative metrics comparison\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "if not alt_metrics_by_mouse.empty:\n",
    "    # Select key metrics to visualize\n",
    "    viz_metrics = [\n",
    "        (\"auc_0.0_0.5s\", \"Early AUC 0-0.5s\"),\n",
    "        (\"auc_1.0_2.0s\", \"Late AUC 1-2s\"),  \n",
    "        (\"sustained_ratio\", \"Sustained ratio\\n(late/early)\"),\n",
    "    ]\n",
    "    \n",
    "    # Filter to metrics that exist\n",
    "    viz_metrics = [(m, l) for m, l in viz_metrics if m in alt_metrics_by_mouse.columns]\n",
    "    \n",
    "    if viz_metrics:\n",
    "        fig, axes = plt.subplots(1, len(viz_metrics), figsize=(4*len(viz_metrics), 4.5))\n",
    "        if len(viz_metrics) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        mouse_colors = assign_mouse_colors_consistent(alt_metrics_by_mouse[\"mouse\"].unique())\n",
    "        \n",
    "        for ax, (metric, label) in zip(axes, viz_metrics):\n",
    "            pivot = alt_metrics_by_mouse.pivot(index=\"mouse\", columns=\"group\", values=metric)\n",
    "            groups_present = [g for g in [\"No halt\", \"Apply halt\"] if g in pivot.columns]\n",
    "            \n",
    "            if len(groups_present) < 2:\n",
    "                ax.text(0.5, 0.5, \"Insufficient data\", ha=\"center\", va=\"center\")\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "            \n",
    "            x_positions = np.arange(len(groups_present))\n",
    "            \n",
    "            # Plot individual mice\n",
    "            for mouse in pivot.index:\n",
    "                values = pivot.loc[mouse, groups_present]\n",
    "                if values.isna().all():\n",
    "                    continue\n",
    "                ax.plot(\n",
    "                    x_positions,\n",
    "                    values.to_numpy(dtype=float),\n",
    "                    marker=\"o\",\n",
    "                    linewidth=1.1,\n",
    "                    alpha=0.65,\n",
    "                    color=mouse_colors.get(mouse, \"#1f77b4\"),\n",
    "                    zorder=2,\n",
    "                )\n",
    "            \n",
    "            # Plot group means\n",
    "            group_means = pivot[groups_present].mean(axis=0)\n",
    "            group_sems = pivot[groups_present].apply(lambda col: sem(col.dropna()), axis=0)\n",
    "            \n",
    "            ax.errorbar(\n",
    "                x_positions,\n",
    "                group_means.to_numpy(dtype=float),\n",
    "                yerr=group_sems.to_numpy(dtype=float),\n",
    "                fmt=\"o-\",\n",
    "                color=\"#333333\",\n",
    "                linewidth=2.1,\n",
    "                capsize=4,\n",
    "                label=\"Mean ± SEM\",\n",
    "                zorder=3,\n",
    "            )\n",
    "            \n",
    "            ax.set_xticks(x_positions)\n",
    "            ax.set_xticklabels(groups_present)\n",
    "            ax.set_ylabel(label)\n",
    "            ax.set_title(label)\n",
    "            ax.grid(True, which=\"both\", axis=\"y\", linestyle=\":\", linewidth=0.7)\n",
    "        \n",
    "        plt.suptitle(\"Alternative Temporal Dynamics Metrics\", fontsize=12, y=1.02)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if OUTPUT_DIR is not None:\n",
    "            fig.savefig(OUTPUT_DIR / \"alternative_metrics_comparison.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "aeon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
