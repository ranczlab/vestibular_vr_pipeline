{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# View GCaMP mismatch closed and open loop seesion 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from analysis_functions import *\n",
    "from model_functions import *\n",
    "import matplotlib.patches as patches\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RunTresholdDict = {'B3M1': 145, 'B3M2': 295, 'B3M3': 325, 'B2M4': 110, 'B2M5': 180}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCaMP_MM_1 = pd.read_csv('GCaMP_MMclosed_open_session1.csv', dtype=dtype_dict)\n",
    "GCaMP_MM_2 = pd.read_csv('GCaMP_MMclosed_open_session2.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chaning event name to halt and making it so that its True when there is a halt\n",
    "#GCaMP_MM_1.loc[:, 'event'] = GCaMP_MM_1['event'].replace({False: True, True: False})\n",
    "GCaMP_MM_1.rename(columns = {'event': 'halt'}, inplace = True)\n",
    "GCaMP_MM_2.rename(columns = {'event': 'halt'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make sure the index provides inforamtion of seconds since start\n",
    "GCaMP_MM_1.set_index('Seconds', inplace=True)\n",
    "GCaMP_MM_2.set_index('Seconds', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check that the same mice are in the datsets\n",
    "print(GCaMP_MM_1.mouseID.unique())\n",
    "print(GCaMP_MM_2.mouseID.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## View session data\n",
    "- Loop through the mouse names present in one of the dataframes (ideally they should be the same)\n",
    "- save a variable where each session is saved for the current mouse\n",
    "- use the view_session_mouse() funciton from analysis_functions.py to plot the Delta F/F 470 fluorescence and movement in X direction with halts in grey, and session blocks marked in colors.\n",
    "- Edit the function to plot different fluorescence traces, movements, and eyes.\n",
    "- This is mostly to get an impression of the overall data trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in GCaMP_MM_1.mouseID.unique():\n",
    "    mousedata = {'session 1':GCaMP_MM_1.loc[GCaMP_MM_1.mouseID == mouse], 'session 2':GCaMP_MM_2.loc[GCaMP_MM_2.mouseID == mouse]}\n",
    "    fig, ax =view_session_mouse(mousedata, mouse)\n",
    "    fig.savefig(f'Figures/GCaMP_{mouse}_view_alignment.png', format = 'png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter mice to get unique indexes\n",
    "mouse_data = {'session 1':{'closedloop': {},'openloop': {} }, 'session 2': {'closedloop': {},'openloop': {}}}\n",
    "\n",
    "for mouse in GCaMP_MM_1.mouseID.unique():\n",
    "    mouse_data['session 1']['closedloop'][mouse] = filter_data(GCaMP_MM_1, filters = [mouse, 'closed_block'])\n",
    "    mouse_data['session 1']['openloop'][mouse] = filter_data(GCaMP_MM_1, filters = [mouse, 'open_block'])\n",
    "for mouse in GCaMP_MM_2.mouseID.unique():\n",
    "    mouse_data['session 2']['closedloop'][mouse] = filter_data(GCaMP_MM_2, filters = [mouse, 'closed_block'])\n",
    "    mouse_data['session 2']['openloop'][mouse] = filter_data(GCaMP_MM_2, filters = [mouse, 'open_block'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "def align_to_event_start(df, trace, event_col, range_around_event):\n",
    "    \n",
    "    trace_chunk_list = []\n",
    "    bsl_trace_chunk_list = []\n",
    "    run_speed_list = []\n",
    "    turn_speed_list = []\n",
    "    event_index_list = []\n",
    "    \n",
    "    # Identify the start times for each event\n",
    "    event_times = df.loc[df[event_col] & ~df[event_col].shift(1, fill_value=False)].index\n",
    "\n",
    "    # Calculate the time range around each event\n",
    "    before_0 = range_around_event[0]\n",
    "    after_0 = range_around_event[1]\n",
    "    \n",
    "    # Calculate the target length of each chunk based on the sampling rate\n",
    "    sampling_rate = 0.001\n",
    "    target_length = int(((before_0 + after_0) / sampling_rate) + 1)  # Include both ends\n",
    "    Index= pd.Series(np.linspace(-range_around_event[0], range_around_event[1], target_length)) # common index\n",
    "    \n",
    "    for event_time in event_times:\n",
    "        \n",
    "        # Determine the time range for each chunk\n",
    "        start = event_time - before_0\n",
    "        end = event_time + after_0\n",
    "        \n",
    "        # Extract the chunk from the trace column\n",
    "        chunk = df[trace].loc[start:end]\n",
    "        runspeed = df['movementX'].loc[start:event_time].mean() #Saving mean run speed up until halt\n",
    "        turningspeed = df['movementY'].loc[start:event_time].mean() \n",
    "        # Normalize the index to start at -before_0\n",
    "        chunk.index = (chunk.index - chunk.index[0]) - before_0\n",
    "        # Check if the chunk is shorter than the target length\n",
    "        if len(chunk) < target_length:\n",
    "            # Pad the chunk with NaN values at the end to reach the target length\n",
    "            padding = pd.Series([np.nan] * (target_length - len(chunk)), index=pd.RangeIndex(len(chunk), target_length))\n",
    "            chunk = pd.concat([chunk, padding])\n",
    "            chunk.index = Index # Getting the same index as the others\n",
    "        \n",
    "        # Baseline the chunk\n",
    "        baselined_chunk = baseline(chunk)\n",
    "        \n",
    "        # Append the chunk and baselined chunk to lists\n",
    "        trace_chunk_list.append(chunk.values)\n",
    "        bsl_trace_chunk_list.append(baselined_chunk.values)\n",
    "        run_speed_list.append(runspeed)\n",
    "        turn_speed_list.append(turningspeed)\n",
    "        event_index_list.append(event_time)  # Store the event time for use in final column names\n",
    "    # Convert lists of arrays to DataFrames\n",
    "    try:\n",
    "        trace_chunks = pd.DataFrame(np.column_stack(trace_chunk_list), columns=event_index_list)\n",
    "        bsl_trace_chunks = pd.DataFrame(np.column_stack(bsl_trace_chunk_list), columns=event_index_list)\n",
    "        run_speeds = pd.DataFrame(np.column_stack(run_speed_list), columns=event_index_list)\n",
    "        turn_speeds = pd.DataFrame(np.column_stack(turn_speed_list), columns=event_index_list)\n",
    "        movement_speeds = pd.concat([run_speeds, turn_speeds])\n",
    "        \n",
    "        # Set the index as the common time range index for each chunk\n",
    "        trace_chunks.index = Index\n",
    "        bsl_trace_chunks.index = Index\n",
    "        movement_speeds.index = ['Mean_moveX', 'Mean_moveY'] #set X and Y movement as movement speed index\n",
    "        \n",
    "        return trace_chunks, bsl_trace_chunks, movement_speeds\n",
    "    \n",
    "    except ValueError:\n",
    "        if len(event_times) < 1:\n",
    "            print('could not align to events because there were none, will return nothing')\n",
    "            \n",
    "        return 0, 0, 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aligning open and closed loop block data to halt start times\n",
    "mouse_aligned = {'session 1':{'closedloop': {},'openloop': {} }, 'session 2': {'closedloop': {},'openloop': {}}}\n",
    "move_speeds = {'session 1':{'closedloop': {},'openloop': {} }, 'session 2': {'closedloop': {},'openloop': {}}}\n",
    "\n",
    "#Using the aling_to_event_start function, make sure that the sampling rate = 0.001, otherwise, change the sampling_rate variable in the function\n",
    "for session, session_dict in mouse_data.items():\n",
    "    for block, mice in session_dict.items():\n",
    "        for mouse, df in mice.items():\n",
    "            event_alinged, bsl_event_alinged, run_speeds = align_to_event_start(df, '470_dfF', 'halt',[1,2])\n",
    "            mouse_aligned[session][block][mouse]  = bsl_event_alinged  #bsl indicates that it is baselined to the last 1 second before halt\n",
    "            move_speeds[session][block][mouse]  = run_speeds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "move_speeds['session 1']['closedloop']['B3M1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mouse_aligned['session 1']['closedloop']['B3M1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mouse_aligned['session 1']['closedloop'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_aligned_nohalt = {'session 1':{'closedloop': {},'openloop': {} }, 'session 2': {'closedloop': {},'openloop': {}}}\n",
    "move_speeds_nohalt = {'session 1':{'closedloop': {},'openloop': {} }, 'session 2': {'closedloop': {},'openloop': {}}}\n",
    "for session, session_dict in mouse_data.items():\n",
    "    for block, mice in session_dict.items():\n",
    "        for mouse, df in mice.items():\n",
    "            event_alinged, bsl_event_alinged, run_speeds = align_to_event_start(df, '470_dfF', 'No_halt',[1,2])\n",
    "            mouse_aligned_nohalt[session][block][mouse] = bsl_event_alinged  #bsl indicates that it is baselined to the last 1 second before halt\n",
    "            move_speeds_nohalt[session][block][mouse]  = run_speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m Session 1 \\033[0m')\n",
    "mean_mouse_dict_s1 =plot_compare_blocks(mouse_aligned['session 1'], 'halt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m Session 2 \\033[0m')\n",
    "mean_mouse_dict_s2 =plot_compare_blocks(mouse_aligned['session 2'], 'halt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mouse_dict_s1_nohalt =plot_compare_blocks(mouse_aligned_nohalt['session 1'], 'No halt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "mouse_aligned['session 1']['openloop']['B2M5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_mouse_sessions(\n",
    "    mouse_aligned,\n",
    "    mouse_aligned_nohalt,\n",
    "    block_names,\n",
    "    title=\"Mouse Sessions\",\n",
    "    stimulus_duration=1,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot session-specific traces for each mouse with control data.\n",
    "\n",
    "    Parameters:\n",
    "    - mouse_aligned (dict): Dictionary containing session data.\n",
    "    - mouse_aligned_nohalt (dict): Dictionary containing control data.\n",
    "    - block_names (list): List of block names (e.g., ['openloop', 'closedloop']) to plot.\n",
    "    - title (str): Title prefix for each mouse figure.\n",
    "    - stimulus_duration (float): Duration of the stimulus in seconds (default: 1 second).\n",
    "    \"\"\"\n",
    "    mice = set()\n",
    "    sessions = mouse_aligned.keys()\n",
    "\n",
    "    # Collect all mice\n",
    "    for session in mouse_aligned.values():\n",
    "        for block in block_names:\n",
    "            mice.update(session[block].keys())\n",
    "\n",
    "    for mouse in mice:\n",
    "        # Create a figure for each mouse\n",
    "        fig, axes = plt.subplots(1, len(block_names), figsize=(5 * len(block_names), 4))\n",
    "        axes = np.atleast_1d(axes)  # Ensure axes is iterable\n",
    "        fig.suptitle(f\"{title}: {mouse}\")\n",
    "\n",
    "        for i, block in enumerate(block_names):\n",
    "            ax = axes[i]\n",
    "            ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "            # Plot control data (averaged across sessions)\n",
    "            control_data = []\n",
    "            for session in mouse_aligned_nohalt.values():\n",
    "                if block in session and mouse in session[block]:\n",
    "                    control_data.append(session[block][mouse])\n",
    "\n",
    "            if control_data:\n",
    "                # Ensure all arrays have the same length and use their time index\n",
    "                valid_control_data = [\n",
    "                    arr for arr in control_data if arr.shape[0] > 0\n",
    "                ]\n",
    "                if valid_control_data:\n",
    "                    time_index = valid_control_data[0].index\n",
    "                    control_data_concat = np.concatenate(valid_control_data, axis=1)\n",
    "                    control_mean = control_data_concat.mean(axis=1)\n",
    "                    control_std = control_data_concat.std(axis=1)\n",
    "                    ax.plot(\n",
    "                        time_index,\n",
    "                        control_mean,\n",
    "                        label=\"Control\",\n",
    "                        color=\"black\",\n",
    "                    )\n",
    "                    ax.fill_between(\n",
    "                        time_index,\n",
    "                        control_mean - control_std,\n",
    "                        control_mean + control_std,\n",
    "                        color=\"black\",\n",
    "                        alpha=0.1,\n",
    "                    )\n",
    "\n",
    "            # Plot main traces for each session\n",
    "            for session_name, session in mouse_aligned.items():\n",
    "                if block in session and mouse in session[block]:\n",
    "                    main_data = session[block][mouse]\n",
    "                    time_index = main_data.index\n",
    "                    main_mean = main_data.mean(axis=1)\n",
    "                    main_std = main_data.std(axis=1)\n",
    "                    ax.plot(\n",
    "                        time_index,\n",
    "                        main_mean,\n",
    "                        label=f\"{session_name}\",\n",
    "                        alpha=0.8,\n",
    "                    )\n",
    "                    ax.fill_between(\n",
    "                        time_index,\n",
    "                        main_mean - main_std,\n",
    "                        main_mean + main_std,\n",
    "                        alpha=0.3,\n",
    "                    )\n",
    "\n",
    "            # Shade the stimulus area\n",
    "            ax.axvline(0, color=\"grey\", linestyle=\"--\")\n",
    "            ax.axvspan(\n",
    "                0,\n",
    "                stimulus_duration,\n",
    "                color=\"grey\",\n",
    "                alpha=0.1,\n",
    "                label=\"Stimulus\",\n",
    "            )\n",
    "\n",
    "            ax.set_title(f\"{block} Block\")\n",
    "            ax.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.close(fig)  # Clear the figure after displaying it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mouse_sessions(\n",
    "    mouse_aligned,\n",
    "    mouse_aligned_nohalt,\n",
    "    block_names=['openloop', 'closedloop'],\n",
    "    title=\"Mouse Data Comparison\",\n",
    "    stimulus_duration=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mean_across_blocks(session_blocks, control_blocks, title=\"Mean Across Blocks\", stimulus_duration = 1):\n",
    "    \"\"\"\n",
    "    Plot a single figure with the mean across mouse means for each block.\n",
    "    \n",
    "    Parameters:\n",
    "    - session_blocks (dict): Dictionary of session data, where keys are block names\n",
    "                             and values are dictionaries of mouse data.\n",
    "    - control_blocks (dict): Dictionary of control data with the same structure.\n",
    "    - title (str): Title of the plot.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.spines[['right', 'top']].set_visible(False)\n",
    "\n",
    "    for block_name, mouse_data in session_blocks.items():\n",
    "        if not mouse_data:\n",
    "            print(f\"No data for block: {block_name}\")\n",
    "            continue\n",
    "\n",
    "        # Compute mean and std across all mice\n",
    "        block_means = [data.mean(axis=1) for data in mouse_data.values()]\n",
    "        mean_across_mice = pd.concat(block_means, axis=1).mean(axis=1)\n",
    "        std_across_mice = pd.concat(block_means, axis=1).std(axis=1)\n",
    "\n",
    "        # Plot block trace\n",
    "        ax.plot(mean_across_mice, label=f'{block_name} Mean')\n",
    "        ax.fill_between(\n",
    "            mean_across_mice.index,\n",
    "            mean_across_mice - std_across_mice,\n",
    "            mean_across_mice + std_across_mice,\n",
    "            alpha=0.2,\n",
    "        )\n",
    "\n",
    "    # Plot control trace\n",
    "    if control_blocks:\n",
    "        control_means = [\n",
    "            data.mean(axis=1) for block_data in control_blocks.values()\n",
    "            for data in block_data.values()\n",
    "        ]\n",
    "        control_mean = pd.concat(control_means, axis=1).mean(axis=1)\n",
    "        control_std = pd.concat(control_means, axis=1).std(axis=1)\n",
    "\n",
    "        ax.plot(control_mean, label=\"Control Mean\", color='black', linestyle='--')\n",
    "        ax.fill_between(\n",
    "            control_mean.index,\n",
    "            control_mean - control_std,\n",
    "            control_mean + control_std,\n",
    "            color='grey',\n",
    "            alpha=0.3,\n",
    "        )\n",
    "\n",
    "    ax.axvline(0, color='grey', linestyle='--')\n",
    "    ax.axvspan(0, stimulus_duration, color='grey', alpha=0.1)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mean_across_blocks(session_blocks, control_blocks, title=\"Mean Across All Blocks\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = mouse_aligned.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_aligned_vars(aligned_data_dict, aligned_movement_dict):\n",
    "    # Initialize an empty list to store results\n",
    "    results = []\n",
    "    \n",
    "    for session_number, session_blocks in aligned_data_dict.items():\n",
    "        for session_block, mice_data in session_blocks.items():\n",
    "            for mouse_id, item in mice_data.items():\n",
    "                run_df = aligned_movement_dict[session_number][session_block][mouse_id]\n",
    "                # Check if the item is a DataFrame\n",
    "                if not isinstance(item, pd.DataFrame):\n",
    "                    print(f\"Warning: The data for Mouse ID '{mouse_id}' in session '{session_number}' and block '{session_block}' is not a DataFrame. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Copy the DataFrame and ensure the index is numeric\n",
    "                df = item.copy()\n",
    "                df.index = pd.to_numeric(df.index)\n",
    "\n",
    "                # Process each column independently\n",
    "                for column in df.columns:\n",
    "                    event_time_data = df.loc[0:1, column]  # Data during the event (0 to +1 seconds)\n",
    "                    post_event_data = df.loc[1:2, column]  # Data during the first second after the event (+1 to +2 seconds)\n",
    "\n",
    "                    peak_response = event_time_data.max()  # Max response during the event\n",
    "                    min_response = event_time_data.min()  # Minimum response during the event\n",
    "                    mean_response_event = event_time_data.mean()  # Mean response during the event\n",
    "                    mean_response_post_event = post_event_data.mean()  # Mean response during the post-event time\n",
    "                    min_response_post_event = post_event_data.min()  #Minimum response during the post-event time\n",
    "                    peak_response_post_event = post_event_data.max() #Maximum response during the post-event time\n",
    "\n",
    "                    #Given Mean_moveX and Y being the row names in the movement df, the 1 second pre halt movement speeds are added\n",
    "                    x_move = run_df.loc['Mean_moveX', column]\n",
    "                    y_move = run_df.loc['Mean_moveY', column]\n",
    "    \n",
    "                    #add results to list of dicts\n",
    "                    results.append({\n",
    "                        \"SessionNumber\": session_number,\n",
    "                        \"SessionBlock\": session_block,\n",
    "                        \"MouseID\": mouse_id,\n",
    "                        \"EventTime\": column,\n",
    "                        \"moveX\": x_move,\n",
    "                        \"moveY\": y_move,\n",
    "                        \"PeakResponse\": peak_response,\n",
    "                        \"MinResponse\":  min_response,\n",
    "                        \"MeanResponse\": mean_response_event,\n",
    "                        \"MeanResponse_after\": mean_response_post_event,\n",
    "                        \"MinResponse_after\": min_response_post_event,\n",
    "                        \"PeakResponse_after\": peak_response_post_event\n",
    "                    })\n",
    "\n",
    "    # convert to a pandas df\n",
    "    output_df = pd.DataFrame(results)\n",
    "    return output_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_variables = extract_aligned_vars(mouse_aligned, move_speeds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_variables_nohalt = extract_aligned_vars(mouse_aligned_nohalt, move_speeds_nohalt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_variables_nohalt['event']='no halt'\n",
    "extracted_variables['event']='halt'\n",
    "combined_vars = pd.concat([extracted_variables_nohalt, extracted_variables])\n",
    "\n",
    "combined_vars.to_csv('GCaAMP_MM_extracted_vars.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Consider adding to the fitted model a continous variable which is the time column\n",
    "#EventTime should currently be seconds from session start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "# Look for correlation between running and fluorescence changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Compute Pearson correlation\n",
    "pearson_corr, pearson_pval = pearsonr(GCaMP_MM_1['movementX'], GCaMP_MM_1['470_dfF'])\n",
    "\n",
    "# Compute Spearman correlation (handles nonlinear relationships better)\n",
    "spearman_corr, spearman_pval = spearmanr(GCaMP_MM_1['movementX'], GCaMP_MM_1['470_dfF'])\n",
    "\n",
    "print(f\"Pearson correlation: {pearson_corr}, p-value: {pearson_pval}\")\n",
    "print(f\"Spearman correlation: {spearman_corr}, p-value: {spearman_pval}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mouse in GCaMP_MM_1.mouseID.unique():\n",
    "    subset = filter_data(GCaMP_MM_1, [mouse, 'day1'])\n",
    "    # Compute Pearson correlation\n",
    "    pearson_corr, pearson_pval = pearsonr(subset['movementX'], subset['470_dfF'])\n",
    "    \n",
    "    # Compute Spearman correlation (handles nonlinear relationships better)\n",
    "    spearman_corr, spearman_pval = spearmanr(subset['movementX'], subset['470_dfF'])\n",
    "    print(f'\\n \\033[1m {mouse} \\033[0m \\n')\n",
    "    print(f\"Pearson correlation: {pearson_corr}, p-value: {pearson_pval}\")\n",
    "    print(f\"Spearman correlation: {spearman_corr}, p-value: {spearman_pval}\")\n",
    "    \n",
    "    resampled = subset.sample(10000, random_state=9)  # Sample 10,000 rows\n",
    "    pearson_corr, pearson_pval = pearsonr(resampled['movementX'], resampled['470_dfF'])\n",
    "    spearman_corr, spearman_pval = spearmanr(resampled['movementX'], resampled['470_dfF'])\n",
    "    print('\\n Random 1000 samples: \\n')\n",
    "    print(f\"Subset Pearson correlation: {pearson_corr}, p-value: {pearson_pval}\")\n",
    "    print(f\"Subset Spearman correlation: {spearman_corr}, p-value: {spearman_pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def correlation_remove(data, fluorescence=\"470_dfF\", movement=[\"movementX\", \"movementY\"], chunk_size=100000):\n",
    "    \"\"\"\n",
    "    Remove the effect of movement from the fluorescence signal using linear regression.\n",
    "\n",
    "    Parameters:\n",
    "    - data (DataFrame): The input data containing fluorescence and movement data.\n",
    "    - fluorescence (str): Column name of the fluorescence signal.\n",
    "    - movement (list): List of column names representing movement data.\n",
    "    - chunk_size (int): Number of rows to process at a time to handle memory constraints.\n",
    "\n",
    "    Returns:\n",
    "    - detrended_df (DataFrame): A DataFrame with the detrended fluorescence signal.\n",
    "    \"\"\"\n",
    "    detrended_data = []\n",
    "\n",
    "    # Combine multiple movement columns into a single column\n",
    "    if len(movement) > 1:\n",
    "        data['movement_combined'] = data[movement].sum(axis=1)\n",
    "        movement_col = 'movement_combined'\n",
    "    else:\n",
    "        movement_col = movement[0]\n",
    "\n",
    "    # Process data in chunks\n",
    "    for start in range(0, len(data), chunk_size):\n",
    "        end = start + chunk_size\n",
    "        chunk = data.iloc[start:end].copy()  # Ensure we work on a copy\n",
    "\n",
    "        # Skip chunks with identical or missing movement values\n",
    "        if chunk[movement_col].nunique() <= 1:  # All values are identical or missing\n",
    "            print(f\"Skipping chunk {start}-{end} due to insufficient variability in {movement_col}\")\n",
    "            continue\n",
    "\n",
    "        # Perform linear regression\n",
    "        slope, intercept, _, _, _ = linregress(chunk[movement_col], chunk[fluorescence])\n",
    "\n",
    "        # Remove the effect of movement\n",
    "        chunk[f\"{fluorescence}_detrended\"] = chunk[fluorescence] - (slope * chunk[movement_col] + intercept)\n",
    "\n",
    "        # Append the detrended data\n",
    "        detrended_data.append(chunk[[f\"{fluorescence}_detrended\"]])\n",
    "\n",
    "    # Combine all processed chunks\n",
    "    if detrended_data:\n",
    "        detrended_df = pd.concat(detrended_data, axis=0)\n",
    "    else:\n",
    "        raise ValueError(\"No valid data found for detrending.\")\n",
    "\n",
    "    # Plot comparison\n",
    "    fig, ax = plt.subplots(3, figsize=(15, 6))\n",
    "    ax[0].plot(data.index, data[fluorescence], label=\"Original Fluorescence\", alpha=0.5)\n",
    "    if not detrended_df.empty:\n",
    "        ax[0].plot(detrended_df.index, detrended_df[f\"{fluorescence}_detrended\"], label=\"Detrended Fluorescence\", alpha=0.8)\n",
    "    ax[1].plot(data.index, data[movement[0]])\n",
    "    ax[2].plot(data.index, data[movement[1]])\n",
    "    ax[0].set_title(\"Fluorescence Signal Before and After Movement Correction\")\n",
    "    ax[0].set_xlabel(\"Time (s)\")\n",
    "    ax[0].set_ylabel(\"Fluorescence Signal\")\n",
    "    ax[0].legend()\n",
    "    plt.show()\n",
    "\n",
    "    return detrended_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = filter_data(GCaMP_MM_1, ['B3M3', 'day1'])\n",
    "\n",
    "detrended_data = correlation_remove(subset, fluorescence=\"470_dfF\", movement=[\"movementX\", \"movementY\"], chunk_size=300000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
